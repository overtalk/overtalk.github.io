{"meta":{"title":"QinHan's Site","subtitle":"","description":"","author":"QinHan","url":"https://overtalk.site","root":"/"},"pages":[{"title":"","date":"2022-07-19T07:53:37.889Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":" _data/links.json","permalink":"https://overtalk.site/%20_data/links.json","excerpt":"","text":"{\"NickYang\":{\"link\":\"https://cppfans.org/\",\"avatar\":\"https://avatars3.githubusercontent.com/u/3690738?s=400&v=4\",\"desc\":\"Be a simple man, 言行相成内外相应\"},\"一剑破万法\":{\"link\":\"https://taohuawu.club\",\"avatar\":\"https://taohuawu.club/icons/avatar.png\",\"desc\":\"潘少的一亩三分地，编程、动漫、读书、历史、随笔\"},\"MJJ\":{\"link\":\"http://qq19971017.github.io\",\"avatar\":\"https://avatars1.githubusercontent.com/u/30613857?s=400&v=4\",\"desc\":\"计算机视觉大佬\"}}"},{"title":"- About me -","date":"2022-07-19T07:53:37.901Z","updated":"2022-07-19T07:53:37.901Z","comments":true,"path":"about/index.html","permalink":"https://overtalk.site/about/index.html","excerpt":"","text":"当你发现自己的才华撑不起野心时，就请安静下来学习吧！ 光有好奇心而不去实践，等于自愿放弃成功机会 Just Do It！！"},{"title":"Category","date":"2022-07-19T07:53:37.901Z","updated":"2022-07-19T07:53:37.901Z","comments":true,"path":"categories/index.html","permalink":"https://overtalk.site/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2022-07-19T07:53:37.981Z","updated":"2022-07-19T07:53:37.981Z","comments":true,"path":"links/index.html","permalink":"https://overtalk.site/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2022-07-19T07:53:37.981Z","updated":"2022-07-19T07:53:37.981Z","comments":true,"path":"repository/index.html","permalink":"https://overtalk.site/repository/index.html","excerpt":"","text":""},{"title":"Tag","date":"2022-07-19T07:53:37.981Z","updated":"2022-07-19T07:53:37.981Z","comments":true,"path":"tags/index.html","permalink":"https://overtalk.site/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"bitmap","slug":"bitmap","date":"2022-07-19T15:47:57.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2022/07/19/bitmap/","link":"","permalink":"https://overtalk.site/2022/07/19/bitmap/","excerpt":"","text":"BitMap 的一种实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# -*- coding: utf-8 -*-class CustomBitsetType(object): INT_BITS = 64 - 1 def __init__(self): self.data = &#123;&#125; # &#123;index: int64&#125; def get_bit(self, index): key, bit_pos = divmod(index, CustomBitsetType.INT_BITS) if key not in self.data: return False return bool(self.data[key] &amp; 1&lt;&lt;bit_pos) def set_bit(self, index, bit_value): key, bit_pos = divmod(index, CustomBitsetType.INT_BITS) if key not in self.data: if bit_value: self.data[key] = 1 &lt;&lt; bit_pos return if bit_value: self.data[key] = self.data[key] | 1&lt;&lt;bit_pos return value = self.data[key] &amp; ~(1 &lt;&lt; bit_pos) if value &gt; 0: self.data[key] = value else: self.data.pop(key) # region -------------------- 数据数据被同步到 -------------------- def on_setattr(self, key, old, new): old = old or 0 new = new or 0 for i in range(CustomBitsetType.INT_BITS): in_old = old &amp; 1 &lt;&lt; i &gt; 0 in_new = new &amp; 1 &lt;&lt; i &gt; 0 if in_old != in_new: self.on_set_bit(key * CustomBitsetType.INT_BITS + i, in_old, in_new) def on_set_bit(self, index, old, new): self.set_bit(index, new) # endregion -------------------- 数据数据被同步到 --------------------bitset = CustomBitsetType()remote_bitset = CustomBitsetType()print(\"[local]\", bitset.get_bit(12))print(\"[local]\", bitset.set_bit(12, True))print(\"[local]\", bitset.get_bit(12))print(\"=========================\")# NOTE: mock 数据同步到远端for k, v in bitset.data.items(): remote_bitset.on_setattr(k, 0, v)print(\"[remote]\", remote_bitset.get_bit(11))print(\"[remote]\", remote_bitset.get_bit(12))print(bitset.data, remote_bitset.data) 运行结果 12345678&gt; &amp; C:/Python39/python.exe test.py[local] False[local] None[local] True=========================[remote] False[remote] True&#123;0: 4096&#125; &#123;0: 4096&#125;","categories":[],"tags":[]},{"title":"导航网格-基础概念&数据结构","slug":"recast-1","date":"2021-02-02T16:38:43.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2021/02/02/recast-1/","link":"","permalink":"https://overtalk.site/2021/02/02/recast-1/","excerpt":"","text":"recastnavigation 导读，看了很多大佬写的博客，自己进行一下总结 本文中提到的数据结构都在 Recast.h 中 RecastNavigation 项目地址 basicAABB(Axis-aligned bounding box) 坐标轴对齐的包围盒，它被定义为包含该对象，且边平行于坐标轴的最小六面体 AABB内的点满足以下条件： 123xmin≤x≤xmaxymin≤y≤ymaxzmin≤z≤zmax 特别重要的两个顶点为：Pmin = [Xmin Ymin Zmin]，Pmax = [ Xmax Ymax Zmax] recast项目中用float bmin[3], bmax[3];来描述一个AABB 如何理解体素？ 从数据结构上来理解也许非常简单。 一般模型存储的是顶点和面等数据，每个顶点在无限空间的任意一个位置。而体素空间是一个有限空间，包含了 widthdepthheight 个体素，每个体素大小是固定的，在Recast中由CellSize和CellHeight决定。可想象一个魔方，每一块大小为cellSizecellHeight，一共有widthheightdepth大小。 体素化的过程就是求得模型的包围盒，在xz轴上以CellSize划分，在y轴上以CellHeight划分，得到一个[x][z][y]体素数组，再根据这个体素是否包含原模型的面，决定这个体素是实心还是空心，可行走还是不可行走等属性。 区间 rcSpan 一列（xz平面投影相同）连续的体素盒子 由rcSpan这个结构体来表示 smin和smax表示连续体素的最低y坐标和最高y坐标（底面和顶面） next指针实现了一个链表，方便管理投影相同的所有区间（区间与区域之前不连续） xz的坐标记录在高度场中，结构体本身没有记 123456789101112131415// Recast.h -&gt; struct rcSpan// line: 276~282/// Defines the number of bits allocated to rcSpan::smin and rcSpan::smax.static const int RC_SPAN_HEIGHT_BITS = 13;/// Represents a span in a heightfield./// @see rcHeightfieldstruct rcSpan&#123; unsigned int smin : RC_SPAN_HEIGHT_BITS; ///&lt; The lower limit of the span. [Limit: &lt; #smax] unsigned int smax : RC_SPAN_HEIGHT_BITS; ///&lt; The upper limit of the span. [Limit: &lt;= #RC_SPAN_MAX_HEIGHT] unsigned int area : 6; ///&lt; The area id assigned to the span. rcSpan* next; ///&lt; The next span higher up in column.&#125;; 高度场 heightfield 容纳所有地图元素的空间容器 高度场维护了一个二维数组来记录空间(特指span)集合，二维数组的单个元素是在xz平面投影相同的span的链表 12345678910111213141516171819202122232425// Recast.h -&gt; struct rcHeightfield// line: 294~313/// A dynamic heightfield representing obstructed space./// @ingroup recaststruct rcHeightfield&#123; rcHeightfield(); ~rcHeightfield(); int width; ///&lt; The width of the heightfield. (Along the x-axis in cell units.) int height; ///&lt; The height of the heightfield. (Along the z-axis in cell units.) float bmin[3]; ///&lt; The minimum bounds in world space. [(x, y, z)] float bmax[3]; ///&lt; The maximum bounds in world space. [(x, y, z)] float cs; ///&lt; The size of each cell. (On the xz-plane.) float ch; ///&lt; The height of each cell. (The minimum increment along the y-axis.) rcSpan** spans; ///&lt; Heightfield of spans (width*height). rcSpanPool* pools; ///&lt; Linked list of span pools. rcSpan* freelist; ///&lt; The next free span.private: // Explicitly-disabled copy constructor and copy assignment operator. rcHeightfield(const rcHeightfield&amp;); rcHeightfield&amp; operator=(const rcHeightfield&amp;);&#125;; 紧缩空间 高度场中的span是三角面的体素集，是“实心”的部分 紧缩空间是将实心区域之间的“空心”部分取出来 y是起始高度，也是“实心”空间的可行走的上表面 h是空心的连续高度 con用一个uint来表示与4个邻居的联通情况（二进制位压缩表示） 1234567891011// Recast.h -&gt; struct rcCompactSpan// line: 323~329/// Represents a span of unobstructed space within a compact heightfield.struct rcCompactSpan&#123; unsigned short y; ///&lt; The lower extent of the span. (Measured from the heightfield's base.) unsigned short reg; ///&lt; The id of the region the span belongs to. (Or zero if not in a region.) unsigned int con : 24; ///&lt; Packed neighbor connection data. unsigned int h : 8; ///&lt; The height of the span. (Measured from #y.)&#125;; 紧缩高度场 场景内的紧缩空间集合 rcCompactCell 这个结构记录了投影坐标为xz的这一列上CompactSpan的个数以及在数组中的起始id123456789// Recast.h -&gt; struct rcCompactCell// line: 316~320/// Provides information on the content of a cell column in a compact heightfield.struct rcCompactCell&#123; unsigned int index : 24; ///&lt; Index to the first span in the column. unsigned int count : 8; ///&lt; Number of spans in the column.&#125;; rcCompactHeightfield rcCompactSpan* spans 是一个一维数组，按id递增的顺序记录了高度场内的所有CompactSpan1234567891011121314151617181920212223242526// Recast.h -&gt; struct rcCompactHeightfield// line: 333~353/// A compact, static heightfield representing unobstructed space./// @ingroup recaststruct rcCompactHeightfield&#123; rcCompactHeightfield(); ~rcCompactHeightfield(); int width; ///&lt; The width of the heightfield. (Along the x-axis in cell units.) int height; ///&lt; The height of the heightfield. (Along the z-axis in cell units.) int spanCount; ///&lt; The number of spans in the heightfield. int walkableHeight; ///&lt; The walkable height used during the build of the field. (See: rcConfig::walkableHeight) int walkableClimb; ///&lt; The walkable climb used during the build of the field. (See: rcConfig::walkableClimb) int borderSize; ///&lt; The AABB border size used during the build of the field. (See: rcConfig::borderSize) unsigned short maxDistance; ///&lt; The maximum distance value of any span within the field. unsigned short maxRegions; ///&lt; The maximum region id of any span within the field. float bmin[3]; ///&lt; The minimum bounds in world space. [(x, y, z)] float bmax[3]; ///&lt; The maximum bounds in world space. [(x, y, z)] float cs; ///&lt; The size of each cell. (On the xz-plane.) float ch; ///&lt; The height of each cell. (The minimum increment along the y-axis.) rcCompactCell* cells; ///&lt; Array of cells. [Size: #width*#height] rcCompactSpan* spans; ///&lt; Array of spans. [Size: #spanCount] unsigned short* dist; ///&lt; Array containing border distance data. [Size: #spanCount] unsigned char* areas; ///&lt; Array containing area id data. [Size: #spanCount]&#125;; BVH(Bounding volume hierarchy) 包围体层次结构，是一种用树形结构组织管理空间内物体（几何体）的方法，在项目的代码注释中也被称为AABB Tree。 分水岭算法 分水岭算法是一种图像区域分割法，在分割的过程中，它会把跟临近像素间的相似性作为重要的参考依据，从而将在空间位置上相近并且灰度值相近的像素点互相连接起来构成一个封闭的轮廓 分水岭算法的目标就是找出不同区域之间的分水线，其过程就是让水位不断上升满满淹没汇水盆地，同时构建水坝阻挡不同的盆地交汇。这些水坝就是最终连接好的单像素边缘 生成navmesh时面板上输入的参数 所有的参数都对应在下面的 struct 中1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071// Recast.h -&gt; struct rcCompactHeightfield// line: 196~263/// Specifies a configuration to use when performing Recast builds./// @ingroup recaststruct rcConfig&#123; /// The width of the field along the x-axis. [Limit: &gt;= 0] [Units: vx] int width; /// The height of the field along the z-axis. [Limit: &gt;= 0] [Units: vx] int height; /// The width/height size of tile's on the xz-plane. [Limit: &gt;= 0] [Units: vx] int tileSize; /// The size of the non-navigable border around the heightfield. [Limit: &gt;=0] [Units: vx] int borderSize; /// The xz-plane cell size to use for fields. [Limit: &gt; 0] [Units: wu] float cs; /// The y-axis cell size to use for fields. [Limit: &gt; 0] [Units: wu] float ch; /// The minimum bounds of the field's AABB. [(x, y, z)] [Units: wu] float bmin[3]; /// The maximum bounds of the field's AABB. [(x, y, z)] [Units: wu] float bmax[3]; /// The maximum slope that is considered walkable. [Limits: 0 &lt;= value &lt; 90] [Units: Degrees] float walkableSlopeAngle; /// Minimum floor to 'ceiling' height that will still allow the floor area to /// be considered walkable. [Limit: &gt;= 3] [Units: vx] int walkableHeight; /// Maximum ledge height that is considered to still be traversable. [Limit: &gt;=0] [Units: vx] int walkableClimb; /// The distance to erode/shrink the walkable area of the heightfield away from /// obstructions. [Limit: &gt;=0] [Units: vx] int walkableRadius; /// The maximum allowed length for contour edges along the border of the mesh. [Limit: &gt;=0] [Units: vx] int maxEdgeLen; /// The maximum distance a simplfied contour's border edges should deviate /// the original raw contour. [Limit: &gt;=0] [Units: vx] float maxSimplificationError; /// The minimum number of cells allowed to form isolated island areas. [Limit: &gt;=0] [Units: vx] int minRegionArea; /// Any regions with a span count smaller than this value will, if possible, /// be merged with larger regions. [Limit: &gt;=0] [Units: vx] int mergeRegionArea; /// The maximum number of vertices allowed for polygons generated during the /// contour to polygon conversion process. [Limit: &gt;= 3] int maxVertsPerPoly; /// Sets the sampling distance to use when generating the detail mesh. /// (For height detail only.) [Limits: 0 or &gt;= 0.9] [Units: wu] float detailSampleDist; /// The maximum distance the detail mesh surface should deviate from heightfield /// data. (For height detail only.) [Limit: &gt;=0] [Units: wu] float detailSampleMaxError;&#125;; 生成导航网格 Recast部分的功能就是生成整个导航网格，其核心方法是 Sample_SoloMesh::handleBuild class Sample_SoloMesh 是 头文件Sample.h 中的 class Sample 的实现这个函数注释非常友好地揭露了生成整个NavMesh导航网格的8个步骤，分别是： Step 1. Initialize build config Step 2. Rasterize input polygon soup Step 3. Filter walkables surfaces Step 4. Partition walkable surface to simple regions Step 5. Trace and simplify region contours Step 6. Build polygons mesh from contours Step 7. Create detail mesh which allows to access approximate height on each polygon Step 8. Create Detour data from Recast poly mesh 读入数据 构建方式选择，一共三种 123456789101112131415// RecastDemo/main.cpp// line:60~70Sample* createSolo() &#123; return new Sample_SoloMesh(); &#125;Sample* createTile() &#123; return new Sample_TileMesh(); &#125;Sample* createTempObstacle() &#123; return new Sample_TempObstacles(); &#125;static SampleItem g_samples[] =&#123; &#123; createSolo, \"Solo Mesh\" &#125;, &#123; createTile, \"Tile Mesh\" &#125;, &#123; createTempObstacle, \"Temp Obstacles\" &#125;,&#125;;static const int g_nsamples = sizeof(g_samples) / sizeof(SampleItem); recastDemo编辑器使用SDL来做编辑器 其创建[Choose Sample]GUI列表和对应的选择响应函数在RecastDemo/main.cpp line:611~666 12345678910111213141516171819202122232425262728293031323334353637383940// RecastDemo/main.cpp// line:611~666if (showSample)&#123; // 显示choose sample列表 static int levelScroll = 0; if (imguiBeginScrollArea(\"Choose Sample\", width-10-250-10-200, height-10-250, 200, 250, &amp;levelScroll)) mouseOverMenu = true; Sample* newSample = 0; for (int i = 0; i &lt; g_nsamples; ++i) &#123; if (imguiItem(g_samples[i].name.c_str())) &#123; newSample = g_samples[i].create(); // 这里是点击选中响应代码，会创建对应的Sample，在上下文中是Sample_SoloMesh if (newSample) sampleName = g_samples[i].name; &#125; &#125; if (newSample) &#123; delete sample; sample = newSample; sample-&gt;setContext(&amp;ctx); // m_ctx = ctx，ctx是个全局上下文环境，主要用于计时、Log等。 if (geom) // geom是模型数据，在选择模型之后切换Sample方式才会进入这里 &#123; sample-&gt;handleMeshChanged(geom); &#125; &#125; if (geom || sample) &#123; //...做一些编辑器的更新工作 //...计算相机位置，由于这个函数循环在跑，所以如果showSample是True的时候相机会被无限拉回，感觉条件改为newSample更合理一点？ //...设置GL_FOG_START和GL_FOG_END &#125; imguiEndScrollArea();&#125; 接着再点击界面的[Choose Mesh]，选择一个.obj文件 由v/vt/f/vn等key开头，后面跟相应的数据，以空格分开 其中v表示顶点，f表示面，即顶点索引","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"},{"name":"recastnavigation","slug":"recastnavigation","permalink":"https://overtalk.site/tags/recastnavigation/"}]},{"title":"mongo 杂记","slug":"mongo-metas","date":"2021-01-19T10:22:54.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2021/01/19/mongo-metas/","link":"","permalink":"https://overtalk.site/2021/01/19/mongo-metas/","excerpt":"","text":"纪录 mongo 的一些杂糅知识点 ObjectId 首先通过终端命令行，向mongodb的collection中插入一条不带“_id”的记录。然后，通过查询刚插入的数据，发现自动生成了一个objectId，4e7020cb7cac81af7136236b。具体操作如图1所示。 “4e7020cb7cac81af7136236b”这个24位的字符串，虽然看起来很长，也很难理解，但实际上它是由一组十六进制的字符构成，每个字节两位的十六进制数字，总共用了12字节的存储空间。相比MYSQL int类型的4个字节，MongoDB确实多出了很多字节。不过按照现在的存储设备，多出来的字节应该不会成为什么瓶颈。不过MongoDB的这种设计，体现着空间换时间的思想。官网中对ObjectId的规范，如图2所示。 1) Time 时间戳。将刚才生成的objectid的前4位进行提取“4e7020cb”，然后按照十六进制转为十进制，变为“1315971275”，这个数字就是一个时间戳。通过时间戳的转换，就成了易看清的时间格式，如图3所示。 2) Machine 机器。接下来的三个字节就是“7cac81”，这三个字节是所在主机的唯一标识符，一般是机器主机名的散列值，这样就确保了不同主机生成不同的机器hash值，确保在分布式中不造成冲突，这也就是在同一台机器生成的objectId中间的字符串都是一模一样的原因。 3) PID 进程ID。上面的Machine是为了确保在不同机器产生的objectId不冲突，而pid就是为了在同一台机器不同的mongodb进程产生了objectId不冲突，接下来的“af71”两位就是产生objectId的进程标识符。 4) INC 自增计数器。前面的九个字节是保证了一秒内不同机器不同进程生成objectId不冲突，这后面的三个字节“36236b”是一个自动增加的计数器，用来确保在同一秒内产生的objectId也不会发现冲突，允许256的3次方等于16777216条记录的唯一性。 总的来看，objectId的前4个字节时间戳，记录了文档创建的时间；接下来3个字节代表了所在主机的唯一标识符，确定了不同主机间产生不同的objectId；后2个字节的进程id，决定了在同一台机器下，不同mongodb进程产生不同的objectId；最后通过3个字节的自增计数器，确保同一秒内产生objectId的唯一性。ObjectId的这个主键生成策略，很好地解决了在分布式环境下高并发情况主键唯一性问题，值得学习借鉴。 附带一段有关于python中使用bson id的代码 可以利用base64编码将 objectid 转化成字符串，可以作为唯一id，某大厂自研引擎就是这样干的","categories":[{"name":"mongo","slug":"mongo","permalink":"https://overtalk.site/categories/mongo/"}],"tags":[{"name":"mongo","slug":"mongo","permalink":"https://overtalk.site/tags/mongo/"}]},{"title":"Python 如何查找属性","slug":"py-attribute","date":"2020-11-08T15:21:28.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/11/08/py-attribute/","link":"","permalink":"https://overtalk.site/2020/11/08/py-attribute/","excerpt":"","text":"查看对象内部所有属性名和属性值组成的字典 python 的 dict 属性类 &amp; 类对象 的 dict 属性 在 Python 类的内部，无论是 类属性 还是 实例属性，都是以字典的形式进行存储的，其中属性名作为键，而值作为该键对应的值。 为了方便用户查看类中包含哪些属性，Python 类提供了 dict 属性。需要注意的一点是，该属性可以用 类名 或者 类的实例对象 来调用。 用 类名 直接调用 dict，会输出该由类中所有类属性组成的字典 而使用 类的实例对象 调用 dict，会输出由类中所有实例属性组成的字典 12345678910111213141516# -*- coding:utf-8 -*-class CLanguage: a = 1 b = 2 def __init__ (self): self.name = \"C语言中文网\" self.add = \"http://c.biancheng.net\"#通过类名调用__dict__print(CLanguage.__dict__)#通过类实例对象调用 __dict__clangs = CLanguage()print(clangs.__dict__) 输出12&#123;'a': 1, '__module__': '__main__', 'b': 2, '__doc__': None, '__init__': &lt;function __init__ at 0x0000000002E22518&gt;&#125;&#123;'add': 'http://c.biancheng.net', 'name': 'C\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe4\\xb8\\xad\\xe6\\x96\\x87\\xe7\\xbd\\x91'&#125; 类继承 对于具有继承关系的父类和子类来说，父类有自己的 dict，同样子类也有自己的 dict，它不会包含父类的 dict。 1234567891011121314151617181920212223242526272829# -*- coding:utf-8 -*-class CLanguage: a = 1 b = 2 def __init__ (self): self.name = \"C语言中文网\" self.add = \"http://c.biancheng.net\" class CL(CLanguage): c = 1 d = 2 def __init__ (self): self.na = \"Python教程\" self.ad = \"http://c.biancheng.net/python\"#父类名调用__dict__print(CLanguage.__dict__)#子类名调用__dict__print(CL.__dict__)#父类实例对象调用 __dict__clangs = CLanguage()print(clangs.__dict__)#子类实例对象调用 __dict__cl = CL()print(cl.__dict__) 结果 1234&#123;'a': 1, '__module__': '__main__', 'b': 2, '__doc__': None, '__init__': &lt;function __init__ at 0x0000000003222518&gt;&#125;&#123;'__module__': '__main__', '__doc__': None, 'c': 1, '__init__': &lt;function __init__ at 0x0000000003222588&gt;, 'd': 2&#125;&#123;'add': 'http://c.biancheng.net', 'name': 'C\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe4\\xb8\\xad\\xe6\\x96\\x87\\xe7\\xbd\\x91'&#125;&#123;'na': 'Python\\xe6\\x95\\x99\\xe7\\xa8\\x8b', 'ad': 'http://c.biancheng.net/python'&#125; 显然，通过子类直接调用的 dict 中，并没有包含父类中的 a 和 b 类属性；同样，通过子类对象调用的 dict，也没有包含父类对象拥有的 name 和 add 实例属性。 总结 class 和 类对象 都有自己的 dict属性 由此可见， 类的静态函数、类函数、普通函数、全局变量以及一些内置的属性- 都是放在类dict里的 类对象的dict中存储了一些self.xxx的一些东西 python中的int，list，dict等常用数据类型没有 dict 属性 发生继承时候的 dict 属性 子类有自己的 dict， 父类也有自己的 dict 子类的全局变量和函数放在子类的dict中，父类的放在父类dict中 属性的查找123456789101112131415161718192021222324## -*- coding:utf-8 -*-class Kls(object): def __init__(self, a): super(Kls, self).__init__() self.a = a def func(self): print \"self\" def __getattribute__(self, name): print \"in __getattribute__\", name return super(Kls, self).__getattribute__(name) def __getattr__(self, name): print \"in __getattr__\", name k = Kls(1)k.a # in __getattribute__, ak.b # in __getattribute__, b # in __getattr__, bk.func # in __getattribute__, func 可以看到，不管属性有没有找到，getattribute 这个方法首先会调用到，这是属性查找的入口。 在这种情况下，属性访问会先去查看k的 dict 。这是一个dict，目前的内容是{“a”: 1}，于是查找a属性的时候，直接返回dict里的内容。 而对于b，在k的dict里没找到，python会去a的type，即class的 dict 里去找，Kls这个类的 dict 也没有b，这个时候查找失败，会调用 getattr 这个方法。 值得注意的是，func这个函数是存在类的 dict 里的。这也是为什么reload之后，instance的方法会生效的原因。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"python","slug":"python","permalink":"https://overtalk.site/tags/python/"}]},{"title":"Linux TCP/IP 性能调优","slug":"network-tcp-optimization","date":"2020-10-10T03:51:46.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/10/10/network-tcp-optimization/","link":"","permalink":"https://overtalk.site/2020/10/10/network-tcp-optimization/","excerpt":"","text":"转自Senlin’s Blog 再谈三次握手 Linux 提供了listen()系统调用，它的作用是在 server socket 上监听新的连接请求： 1int listen(int sockfd, int backlog); 那么listen()的第二个参数backlog的作用是什么呢？让我们先回顾一下 TCP 的三次握手： 对于 server 来说，一个新的连接首先会经过 SYN_RECV 状态，然后才会进入 ESTABLISHED 状态。那么对于每个 server socket 来说，内核需要两个队列来保存所有连接的信息： 一个是半连接队列 (incompletely queue)，用来保存所有处在 SYN_RECV 状态的连接。 另一个是连接队列 (completely queue)，用来保存所有处在 ESTABLISHED 状态的连接。 也就是说，当一个新的连接进入 SYNC_RECV 状态时，内核会将它放到半连接队列中。而当这个连接从 SYNC_RECV 状态进入到 ESTABLISHED 状态时，内核会将它从半连接队列中移动到连接队列中。最后当accept()返回时，这个连接也会从连接队列中移走。 listen()的backlog参数其实是用来指定连接队列的长度。而如果要改变半连接队列的长度，则需要改变内核参数： 123$ sudo vi /etc/sysctl.confnet.ipv4.tcp_max_syn_backlog = 1024 # 半连接队列的长度$ sudo sysctl -p # 使改变生效 在实际情况中，如果 server 的负载比较高，无法迅速地accept()新的连接，就可能导致连接队列满了，这时候就需要调高listen()的backlog参数。然而注意到，backlog参数有一个上限，这个上限由内核参数net.core.somaxconn决定，这个参数的默认值是128。也就是说，如果我们要让backlog的上限大于 128，就需要调高net.core.somaxconn这个内核参数的值： 123$ sudo vi /etc/sysctl.confnet.core.somaxconn = 1024 # listen backlog 的上限，默认值是 128$ sudo sysctl -p # 使改变生效 让我们思考一个问题，对于 server 的一个连接来说，当它接收到 client 发送的 ACK segment 之后，就会从 SYNC_RECV 进入到 ESTABLISHED 状态，但如果这时连接队列满了，那么会发生什么事情呢？ 默认情况下，server的 TCP 协议栈会丢弃这个 ACK segment。但此时这个连接仍然处在 SYNC_RECV 状态，所以 server 的 TCP 协议栈会重新发送 SYN/ACK 给 client。下图显示了进行一次重试的过程： 最大的重传次数由内核参数net.ipv4.tcp_synack_retries规定，默认情况下，这个值是 5，重传 5 次的总耗时约为 180 秒。在某些情况下，我们可以调小这个值，以减小重传的超时时间。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"https://overtalk.site/tags/tcp/"}]},{"title":"两种同步模式：状态同步和帧同步","slug":"synchronization","date":"2020-08-14T10:26:18.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/08/14/synchronization/","link":"","permalink":"https://overtalk.site/2020/08/14/synchronization/","excerpt":"","text":"转自知乎 - 两种同步模式：状态同步和帧同步 一、同步 所谓同步，就是要多个客户端表现效果是一致的，例如我们玩王者荣耀的时候，需要十个玩家的屏幕显示的英雄位置完全相同、技能释放角度、释放时间完全相同，这个就是同步。就好像很多个人一起跳街舞齐舞，每个人的动作都要保持一致。而对于大多数游戏，不仅客户端的表现要一致，而且需要客户端和服务端的数据是一致的。所以，同步是一个网络游戏概念，只有网络游戏才需要同步，而单机游戏是不需要同步的。 二、状态同步和帧同步的区别 最大的区别就是战斗核心逻辑写在哪，状态同步的战斗逻辑在服务端，帧同步的战斗逻辑在客户端。战斗逻辑是包括技能逻辑、普攻、属性、伤害、移动、AI、检测、碰撞等等的一系列内容，这常常也被视为游戏开发过程中最难的部分。由于核心逻辑必须知道一个场景中的所有实体情况，所以MMO游戏（例如魔兽世界）就必须把战斗逻辑写在服务端，所以MMO游戏必须是状态同步的，因为MMO游戏的客户端承载有限，并不能把整张地图的实体全部展现出来（例如100米以外的NPC和玩家就不显示了），所以客户端没有足够的信息计算全图的人的所有行为。 具体到客户端和服务端通信上，在状态同步下，客户端更像是一个服务端数据的表现层，举个例子，一个英雄的几乎所有属性（例如血量、攻击、防御、攻速、魔法值等等）都是服务端传给客户端的，而且在属性发生改变的时候，服务端需要实时告诉客户端哪些属性改变了，客户端并不能改变这些属性，而是服务端传来多少属性就显示多少属性（虽然可以改变客户端数值达到表现上的效果，例如无限血量，但是服务端那边的血量属性为0时，一样要死）。再举个例子，一个英雄要释放一个非指向性技能（例如伊泽瑞尔的Q），具体的过程就是，客户端通知服务端“我要释放一个技能”-》服务端通知客户端“在某地以什么方向释放某技能”-》客户端根据这些信息创建一个特效放在某地，然后以某个方向飞行-》服务端根据碰撞检测逻辑判断到某个时刻，这个技能碰到了敌方英雄，通知客户端-》客户端根据服务端信息，删除特效，被打的英雄减血同时播放受击特效。 而在帧同步下，通信就比较简单了，服务端只转发操作，不做任何逻辑处理。以下图为例： 现在同一局里有4个玩家，也就是4个客户端，这时客户端A释放了一个技能x，此时将操作传递给服务端，服务端不做任何判断，直接把A的操作全部分发给ABCD，则ABCD同时让客户端A控制的英雄释放技能x。 三、流量 状态同步比帧同步流量消耗大，例如一个复杂游戏的英雄属性可能有100多条，每次改变都要同步一次属性，这个消耗是巨大的，而帧同步不需要同步属性；例如释放一个技能，服务端需要通知客户端很多条消息（必须是分步的，不然功能做不了），而帧同步就只需要转发一次操作就行了。 四、回放&amp;观战 帧同步的回放&amp;观战比状态同步好做得多，因为只需要保存每局所有人的操作就好了，而状态同步的回放&amp;观战，需要有一个回放&amp;观战服务器，当一局战斗打响，战斗服务器在给客户端发送消息的同时，还需要把这些消息发给放&amp;观战服务器，回放&amp;观战服务器做储存，如果有其他客户端请求回放或者观战，则回放&amp;观战服务器把储存起来的消息按时间发给客户端。 五、安全性 状态同步的安全性比帧同步高很多，因为状态同步的所有逻辑和数值都是在服务端的，如果想作弊，就必须攻击服务器，而攻击服务器的难度比更改自己客户端数据的难度高得多，而且更容易被追踪，被追踪到了还会有极高的法律风险。而帧同步因为所有数据全部在客户端，所以解析客户端的数据之后，就可以轻松达到自己想要的效果，例如moba类游戏的全图挂，吃鸡游戏的透视挂，都是没办法防止的，而更改数据达到胜利的作弊方式（例如更改自己的英雄攻击力）可以通过服务器比对同局其他人的战斗结果来预防。 六、服务器压力 状态同步服务器压力比较大，因为要做更多运算。 七、开发效率 首先要说，状态同步的游戏占主流，其次就是状态同步开发起来比较难。而帧同步服务器开发难度低，同一套方案可以给很多不同类型的游戏使用，反正都是转发操作；减少了服务端客户端沟通，老实说，没有扯皮的时间，开发效率最起码提高20%，状态同步的方案下，同一个功能至少需要一个客户端和服务端共同完成；PVP和PVE基本用的是同一套代码，做完PVP很容易就可以做单机的PVE。 八、使用帧同步的知名游戏 王者荣耀、魔兽争霸3、所有格斗类游戏 九、断线重连 状态同步的断线重连很好做，无非就是把整个场景和人物全部重新生成一遍，各种数值根据服务端提供加到人物身上而已。帧同步的断线重连就比较麻烦了，例如客户端在战场开始的第10秒短线了，第15秒连回来了，就需要服务端把第10秒到第15秒之间5秒内的所有消息一次性发给客户端，然后客户端加速整个游戏的核心逻辑运行速度（例如加速成10倍），直到追上现有进度。 十、注意点 需要保证每次随机的数字都相同，所以需要自己实现一套随机数，不能用unity自带的那个随机数接口，而且需要服务端发送相同的随机种子；因为非常微小的误差就有可能产生蝴蝶效应，所以所有float型的参数必须变成int型，保证计算结果一致。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"},{"name":"游戏","slug":"编程/游戏","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"https://overtalk.site/tags/%E6%B8%B8%E6%88%8F/"}]},{"title":"TCP连接的TIME_WAIT和CLOSE_WAIT 状态解说","slug":"network-wait","date":"2020-08-07T10:23:14.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/08/07/network-wait/","link":"","permalink":"https://overtalk.site/2020/08/07/network-wait/","excerpt":"","text":"转自博客园 相信很多运维工程师遇到过这样一个情形: 用户反馈网站访问巨慢, 网络延迟等问题, 然后就迫切地登录服务器,终端输入命令”netstat -anp | grep TIME_WAIT | wc -l “ 查看一下, 接着发现有几百几千甚至几万个TIME_WAIT 连接数. 顿时慌了~ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647通过 \"netstat -anp | grep TIME_WAIT | wc -l\" 命令查看数量, 发现TIME_WAIT的连接数量很多! 可能是因为服务器主动关闭连接导致TIME_WAIT产生了很多.发现系统存在大量TIME_WAIT状态的连接, 可以通过调整系统内核参数来解决: 打开 sysctl.conf 文件，修改以下几个参数：[root@web01 ~]# vim /etc/sysctl.confnet.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_timestamps = 1 net.ipv4.tcp_syncookies = 1net.ipv4.tcp_fin_timeout = 30 [root@web01 ~]# sysctl -p 接着被告知: 开启 tw_recylce 和 tw_reuse 功能, 一定需要 timestamps 的支持，而且这些配置一般不建议开启，但是对解决TIME_WAIT很多的问题，有很好的用处。果然, 经过如上配置后, 过了几分钟，再查看TIME_WAIT的数量快速下降了不少，并且后面也没发现哪个用户说有问题了. 做到这里, 相信大多数运维人员想当然地以为问题已经解决了,但是，要彻底理解并解决这个问题，可能就没这么简单，或者说，要想彻底搞清楚并解决这个问题, 还是有很长的路要走滴! 相关查看命令:[root@web01 ~]# netstat -n | awk '/^tcp/ &#123;++state[$NF]&#125; END &#123;for(key in state) print key,\"\\t\",state[key]&#125;'会得到类似下面的结果,具体数字会有所不同:LAST_ACK 1SYN_RECV 14ESTABLISHED 79FIN_WAIT1 28FIN_WAIT2 3CLOSING 5TIME_WAIT 1669 [root@web01 ~]# sysctl -a | grep time | grep waitnet.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120net.netfilter.nf_conntrack_tcp_timeout_close_wait = 60net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120 执行命令\"netstat -na\"查看到的相关TCP状态解释:LISTEN: 侦听来自远方的TCP端口的连接请求;SYN-SENT: 在发送连接请求后等待匹配的连接请求;SYN-RECEIVED: 在收到和发送一个连接请求后等待对方对连接请求的确认;ESTABLISHED: 代表一个打开的连接;FIN-WAIT-1: 等待远程TCP连接中断请求, 或先前的连接中断请求的确认;FIN-WAIT-2: 从远程TCP等待连接中断请求;CLOSE-WAIT: 等待从本地用户发来的连接中断请求;CLOSING: 等待远程TCP对连接中断的确认;LAST-ACK: 等待原来的发向远程TCP的连接中断请求的确认;TIME-WAIT: 等待足够的时间以确保远程TCP接收到连接中断请求的确认;CLOSE: 没有任何连接状态; 下面简单解释下什么是TIME-WAIT和CLOSE-WAIT ? 通常来说要想解决问题，就要先理解问题。有时遇到问题,上网百度个解决方案,临时修复了问题,就以为问题已经不在了, 其实问题不是真的不存在了，而是可能隐藏在更深的地方，只是我们没有发现，或者以现有自己的的知识水平无法发现而已。总所周知，由于socket是全双工的工作模式，一个socket的关闭，是需要四次握手来完成的: 主动关闭连接的一方，调用close()；协议层发送FIN包 ; 被动关闭的一方收到FIN包后，协议层回复ACK；然后被动关闭的一方，进入CLOSE_WAIT状态，主动关闭的一方等待对方关闭，则进入FIN_WAIT_2状态；此时，主动关闭的一方等待被动关闭一方的应用程序，调用close操作 ; 被动关闭的一方在完成所有数据发送后，调用close()操作；此时，协议层发送FIN包给主动关闭的一方，等待对方的ACK，被动关闭的一方进入LAST_ACK状态； 主动关闭的一方收到FIN包，协议层回复ACK；此时，主动关闭连接的一方，进入TIME_WAIT状态；而被动关闭的一方，进入CLOSED状态 ; 等待2MSL时间，主动关闭的一方，结束TIME_WAIT，进入CLOSED状态 ; 通过上面的一次socket关闭操作，可以得出以下几点： 主动关闭连接的一方 – 也就是主动调用socket的close操作的一方，最终会进入TIME_WAIT状态 ; 被动关闭连接的一方，有一个中间状态，即CLOSE_WAIT，因为协议层在等待上层的应用程序，主动调用close操作后才主动关闭这条连接 ; TIME_WAIT会默认等待2MSL时间后，才最终进入CLOSED状态； 在一个连接没有进入CLOSED状态之前，这个连接是不能被重用的！ 所以说这里凭直觉看，TIME_WAIT并不可怕，CLOSE_WAIT才可怕，因为CLOSE_WAIT很多，表示说要么是你的应用程序写的有问题，没有合适的关闭socket；要么是说，你的服务器CPU处理不过来（CPU太忙）或者你的应用程序一直睡眠到其它地方(锁，或者文件I/O等等)，你的应用程序获得不到合适的调度时间，造成你的程序没法真正的执行close操作。 那么这里又出现两个问题： 上面提到的连接重用，那连接到底是个什么概念？ 协议层为什么要设计一个TIME_WAIT状态？这个状态为什么默认等待2MSL时间才会进入CLOSED 先解释清楚这两个问题后, 接着再来看开头提到的/etc/sysctl.conf文件中那几个网络配置参数究竟有什么用，以及TIME_WAIT的后遗症问题。 Socket连接到底是个什么概念？ socket 其实就是一个五元组，包括：源IP, 源端口, 目的IP, 目的端口, 类型(TCP or UDP) . 这个五元组，即标识了一条可用的连接。 需要注意是是，经常有很多人把一个socket定义成四元组，也就是源IP:源端口+目的IP:目的端口，这个定义是不正确的。 比如说，如果本地出口IP是110.122.144.166，那么你的浏览器在连接某一个Web服务器，例如百度的时候，这条socket连接的四元组可能就是：[110.122.144.166:45678, tcp, 110.88.92.104:80] , 源IP为你的出口IP地址 110.122.144.166，源端口为随机端口 45678，目的IP为百度的某一个负载均衡服务器IP 110.88.92.104，端口为HTTP标准的80端口。 如果这个时候，你再开一个浏览器，访问百度，将会产生一条新的连接：[110.122.144.166:43678, tcp, 110.88.92.104:80] , 这条新的连接的源端口为一个新的随机端口 43678。如此来看，如果你的本机需要压测百度，那么你最多可以创建多少个连接呢？ TIME_WAIT有什么用？ 如果来做个类比的话，TIME_WAIT的出现，对应的是你的程序里的异常处理，它的出现，就是为了解决网络的丢包和网络不稳定所带来的其他问题： 防止前一个连接【五元组，这里继续以 110.122.144.166:45678, tcp, 110.88.92.104:80 为例】上延迟的数据包或者丢失重传的数据包，被后面复用的连接【前一个连接关闭后，此时你再次访问百度，新的连接可能还是由110.122.144.166:45678, tcp, 110.88.92.104:80 这个五元组来表示，也就是源端口凑巧还是45678】错误的接收（异常：数据丢了，或者传输太慢了），参见下图： SEQ=3的数据包丢失，重传第一次，没有得到ACK确认 如果没有TIME_WAIT，或者TIME_WAIT时间非常端，那么关闭的连接【110.122.144.166:45678, tcp, 110.88.92.104:80 的状态变为了CLOSED，源端口可被再次利用】，马上被重用【对110.88.92.104:80新建的连接，复用了之前的随机端口45678】，并连续发送SEQ=1,2 的数据包; 此时，前面的连接上的SEQ=3的数据包再次重传，同时，seq的序号刚好也是3（这个很重要，不然，SEQ的序号对不上，就会RST掉），此时，前面一个连接上的数据被后面的一个连接错误的接收; 确保连接方能在时间范围内，关闭自己的连接。其实，也是因为丢包造成的，参见下图： 主动关闭方关闭了连接，发送了FIN； 被动关闭方回复ACK同时也执行关闭动作，发送FIN包；此时，被动关闭的一方进入LAST_ACK状态; 主动关闭的一方回去了ACK，主动关闭一方进入TIME_WAIT状态； 但是最后的ACK丢失，被动关闭的一方还继续停留在LAST_ACK状态; 此时，如果没有TIME_WAIT的存在，或者说，停留在TIME_WAIT上的时间很短，则主动关闭的一方很快就进入了CLOSED状态，也即是说，如果此时新建一个连接，源随机端口如果被复用，在connect发送SYN包后，由于被动方仍认为这条连接【五元组】还在等待ACK，但是却收到了SYN，则被动方会回复RST; 造成主动创建连接的一方，由于收到了RST，则连接无法成功; 所以，这里看到了，TIME_WAIT的存在是很重要的，如果强制忽略TIME_WAIT，还是有很高的机率，造成数据粗乱，或者短暂性的连接失败。那么，为什么说TIME_WAIT状态会是持续2MSL（2倍的max segment lifetime）呢？这个时间可以通过修改内核参数调整吗？第一，这个2MSL，是RFC 793里定义的，参见RFC的截图标红的部分： 这个定义，更多的是一种保障（IP数据包里的TTL，即数据最多存活的跳数，真正反应的才是数据在网络上的存活时间），确保最后丢失了ACK，被动关闭的一方再次重发FIN并等待回复的ACK，一来一去两个来回。内核里，写死了这个MSL的时间为：30秒（有读者提醒，RFC里建议的MSL其实是2分钟，但是很多实现都是30秒），所以TIME_WAIT的即为1分钟. 所以，再次回想一下前面的问题，如果一条连接，即使在四次握手关闭了，由于TIME_WAIT的存在，这个连接，在1分钟之内，也无法再次被复用，那么，如果你用一台机器做压测的客户端，你一分钟能发送多少并发连接请求？如果这台是一个负载均衡服务器，一台负载均衡服务器，一分钟可以有多少个连接同时访问后端的服务器呢？ TIME_WAIT很多，可怕吗？ 如果你通过 “ss -tan state time-wait | wc -l” 发现，系统中有很多TIME_WAIT，看到时相信很多人都会紧张。多少算多呢？几百几千？如果是这个量级，其实真的没必要紧张。因为: 这个量级，因为TIME_WAIT所占用的内存很少很少；因为记录和寻找可用的local port所消耗的CPU也基本可以忽略。会占用内存吗？当然！任何你可以看到的数据，内核里都需要有相关的数据结构来保存这个数据啊。一条Socket处于TIME_WAIT状态，它也是一条“存在“的socket，内核里也需要有保持它的数据： 内核里有保存所有连接的一个hash table，这个hash table里面既包含TIME_WAIT状态的连接，也包含其他状态的连接。主要用于有新的数据到来的时候，从这个hash table里快速找到这条连接。不同的内核对这个hash table的大小设置不同，你可以通过dmesg命令去找到你的内核设置的大小： 12[root@web01 ~]# dmesg |grep --color \"TCP established hash table\"TCP established hash table entries: 524288 (order: 11, 8388608 bytes) 还有一个hash table用来保存所有的bound ports，主要用于可以快速的找到一个可用的端口或者随机端口： 12[root@web01 ~]# dmesg |grep --color \"TCP bind hash table\"TCP bind hash table entries: 65536 (order: 8, 1048576 bytes) 由于内核需要保存这些数据，必然，会占用一定的内存。 那么会消耗CPU吗？当然！每次找到一个随机端口，还是需要遍历一遍bound ports的吧，这必然需要一些CPU时间。TIME_WAIT很多，既占内存又消耗CPU，这也是为什么很多人，看到TIME_WAIT很多，就蠢蠢欲动的想去干掉他们。其实，如果你再进一步去研究，1万条TIME_WAIT的连接，也就多消耗1M左右的内存，对现代的很多服务器，已经不算什么了。至于CPU，能减少它当然更好，但是不至于因为1万多个hash item就担忧。如果要真的想去调优，还是需要搞清楚调优方案以及调优参数背后的意义！ TIME_WAIT调优，则必须理解的几个调优参数:net.ipv4.tcp_timestamps RFC 1323 在 TCP Reliability一节里，引入了timestamp的TCP option，两个4字节的时间戳字段，其中第一个4字节字段用来保存发送该数据包的时间，第二个4字节字段用来保存最近一次接收对方发送到数据的时间。有了这两个时间字段，也就有了后续优化的余地。tcp_tw_reuse 和 tcp_tw_recycle就依赖这些时间字段。 net.ipv4.tcp_tw_reuse 从字面意思来看，这个参数是reuse TIME_WAIT状态的连接。时刻记住一条socket连接，就是那个五元组，出现TIME_WAIT状态的连接，一定出现在主动关闭连接的一方。所以，当主动关闭连接的一方，再次向对方发起连接请求的时候（例如，客户端关闭连接，客户端再次连接服务端，此时可以复用了；负载均衡服务器，主动关闭后端的连接，当有新的HTTP请求，负载均衡服务器再次连接后端服务器，此时也可以复用），可以复用TIME_WAIT状态的连接。 通过字面解释以及例子说明，可以看到，tcp_tw_reuse应用的场景：某一方，需要不断的通过“短连接“连接其他服务器，总是自己先关闭连接(TIME_WAIT在自己这方)，关闭后又不断的重新连接对方。 那么，当连接被复用了之后，延迟或者重发的数据包到达，新的连接怎么判断，到达的数据是属于复用后的连接，还是复用前的连接呢？那就需要依赖前面提到的两个时间字段了。复用连接后，这条连接的时间被更新为当前的时间，当延迟的数据达到，延迟数据的时间是小于新连接的时间，所以，内核可以通过时间判断出，延迟的数据可以安全的丢弃掉了。 这个配置，依赖于连接双方，同时对timestamps的支持。同时，这个配置，仅仅影响outbound连接，即做为客户端的角色，连接服务端[connect(dest_ip, dest_port)]时复用TIME_WAIT的socket。 net.ipv4.tcp_tw_recycle 从字面意思来看，这个参数是销毁掉 TIME_WAIT。当开启了这个配置后，内核会快速的回收处于TIME_WAIT状态的socket连接。多快？不再是2MSL，而是一个RTO（retransmission timeout，数据包重传的timeout时间）的时间，这个时间根据RTT动态计算出来，但是远小于2MSL。 有了这个配置，还是需要保障丢失重传或者延迟的数据包，不会被新的连接(注意，这里不再是复用了，而是之前处于TIME_WAIT状态的连接已经被destroy掉了，新的连接，刚好是和某一个被destroy掉的连接使用了相同的五元组而已)所错误的接收。在启用该配置，当一个socket连接进入TIME_WAIT状态后，内核里会记录包括该socket连接对应的五元组中的对方IP等在内的一些统计数据，当然也包括从该对方IP所接收到的最近的一次数据包时间。当有新的数据包到达，只要时间晚于内核记录的这个时间，数据包都会被统统的丢掉。 这个配置，依赖于连接双方对timestamps的支持。同时，这个配置，主要影响到了inbound的连接（对outbound的连接也有影响，但是不是复用），即做为服务端角色，客户端连进来，服务端主动关闭了连接，TIME_WAIT状态的socket处于服务端，服务端快速的回收该状态的连接。 由此，如果客户端处于NAT的网络(多个客户端，同一个IP出口的网络环境)，如果配置了tw_recycle，就可能在一个RTO的时间内，只能有一个客户端和自己连接成功(不同的客户端发包的时间不一致，造成服务端直接把数据包丢弃掉)。 下面通过案例和图示，来加深下理解: 客户端IP地址为：180.172.35.150，我们可以认为是浏览器; 负载均衡有两个IP，外网IP地址为 115.29.253.156，内网地址为10.162.74.10；外网地址监听80端口; 负载均衡背后有两台Web服务器，一台IP地址为 10.162.74.43，监听80端口；另一台为 10.162.74.44，监听 80 端口; Web服务器会连接数据服务器，IP地址为 10.162.74.45，监听 3306 端口; 这种简单的架构下，我们来看看，在不同的情况下，上面谈论的tw_reuse/tw_recycle对网络连接的影响。 先做个假定： 客户端通过HTTP/1.1连接负载均衡，也就是说，HTTP协议投Connection为keep-alive，所以假定，客户端对负载均衡服务器的socket连接，客户端会断开连接，所以TIME_WAIT出现在客户端; Web服务器和MySQL服务器的连接，我们假定，Web服务器上的程序在连接结束的时候，调用close操作关闭socket资源连接，所以，TIME_WAIT出现在 Web 服务器端。 那么，在这种假定下： Web服务器上，肯定可以配置开启的配置：tcp_tw_reuse；如果Web服务器有很多连向DB服务器的连接，可以保证socket连接的复用。 那么，负载均衡服务器和Web服务器，谁先关闭连接，则决定了我们怎么配置tcp_tw_reuse/tcp_tw_recycle了。 方案一：负载均衡服务器 首先关闭连接, 在这种情况下，因为负载均衡服务器对Web服务器的连接，TIME_WAIT大都出现在负载均衡服务器上，所以: 在负载均衡服务器上的配置： 12net.ipv4.tcp_tw_reuse = 1 //尽量复用连接net.ipv4.tcp_tw_recycle = 0 //不能保证客户端不在NAT的网络啊 在Web服务器上的配置为： 12net.ipv4.tcp_tw_reuse = 1 //这个配置主要影响的是Web服务器到DB服务器的连接复用net.ipv4.tcp_tw_recycle： 设置成1和0都没有任何意义。想一想，在负载均衡和它的连接中，它是服务端，但是TIME_WAIT出现在负载均衡服务器上；它和DB的连接，它是客户端，recycle对它并没有什么影响，关键是reuse 方案二：Web服务器首先关闭来自负载均衡服务器的连接 在这种情况下，Web服务器变成TIME_WAIT的重灾区。负载均衡对Web服务器的连接，由Web服务器首先关闭连接，TIME_WAIT出现在Web服务器上；Web服务器对DB服务器的连接，由Web服务器关闭连接，TIME_WAIT也出现在它身上，此时: 负载均衡服务器上的配置： 12net.ipv4.tcp_tw_reuse：0 或者 1 都行，都没有实际意义net.ipv4.tcp_tw_recycle=0 //一定是关闭recycle 在Web服务器上的配置： 12net.ipv4.tcp_tw_reuse = 1 //这个配置主要影响的是Web服务器到DB服务器的连接复用net.ipv4.tcp_tw_recycle=1 //由于在负载均衡和Web服务器之间并没有NAT的网络，可以考虑开启recycle，加速由于负载均衡和Web服务器之间的连接造成的大量TIME_WAIT 问题1: 通常说的连接池可以复用连接，是不是意味着，需要等到上个连接time wait结束后才能再次使用? 所谓连接池复用，复用的一定是活跃的连接，所谓活跃，第一表明连接池里的连接都是ESTABLISHED的，第二，连接池做为上层应用，会有定时的心跳去保持连接的活跃性。既然连接都是活跃的，那就不存在有TIME_WAIT的概念了，在上篇里也有提到，TIME_WAIT是在主动关闭连接的一方，在关闭连接后才进入的状态。既然已经关闭了，那么这条连接肯定已经不在连接池里面了，即被连接池释放了。 问题2: 作为负载均衡的机器随机端口使用完的情况下大量time_wait，不调整上面文中说的那三个参数，有其他的更好的方案吗？ 第一，随机端口使用完，你可以通过调整/etc/sysctl.conf下的net.ipv4.ip_local_port_range配置，至少修改成 net.ipv4.ip_local_port_range=1024 65535，保证你的负载均衡服务器至少可以使用6万个随机端口，也即可以有6万的反向代理到后端的连接，可以支持每秒1000的并发（想一想，因为TIME_WAIT状态会持续1分钟后消失，所以一分钟最多有6万，每秒1000）；如果这么多端口都使用完了，也证明你应该加服务器了，或者，你的负载均衡服务器需要配置多个IP地址，或者，你的后端服务器需要监听更多的端口和配置更多的IP（想一下socket的五元组） 第二，大量的TIME_WAIT，多大量？如果是几千个，其实不用担心，因为这个内存和CPU的消耗有一些，但是是可以忽略的。 第三，如果真的量很大，上万上万的那种，可以考虑，让后端的服务器主动关闭连接，如果后端服务器没有外网的连接只有负载均衡服务器的连接（主要是没有NAT网络的连接），可以在后端服务器上配置tw_recycle，然后同时，在负载均衡服务器上，配置tw_reuse。 ==============================简单解释下TCP状态转移================================ 简单来说 一端忘记close,将造成另一端大量的close_wait的状态。 主动执行close的一端,在量特别大的情况下,对so_linger没有做设置,将造成大量的time_wait状态的连接。 TCP状态转移要点 TCP协议规定,对于已经建立的连接,网络双方要进行四次握手才能成功断开连接,如果缺少了其中某个步骤,将会使连接处于假死状态,连接本身占用的资源不会被释放。网络服务器程序要同时管理大量连接,所以很有必要保证无用连接完全断开,否则大量僵死的连接会浪费许多服务器资源 客户端TCP状态迁移: 1CLOSED -&gt; SYN_SENT -&gt; ESTABLISHED -&gt; FIN_WAIT_1 -&gt; FIN_WAIT_2 -&gt; TIME_WAIT -&gt; CLOSED 服务器TCP状态迁移: 1CLOSED -&gt; LISTEN -&gt; SYN收到 -&gt; ESTABLISHED -&gt; CLOSE_WAIT -&gt; LAST_ACK -&gt; CLOSED 当客户端开始连接时,服务器还处于LISTENING,客户端发一个SYN包后,他就处于SYN_SENT状态,服务器就处于SYS收到状态,然后互相确认进入连接状态ESTABLISHED. 相关状态解释 LISTENING状态 服务启动后首先处于侦听(LISTENING)状态。 ESTABLISHED状态 ESTABLISHED的意思是建立连接。表示两台机器正在通信。 CLOSE_WAIT 对方主动关闭连接或者网络异常导致连接中断,这时我方的状态会变成CLOSE_WAIT 此时我方要调用close()来使得连接正确关闭 TIME_WAIT 我方主动调用close()断开连接,收到对方确认后状态变为TIME_WAIT,缺省为240秒。TCP协议规定TIME_WAIT状态会一直持续2MSL(即两倍的分段最大生存期),以此来确保旧的连接状态不会对新连接产生影响。处于TIME_WAIT状态的连接占用的资源不会被内核释放,所以作为服务器,在可能的情况下,尽量不要主动断开连接,以减少TIME_WAIT状态造成的资源浪费。 目前有一种避免TIME_WAIT资源浪费的方法,就是关闭socket的LINGER选项。但这种做法是TCP协议不推荐使用的,在某些情况下这个操作可能会带来错误. 断开连接的时候, 当发起主动关闭的左边这方发送一个FIN过去后,右边被动关闭的这方要回应一个ACK,这个ACK是TCP回应的,而不是应用程序发送的,此时,被动关闭的一方就处于CLOSE_WAIT状态了。如果此时被动关闭的这一方不再继续调用closesocket,那么他就不会发送接下来的FIN,导致自己老是处于CLOSE_WAIT。只有被动关闭的这一方调用了closesocket,才会发送一个FIN给主动关闭的这一 方,同时也使得自己的状态变迁为LAST_ACK。 出现大量CLOSE_WAIT的原因很简单,就是某一方在网络连接断开后,没有检测到这个错误,没有执行closesocket,导致了这个状态的实现,这在TCP/IP协议的状态变迁图上可以清楚看到。同时和这个相对应的还有一种叫TIME_WAIT的。一端的Socket调用close后,另一端的Socket没有调用close 另外,把SOCKET的SO_LINGER设置为0秒拖延(也就是立即关闭)在很多时候是有害处的。 还有,把端口设置为可复用是一种不安全的网络编程方法 当主动关闭的一方发送FIN到被动关闭这边后,被动关闭这边的TCP马上回应一个ACK过去,同时向上面应用程序提交一个ERROR,导 致上面的SOCKET的send或者recv返回SOCKET_ERROR,正常情况下,如果上面在返回SOCKET_ERROR后调用了closesocket,那么被动关闭的者一方的TCP就会发送一个FIN过去,自己的状态就变迁到LAST_ACK. 使用netstat -na命令即可知道到当前的TCP连接状态。一般LISTEN、ESTABLISHED、TIME_WAIT是比较常见。 分析: time_wait过多这个问题主要因为TCP的结束流程未走完,造成连接未释放。现设客户端主动断开连接,流程如下: 12345678910111213Client 消息 Serverclose()------ FIN -------&gt;FIN_WAIT1 CLOSE_WAIT&lt;----- ACK -------FIN_WAIT2close()&lt;------ FIN ------TIME_WAIT LAST_ACK------ ACK -------&gt;CLOSEDCLOSED 如上图所示,由于Server的Socket在客户端已经关闭时而没有调用关闭,造成服务器端的连接处在“挂起”状态,而客户端则处在等待应答的状态上。此问题的典型特征是:一端处于FIN_WAIT2 ,而另一端处于CLOSE_WAIT . 对于基于TCP的HTTP协议,关闭TCP连接的是Server端,这样,Server端会进入TIME_WAIT状态,可 想而知,对于访问量大的Web Server,会存在大量的TIME_WAIT状态,假如server一秒钟接收1000个请求,那么就会积压240*1000=240,000个TIME_WAIT的记录,维护这些状态给Server带来负担。当然现代操作系统都会用快速的查找算法来管理这些TIME_WAIT,所以对于新的TCP连接请求,判断是否hit中一个TIME_WAIT不会太费时间,但是有这么多状态要维护总是不好。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"https://overtalk.site/tags/tcp/"}]},{"title":"负载均衡算法 - P2C","slug":"lb-algorithm","date":"2020-07-31T17:05:04.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/07/31/lb-algorithm/","link":"","permalink":"https://overtalk.site/2020/07/31/lb-algorithm/","excerpt":"","text":"探究Envoy负载平衡算法 一般常见的负载均衡算法有： 随机法 轮循 哈希 加权轮询（Weight Round Robin）法 上文介绍了一个更加优秀的算法，P2C，主要的思想就是每次取两个，然后选择权重更高的那一个","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"loadbalance","slug":"loadbalance","permalink":"https://overtalk.site/tags/loadbalance/"}]},{"title":"std::ref和std::cref使用","slug":"cpp-ref","date":"2020-07-31T15:07:39.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/07/31/cpp-ref/","link":"","permalink":"https://overtalk.site/2020/07/31/cpp-ref/","excerpt":"","text":"为什么C++11引入了std::ref？ C++本身有引用（&amp;），为什么C++11又引入了std::ref？ 主要是考虑函数式编程（如std::bind）在使用时，是对参数直接拷贝，而不是引用。如下例子： 12345678910111213141516171819202122#include &lt;functional&gt;#include &lt;iostream&gt; void f(int&amp; n1, int&amp; n2, const int&amp; n3)&#123; std::cout &lt;&lt; \"In function: \" &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; ' ' &lt;&lt; n3 &lt;&lt; '\\n'; ++n1; // increments the copy of n1 stored in the function object ++n2; // increments the main()'s n2 // ++n3; // compile error&#125; int main()&#123; int n1 = 1, n2 = 2, n3 = 3; std::function&lt;void()&gt; bound_f = std::bind(f, n1, std::ref(n2), std::cref(n3)); n1 = 10; n2 = 11; n3 = 12; std::cout &lt;&lt; \"Before function: \" &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; ' ' &lt;&lt; n3 &lt;&lt; '\\n'; bound_f(); std::cout &lt;&lt; \"After function: \" &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; ' ' &lt;&lt; n3 &lt;&lt; '\\n';&#125; output 1234Output:Before function: 10 11 12In function: 1 11 12After function: 10 12 12 上述代码在执行std::bind后，在函数f()中n1的值仍然是1，n2和n3改成了修改的值。说明std::bind使用的是参数的拷贝而不是引用。具体为什么std::bind不使用引用，可能确实有一些需求，使得C++11的设计者认为默认应该采用拷贝，如果使用者有需求，加上std::ref即可。 创建线程的时候也会用到！！！12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;chrono&gt;#include &lt;future&gt;#include &lt;iostream&gt;#include &lt;thread&gt;struct _data &#123; int32_t value;&#125;;_data data = &#123;0&#125;;int main() &#123; std::promise&lt;_data&gt; data_promise; //创建一个承诺 std::future&lt;_data&gt; data_future = data_promise.get_future(); //得到这个承诺封装好的期望 // prepare func auto prepare_data_func = std::bind( [](std::promise&lt;_data&gt; &amp;data_promise) &#123; std::this_thread::sleep_for(std::chrono::seconds(2)); //模拟生产过程 data_promise.set_value(&#123;221&#125;); //通过set_value()反馈结果 &#125;, std::ref(data_promise)); // process func auto process_data_func = std::bind( [](std::future&lt;_data&gt; &amp;data_future) &#123; std::cout &lt;&lt; data_future.get().value &lt;&lt; std::endl; //通过get()获取结果 &#125;, std::ref(data_future)); std::thread prepare_data_thread(prepare_data_func); std::thread process_data_thread(process_data_func); prepare_data_thread.join(); process_data_thread.join(); std::cout &lt;&lt; \"--- pause ---\" &lt;&lt; std::endl; return 0;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"后端设计中遇到的一些问题记录","slug":"interview-game","date":"2020-07-31T13:39:43.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/07/31/interview-game/","link":"","permalink":"https://overtalk.site/2020/07/31/interview-game/","excerpt":"","text":"记录一些坑 / 设计 如何设计一个投票系统？ 多节点部署，统一先写入redis 定时从redis中读取数据落数据库mysql，再做统计之类的工作 数据溢出问题？ 比如说购买道具，前端输入了一个特别大的数量，然后乘以单价之后可能会溢出，应该如何避免这种问题？ 两次 a-1 等于 a-2 的问题？ 比如说购买道具，客户端发了一次购买购买道具的请求，处理中又发送了另外一个购买请求，如何解决这类问题？ 英雄技能冷却，如何做？ 用最小堆，按照时间戳排序，每次只取出堆定元素判断是否已经完成冷却，如果没有则所有的技能都没有冷却，否则再取堆顶 微信红包如何随机的分成n个？ 比如100元，由10个人分，那么平均一个人是10元钱。然后付款后，系统开始分份儿。 第一份：系统由0～10元之间随机一个数，作为这一份的钱数，设x1。 第二份：剩下的钱(100-x1)，系统由0～(100-x1)/(10-1)随机一个数，作为这份的钱数，设x2 … 第n份：剩下的钱(100-x1-x2-…-xn)，系统由0~(100-x1-x2-…-xn-1)/(10-n)随机一个数，作为这个份的钱数，设为xn。 游戏中的支付一般怎么做？ 一般服务端先去平台创建好订单，然后通知客户端 客户端根据订单号去支付 支付完成之后然后再由平台通知服务器/完成之后客户端告诉服务器支付完成，然后由服务器去平台认证","categories":[{"name":"interview","slug":"interview","permalink":"https://overtalk.site/categories/interview/"}],"tags":[{"name":"interview","slug":"interview","permalink":"https://overtalk.site/tags/interview/"}]},{"title":"algorithm - 查找","slug":"algorithm-search","date":"2020-07-29T17:10:19.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/07/29/algorithm-search/","link":"","permalink":"https://overtalk.site/2020/07/29/algorithm-search/","excerpt":"","text":"记录一些常用的查找算法 数据结构-树 很多都是用于查找的 二分查找123456789101112131415161718int binary_search_f(std::vector&lt;int&gt; &amp;src, int value, int l, int r) &#123; if (l &gt; r) &#123; return -1; &#125; int mid = (l + r) / 2; if (value == src[mid]) &#123; return mid; &#125; else if (value &gt; src[mid]) &#123; return binary_search_f(src, value, mid + 1, r); &#125; return binary_search_f(src, value, l, mid - 1);&#125;int binary_search(std::vector&lt;int&gt; &amp;src, int value) &#123; return binary_search_f(src, value, 0, src.size() - 1);&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://overtalk.site/tags/algorithm/"}]},{"title":"B树 & B+树","slug":"algorithm-btree","date":"2020-07-29T16:32:17.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/07/29/algorithm-btree/","link":"","permalink":"https://overtalk.site/2020/07/29/algorithm-btree/","excerpt":"","text":"[B树 &amp; B+树详解]（https://juejin.im/entry/5b0cb64e518825157476b4a9）","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://overtalk.site/tags/algorithm/"}]},{"title":"3 分钟理解完全二叉树、平衡二叉树、二叉查找树","slug":"algorithm-binary-tree","date":"2020-07-29T15:41:38.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/07/29/algorithm-binary-tree/","link":"","permalink":"https://overtalk.site/2020/07/29/algorithm-binary-tree/","excerpt":"","text":"二叉树是什么就不用介绍了！ 本文给大家分享的是常见的三种二叉树：完全二叉树、平衡二叉树、二叉查找（搜索）树 本文也是为以后的 红黑树，B树，B+树 做准备的 完全二叉树 完全二叉树是一种特殊的二叉树，满足以下要求： 所有叶子节点都出现在 k 或者 k-1 层，而且从 1 到 k-1 层必须达到最大节点数； 第 k 层可以不是满的，但是第 k 层的所有节点必须集中在最左边。 需要注意的是不要把完全二叉树和“满二叉树”搞混了，完全二叉树不要求所有树都有左右子树，但它要求： 任何一个节点不能只有右子树没有左子树 叶子节点出现在最后一层或者倒数第二层，不能再往上 用一张图对比下“完全二叉树”和“满二叉树”： 当我们用数组实现一个完全二叉树时，叶子节点可以按从上到下、从左到右的顺序依次添加到数组中，然后知道一个节点的位置，就可以轻松地算出它的父节点、孩子节点的位置。 以上面图中完全二叉树为例，标号为 2 的节点，它在数组中的位置也是 2，它的父节点就是 (k/2 = 1)，它的孩子节点分别是 (2k=4) 和 (2k+1=5)，别的节点也是类似。 完全二叉树使用场景： 根据前面的学习，我们了解到完全二叉树的特点是：“叶子节点的位置比较规律”。因此在对数据进行排序或者查找时可以用到它，比如堆排序就使用了它。 平衡二叉树 二叉树的提出其实主要就是为了提高查找效率，比如我们常用的 HashMap 在处理哈希冲突严重时，拉链过长导致查找效率降低，就引入了红黑树。 我们知道，二分查找可以缩短查找的时间，但是它要求 查找的数据必须是有序的。每次查找、操作时都要维护一个有序的数据集，于是有了二叉查找树这个概念。 二叉查找树（又叫二叉排序树），它是具有下列性质的二叉树： 若左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若右子树不空，则右子树上所有结点的值均大于或等于它的根结点的值； 左、右子树也分别为二叉排序树。 如下图所示： 也就是说，二叉查找树中，左子树都比节点小，右子树都比节点大，递归定义。 根据二叉排序树这个特点我们可以知道：二叉排序树的中序遍历一定是从小到大的。 比如上图，中序遍历结果是： 1 3 4 6 7 8 10 13 14 二叉排序树的性能 在最好的情况下，二叉排序树的查找效率比较高，是 O(logn)，其访问性能近似于折半查找； 但最差时候会是 O(n)，比如插入的元素是有序的，生成的二叉排序树就是一个链表，这种情况下，需要遍历全部元素才行（见下图 b）。 如果我们可以保证二叉排序树不出现上面提到的极端情况（插入的元素是有序的，导致变成一个链表），就可以保证很高的效率了。 但这在插入有序的元素时不太好控制，按二叉排序树的定义，我们无法判断当前的树是否需要调整。 因此就要用到平衡二叉树（AVL 树）了。 二叉查找（搜索）树 平衡二叉树的提出就是为了保证树不至于太倾斜，尽量保证两边平衡。因此它的定义如下： 平衡二叉树要么是一棵空树 要么保证左右子树的高度之差不大于 1 子树也必须是一颗平衡二叉树 也就是说，树的两个左子树的高度差别不会太大。 那我们接着看前面的极端情况的二叉排序树，现在用它来构造一棵平衡二叉树。 以 12 为根节点，当添加 24 为它的右子树后，根节点的左右子树高度差为 1，这时还算平衡，这时再添加一个元素 28： 这时根节点 12 觉得不平衡了，我左孩子一个都没有，右边都有俩了，超过了之前说的最大为 1，不行，给我调整！ 于是我们就需要调整当前的树结构，让它进行旋转。 因为最后一个节点加到了右子树的右子树，就要想办法给右子树的左子树加点料，因此需要逆时针旋转，将 24 变成根节点，12 右旋成 24 的左子树，就变成了这样（有点丑哈哈）： 这时又恢复了平衡，再添加 37 到 28 的右子树，还算平衡： 这时如果再添加一个 30，它就需要在 37 的左子树： 这时我们可以看到这个树又不平衡了，以 24 为根节点的树，明显右边太重，左边太稀，想要保持平衡就 24 得让位给 28，然后变成这样： 丑了点，但的确保持了平衡。 依次类推，平衡二叉树在添加和删除时需要进行旋转保持整个树的平衡，内部做了这么复杂的工作后，我们在使用它时，插入、查找的时间复杂度都是 O(logn)，性能已经相当好了。 下面使用go实现一个二叉查找树 要实现一个二叉搜索树， 我们需要实现节点的插入和删除，要实现节点的查找(搜索)，要实现前序遍历、中序遍历和后序遍历，要实现最大节点和最小节点的查找。 下面就让我们实现这个二叉搜索树。 定义基本数据结构 常规地，我们定义节点的类型，每个节点包含它的值以及左右节点。因为目前Go泛型还没有发布，所以这里我们实现一个元素为int类型的具体的二叉搜索树，等泛型实现后可以改成抽象的二叉搜索树。 树只要包含根节点可以了。 12345678910// Node 定义节点.type Node struct &#123; value int // 因为目前Go的泛型还没有发布，所以我们这里以一个int具体类型为例 left *Node // 左子节点 right *Node // 右子节点&#125;// BST 是一个节点的值为int类型的二叉搜索树.type BST struct &#123; root *Node&#125; 数据结构有了，接下来就是实现各个方法。 搜索 检查一个节点是否存在比较简单，因为二叉搜索树是有序的。12345678910111213141516func (this *BST) Search(value int) bool &#123; return search(this.root, value)&#125;func search(n *Node, value int) bool &#123; if n == nil &#123; return false &#125; if value &lt; n.value &#123; return search(n.left, value) &#125; if value &gt; n.value &#123; return search(n.right, value) &#125; return true&#125; 最大值 &amp; 最小值1234567891011121314151617181920212223242526272829303132func (this *BST) Min() (int, bool) &#123; return min(this.root)&#125;func min(node *Node) (int, bool) &#123; if node == nil &#123; return 0, false &#125; for node.left != nil &#123; node = node.left &#125; return node.value, true&#125;func (this *BST) Max() (int, bool) &#123; return max(this.root)&#125;func max(node *Node) (int, bool) &#123; if node == nil &#123; return 0, false &#125; for node.right != nil &#123; node = node.right &#125; return node.value, true&#125; 插入和删除 既然是一棵树，就需要增加节点用来构造树，大部分情况下也需要删除节点。 增加节点的时候，需要判断应该往左边子树上添加，还是往右边子树上添加。天然地，既然二叉搜索树是一个有序的，那么我们就可以进行比较，然后递归的实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465func (this *BST) Insert(value int) &#123; if this.root == nil &#123; this.root = &amp;Node&#123;value: value&#125; return &#125; insert(this.root, value)&#125;func insert(node *Node, value int) &#123; if value == node.value &#123; return &#125; else if value &gt; node.value &#123; // insert to the right if node.right == nil &#123; node.right = &amp;Node&#123;value: value&#125; return &#125; insert(node.right, value) &#125; else &#123; // insert to the left if node.left == nil &#123; node.left = &amp;Node&#123;value: value&#125; return &#125; insert(node.left, value) &#125;&#125;func (this *BST) Remove(value int) bool &#123; return remove(this.root, value)&#125;func remove(node *Node, value int) bool &#123; if node == nil &#123; return false &#125; if node.value &lt; value &#123; return remove(node.left, value) &#125; else if node.value &gt; value &#123; return remove(node.right, value) &#125; if node.left == nil &amp;&amp; node.right == nil &#123; node = nil return true &#125; if node.left == nil &#123; node = node.right return true &#125; if node.right == nil &#123; node = node.left return true &#125; // 左右都不为空 value, _ = min(node.right) node.value = value remove(node.right, value) return true&#125; 遍历 可以实现先序遍历、中序遍历和后序遍历，先中后指的是根节点相对子节点的处理顺序。12345678910111213141516171819202122func (this *BST) PreOrderTraverse(f func(int)) &#123; preOrderTraverse(this.root, f)&#125;func preOrderTraverse(n *Node, f func(int)) &#123; if n != nil &#123; f(n.value) // 前 preOrderTraverse(n.left, f) preOrderTraverse(n.right, f) &#125;&#125;// PostOrderTraverse 后序遍历func (this *BST) PostOrderTraverse(f func(int)) &#123; postOrderTraverse(this.root, f)&#125;func postOrderTraverse(n *Node, f func(int)) &#123; if n != nil &#123; postOrderTraverse(n.left, f) postOrderTraverse(n.right, f) f(n.value) // 后 &#125;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://overtalk.site/tags/algorithm/"}]},{"title":"算法面试题","slug":"interview-algorithm","date":"2020-07-28T09:11:20.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/07/28/interview-algorithm/","link":"","permalink":"https://overtalk.site/2020/07/28/interview-algorithm/","excerpt":"","text":"各种排序算法 必考，不说了 最大堆，最小堆 适合每次只关心最小的/最大的数据 栈如何 O(1) 的时间复杂度中取出栈中最小的数？ 双栈即可，一个栈记录最小的数 B 和 B+ 树的区别？ 知乎大佬的讲解","categories":[{"name":"interview","slug":"interview","permalink":"https://overtalk.site/categories/interview/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://overtalk.site/tags/algorithm/"},{"name":"interview","slug":"interview","permalink":"https://overtalk.site/tags/interview/"}]},{"title":"cpp 面试题","slug":"interview-cpp","date":"2020-07-28T09:01:33.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/07/28/interview-cpp/","link":"","permalink":"https://overtalk.site/2020/07/28/interview-cpp/","excerpt":"","text":"i++ &amp; ++i 有什么区别？ i++返回的是i的值，而++i返回的是i+1的值。也就是++i是一个确定的值，是一个可修改的左值。 这里有很多的经典笔试题： 1234567891011int main()&#123; int i = 1; printf(\"%d,%d\\n\", ++i, ++i); //3,3 printf(\"%d,%d\\n\", ++i, i++); //5,3 printf(\"%d,%d\\n\", i++, i++); //6,5 printf(\"%d,%d\\n\", i++, ++i); //8,9 system(\"pause\"); return 0;&#125; 首先是函数的入栈顺序从右向左入栈的，计算顺序也是从右往左计算的，不过都是计算完以后在进行的压栈操作： 对于第5行代码，首先执行++i，返回值是i，这时i的值是2，再次执行++i，返回值是i，得到i=3，将i压入栈中，此时i为3，也就是压入3，3； 对于第6行代码，首先执行i++，返回值是原来的i，也就是3，再执行++i，返回值是i，依次将3，5压入栈中得到输出结果 对于第7行代码，首先执行i++，返回值是5，再执行i++返回值是6，依次将5，6压入栈中得到输出结果 对于第8行代码，首先执行++i，返回i，此时i为8，再执行i++，返回值是8，此时i为9，依次将i，8也就是9，8压入栈中，得到输出结果。 为什么不推荐在析构函数中抛出异常 如果析构函数抛出异常，则异常点之后的程序不会执行，如果析构函数在异常点之后执行了某些必要的动作比如释放某些资源，则这些动作不会执行，会造成诸如资源泄漏的问题。 通常异常发生时，c++的机制会调用已经构造对象的析构函数来释放资源，此时若析构函数本身也抛出异常，则前一个异常尚未处理，又有新的异常，会造成程序崩溃的问题。 当在某一个析构函数中会有一些可能（哪怕是一点点可能）发生异常时，那么就必须要把这种可能发生的异常完全封装在析构函数内部，决不能让它抛出函数之外 12345678910111213virtual ~ MyTest_Base ()&#123;cout &lt;&lt; \"开始准备销毁一个MyTest_Base类型的对象\"&lt;&lt; endl;// 一点小的改动。把异常完全封装在析构函数内部try&#123;// 注意：在析构函数中抛出了异常throw std::exception(\"在析构函数中故意抛出一个异常，测试！\");&#125;catch(…) &#123;&#125;&#125; 指针和引用有什么区别？ 指针：指针是一个变量，只不过这个变量存储的是一个地址，指向内存的一个存储单元；而引用跟原来的变量实质上是同一个东西，只不过是原变量的一个别名而已 可以有const指针，但是没有const引用； 指针的值可以为空，但是引用的值不能为NULL，并且引用在定义的时候必须初始化； “sizeof引用”得到的是所指向的变量(对象)的大小，而”sizeof指针”得到的是指针本身的大小； 引用和指针一样，占用固定大小的内存（sizeof(A&amp;)并不是一个引用真是占用的内存大小） 函数形参定义为 &amp; 的时候，压栈的时候，A&amp; 也是8个byte，和指针的占用是一样的，引用也具有高效性 非常量的引用只可以指向左值12int&amp; a = 10; // 错误int&amp; a = int(10); // 错误 例如函数 void func(std::string&amp; str)，就不可以使用 func(&quot;test) 来调用 可以修改成 void func(const std::string&amp; str) 空的 class sizeof 之后的大小是多少？ 大小为1 类的实例化，所谓类的实例化就是在内存中分配一块地址，每个实例在内存中都有独一无二的地址。同样空类也会被实例化（别拿豆包不当干粮，空类也是类啊），所以编译器会给空类隐含的添加一个字节，这样空类实例化之后就有了独一无二的地址了。所以空类的sizeof为1。 class 中 const 变量如何赋值？ 在类中声明变量为const类型，但是不可以初始化 const常量的初始化必须在构造函数初始化列表中初始化，而不可以在构造函数函数体内初始化1234567class A&#123;public: A(int size) : SIZE(size) &#123;&#125;;private: const int SIZE;&#125;; map 遍历时删除某个元素 错误方法： 12345for (auto iter = map_to_del.begin(); iter != map_to_del.end(); ++iter) &#123; cout &lt;&lt; \"key: \" &lt;&lt; iter-&gt;first &lt;&lt; \" value: \" &lt;&lt; *iter-&gt;second &lt;&lt; endl; delete iter-&gt;second; map_to_del.erase(iter);&#125; 正确方法： 12345for (auto iter = map_to_del.begin(); iter != map_to_del.end();) &#123; cout &lt;&lt; \"key: \" &lt;&lt; iter-&gt;first &lt;&lt; \" value: \" &lt;&lt; *iter-&gt;second &lt;&lt; endl; delete iter-&gt;second; map_to_del.erase(iter++);&#125; 运行结果与第一种方式相同，这种删除方式也是STL源码一书中推荐的方式，分析 m.erase(it++)语句，map中在删除iter的时候，先将iter做缓存，然后执行iter++使之指向下一个结点，再进入erase函数体中执行删除操作，删除时使用的iter就是缓存下来的iter(也就是当前iter(做了加操作之后的iter)所指向结点的上一个结点)。 根据以上分析，可以看出（m.erase(it++) ）和（m.erase(it); iter++; ）这个执行序列是不相同的。 前者在erase执行前进行了加操作，在it被删除(失效)前进行了加操作，是安全的； 后者是在erase执行后才进行加操作，而此时iter已经被删除(当前的迭代器已经失效了)，对一个已经失效的迭代器进行加操作，行为是不可预期的，这种写法势必会导致 map操作的失败并引起进程的异常。 map / vector 等容器for遍历的时候123for (const auto &amp;iter : vec) &#123; std::cout &lt;&lt; iter.GetA() &lt;&lt; std::endl;&#125; 一定要 referfence，const 根据实际情况来决定加不加 因为取容器中的数据的时候，容器返回的是存的对象的 reference, 如果接受的时候不用 reference 则会调用拷贝构造函数 封装，继承，多态？ 函数重载 返回值类型不会作为函数重载的一个标准 下面的 void GetA() 函数就不和 int GetA() 构成重载关系，会编译报错 只有 形参 &amp; const 可以作为函数重载的判断标准1234567891011121314151617181920212223#include &lt;iostream&gt;class A &#123;public: int GetA() &#123; std::cout &lt;&lt; \"non-const\" &lt;&lt; std::endl; return 12; &#125;// void GetA()&#123;&#125; int GetA() const &#123; std::cout &lt;&lt; \"const\" &lt;&lt; std::endl; return 12; &#125;&#125;;int main() &#123; A a1; const A a2; a1.GetA(); // non-const a2.GetA(); // const&#125; a1 不是 const 变量，默认会调用非 const 的方法，而 a2 是 const 变量，调用 const 方法 如果只有 const 方法的话，在 a1 调用的时候会默认转化成 const 变量 const &amp; staticconst 详解 const 修饰类成员函数的时候，该函数不可以修改类成员变量，并且调用其他类成员函数也必须是const函数 const 修饰类成员变量的初始化只可以在构造函数的初始化列表中进行。 const 修饰普通变量时候，其含义永远看他左边的内容，如果左边没有类型，则看右边的类型 const A** var : 指向（const A）类型的二重指针 A const ** var : 同上 A* const * var : 指向（A* const）类型的常量指针，指针本身不可变 A** const var : 指向（A** const）类型的常量指针，指针本身不可变 static 详解 static 修饰全局变量的时候，非 lazy 初始化 static 修饰局部变量的时候，例如函数中的一个 static 变量，它是 lazy 初始化的 static 修饰class 成员函数/变量的时候，与具体的实例无关 甚至可以将 nullptr 转化成对象再调用static方法，也不会出错，因为不会用到该对象 拷贝构造 先看下面两段代码，有啥区别1234567891011class A &#123;&#125;;int main() &#123; A a; A a1; a1 = a; //////// A a; A a2(a); // A a2(a);&#125; 后面的代码段会调用拷贝构造函数，前面则是先构造，再拷贝 区别在于：如果 class A 中存在一些 const变量 的时候，在构造的时候const变量就已经定了，后续无法改变了 c++ 中的四种 cast 参考 智能指针 new和malloc的区别 new/delete是C++关键字，需要编译器支持。malloc/free是库函数，需要头文件支持。 使用new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算。而malloc则需要显式地指出所需内存的尺寸。 new操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故new是符合类型安全性的操作符。而malloc内存分配成功则是返回void * ，需要通过强制类型转换将void*指针转换成我们需要的类型。 new内存分配失败时，会抛出bac_alloc异常。malloc分配内存失败时返回NULL。 new会先调用operator new函数，申请足够的内存（通常底层使用malloc实现）。然后调用类型的构造函数，初始化成员变量，最后返回自定义类型指针。delete先调用析构函数，然后调用operator delete函数释放内存（通常底层使用free实现）。 malloc/free是库函数，只能动态的申请和释放内存，无法强制要求其做自定义类型对象构造和析构工作。 线程之间的数据共享 管道(pipe) 有名管道(namedpipe) 信号量(semaphore) 消息队列(messagequeue) 信号(sinal) 共享内存(shared memory) 套接字(socket)","categories":[{"name":"interview","slug":"interview","permalink":"https://overtalk.site/categories/interview/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"},{"name":"interview","slug":"interview","permalink":"https://overtalk.site/tags/interview/"}]},{"title":"clion 配置","slug":"clion","date":"2020-07-22T16:10:56.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/07/22/clion/","link":"","permalink":"https://overtalk.site/2020/07/22/clion/","excerpt":"","text":"链接","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"clion","slug":"clion","permalink":"https://overtalk.site/tags/clion/"}]},{"title":"多线程”一写多读”模式下的无锁设计","slug":"lock-free","date":"2020-07-21T11:53:41.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/07/21/lock-free/","link":"","permalink":"https://overtalk.site/2020/07/21/lock-free/","excerpt":"","text":"转自冷风寒雨宿天涯 缘起 在linux多线程环境下对同一变量进行读写时，经常会遇到读写的原子性问题，即会出现竞争条件。为了解决多个线程对同一变量访问时的竞争条件问题，操作系统层面提供了锁、信号量、条件变量等几种线程同步机制。如果对变量的每次访问都使用上述机制，由于系统调用会陷入内核空间，需要频繁的进行上下文切换，这就导致了程序的时间开销比较大。 自然的，我们就想到，在多线程环境中，在某些情况下是否能减少甚至避免使用系统调用？答案是肯定的。 如果对多线程下的变量访问进行分析，可以看到，线程对变量的访问可以分为以下几类： 一个线程写，另一个线程读，简称一写一读 多个线程写，一个线程读，简称多写一读 一个线程写，多个线程读，简称一写多读。 多个线程写，多个线程读，简称多写多读。 在linux 系统中，多个线程同时读一个变量是不需要同步的，而多个线程同时写一个变量或一个线程写而其他线程读某个变量，是需要同步的，可以总结为：”多读不互斥，而读写和多写互斥“。 由于多个线程对同一变量的读不需要同步，因而一写多读和一写一读并无本质区别，进而可以把多线程下对变量访问依据是否需要同步而合并成如下三类： 一写多读 多写一读 多写多读 解决上面所有的互斥，都可以使用系统调用。上面已经提到，在某些情况下我们是可以避免使用代价高昂的系统调用的。而“一写多读”就是这些特殊情况中的一种。 双buffer “无锁” 设计 使用系统调用进行同步的主要问题在于频繁切换上下文耗时较长，而后台系统的处理速度又是除正确性之外最为关键的指标。为提高系统的运行速度，我们可以使用用其他系统资源来换取时间的办法，从而避免使用锁之类系统调用。在这些方法中，最常见的就是用空间换取时间。 针对一写多读的情况，可以使用 “双 buffer” 及共享指针机制来实现对同一变量高效访问，同时又能保证不会出现竞争条件。这一实现的技术关键点在于以下两个方面： 双 buffer 的备份机制，避免了同时读写同一变量。双buffer 就是指对于通常要被多个线程访问的变量，再额外定义一个备份变量。 由于是一写多读，写线程只向备份变量中写入，而所有的读线程只需要访问主变量本身即可。当写进程对备份变量的写操作完成后，会触发主变量指针和备份变量指针的互换操作，即指针切换，从而将原变量和备份变量的身份进行互换，达到数据更新的目的。 共享指针 shared_ptr，由于其记录了对变量的引用次数，因而可以避免指针切换时的“访问丢失”问题。 为了便于理解，本文使用 C++ 中的 map 类型变量作为示意，当然，本文的方法可以推广到一写多读模式下任意数据类型的更新中。使用双 buffer 的示意图如下： 注意 ptr 和 bak_ptr 都是整个map 的指针，上面蓝色箭头表示通过两个指针访问 map 中的元素，ptr 和bak_ptr 本身并不指向元素。 在系统启动时，把两个智能指针分别初始化为一个主map 和一个备份 map。之后把全部数据更新到主map中开始对外提供服务。当外部需要读取数据时(多读），全部通过主map 的智能指针 ptr 来实现。而数据的更新全部通过备份map 的指针bak_ptr 来实现。由此可以看出，由于使用了两个map，即双buffer，使得数据的读和写进行了分离，互不影响，不会出现竞争条件，避免了锁的使用。 指针的切换 由于读写分离，双buffer机制下的数据读写不会出现竞争条件。在备份map 中数据更新完成时，必然需要一种方式，使得新数据能被使用到。这里需要做的就是把主map和备份map 的共享指针指向的内容互换，即ptr 和bak_ptr 指向的内容互换。指针切换如下图所示： 那么，在指针互换时，会出现什么问题呢？ 在指针的切换过程中，会出现如下两个问题： 由于对主map 的读是多线程的读，会出现多线程同使用主map 共享指针ptr 的情形，而互换指针时，需要对主map 的指针进行写操作，那么对同一指针 ptr 的读和写的竞争条件如何解决？ 在准备互换ptr 和 bak_ptr 指向的内容时，如果某个读线程正在使用 ptr 访问主map，直接互换就可能出现读线程再通过ptr获取数据时访问失效的问题，严重的情况下会访问到无效内存导致程序崩溃。这一问题本文简称为”指针访问丢失“问题，类似于常规指针中出现的野指针或悬垂指针的问题。 ptr 竞争条件的解决 当指针切换时，单线程对 bak_ptr 的写操作已经完成，因而对其可以随便读写。但由于多个读线程可能还在使用ptr，切换指针时对 ptr 的读写就要十分的小心。为了避免对 ptr 的读写出现竞争条件，本文使用了自旋锁来对ptr 的读写进行同步。使用自旋锁的原因有两个： 只在指针切换时使用锁，而不是在读写两个map 时使用锁，因而锁的使用频率会非常的低，由此导致的上下文切换的代价是可接受的。 由于指针切换时 ptr 处于的情形是一写多读，指针互换准备对 ptr 进行写操作时，要获取锁的等待时间并不长，并不会有长时间的锁等待出现，因而可以使用代价更小的自旋锁，而不是使用代价更高的读写锁。 指针访问丢失 上面已经介绍了指针访问丢失的情形，即在两个指针切换时，多个读线程可能正在使用ptr。为了避免出现读线程会读取到无效数据，本文使用的方法是利用共享指针的引用计数来实现指针的延迟互换。 解决ptr 的竞争条件和指针访问丢失问题后，就可以安全的使用双buffer 方案了。 最终的代码如下，其中 mapptr 就是主map 指针，bakptr 是备份map 的指针： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class UpdateData &#123; public: UpdateData():flag_(0) &#123; &#125; void PeriodTask(); void SetFlag(int i) &#123; flag_ = i; &#125; private: shared_ptr&lt;map&gt; map_ptr_; SpinLock map_rwspinlock_; shared_ptr&lt;map&gt; bak_map_ptr_; int flag_; shared_ptr&lt;map&gt; GetMainMapPtr(); void SetMainMapPtr(shared_ptr&lt;map&gt; new_map_ptr); void SwitchMapPtr(); void PeriodTask(); void GetData(shared_ptr&lt;map&gt; ptr) &#123; ptr[\"abc\"] = \"def\"; ... &#125;&#125;;// 获取主map 指针shared_ptr&lt;map&gt; UpdateData::GetMainMapPtr() &#123; Lock(map_rwspinlock_); // 加自旋锁，避免对 ptr 访问出现竞争条件 return map_ptr_; // 主map 指针&#125;// 设置主map 指针void UpdateData::SetMainMapPtr(shared_ptr&lt;map&gt; new_map_ptr) &#123; Lock(map_rwspinlock_); // 加自旋锁，避免对 ptr 访问出现竞争条件 map_ptr_ = new_map_ptr;&#125;// 真正的切换指针void UpdateData::SwitchMapPtr() &#123; shared_ptr&lt;map&gt; old_map_ptr = GetMainMapPtr(); SetMainMapPtr(bak_ptr_); // 这里新数据已经可以被使用了 // 用引用次数来解决访问丢失问题 while (old_map_ptr.unique() &#123; ::usleep(10000); // 指针延迟互换 &#125; bak_map_ptr_ = old_map_ptr; bak_map_ptr_-&gt;clear();&#125;// 定时任务void UpdateData::PeriodTask() &#123; while(flag) &#123; ::sleep(300); // 每5分钟更新一次数据 GetData(bak_ptr_); // 新数据写到备份 map 中 SwitchMapPtr(); &#125;&#125; 需要注意的是，SwitchMapPtr 中调用 SetMainMapPtr(bakptr) 之后，即使程序一直处在while 循环中，再有新的线程通过 mapptr\\ 来访问主map 的数据时，使用的已经是新的数据了。while 循环是为了解决指针访问丢失问题。当引用次数为1时，即 unique 为真时，表示已经没有读线程再使用旧的 map 了，只剩下SwitchMapPtr 中old_map_ptr 这一个引用了，这时可以安全的释放旧的map，并把它清空当作备份map继续进行数据的更新操作。 从上面可以看出，通过使用双buffer和共享指针，避免了在一写多读模式中对数据的读写频繁加锁，实现了”无锁“ 的设计。 延伸 即然双buffer可以很好的用于一写多读模式，那么对于”多写一读“或”多写多读“模式，是否也可以引入双buffer 模式呢？ 在含有多线程写同一变量的情形下下，其实是不太适合使用双buffer 方案的。主要原因是： 多写的情形下，需要在 bak_map 的多个写操作之间通过锁来同步，虽然避免了对读写互斥情形的加锁，但是多线程写时通常对数据的实时性要求较高，如果使用双buffer，所有新数据必须要等到指针切换时才能被使用，很可能达不到实时性要求。 多线程写时若用双buffer，则在指针切换时也需要给bak_map 加锁，并且也要用类似于上面的while 循环来保证没有线程在执行写入操作时才能进行指针切换，而且此时也要等待多读的完成才能进行切换，这时就会出现对 bak_map 的锁定时间过长，在数据更新频繁的情况下是不合适的。 因而，在多写的模式下，还是优先用读写锁等操作系统提供的同步机制。 结语 双buffer 方案在多线程环境下能较好的解决 “一写多读” 时的数据更新问题，特别是适用于数据需要定期更新，且一次更新数据量较大的情形。而这种情形在后台开发中十分常见。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"lock-free","slug":"lock-free","permalink":"https://overtalk.site/tags/lock-free/"}]},{"title":"golang - 一些数据结构的底层实现","slug":"go-impl","date":"2020-07-16T16:01:45.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/07/16/go-impl/","link":"","permalink":"https://overtalk.site/2020/07/16/go-impl/","excerpt":"","text":"主要是一些数据结构的底层实现 Channel 的底层实现 参考链接 前言 channel是Golang在语言层面提供的goroutine间的通信方式，比Unix管道更易用也更轻便。channel主要用于进程内各goroutine间通信，如果需要跨进程通信，建议使用分布式系统的方法来解决。 本章从源码角度分析channel的实现机制，实际上这部分源码非常简单易读。 chan数据结构 src/runtime/chan.go:hchan定义了channel的数据结构：12345678910111213type hchan struct &#123; qcount uint // 当前队列中剩余元素个数 dataqsiz uint // 环形队列长度，即可以存放的元素个数 buf unsafe.Pointer // 环形队列指针 elemsize uint16 // 每个元素的大小 closed uint32 // 标识关闭状态 elemtype *_type // 元素类型 sendx uint // 队列下标，指示元素写入时存放到队列中的位置 recvx uint // 队列下标，指示元素从队列的该位置读出 recvq waitq // 等待读消息的goroutine队列 sendq waitq // 等待写消息的goroutine队列 lock mutex // 互斥锁，chan不允许并发读写&#125; 从数据结构可以看出channel由环形队列、互斥锁、类型信息、goroutine等待队列组成，下面分别说明其原理。 环形队列 chan内部实现了一个环形队列作为其缓冲区，队列的长度是创建chan时指定的。 下图展示了一个可缓存6个元素的channel示意图： dataqsiz指示了队列长度为6，即可缓存6个元素； buf指向队列的内存，队列中还剩余两个元素； qcount表示队列中还有两个元素； sendx指示后续写入的数据存储的位置，取值[0, 6)； recvx指示从该位置读取数据, 取值[0, 6)； 等待队列 从channel读数据，如果channel缓冲区为空或者没有缓冲区，当前goroutine会被阻塞。 向channel写数据，如果channel缓冲区已满或者没有缓冲区，当前goroutine会被阻塞。 被阻塞的goroutine将会挂在channel的等待队列中： 因读阻塞的goroutine会被向channel写入数据的goroutine唤醒； 因写阻塞的goroutine会被从channel读数据的goroutine唤醒； 下图展示了一个没有缓冲区的channel，有几个goroutine阻塞等待读数据： 注意，一般情况下recvq和sendq至少有一个为空。只有一个例外，那就是同一个goroutine使用select语句向channel一边写数据，一边读数据。 类型信息 一个channel只能传递一种类型的值，类型信息存储在hchan数据结构中。 elemtype代表类型，用于数据传递过程中的赋值； elemsize代表类型大小，用于在buf中定位元素位置。 锁 一个channel同时仅允许被一个goroutine读写，为简单起见，本章后续部分说明读写过程时不再涉及加锁和解锁。 channel读写创建channel 创建channel的过程实际上是初始化hchan结构。其中类型信息和缓冲区长度由make语句传入，buf的大小则与元素大小和缓冲区长度共同决定。 创建channel的伪代码如下所示： 12345678910func makechan(t *chantype, size int) *hchan &#123; var c *hchan c = new(hchan) c.buf = malloc(元素类型大小*size) c.elemsize = 元素类型大小 c.elemtype = 元素类型 c.dataqsiz = size return c&#125; 向channel写数据 向一个channel中写数据简单过程如下： 如果等待接收队列recvq不为空，说明缓冲区中没有数据或者没有缓冲区，此时直接从recvq取出G,并把数据写入，最后把该G唤醒，结束发送过程； 如果缓冲区中有空余位置，将数据写入缓冲区，结束发送过程； 如果缓冲区中没有空余位置，将待发送数据写入G，将当前G加入sendq，进入睡眠，等待被读goroutine唤醒； 简单流程图如下： 从channel读数据 从一个channel读数据简单过程如下： 如果等待发送队列sendq不为空，且没有缓冲区，直接从sendq中取出G，把G中数据读出，最后把G唤醒，结束读取过程； 如果等待发送队列sendq不为空，此时说明缓冲区已满，从缓冲区中首部读出数据，把G中数据写入缓冲区尾部，把G唤醒，结束读取过程； 如果缓冲区中有数据，则从缓冲区取出数据，结束读取过程； 将当前goroutine加入recvq，进入睡眠，等待被写goroutine唤醒； 简单流程图如下： 关闭channel 关闭channel时会把recvq中的G全部唤醒，本该写入G的数据位置为nil。把sendq中的G全部唤醒，但这些G会panic。 除此之外，panic出现的常见场景还有： 关闭值为nil的channel 关闭已经被关闭的channel 向已经关闭的channel写数据 Interface 的底层实现 参考链接 golang中的接口分为带方法的接口和空接口。 带方法的接口在底层用iface表示。 空接口的底层则是eface表示。 接口的原型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//runtime/runtime2.go//非空接口type iface struct &#123; tab *itab data unsafe.Pointer&#125;type itab struct &#123; inter *interfacetype _type *_type link *itab hash uint32 // copy of _type.hash. Used for type switches. bad bool // type does not implement interface inhash bool // has this itab been added to hash? unused [2]byte fun [1]uintptr // variable sized&#125;//******************************//空接口type eface struct &#123; _type *_type data unsafe.Pointer&#125;//========================//这两个接口共同的字段_type//========================//runtime/type.go//_type这个结构体是golang定义数据类型要用的。type _type struct &#123; size uintptr ptrdata uintptr // size of memory prefix holding all pointers hash uint32 tflag tflag align uint8 fieldalign uint8 kind uint8 alg *typeAlg // gcdata stores the GC type data for the garbage collector. // If the KindGCProg bit is set in kind, gcdata is a GC program. // Otherwise it is a ptrmask bitmap. See mbitmap.go for details. gcdata *byte str nameOff ptrToThis typeOff&#125; iface","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"algorithm - 最大/小堆","slug":"algrorithm-heap","date":"2020-07-15T15:23:43.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/07/15/algrorithm-heap/","link":"","permalink":"https://overtalk.site/2020/07/15/algrorithm-heap/","excerpt":"","text":"堆 堆的一个经典的实现是完全二叉树(complete binary tree)。这样实现的堆成为二叉堆(binary heap)。 完全二叉树是增加了限定条件的二叉树。假设一个二叉树的深度为n。为了满足完全二叉树的要求，该二叉树的前n-1层必须填满，第n层也必须按照从左到右的顺序被填满，比如下图: 为了实现堆的操作，我们额外增加一个要求: 任意节点的优先级不小于它的子节点。如果在上图中，设定小的元素值享有高的优先级，那么上图就符合该要求。 这类似于“叠罗汉”。叠罗汉最重要的一点，就是让体重大的参与者站在最下面，让体重小的参与者站在上面 (体重小，优先级高)。为了让“堆”稳固，我们每次只允许最上面的参与者退出堆。也就是，每次取出的优先级最高的元素。 堆的主要操作是插入和删除最小元素(元素值本身为优先级键值，小元素享有高优先级)。在插入或者删除操作之后，我们必须保持该实现应有的性质: 完全二叉树 每个节点值都小于或等于它的子节点。 插入 在插入操作的时候，会破坏上述堆的性质，所以需要进行名为percolate_up的操作，以进行恢复。新插入的节点new放在完全二叉树最后的位置，再和父节点比较。如果new节点比父节点小，那么交换两者。交换之后，继续和新的父节点比较…… 直到new节点不比父节点小，或者new节点成为根节点。这样得到的树，就恢复了堆的性质。 我们插入节点2: 删除 删除操作只能删除根节点。根节点删除后，我们会有两个子树，我们需要基于它们重构堆。进行percolate_down的操作: 让最后一个节点last成为新的节点，从而构成一个新的二叉树。再将last节点不断的和子节点比较。如果last节点比两个子节点中小的那一个大，则和该子节点交换。直到last节点不大于任一子节点都小，或者last节点成为叶节点。 删除根节点1。如图: 1234567891011121314151617181920212223242526272829303132333435363738func HeapSort(s []int) &#123; N := len(s) - 1 // 默认是从这个数组的 index = 1 的位置开始进行堆的构造 for k := N / 2; k &gt;= 1; k-- &#123; sink(s, k, N) &#125; // 到上面一步位置，已经构造好了一个最大堆，堆顶元素是最大的 // 下面开始进行排序 for N &gt; 1 &#123; swap(s, 1, N) // 将最大的放到最后一位 N-- // 减少堆的大小，即最大的元素不动了 sink(s, 1, N) // 重新构造堆，使得最大元素到堆顶 &#125;&#125;func sink(src []int, k, N int) &#123; for &#123; i := k * 2 if i &gt; N &#123; break &#125; if i &lt; N &amp;&amp; src[i+1] &gt; src[i] &#123; i++ &#125; if src[i] &lt;= src[k] &#123; break &#125; // swap swap(src, i, k) k = i &#125;&#125;func swap(s []int, i, j int) &#123; s[i], s[j] = s[j], s[i] &#125; 算法题计算一个无序数组的中位数普通的算法 先进行排序，然后再计算中位数 使用堆 奇数个为例 先拿出 (N/2 + 1) 个元素出来构造一个最大堆，拿剩余的元素一个一个比，如果大于堆顶，直接丢弃 如果小于堆顶，替换堆顶，重新生成一次堆 直到最后一个数 o(1) 时间复杂度获取一个栈的最小元素 在维护数据栈之外，维护另外一个栈（排序栈），每次push的时候，将其压入数据栈中 将排序栈的栈顶元素于待压入的元素比较大小，压入较小的那一个 每次 pop 的时候两个栈同时 pop，这样就可以保持 o(1)复杂度获取最小元素","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://overtalk.site/tags/algorithm/"}]},{"title":"彻底弄懂IO这件事情 - 深入理解网络IO","slug":"io-diamond","date":"2020-07-14T09:29:48.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/07/14/io-diamond/","link":"","permalink":"https://overtalk.site/2020/07/14/io-diamond/","excerpt":"","text":"在进行 Linux 网络编程开发的时候，免不了会涉及到 IO 模型的讨论。《Unix 网络编程》一书中提到的几种 IO 模型，我们在开发过程中，讨论最多的应该就是三种： 阻塞 IO、非阻塞 IO 以及 异步 IO。 本文试图理清楚几种 IO 模型的根本性区别，同时分析了为什么在 Linux 网络编程中最好要用非阻塞式 IO。 网络 IO 概念准备 在讨论网络 IO 之前，一定要有一个概念上的准备前提: 不要用操作磁盘文件的经验去看待网络 IO。 具体的原因我们在下文中会介绍到。 相比于传统的网络 IO 来说，一个普通的文件描述符的操作可以分为两部分。以 read 为例，我们利用 read 函数从 socket 中同步阻塞的读取数据，整个流程如下所示： 调用 read 后，该调用会转入内核调用 内核会等待该 socket 的可读事件，直到远程向 socket 发送了数据。可读事件成立 (这里还需要满足 TCP 的低水位条件，但是不做太详细的讨论) 数据包到达内核，接着内核将数据拷贝到用户进程中，也就是 read 函数指定的 buffer 参数中。至此，read 调用结束。 可以看到除了转入内核调用，与传统的磁盘 IO 不同的是，网络 IO 的读写大致可以分为两个阶段： 等待阶段：等待 socket 的可读或者可写事件成立 拷贝数据阶段：将数据从内核拷贝到用户进程，或者从用户进程拷贝到内核中， 三种 IO 模型的区别 我们日常开发遇到最多的三种 IO 模型分别是：同步阻塞 IO、同步非阻塞 IO、异步 IO。 这些名词非常容易混淆，为什么一个 IO 会有两个限定词：同步和阻塞？同步和阻塞分别代表什么意思？ 简单来说： 等待 阻塞: 在 socket 操作的第一个阶段，也就是用户等待 socket 可读可写事件成立的这个阶段。如果一直等待下去，直到成立后，才进行下个阶段，则称为阻塞式 IO；如果发现 socket 非可读可写状态，则直接返回，不等待，也不进行下个阶段，则称为非阻塞式 IO。 拷贝 同步: 从内核拷贝到用户空间的这个阶段，如果直到\b从开始拷贝直到拷贝结束，read 函数才返回，则称为同步 IO。如果在调用 read 的时候就直接返回了，等到数据拷贝结束，才通过某种方式 (例如回调) 通知到用户，这种被称为异步 IO。 所谓异步，实际上就是非同步非阻塞。 同步阻塞 IO1read(fd, buffer, count) Linux 下面如果直接不对 fd 进行特殊处理，直接调用 read，就是同步阻塞 IO。同步阻塞 IO 的两个阶段都需要等待完成后，read 才会返回。 也就是说，如果远程一直没有发送数据，则 read 一直就不会返回，整个线程就会阻塞到这里了。 同步非阻塞 IO 对于同步非阻塞 IO 来说，如果没有可读可写事件，则直接返回；如果有，则进行第二个阶段，复制数据。 在 linux 下面，需要使用 fcntl 将 fd 变为非阻塞的。 12int flags = fcntl(socket, F_GETFL, 0);fcntl(socket, F_SETFL, flags | O_NONBLOCK); 同时，如果 read 的时候，fd 不可读，则 read 调用会触发一个 EWOULDBLOCK 错误 (或者 EAGAIN，EWOULDBLOCK 和 EAGAIN 是一样的)。用户只要检查下 errno == EWOULDBLOCK, 即可判断 read 是否返回正常。 基本在 Linux 下进行网络编程，非阻塞 IO 都是不二之选。 异步 IO Linux 开发者应该很少使用纯粹的异步 IO。因为目前来说，Linux 并没有一个完美的异步 IO 的解决方案。pthread 虽然提供了 aio 的接口，但是这里不做太具体的讨论了。 我们平常接触到的异步 IO 库或者框架都是在代码层面把操作封装成了异步。但是在具体调用 read 或者 write 的时候，一般还是用的非阻塞式 IO。 不能用操作磁盘 IO 的经验看待网络 IO 为什么不能用操作磁盘 IO 的经验看待网络 IO。实际上在磁盘 IO 中，等待阶段是不存在的，因为磁盘文件并\b不像网络 IO 那样，需要等待远程传输数据。 所以有的时候，习惯了操作磁盘 IO 的开发者会无法理解同步阻塞 IO 的工作过程，无法理解为什么 read 函数不会返回。 关于磁盘 IO 与同步非阻塞的讨论，在知乎上有一篇帖子 为什么书上说同步非阻塞 io 在对磁盘 io 上不起作用? 讨论了这个问题。 为什么在 Linux 网络编程中最好要用非阻塞式 IO？ 上文说到，在 linux 网络编程中，如果使用阻塞式的 IO，假如某个 fd 长期不可读，那么一个线程相应将会被长期阻塞，那么线程资源就会被白白浪费。 那么，如果我们用了 epoll，还必须要使用非阻塞 IO 吗？ 因为如果使用 epoll 监听了 fd 的可读事件，在 epoll_wait 之后调用 read，此时 fd 一定是可读的， 那么此时非阻塞 IO 相比于阻塞 IO 的优势不就没了吗？ 实际上，并不是这样的。epoll 也必须要搭配非阻塞 IO 使用。 总结来说，原因有二： fd 在 read 之前有可能会重新进入不可读的状态。要么被其他方式读走了 (参考惊群问题), 还有可能被内核抛弃了，总的来说，fd 因为在 read 之前，数据被其他方式读走，fd 重新变为不可读。此时，用阻塞式 IO 的 read 函数就会阻塞整个线程。 epoll 只是返回了可读事件，但是并没有返回可以读多少数据量。因此，非阻塞 IO 的做法是读多次，直到不能读。而阻塞 io 却只能读一次，因为万一一次就读完了缓冲区所有数据，第二次读的时候，read 就会又阻塞了。但是对于 epoll 的 ET 模式来说，缓冲区的数据只会在改变的通知一次，如果此次没有消费完，在下次数据到来\b之前，可读事件再也不会通知了。那么对于只能调用一次 read 的阻塞式 IO 来说，未读完的数据就有可能永远读不到了。 因此，在 Linux 网络编程中最好使用非阻塞式 IO。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://overtalk.site/tags/linux/"},{"name":"io","slug":"io","permalink":"https://overtalk.site/tags/io/"}]},{"title":"如何设计一个缓存系统","slug":"design-cache","date":"2020-07-10T10:05:36.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/07/10/design-cache/","link":"","permalink":"https://overtalk.site/2020/07/10/design-cache/","excerpt":"","text":"前言 设计一个缓存系统，不得不要考虑的问题就是： 缓存穿透、缓存击穿与失效时的雪崩效应。 缓存穿透 缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。 在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。 解决方案 有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。 另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。 布隆过滤器详解 缓存雪崩 缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。 解决方案 缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。 这里分享一个简单方案就是讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。 缓存击穿 对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。 缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回射到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。 解决方案使用互斥锁(mutex key) 业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。 SETNX，是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果。在redis2.6.1之前版本未实现setnx的过期时间 提前”使用互斥锁(mutex key) 在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。 当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。 “永远不过期” 这里的“永远不过期”包含两层意思： 从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期 从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。 资源保护 采用netflix的hystrix，可以做资源的隔离保护主线程池，如果把这个应用到缓存的构建也未尝不可。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://overtalk.site/tags/Redis/"}]},{"title":"布隆过滤器","slug":"bloom-filter","date":"2020-07-10T09:58:36.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/07/10/bloom-filter/","link":"","permalink":"https://overtalk.site/2020/07/10/bloom-filter/","excerpt":"","text":"摘抄自布隆过滤器go实现 布隆过滤器原理 布隆过滤器一般用来判断一个数据是否在一个很大的数据集合里面。当然可以用数组，集合，树等数据结构和各种查找法都可以做同样的事情，但是布隆过滤器有更好的时间效率和空间效率。比特币实现SPV节点时使用了布隆过滤器来查询交易。布隆过滤器可以判断一个数在不在集合里，但存在一定的误判率。 布隆过滤器的核心是一个超大的位数组和几个哈希函数。假设位数组的长度为m,哈希函数的个数为k。 以上图为例，在这里维数组长度为18，哈希函数个数为3个。首先将维数组所有位全部置0。集合中有的3个数据x,y,z，通过3个哈希函数对每一个数据进行计算，得到该数据的哈希值，这个哈希值对应维数组上面的一个点，然后将对应位数组的位置1。这样3个数据会生成9个点。对于另外一个数据w，查询它 在不在集合中的方法是对w通过3个哈希函数映射到位数组上，判断3个映射位置是否为1。只要有一个位置为0，就能说明w一定不在集合中。反之如果3个点都为1，则说明这个元素可能在集合中。此处不能判断元素一定在集合中，因为存在一定的误判率。比如对于上图中的4,5,6这3个位置都为1，但是它是不同的数据映射到的点。如果有一个数据刚好映射到这3个位置，虽然它不在集合中，但是我们也会误判它。 添加元素 将要添加的元素给k个哈希函数进行计算 得到位于位数组上面的k个位置 将位数组上对应位置1 查询元素 将要查询的元素给k个哈希函数 得到对应于位数组上的k个位置 如果k个位置有一个为0，则肯定不在集合中 如果k个位置全部为1，则可能在集合中 go语言实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package main import ( \"github.com/willf/bitset\" \"fmt\")const DEFAULT_SIZE = 2&lt;&lt;24var seeds = []uint&#123;7, 11, 13, 31, 37, 61&#125; type BloomFilter struct &#123; set *bitset.BitSet funcs [6]SimpleHash&#125; func NewBloomFilter() *BloomFilter &#123; bf := new(BloomFilter) for i:=0;i&lt; len(bf.funcs);i++&#123; bf.funcs[i] = SimpleHash&#123;DEFAULT_SIZE,seeds[i]&#125; &#125; bf.set = bitset.New(DEFAULT_SIZE) return bf&#125; func (bf BloomFilter) add(value string)&#123; for _,f:=range(bf.funcs)&#123; bf.set.Set(f.hash(value)) &#125;&#125; func (bf BloomFilter) contains(value string) bool &#123; if(value == \"\")&#123; return false &#125; ret := true for _,f:=range(bf.funcs)&#123; ret = ret &amp;&amp; bf.set.Test(f.hash(value)) &#125; return ret&#125; type SimpleHash struct&#123; cap uint seed uint&#125; func (s SimpleHash) hash(value string) uint&#123; var result uint = 0 for i:=0;i&lt; len(value);i++&#123; result = result*s.seed+uint(value[i]) &#125; return (s.cap-1)&amp;result&#125; func main()&#123; filter := NewBloomFilter() fmt.Println(filter.funcs[1].seed) str1 := \"hello,bloom filter!\" filter.add(str1) str2 := \"A happy day\" filter.add(str2) str3 := \"Greate wall\" filter.add(str3) fmt.Println(filter.contains(str1)) fmt.Println(filter.contains(str2)) fmt.Println(filter.contains(str3)) fmt.Println(filter.contains(\"blockchain technology\"))&#125;``` - 这里位数组用了一个第三方的bitset库，见[github](github.com/willf/bitset)- 打印结果：```bash11truetruetruefalse","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://overtalk.site/tags/Redis/"}]},{"title":"为什么游戏的server不适合微服务化？","slug":"essay-20-6-29","date":"2020-06-29T10:10:00.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/06/29/essay-20-6-29/","link":"","permalink":"https://overtalk.site/2020/06/29/essay-20-6-29/","excerpt":"","text":"作者：hongjic93 链接：https://www.zhihu.com/question/359630395/answer/954452799 比如moba类游戏，就看LOL的客户端吧，想象一下。 账号系统，符文系统，英雄系统，皮肤系统，好友系统，好友之间messaging，这些都是常规操作，如果流量足够大，当然可以用微服务的架构去做。 不过这不是这个游戏的核心，核心是MOBA：Multiplayer online battle arena。特性是什么？ 10个人之间各种游戏事件的高速多向通讯 streaming/broadcast/multicast/pubsub各种通讯模式所以游戏的核心在于小规模群体之间的高速网络通信。就是对方说的realtime。多了一个10ms的延迟玩家就要骂娘了。 微服务为了把业务完美拆解，把原来的同一个进程里的模块拆分成不同的服务，显著增加额外的网络开销。更别说什么service mesh，各种gateway，proxy，sidecar，简直就是担心延迟太低。 微服务基本只有request/response的模式。做不了streaming？微服务通常要求应用是无状态的才能做到水平扩展。streaming本身就是加入了状态 我可以想像，为了提高通讯的性能，一场英雄联盟游戏很可能会使用同一个服务器负责这10个玩家之间的通讯，这样就使得数据可以在本地交换，性能最大化。这对客户端或者说服务端统一网关的要求是必须支持sticky routing。假设客户端连接断了，接下来的必须重连之前的同一个服务器。微服务的stateless，水瓶扩展要求本身就是反sticky routing的，因为sticky routing本身就是状态。 对服务端集群来说，同时有无数个LOL比赛在进行，每个都可以看成一个沙盒，每个沙盒都处于一个不同的状态：塔被推了几个了，你被杀了几次了，对面几个超神了，20分钟到了没。 这些都是长时间存在的状态，直到游戏结束，服务端才可以清理一场游戏的状态。所以虽然不用把这些状态写进持久性存储，但是必然会在内存中存在很长时间。都是状态，反正有状态，就别想用微服务。除非你说把这些状态都移到redis里去，那么在服务器在信息流传输到一半还要做一个remote request，一来一回，延迟就上升了。总之怎样都不好。（比如想象对方在A你的水晶，每一次A的操作都是一个event，被streaming到服务端的沙盒中，沙盒中有一个流处理器，每次接收到一个你水晶被A的event都会计算一下你水晶爆了没。这个计算需要极快，你是不可能把你水晶生命值的数据存在远端的） 像这类游戏，都是对网络，内存，CPU的优化需求很高，整个游戏进行过程中，几乎不存在什么RPC call，真的需要remote data，也应该是prefetch，就是在游戏刚开始的时候加载好微服务不是什么银弹，也就是方便拆解一下原来的CRUD应用罢了而已，一没触及高级的交互方式，二没触及分布式系统真正的难点：状态，其实没有大家想的那么有用。之所以感觉上好像微服务改变了互联网，只不过90%的互联网应用都只是简单小规模的CRUD而已。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://overtalk.site/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://overtalk.site/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"py-notes","slug":"py-notes","date":"2020-06-16T10:15:29.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/06/16/py-notes/","link":"","permalink":"https://overtalk.site/2020/06/16/py-notes/","excerpt":"","text":"Python的星号（、*）的作用 函数的可变参数 当函数的参数前面有一个星号的时候表示这是一个可变的位置参数，两个星号*表示是可变的关键字参数。 12345678910111213#!env python#coding=utf-8#def foo(*args, **kwarg): for item in args: print item for k,v in kwarg.items(): print k,v print 30*'='if __name__ == '__main__': foo(1, 2, 3, a=4, b=5) foo(2, 3, a=4, b=5, c=1) 输出如下： 12345678910111213root@web-Dev ~/station $ python test_param.py123a 4b 5==============================23a 4c 1b 5============================== 这样我们可以传入任意个数的参数。 unpack参数 星号把序列/集合解包（unpack）成位置参数，两个星号*把字典解包成关键字参数。下面通过示例来进一步加深理解： 1234567891011121314151617181920#!env python#coding=utf-8def foo(*args, **kwarg): for item in args: print item for k,v in kwarg.items(): print k,v print 30*'='if __name__ == '__main__': #foo(1, 2, 3, a=4, b=5) #foo(2, 3, a=4, b=5, c=1) v = (1, 2, 4) v2 = [11, 15, 23] d = &#123;'a':1, 'b':12&#125; foo(v, d) foo(*v, **d) foo(v2, d) foo(*v2, **d) 输出如下： 12345678910111213141516171819root@web-Dev ~/station $ python test_param.py(1, 2, 4)&#123;'a': 1, 'b': 12&#125;==============================124a 1b 12==============================[11, 15, 23]&#123;'a': 1, 'b': 12&#125;==============================111523a 1b 12============================== 上面的示例中如果v、v2、d没有加星号那么就当成了一个参数传递给了函数，如果加了星号那么就会解包后传递给函数。foo(d, *d)等价于foo(1, 2, 4, a=1, b=12)。 几个注意点 可变位置参数*args是一个元组，是不可修改的。1234567891011121314&gt;&gt;&gt; def foo(*args):... args[0] = 5...&gt;&gt;&gt; foo(1, 2, 3)Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt; File \"&lt;stdin&gt;\", line 2, in fooTypeError: 'tuple' object does not support item assignment&gt;&gt;&gt; l = [1, 2, 3]&gt;&gt;&gt; foo(*l)Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt; File \"&lt;stdin&gt;\", line 2, in fooTypeError: 'tuple' object does not support item assignment 无论我们怎么传入参数，args都是一个tuple类型，不能进行修改。 对于字典类型的如果只使用一个型号*那么传入的只是字典的键。 12345678&gt;&gt;&gt; def foo2(*args, **kwarg):... print args, kwarg...&gt;&gt;&gt; d = &#123;'a':1, 'b':2, 'c':3&#125;&gt;&gt;&gt; foo2(*d)('a', 'c', 'b') &#123;&#125;&gt;&gt;&gt; foo2(**d)() &#123;'a': 1, 'c': 3, 'b': 2&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"},{"name":"python","slug":"python","permalink":"https://overtalk.site/tags/python/"}]},{"title":"理解字节序","slug":"endian","date":"2020-06-01T11:10:45.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/06/01/endian/","link":"","permalink":"https://overtalk.site/2020/06/01/endian/","excerpt":"","text":"计算机硬件有两种储存数据的方式：大端字节序（big endian）和小端字节序（little endian）。 举例来说，数值0x2211使用两个字节储存：高位字节是0x22，低位字节是0x11。 大端字节序：高位字节在前，低位字节在后，这是人类读写数值的方法。 小端字节序：低位字节在前，高位字节在后，即以0x1122形式储存。 0x1234567 的大端字节序和小端字节序的写法如下图。 为什么会有小端字节序？ 为什么要有字节序，每次读写都要区分，多麻烦！统一使用大端字节序，不是更方便吗？ 答案是，计算机电路先处理低位字节，效率比较高，因为计算都是从低位开始的。所以，计算机的内部处理都是小端字节序。 但是，人类还是习惯读写大端字节序。所以，除了计算机的内部处理，其他的场合几乎都是大端字节序，比如网络传输和文件储存。 计算机处理字节序的时候，不知道什么是高位字节，什么是低位字节。它只知道按顺序读取字节，先读第一个字节，再读第二个字节。 如果是大端字节序，先读到的就是高位字节，后读到的就是低位字节。小端字节序正好相反。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"endian","slug":"endian","permalink":"https://overtalk.site/tags/endian/"}]},{"title":"《FreeSWITCH权威指南》解读","slug":"rtc-freeswitch","date":"2020-05-24T12:28:22.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/05/24/rtc-freeswitch/","link":"","permalink":"https://overtalk.site/2020/05/24/rtc-freeswitch/","excerpt":"","text":"读《FreeSWITCH权威指南》一书的一些笔记 一些基础的命令12# 查看 internal Profile 上面的注册用户freeswitch&gt; sofia status profile internal reg 一些缩写的解释 PBX 系统 ： 什么是FreeSWITCH？ 开源的，跨平台的，伸缩性极好的，免费的，多协议的 电话软交换平台 伸缩性：从一个简单的软电话客户端 到 运营商级的软交换设备，几乎无所不能。 多协议的：支持 SIP，H323，Skype，Google Talk 等多种通信协议，并且可以与各种开源的 PBX 系统（例如：sipXecs，Call Weaver，Bayonne，YATE，Asterisk等）通信，也可以与商用的交换系统（如华为，中兴的交换机或者是思科，Avaya的交换机等）互通。 FreeSWITCH 是一个 B2BUA(Back to Back User Agent)，它作为一个背靠背的用户代理帮助通信双方进行实时的语音视频通行 如何安装 &amp; 运行安装 TODO 运行 虽然参数众多，用到的也没有几个 freeswitch -nc : 启动到后台 freeswitch -nonat : freeswitch默认启用uPnP(或NAT-PMP)协议，尝试进行打孔 判断 freeswitch 是否运行 查看进程 : ps aux | grep freeswitch 查看端口 : netstat -an | grep 5060 呼叫 FreeSWITCH 最基础的功能 发起呼叫 假设用户1003已经注册到freeswitch上 使用 originate命令 发起一次呼叫，然后执行echo回声程序1freeswitch&gt; originate user/1003 &amp;echo 呼叫字符串 上个例子中 user/1003 称为呼叫字符串（Dial String，Call URL） user 是一种特殊的呼叫字符串，后续介绍其他的呼叫字符串。 命令 sofia status profile internal reg 可以查看已经注册的 UA 的注册信息 一些概念 先来看一个场景：Bob 与 Alice 通话，典型的呼叫流程有如下两种 Bob 向 FreeSWITCH 发起呼叫，FreeSWITCH 接着启动一个 UA 呼叫 Alice，两者通话。 FreeSWITCH 同时呼叫 Bob 与 Alice，两者接电话之后，FreeSWITCH 将 a-leg 与 b-leg 桥接（bridge）到一起，两者通话。 上述第一种呼叫流程中，Bob 到 FreeSWITCH 的通话称为来话（注意：在这儿都是针对FreeSWITCH来说的），而 FreeSWITCH 作为一个 B2BUA 再去呼叫 Alice，就称为去话。在第二种呼叫流程中两路通话（两个leg）都是去话。 无论是来/去话，对每一次呼叫，FreeSWITCH都会启动一个 Session（会话，包括SIP会话），用于控制整个呼叫，它会一直持续到通话结束，其中，每个Session都控制着一个Channel（通道，又称信道），Channel是一对 UA 间通信的实体，相当于 FreeSWITCH 的一条腿，每个 Channel 都会用一个 uuid 标识。通话时，FreeSWITCH的作用是将两个Channel（a-leg 和 b-leg，通常先创建的/占主动的叫 a-leg）桥接到一起，使得双方可以通话。 这两路桥接的通话（两条腿）在逻辑上组成一个通话，称为一个 Call APP 与 API 前面的例子中, originate 是 FreeSWITCH 内部的一个命令（command），用于控制 FreeSWITCH 发起一个呼叫。FreeSWITCH 的命令不仅可以在控制台上使用，也可以在各种 嵌入式脚本，Event Socket（fs_cli就是使用了ESL库） 或者 HTTP RPC 上使用，所有的命令都遵循一个抽象的接口，因而这些命令又称 API Commands。 echo 则是一个常用的应用程序（Application，APP），它的作用是控制一个 Channel 的一端。一个 Channel 有两端（呼叫方，被呼叫方）。 使用echo时。电话接通后相当于呼叫方在和 echo通话。 后面我们会说到，他们实际上组成了 FreeSWITCH 的一条腿（leg），这种童话称为“单腿模式（one-legged connection）”。 其他的一些的 app 的使用 1234freeswitch&gt; originate user/1003 &amp;parkfreeswitch&gt; originate user/1003 &amp;holdfreeswitch&gt; originate user/1003 &amp;playback(/root/welcome.wav)freeswitch&gt; originate user/1003 &amp;record(/tmp/voice_of_1003.wav) 当我们初始化一个呼叫时候，在1003接电话之后对端必须有一个人与之对话（否则，一个Channel只有一端） park 可以将该电话“挂起”，相当于 Channel 特殊的一端。park 的用户体验并不好，因为1003不知道等多久才有人接电话，由于听不到任何声音，用户会奇怪到底有没有接通。 hold 相对比较友好，它在等待的同时会播放音乐。 playback app 可以直接播放一个特定的声音文件 record app 可以直接录音 上面的例子其实都是建立一个Channel，相当于 FreeSWITCH 作为一个 UA 和 1003 进行通话。它是个一条腿（只有a-leg）的通话。大多数情况之下， FreeSWITCH 都是作为一个B2BUA来桥接两个UA进行通话的。在A接听电话以后，bridge程序可以再启动一个UA呼叫 B，如下： 1freeswitch&gt; originate user/a &amp;bridge(/user/b) 这样就可以让a与b进行通话了。我们也可以使用另外一种方式建立他们之间的通话： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152freeswitch&gt; originate user/a &amp;parkfreeswitch&gt; originate user/b &amp;parkfreeswitch&gt; show channelsfreeswitch&gt; uuid_bridge &lt;a_uuid&gt; &lt;b_uuid&gt;``` - 在这，分别呼叫 a &amp; b，并把他们暂时park到一个地方。通过 `show channels` 方法得到 channel UUID，然后通过 `uuid_bridge` 命令将两个 Channel 桥接起来。- 上面我们简单介绍了 - 两条命令（API）：originate &amp; uuid_bridge - 几个程序（APP）：echo &amp; park &amp; bridge- uuid_bridge API 和 bridge APP 有些类似。一个是先呼叫后桥接，另外一个是先桥接后呼叫，到底有啥区别？- **简单来说：一个APP是一个程序（application），它作为一个Channel一端与另一端的UA进行通信，相当于它工作在Channel内部；而一个API则是独立于一个Channel之外的，它只能通过找到Channel的UUID来控制一个Channel（如果需要），相当于一个第三者。**这就是他们的本质区别。- 通常控制台输入的命令都是 API，而在 dialplan 中执行的程序都是 APP（dialplan中也可以执行一些特殊的API）。大部分共用的API都是在mod_commands模块中加载的，而APP则是在mod_dptools中，因而 App 又称为拨号计划工具（DialPlan Tools）。某些模块（如：mod_sofia）有自己持有的API和APP。--- # FreeSWITCH 内部架构- FreeSWITCH 由一个稳定的核心（Core）及一些外围模块组成。这些外围的模块根据其功能&amp;用途分成：EndPoint，Codec，Dialplan，Application等不同的类别，如图所示：![FreeSWITCH架构图](/images/posts/rtc-freeswitch/freeswitch-architecture.png)- 其中，数据库的代码是在核心中实现的，但是上图中将其列出来是因为从逻辑上它是独立的。- FreeSWITCH 内部使用线程模型来处理并发请求，每个连接都是在单独的线程中进行处理，不同线程之间通过 Mutex 互斥访问共享资源，并通过消息和异步事件等方式进行通信。- FreeSWITCH的核心非常短小精悍，绝大部分应用层的功能都是在外围模块中实现。外围模块是可以动态加载（以及卸载）的，在实际应用中可以只加载用到的模块。- 外围模块通过核心提供的 Public API 与核心进行通信，而核心则通过回调（或称钩子）机制执行外围模块中的代码。- TODO ：再看看书- 具体的可以去看书了 --- # 拨号计划- Dialplan，主要作用就是对电话进行**路由**（类似路由表），决定 &amp; 影响通话流程。- XML Dialplan 由一系列的 XML 配置文件组成，可以是静态配置的，也可以使用动态配置方式从其他服务器或者脚本中动态获取。Dialplan 又特定的结构， FreeSWITCH 通过解析相关机构，可以对 Dialplan 进行路由的呼叫，决定执行何种动作或者流程。## 配置文件结构- 默认配置在 conf/dialplan 目录中。- 看一个 Dialplan 的完整结构：```xml &lt;extension name=\"Echo Test\"&gt; &lt;!-- destination_number ：被呼叫的号码 --&gt; &lt;condition field=\"destination_number\" expression=\"^echo|1234$\"&gt; &lt;!-- action 两个参数的含义：app + app 运行的参数 --&gt; &lt;action application=\"answer\" data=\"\"/&gt; &lt;action application=\"echo\" data=\"\"/&gt; &lt;/condition&gt; &lt;/extension&gt; extension 类似于路由表中的表项，每个 extension 都有一个 name 属性，可以为任意合法字符串，对呼叫流程没有任何影响，去一个有含义的名字，有助于在Log中找到。 在 extension 中可以对一些 condition(测试条件) 进行判断，如果满足测试条件所指定的表达式，则执行对于的 action。 拿上面的例子看，condition(测试条件) 是 destination_number ，表示被呼叫的号码， FreeSWITCH 会将呼入电话的号码与后面的正则表达式 ^echo|1234$ 比较，如果满足条件，则执行后面的 action。 第一个 action 为 answer，他是一个 app，用于对来话进行应答（由于是sip呼叫，底层返回200 ok），然后执行 echo。在这个例子中，我们呼叫1234创建了一个单腿的呼叫，与其说我们在和 FreeSWITCH 通话，还不如说在和一个 APP 通话。而 Dialplan 只是帮助我们找到这些个 APP。 系统默认提供的配置文件中又几个 context : default，features，public，skinny-patterns。他们分别在不同的XML配置文件中。 default 是默认的 dialplan，一般来说注册用户都可以通过它来打电话，如拨打其他分机或者外部电话。 public 一般用于接受外来呼叫，因为外部进来的呼叫是不可信的，所以要严格控制。 通道变量 TODO 除了通道变量之外还有一些其他的东西，后续补齐 SIP 模块 Session Initiation Protocol : 控制发起、修改和终结交互式多媒体会话的信令协议。 它是一个对等的协议，类似于P2P。它和 HTTP 不一样，不是CS架构。也不像传统电话那样必须要有一个中心的交换机，它可以在不需要服务器的情况下进行通信。即点对点的通信。 一个 Profile 就类似一个 SIP UA","categories":[{"name":"rtc","slug":"rtc","permalink":"https://overtalk.site/categories/rtc/"},{"name":"book","slug":"rtc/book","permalink":"https://overtalk.site/categories/rtc/book/"},{"name":"freeswitch","slug":"rtc/book/freeswitch","permalink":"https://overtalk.site/categories/rtc/book/freeswitch/"}],"tags":[{"name":"rtc","slug":"rtc","permalink":"https://overtalk.site/tags/rtc/"},{"name":"freeswitch","slug":"freeswitch","permalink":"https://overtalk.site/tags/freeswitch/"}]},{"title":"VoIP 中的一些协议","slug":"rtc-protocol","date":"2020-05-21T09:51:29.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/05/21/rtc-protocol/","link":"","permalink":"https://overtalk.site/2020/05/21/rtc-protocol/","excerpt":"","text":"目前语音通信网络正在由 PSTN 网络向 NGN 以及 IMS网络演进和改造语音业务也由传统的 POTS 话机业务向 VoIP 业务转变 SIP (Session Initiation Protocol) 信令协议 SIP协议 从类似的权威协议－－如 Web 超文本传输协议 (HTTP) 格式化协议以及简单邮件传输协议 (SMTP) 电子邮件协议－－演变而来并且发展成为一个功能强大的新标准。 用于初始、管理和终止网络中的语音和视频会话，具体地说就是用来生成、修改和终结一个或多个参与者之间的会话。 SIP报文内容传送会话描述协议(SDP)，SDP协议描述了会话所使用流媒体细节，如：使用哪个IP端口，采用哪种编解码器等等。 SIP的一个典型用途是：SIP“会话”传输一些简单的经过封包的实时传输协议流。RTP本身才是语音或视频的载体。 SIP好文推荐，主要涉及到一些sip协议的流程 RTP(Real-time Transport Protocol) 数据传输协议 VoIP 语音分组采用 RTP 协议进行传送 RSTP(实时流协议) TODO SDP(会话描述协议) TODO 一些其他的小知识DSP芯片 提供一些技术，例如：静音检测，回声消除，丢包补偿 为了节约网络资源通常在发送端使用 VAD技术，接收端使用 CNG 术 Jitter Buffer 就是用来消除抖动的，通过增加时延的方法 VAD (Voice Activity Detector) 语音动态检测 CNG (Comfort Noise Generator) 舒适噪音产生","categories":[{"name":"rtc","slug":"rtc","permalink":"https://overtalk.site/categories/rtc/"}],"tags":[{"name":"rtc","slug":"rtc","permalink":"https://overtalk.site/tags/rtc/"}]},{"title":"为什么说++i比i++效率高？","slug":"cpp-plus","date":"2020-05-19T11:49:09.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/05/19/cpp-plus/","link":"","permalink":"https://overtalk.site/2020/05/19/cpp-plus/","excerpt":"","text":"不知道你是否听说过++i比i++快的说法，真的如此吗？ ++i与i++的区别 这两个表达式从我们初学编程语言的时候就会接触到。前者是自增后取值，后者是取值后自增。 我们看一个简单的例子。 1234567891011#include &lt;iostream&gt;using namespace std;int main()&#123; int a = 0; int b = 0; int c = a++;//int tmp = a;c=a;a = a + 1 int d = ++b;//b = b + 1;d = b; cout&lt;&lt;\"c=\"&lt;&lt;c&lt;&lt;\";d=\"&lt;&lt;d&lt;&lt;endl; return 0;&#125; 运行结果： 1c=0;d=1 对于这个结果我们并不感到意外。 另外我们还注意到另外一个有意思的现象： 12345678910#include &lt;iostream&gt;using namespace std;int main()&#123; int a = 0; int b = 0; int *c = &amp;(a++); int *d = &amp;(++b); return 0;&#125; 编译后报错： 12main.cpp:7:19: error: lvalue required as unary ‘&amp;’ operand int *c = &amp;(a++); 说&amp;作用于左值，也就是说a++的结果并非左值。但++b的结果是。 可简单理解左值和右值： 左值，有名对象，可赋值 右值，临时对象，不可被赋值 运算符重载 在《运算符重载》一文中已经说到了运算符的重载，通过前面的例子也发现了，对于内置类型，前置自增返回对象的引用，而后置自增返回对象的原值（但非左值）。 基于上述原则，一个前置版本和后置版本的常见实现如下： 123456789101112131415161718192021class Test&#123;public: Test&amp; operator++();//前置自增 const Test operator++(int);//后置自增private: int curPos; //当前位置&#125;;/*前置自增实现范式*/Test&amp; Test::operator++()&#123; ++curPos; //自增 return *this; //取值&#125;/*后置自增实现范式，为了与前置区分开，多了一个int参数，但从来没用过*/const Test Test::operator++(int)&#123; Test tmp = *this; //取值 ++curPos; //自增 return tmp;&#125; 仔细观察后，我们发现前置自增，先自增，后返回原对象的对象；没有产生任何临时对象；而后置自增，先保存原对象，然后自增，最后返回该原临时对象，那么它就需要创建和销毁，这样一来，效率孰高孰低就很清楚了。 在不进行赋值的情况下，内置类型前置和后置自增的汇编都是一样的呢！ 123456void test()&#123; int i = 0; i++; //++i;&#125; 汇编: 1234567push rbpmov rbp, rspmov DWORD PTR [rbp-4], 0add DWORD PTR [rbp-4], 1noppop rbpret 不过，赋值的情况下，并且不开启编译器优化，它们的汇编代码还是有差别的，有兴趣的可以试试。 总结 对于内置类型，前置和后置自增或者自减在编译器优化的情况下，两者并无多大差别，而对于自定义类型，如无特别需要，人们似乎更加偏爱前置自增或自减，因为后置自增常常会产生临时对象。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"一些系统调用的记录","slug":"kernal-systemcall","date":"2020-05-17T13:19:25.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/05/17/kernal-systemcall/","link":"","permalink":"https://overtalk.site/2020/05/17/kernal-systemcall/","excerpt":"","text":"listen 系统调用 socket 系统调用 inet_pton函数 和inet_ntop函数 setsockopt 函数","categories":[{"name":"linux","slug":"linux","permalink":"https://overtalk.site/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://overtalk.site/tags/linux/"},{"name":"kernal","slug":"kernal","permalink":"https://overtalk.site/tags/kernal/"},{"name":"systemcall","slug":"systemcall","permalink":"https://overtalk.site/tags/systemcall/"}]},{"title":"C++ - 中的线程与异步","slug":"cpp-thread-async","date":"2020-05-15T10:17:09.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/05/15/cpp-thread-async/","link":"","permalink":"https://overtalk.site/2020/05/15/cpp-thread-async/","excerpt":"","text":"以前一直觉得golang中的channel在多线程的情况下够好用的了 最近刚刚看到了 c++ 中有关异步的写法 个人觉得在一些特定的应用场景之中，c++ 比 go 好用哎！ 好吧，我不是一个真正的 gopher 😂 Thread in cpp 线程部分比较简单，直接上代码，不多细说了 有关线程的 join() 和 detach() 方法稍微说一点 join() : 等待该线程结束之后才退出 detach() : 分离模式，各自线程结束了之后就直接退出，不存在上面的关系 有的时候我们发现 main() 的线程结束了，其余的线程也会退出，从而造成我们的一些错误认知，认为 main() 的线程就是主线程，它退出之后其他的线程也会退出 其实线程都是平等的，没有主次线程这一种说法 之所以有上面说的那种情况就是因为 main()执行完之后, 会调用exit()。exit() 会让整个进程over终止，那所有线程自然都会退出。 123456789101112131415161718192021222324252627282930#include \"buffer.hpp\"#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;chrono&gt;int main() &#123; auto tf = []&#123; std::chrono::milliseconds dura(2000); for (int i =0; i &lt;10; ++i) &#123; std::cout &lt;&lt; \"tf thread :\" &lt;&lt; i &lt;&lt; std::endl; std::this_thread::sleep_for(dura); &#125; std::cout &lt;&lt; \"--- tf thread over ---\" &lt;&lt; std::endl; &#125;; std::thread t(tf); t.detach(); std::chrono::milliseconds dura(1000); for (int i =0; i &lt;10; ++i) &#123; std::cout &lt;&lt; \"main thread :\" &lt;&lt; i &lt;&lt; std::endl; std::this_thread::sleep_for(dura); &#125; std::cout &lt;&lt; \"--- main thread over ---\" &lt;&lt; std::endl;// t.join(); return 0;&#125; async in cppbasic usage1234567891011#include &lt;iostream&gt;#include &lt;thread&gt;// #include &lt;chrono&gt;#include &lt;future&gt;int main() &#123; auto res = std::async([]&#123;std::cout &lt;&lt; \"async-\" &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl; return 666;&#125;); std::cin.get(); std::cout &lt;&lt; \"main-\" &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl; return 0;&#125; std::launch::deferred 惰性调用（延时执行），直到 res.wait() 的时候才执行123456789101112#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;future&gt;int main() &#123; auto res = std::async(std::launch::deferred,[]&#123;std::cout &lt;&lt; \"async-\" &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl; return 666;&#125;); std::cout &lt;&lt; \"main-\" &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl; std::cin.get(); res.wait(); return 0;&#125; real async1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;future&gt;#include &lt;chrono&gt;int main() &#123; auto tf = []&#123; std::chrono::milliseconds dura(1000); std::this_thread::sleep_for(dura); return 12; &#125;; std::packaged_task&lt;int()&gt; task(tf); auto result = task.get_future(); std::thread t(std::move(task)); t.detach(); std::cout &lt;&lt; \" --- \" &lt;&lt; std::endl; std::cout &lt;&lt; result.get() &lt;&lt; std::endl; return 0;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"音频的一些基础概念","slug":"rtc-basic","date":"2020-05-09T17:02:16.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/05/09/rtc-basic/","link":"","permalink":"https://overtalk.site/2020/05/09/rtc-basic/","excerpt":"","text":"后续要开始做一些音频相关的内容在此记录一些基础的音频知识吧人耳可以听到的声音频率在20HZ~20kHz之间的声波，称为音频。音频采样，是把声音从模拟信号转换为数字信号 参考 音频 属性详解(涉及采样率、通道数、位数、比特率、帧等) PCM数据格式 FFmpeg音频样本 一些基础参数 采集音频的时候会涉及到一些采集参数，比如说：采样频率，采样深度，通道数，在此简单介绍一下 采样频率 采样设备（麦克风）每秒进行的采样次数（每台电脑的麦克风都有固定的采样频率），同样也是所得的数字信号的每秒样本数。 人耳可以听到的频率为 20 hz - 20k hz 之间 采样频率越高，声音的质量也就越好，声音的还原也就越真实，但同时它占的资源比较多。由于人耳的分辨率很有限，太高的频率并不能分辨出来。 8000 Hz - 电话所用采样率, 对于人的说话已经足够 11025 Hz - AM调幅广播所用采样率 22050 Hz 和 24000 Hz - FM调频广播所用采样率 32000 Hz - miniDV 数码视频 camcorder、DAT (LP mode)所用采样率 44100 Hz - 音频 CD, 也常用于 MPEG-1 音频（VCD, SVCD, MP3）所用采样率 47250 Hz - 商用 PCM 录音机所用采样率 48000 Hz - miniDV、数字电视、DVD、DAT、电影和专业音频所用的数字声音所用采样率 50000 Hz - 商用数字录音机所用采样率 96000 或者 192,000 Hz - DVD-Audio、一些 LPCM DVD 音轨、BD-ROM（蓝光盘）音轨、和 HD-DVD （高清晰度 DVD）音轨所用所用采样率 2.8224 MHz - Direct Stream Digital 的 1 位 sigma-delta modulation 过程所用采样率。 如果是双声道(stereo)， 采样就是双份的， 文件也差不多要大一倍。 采样位数 音频在经过采样得到样本后，还需要对该样本执行两个步骤： 量化。音频量化的量化位数常用的有： -8bit (也就是1字节) 只能记录 256 个数, 也就是只能将振幅划分成 256 个等级; 16bit (也就是2字节) 可以细到 65536 个数, 这已是 CD 标准了; 32bit (也就是4字节) 能把振幅细分到 4294967296 个等级, 实在是没必要了. 量化位数又叫做采样位数、位深度、分辨率， 它是指声音的连续强度被数字表示后可以分为多少级。N-bit的意思声音的强度被均分为2^N级。16-bit的话，就是65535级。这是一个很大的数了，人可能也分辨不出六万五千五百三十五分之一的音强差别。也可以说是声卡的分辨率，它的数值越大，分辨率也就越高，所发出声音的能力越强。这里的采样倍数主要针对的是信号的强度特性，采样率针对的是信号的时间（频率）特性这是两个不一样的概念。 二进制编码。也就是把量化所得的结果，即单个声道的样本，以二进制的码字进行存放。其中有两种存放方式： 直接以整形来存放量化结果，即Two’s complement code； 以浮点类型来存放量化结果，即Floating point encoding code。 大多数格式的PCM（脉冲编码调制 - Pulse Code Modulation,PCM）样本数据使用整形来存放，而在对一些对精度要求高的应用方面，则使用浮点型来表示PCM 样本数据 pcm详解 通道数 即声音的通道的数目，一般分为单声道和双声道 可以理解为在声音采集时从一个点进行收集，双声道从两个点进行收集 常有单声道和立体声之分，单声道的声音只能使用一个喇叭发声（有的也处理成两个喇叭输出同一个声道的声音），立体声可以使两个喇叭都发声（一般左右声道有分工） ，更能感受到空间效果，当然还有更多的通道数。 帧 音频在量化得到二进制的码字后，需要进行变换，而变换（MDCT）是以块为单位（block）进行的，一个块由多个（120或128）样本组成。而一帧内会包含一个或者多个块。帧的常见大小有960、1024、2048、4096等。一帧记录了一个声音单元，它的长度是样本长度和声道数的乘积。FFmpeg中 AVFrame 结构体中的 nb_samples 代表的就是一帧中单个声道的音频样本数量。 样本的组合方式 这个主要是针对双声道或多声道音频来说的，对于一个双声道音频来说，它的组合方式可能有以下两种： 交错（interleaved）。以stereo为例，一个stereo音频的样本是由两个单声道的样本交错地进行存储得到的。 平面（planar）。各个声道的样本分开进行存储。 FFmpeg音频解码后的数据是存放在AVFrame结构中的。 Packed格式，frame.data[0]或frame.extended_data[0]包含所有的音频数据中。 Planar格式，frame.data[i]或者frame.extended_data[i]表示第i个声道的数据（假设声道0是第一个）, AVFrame.data数组大小固定为8，如果声道数超过8，需要从frame.extended_data获取声道数据。 比特率 每秒的传输速率(位速, 也叫比特率)。如705.6kbps 或 705600bps, 其中的 b 是 bit, ps 是每秒(per second)的意思，表示每秒705600bit的容量。压缩的音频文件常常用倍速来表示，譬如达到CD音质的MP3是128kbps/44100HZ。注意这里的单位是bit而不是Byte,一个Byte等于8个bit(位),bit是最小的单位，一般用于网络速度的描述和各种通信速度，Byte则用于计算硬盘，内存的大小。 Mbps 即：Milionbit per second(百万位每秒)； Kbps 即： Kilobit per second（千位每秒); bps 即：bit per second (位每秒)， 相应的换算关系为： 1Milionbit=1000Kilobit=1000000bit；1Mbps = 1000 000bps; 再次强调这里是速度单位，指每秒传输的二进制位数，数据传输速率的衡量单位K是十进制含义，但数据存储的K是二进制含义。例如： 通常描述的1M带宽就是1Mbps = 1000 000 bps = 1000 000 / 8 / 1000 = 125; 所以1M带宽的下载速率一般不超过125KB/s 100M宽带也就是100 000 000bps = 100 000 000 / 8 / 1000 / 1000 = 12.5, 所以100M带宽的下载速率最大可达到12.5MB/s 当然了，以上只是理论速率，实际上最大的下载速率可能还达不到那么多，主要还会受到各种损耗的影响，一般100MB宽带下载速率能达到10MB就算不错了。 采样率、采样位数、比特率三者之间的关系 例：根据一个文件的大小推算出文件时长 譬如 “Windows XP 启动.wav” 的文件长度是 424,644 字节, 它是 “22050HZ / 16bit / 立体声” 格式(这可以从其 “属性-&gt;摘要” 里看到), 那么它的每秒的传输速率(位速, 也叫比特率、取样率)是 22050162 = 705600(bit/s), 换算成字节单位就是 705600/8 = 88200(字节/秒),播放时间：424644(总字节数) / 88200(每秒字节数) ≈ 4.8145578(秒)。 但是这还不够精确, 包装标准的 PCM 格式的 WAVE 文件(*.wav)中至少带有 42 个字节的头信息, 在计算播放时间时应该将其去掉, 所以就有：(424644-42) / (22050162/8) ≈ 4.8140816(秒). 这样就比较精确了。也就是： （文件总大小 - 头信息）/ (采样率 * 采样位数 * 通道数 / 8) [也就是比特率] ≈ 文件时长。","categories":[{"name":"rtc","slug":"rtc","permalink":"https://overtalk.site/categories/rtc/"}],"tags":[{"name":"rtc","slug":"rtc","permalink":"https://overtalk.site/tags/rtc/"}]},{"title":"VS Code与CMake真乃天作之合","slug":"cpp-vscode-debug","date":"2020-04-28T14:13:48.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/04/28/cpp-vscode-debug/","link":"","permalink":"https://overtalk.site/2020/04/28/cpp-vscode-debug/","excerpt":"","text":"最近开始从事 c++ 的相关工作 mac 上没有 vs，嫌弃 Clion 太卡了，选择 vs code 作为编译器 vscode 上 debug 代码好麻烦啊，在此记录一下，免得我这鱼木脑袋过几天就忘记了 参考 首先需要安装 c/c++,CMake,CMake Tools 插件，具体插件长啥样可以看上面👆的参考 然后打开 cmake 项目，最下面就有cmake bar，可以点击进行编译 之后在 .vscode 文件夹中写launch.json 就可以了 如下所示： ${workspaceFolder} 就是工作目录 ${fileBasenameNoExtension} 就是你当前打开的文件没有文件扩展名的文件1234567891011121314151617&#123; // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \"version\": \"0.2.0\", \"configurations\": [ &#123; \"type\": \"lldb\", \"request\": \"launch\", \"name\": \"Debug\", \"program\": \"$&#123;workspaceFolder&#125;/build/$&#123;fileBasenameNoExtension&#125;\", \"args\": [], \"cwd\": \"$&#123;workspaceFolder&#125;\", \"preLaunchTask\": \"build\" &#125; ]&#125; 此外，这个Cmake Tools 工具默认的生成地址为 ${workspaceFolder}/build 可以在 setting.json 中修改为：&quot;cmake.buildDirectory&quot;: &quot;${workspaceFolder}/cmake_build&quot;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"Python 使用 C++ dynamic lib","slug":"py-cpp","date":"2020-04-24T10:22:45.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/04/24/py-cpp/","link":"","permalink":"https://overtalk.site/2020/04/24/py-cpp/","excerpt":"","text":"python 使用 c++ 编写的动态连接库 转自manout’s blog 简介 Python 调用 C/C++ 动态库可以使用 ctypes 模块提供的功能。 需要注意的是在使用 C++ 时对导出符号要使用 extern “C” 声明，C++ 编译器会对符号名做名字重整(name mangling), 使导出符号不被 ctypes 模块识别，extern “C” 声明要求编译器对符号按 C 语言的规则处理。ctypes 只能识别 C 导出的符号。 123456extern \"C\"&#123; int foo(int i) &#123; return i * i; &#125;&#125; 编译 gcc/g++ 编译选项包括 -shared 选项1g++ -shared -fPIC foo.cpp -o foo.so -shared 编译为动态链接库 -fPIC 生成位置无关代码，这样链接库中的地址全为相对地址，为解决载入链接库时的地址重定位问题。 Python 使用 ctypes 模块。12345from ctypes import *foo = cdll.LoadLibrary('foo.so').foopam = c_int(10)print (foo(pam.value))","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"},{"name":"python","slug":"python","permalink":"https://overtalk.site/tags/python/"}]},{"title":"C++源码如何变成可执行程序？","slug":"cpp-compiler","date":"2020-04-23T23:00:54.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/04/23/cpp-compiler/","link":"","permalink":"https://overtalk.site/2020/04/23/cpp-compiler/","excerpt":"","text":"C++ 中的 编译 &amp; 连接 过程 预处理 任何以 # 开头的都是预处理指令，当编译器接收到一个源文件时对它做的第一件事情就是处理所有的预处理指令 预处理指令发生在真正的编译之前 eg ： 我们常用的 #include&lt;iostream&gt; 指令，就是将该文件中的所有内容 copy 到当前文件中 define，if，ifdef，ifndef，pragma 编译 编译器将 c++ 代码转化成实际的机器码 所有的 .cpp 文件都会被编译，而头文件则不会，only cpp file，头文件是通过 include 指令加入到 cpp 文件中 每个 cpp 文件也叫做 translation unity（编译单元），会一个一个的被单独编译，每个 cpp 文件会被编译成一个 object 文件（win扩展名为 .obj） 编译器会根据代码创建 abstract syntax tree 来表达我们的代码，之后编译器将根据它来产生真正的机器码 说到底，编译器的工作就是将代码转化成 constant data（常数变量） or instructions 链接 将编译过程产生的所有 object 文件拿到，并将他们联系起来 常见的链接错误unresolved external symbol 连接器找不到它需要的东西 例子：123456789101112131415#include &lt;iostream&gt;void Log(const char *message);int Multiply(int a, int b)&#123; Log(\" In Multiply Func \"); return a * b;&#125;int main()&#123; std::cout &lt;&lt; \" In Main Func \" &lt;&lt; std::endl; return 0;&#125; 这个文件单独编译不会报错 如果没有实现Log函数，在链接的时候会报错，虽然 Multiply 函数看起来像是死代码，但是它有可能被其他的地方用到，所以会发生错误 如果在 Multiply 函数前面加上 static 关键字，就可以解决这个问题 重复的符号 相同的函数实现，一个函数在多个 cpp 文件中实现，在链接的阶段，连接器不知道去链接哪个 一般情况是不会写两遍函数实现，常见的情况就是在头文件中写来函数实现，然后有多个cpp文件都 include 了这个头文件 include 的原理其实就是copy，这样就会有多个函数实现了，这也是我们将函数实现放到 cpp 文件中去的原因 #pragma once 其实就是 #ifndef _LOG_H, #define _LOG_H, #endif ，防止一个头文件被多次 include123456#pragma oncevoid Log(const char* message)&#123; std::cout &lt;&lt; message &lt;&lt; std::endl;&#125; 编译器简介 传统的编译器通常分为三个部分，前端(frontEnd)，优化器(Optimizer)和后端(backEnd) Frontend:前端 词法分析、语法分析、语义分析、生成中间代码 Optimizer:优化器 中间代码优化 Backend:后端 生成机器码 编译器分类GCC GCC（GNU Compiler Collection，GNU编译器套装），是一套由 GNU 开发的编程语言编译器。它是一套以 GPL 及 LGPL 许可证所发行的自由软件，也是 GNU计划的关键部分，亦是自由的类Unix及苹果电脑 Mac OS X 操作系统的标准编译器。 GCC 原名为 GNU C 语言编译器，因为它原本只能处理 C语言。GCC 很快地扩展，变得可处理 C++。之后也变得可处理 Fortran、Pascal、Objective-C、Java, 以及 Ada与其他语言。 LLVM 不同的前端后端使用统一的中间代码LLVM Intermediate Representation (LLVM IR) 如果需要支持一种新的编程语言，那么只需要实现一个新的前端 如果需要支持一种新的硬件设备，那么只需要实现一个新的后端 优化阶段是一个通用的阶段，它针对的是统一的LLVM IR，不论是支持新的编程语言，还是支持新的硬件设备，都不需要对优化阶段做修改 相比之下，GCC的前端和后端没分得太开，前端后端耦合在了一起。所以GCC为了支持一门新的语言，或者为了支持一个新的目标平台，就 变得特别困难 LLVM现在被作为实现各种静态和运行时编译语言的通用基础结构(GCC家族、Java、.NET、Python、Ruby、Scheme、Haskell、D等) Clang LLVM项目的一个子项目，基于LLVM架构的C/C++/Objective-C编译器前端。 相比于GCC，Clang具有如下优点 编译速度快:在某些平台上，Clang的编译速度显著的快过GCC(Debug模式下编译OC速度比GGC快3倍) 占用内存小:Clang生成的AST所占用的内存是GCC的五分之一左右 模块化设计:Clang采用基于库的模块化设计，易于 IDE 集成及其他用途的重用 诊断信息可读性强:在编译过程中，Clang 创建并保留了大量详细的元数据 (metadata)，有利于调试和错误报告 设计清晰简单，容易理解，易于扩展增强 LLVM整体架构，前端用的是clang，广义的LLVM是指整个LLVM架构，一般狭义的LLVM指的是LLVM后端（包含代码优化和目标代码生成）。 源代码（c/c++）经过clang–&gt; 中间代码(经过一系列的优化，优化用的是Pass) –&gt; 机器码","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"c++ 实现 Go 中的 interface","slug":"cpp-interface","date":"2020-04-23T16:08:32.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/04/23/cpp-interface/","link":"","permalink":"https://overtalk.site/2020/04/23/cpp-interface/","excerpt":"","text":"琐碎的知识点 12system(\"pause\"); // for windowsstd::cin.get(); // use this to pause process if linux/mac 单例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;mutex&gt;class Noncopyable&#123;public: Noncopyable() = default; Noncopyable(const Noncopyable &amp;) = delete; Noncopyable &amp;operator=(const Noncopyable &amp;) = delete; Noncopyable(Noncopyable &amp;&amp;) = delete; Noncopyable &amp;operator=(Noncopyable &amp;&amp;) = delete;&#125;;template &lt;typename T&gt;class SingleTon : public Noncopyable&#123;private: static std::once_flag once_; static T *instance_;public: static T *instance() &#123; std::call_once(once_, &amp;SingleTon&lt;T&gt;::Init); return instance_; &#125; static T &amp;get_instance() &#123; return *instance(); &#125; static void ShutDown() &#123; delete instance_; &#125;private: static void Init() &#123; instance_ = new T(); &#125;&#125;;template &lt;typename T&gt;std::once_flag SingleTon&lt;T&gt;::once_;template &lt;typename T&gt;T *SingleTon&lt;T&gt;::instance_ = nullptr; 可以存储任意值的东西 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194#include &lt;unordered_map&gt;#include \"singleTon.hpp\"// 数据类型class DataType final : public SingleTon&lt;DataType&gt;&#123;public: using ptr = DataType *; using Type = uint16_t;private: Type count_&#123;0&#125;;public: Type NewTypeID() &#123; return ++count_; &#125;&#125;;// 基础数据，标明是什么数据类型// 该类数据都继承于他class Base&#123;public: using ptr = Base *;private: DataType::Type type_id_&#123;0U&#125;;public: Base(DataType::Type type_id) : type_id_(type_id) &#123; &#125; virtual ~Base() = default; template &lt;typename T&gt; typename T::ptr Cast() &#123; if (type_id_ != T::type_id_) &#123; return nullptr; &#125; return dynamic_cast&lt;typename T::ptr&gt;(this); &#125;&#125;;template &lt;typename T&gt;class Any final : public Base&#123;public: using ptr = Any *; using Type = T; static T default_data_; static DataType::Type type_id_;private: T data_&#123;default_data_&#125;;public: Any(const T &amp;data) : Base(type_id_), data_(data) &#123; &#125; ~Any() = default; void SetValue(const T &amp;data) &#123; data_ = data; &#125; const T &amp;GetValue() &#123; return data_; &#125;&#125;;template &lt;typename T&gt;T Any&lt;T&gt;::default_data_ = T();template &lt;typename T&gt;DataType::Type Any&lt;T&gt;::type_id_ = DataType::instance()-&gt;NewTypeID();class CustomDataMap final&#123;public: using DataList = std::unordered_map&lt;std::string, Base::ptr&gt;;private: DataList data_list_;public: CustomDataMap() = default; ~CustomDataMap() &#123; for (auto &amp;iter : data_list_) &#123; auto base_data = iter.second; if (base_data == nullptr) &#123; continue; &#125; delete base_data; &#125; data_list_.clear(); &#125; bool HasValue(const std::string &amp;key) &#123; auto iter = data_list_.find(key); if (iter == data_list_.end()) &#123; return false; &#125; return true; &#125; template &lt;typename T&gt; bool AddValue(const std::string &amp;key, const T &amp;value) &#123; auto iter = data_list_.find(key); if (iter != data_list_.end()) &#123; return false; &#125; auto data = new Any&lt;T&gt;(value); auto result = data_list_.insert(std::make_pair(key, data)).second; if (!result) &#123; delete data; return false; &#125; return true; &#125; template &lt;typename T&gt; bool SetValue(const std::string &amp;key, const T &amp;value) &#123; auto iter = data_list_.find(key); if (iter == data_list_.end()) &#123; return false; &#125; auto data_base = iter-&gt;second; if (data_base == nullptr) &#123; return false; &#125; auto data = data_base-&gt;Cast&lt;Any&lt;T&gt;&gt;(); if (data == nullptr) &#123; return false; &#125; data-&gt;SetValue(value); return true; &#125; template &lt;typename T&gt; const T &amp;GetValue(const std::string &amp;key) &#123; auto iter = data_list_.find(key); if (iter == data_list_.end()) &#123; return Any&lt;T&gt;::default_data_; &#125; auto data_base = iter-&gt;second; if (data_base == nullptr) &#123; return Any&lt;T&gt;::default_data_; &#125; auto data = data_base-&gt;Cast&lt;Any&lt;T&gt;&gt;(); if (data == nullptr) &#123; return Any&lt;T&gt;::default_data_; &#125; return data-&gt;GetValue(); &#125;&#125;; 测试 123456789101112131415161718192021#include &lt;iostream&gt;#include \"base/any.hpp\"struct Test&#123; int a; bool b;&#125;;int main()&#123; Test t; t.a = 12; t.b = true; CustomDataMap map; map.AddValue&lt;Test&gt;(\"test\", t); auto value = map.GetValue&lt;Test&gt;(\"test\"); std::cout &lt;&lt; value.a &lt;&lt; \" - \" &lt;&lt; value.b &lt;&lt; std::endl; return 0;&#125;","categories":[{"name":"fragment","slug":"fragment","permalink":"https://overtalk.site/categories/fragment/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"如何查看进程的系统调用","slug":"linux-systemcall","date":"2020-04-15T10:00:58.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/04/15/linux-systemcall/","link":"","permalink":"https://overtalk.site/2020/04/15/linux-systemcall/","excerpt":"","text":"什么是系统调用我就不赘述了，不清楚的可以去参考我的另外一篇博客用户态 内核态 本文主要是带大家看看怎样去查看 进程对于内核的系统调用 linux 进程即文件 在 linux 中，一切皆为文件，socket 是文件，进程也是文件 那么进程的文件在哪呢？ 每个进程都有一个进程号（eg ：pid = 3645） 那么进程的相关文件就在 /proc/3645 目录下 重点关注几个文件夹： ask 目录下就有所有 线程 的信息 fd 文件描述符（一般用数字代表），每个进程都有io，至少三个（标准输入 0，标准输出 1，错误输出 2） 比如一个tcp服务程序，必定至少有一个 listen 的 socket，就对多出一个文件 又比如这个 tcp server 使用了 epoll，使用 epoll_create系统调用 会创建一个fd，也会在这个目录之下 如果出现某个服务（进程）比较卡的时候，就可以进入 task 目录查看是否是进程太多，进行问题排查 例子 一个简单的 echo tcpserver，监听在 0.0.0.0:9999 上 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package mainimport ( \"bufio\" \"fmt\" \"io\" \"log\" \"net\")func main() &#123; addr := \"0.0.0.0:9999\" tcpAddr, err := net.ResolveTCPAddr(\"tcp\", addr) if err != nil &#123; log.Fatalf(\"net.ResovleTCPAddr fail:%s\", addr) &#125; listener, err := net.ListenTCP(\"tcp\", tcpAddr) if err != nil &#123; log.Fatalf(\"listen %s fail: %s\", addr, err) &#125; else &#123; log.Println(\"tcp listening\", addr) &#125; for &#123; conn, err := listener.Accept() if err != nil &#123; log.Println(\"listener.Accept error:\", err) continue &#125; go handleConnection(conn) &#125;&#125;func handleConnection(conn net.Conn) &#123; defer conn.Close() reader := bufio.NewReader(conn) for &#123; // read client request data bytes, err := reader.ReadBytes(byte('\\n')) if err != nil &#123; if err != io.EOF &#123; fmt.Println(\"failed to read data, err:\", err) &#125; else &#123; fmt.Println(\"connection closed\") &#125; return &#125; fmt.Printf(\"request: %s\", bytes) // prepend prefix and send as response line := fmt.Sprintf(\"%s\", bytes) fmt.Printf(\"response: %s\", line) conn.Write([]byte(line)) &#125;&#125; 编译成linux版本 1CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o ./tcp-echo-server-linux ./main.go 上面的终端中启动 echo tcpserver 下面的终端中依次： 获取 echo server 进程号 进入进程对于的目录 进入 fd 目录，可以看到有三个基础的fd（0，1，2）以及一个 socket fd &amp; epoll fd 进入 task 目录 如何查看进程的系统调用 strace -ff -o ./ooxx ./tcp-echo-server-linux 上述命令会运行 tcp-echo-server-linux，并且对它进行系统调用的抓取，并放到当前目录下 执行上述命令之后，多出来很多 xxoo* 的文件，这些文件就记录来每个线程的系统调用 我将 ooxx.30927 中的内容贴出来 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205execve(\"./tcp-echo-server-linux\", [\"./tcp-echo-server-linux\"], 0x7ffcc5d16c08 /* 24 vars */) = 0arch_prctl(ARCH_SET_FS, 0x60c1f0) = 0sched_getaffinity(0, 8192, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]) = 8openat(AT_FDCWD, \"/sys/kernel/mm/transparent_hugepage/hpage_pmd_size\", O_RDONLY) = 3read(3, \"2097152\\n\", 20) = 8close(3) = 0mmap(NULL, 262144, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7ff92955b000mmap(0xc000000000, 67108864, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xc000000000mmap(0xc000000000, 67108864, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0xc000000000mmap(NULL, 33554432, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7ff92755b000mmap(NULL, 2164736, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7ff92734a000mmap(NULL, 65536, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7ff92733a000mmap(NULL, 65536, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7ff92732a000rt_sigprocmask(SIG_SETMASK, NULL, [], 8) = 0sigaltstack(NULL, &#123;ss_sp=NULL, ss_flags=SS_DISABLE, ss_size=0&#125;) = 0sigaltstack(&#123;ss_sp=0xc000002000, ss_flags=0, ss_size=32768&#125;, NULL) = 0rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0gettid() = 30927rt_sigaction(SIGHUP, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGHUP, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGINT, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGINT, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGQUIT, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGQUIT, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGILL, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGILL, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGTRAP, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGTRAP, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGABRT, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGABRT, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGBUS, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGBUS, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGFPE, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGFPE, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGUSR1, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGUSR1, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGSEGV, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGSEGV, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGUSR2, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGUSR2, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGPIPE, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGPIPE, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGALRM, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGALRM, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGTERM, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGTERM, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGSTKFLT, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGSTKFLT, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGCHLD, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGCHLD, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGURG, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGURG, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGXCPU, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGXCPU, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGXFSZ, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGXFSZ, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGVTALRM, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGVTALRM, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGPROF, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGPROF, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGWINCH, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGWINCH, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGIO, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGIO, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGPWR, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGPWR, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGSYS, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGSYS, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRTMIN, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_1, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_2, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_2, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_3, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_3, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_4, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_4, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_5, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_5, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_6, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_6, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_7, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_7, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_8, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_8, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_9, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_9, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_10, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_10, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_11, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_11, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_12, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_12, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_13, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_13, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_14, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_14, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_15, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_15, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_16, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_16, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_17, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_17, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_18, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_18, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_19, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_19, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_20, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_20, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_21, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_21, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_22, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_22, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_23, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_23, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_24, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_24, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_25, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_25, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_26, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_26, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_27, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_27, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_28, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_28, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_29, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_29, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_30, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_30, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_31, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_31, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigaction(SIGRT_32, NULL, &#123;sa_handler=SIG_DFL, sa_mask=[], sa_flags=0&#125;, 8) = 0rt_sigaction(SIGRT_32, &#123;sa_handler=0x459560, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x459690&#125;, NULL, 8) = 0rt_sigprocmask(SIG_SETMASK, ~[], [], 8) = 0clone(child_stack=0xc000062000, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM) = 30928rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0rt_sigprocmask(SIG_SETMASK, ~[], [], 8) = 0clone(child_stack=0xc000064000, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM) = 30929rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0rt_sigprocmask(SIG_SETMASK, ~[], [], 8) = 0clone(child_stack=0xc00005e000, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM) = 30930rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0futex(0x60c2a8, FUTEX_WAIT_PRIVATE, 0, NULL) = 0rt_sigprocmask(SIG_SETMASK, ~[], [], 8) = 0clone(child_stack=0xc000060000, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM) = 30932rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0futex(0x60c2a8, FUTEX_WAIT_PRIVATE, 0, NULL) = 0readlinkat(AT_FDCWD, \"/proc/self/exe\", \"/root/temp/temp/tcp-echo-server-\"..., 128) = 37fcntl(0, F_GETFL) = 0x2 (flags O_RDWR)futex(0xc0000524c8, FUTEX_WAKE_PRIVATE, 1) = 1mmap(NULL, 262144, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7ff9272ea000fcntl(1, F_GETFL) = 0x2 (flags O_RDWR)fcntl(2, F_GETFL) = 0x2 (flags O_RDWR)socket(AF_INET, SOCK_STREAM|SOCK_CLOEXEC|SOCK_NONBLOCK, IPPROTO_TCP) = 3close(3) = 0socket(AF_INET6, SOCK_STREAM|SOCK_CLOEXEC|SOCK_NONBLOCK, IPPROTO_TCP) = 3setsockopt(3, SOL_IPV6, IPV6_V6ONLY, [1], 4) = 0bind(3, &#123;sa_family=AF_INET6, sin6_port=htons(0), inet_pton(AF_INET6, \"::1\", &amp;sin6_addr), sin6_flowinfo=htonl(0), sin6_scope_id=0&#125;, 28) = -1 EADDRNOTAVAIL (Cannot assign requested address)socket(AF_INET6, SOCK_STREAM|SOCK_CLOEXEC|SOCK_NONBLOCK, IPPROTO_TCP) = 4setsockopt(4, SOL_IPV6, IPV6_V6ONLY, [0], 4) = 0bind(4, &#123;sa_family=AF_INET6, sin6_port=htons(0), inet_pton(AF_INET6, \"::ffff:127.0.0.1\", &amp;sin6_addr), sin6_flowinfo=htonl(0), sin6_scope_id=0&#125;, 28) = 0close(4) = 0close(3) = 0socket(AF_INET6, SOCK_STREAM|SOCK_CLOEXEC|SOCK_NONBLOCK, IPPROTO_IP) = 3setsockopt(3, SOL_IPV6, IPV6_V6ONLY, [0], 4) = 0setsockopt(3, SOL_SOCKET, SO_BROADCAST, [1], 4) = 0openat(AT_FDCWD, \"/proc/sys/net/core/somaxconn\", O_RDONLY|O_CLOEXEC) = 4epoll_create1(EPOLL_CLOEXEC) = 5epoll_ctl(5, EPOLL_CTL_ADD, 4, &#123;EPOLLIN|EPOLLOUT|EPOLLRDHUP|EPOLLET, &#123;u32=657387272, u64=140708080971528&#125;&#125;) = 0fcntl(4, F_GETFL) = 0x8000 (flags O_RDONLY|O_LARGEFILE)fcntl(4, F_SETFL, O_RDONLY|O_NONBLOCK|O_LARGEFILE) = 0read(4, \"128\\n\", 65536) = 4read(4, \"\", 65532) = 0epoll_ctl(5, EPOLL_CTL_DEL, 4, 0xc0000a49a4) = 0close(4) = 0setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0bind(3, &#123;sa_family=AF_INET6, sin6_port=htons(9999), inet_pton(AF_INET6, \"::\", &amp;sin6_addr), sin6_flowinfo=htonl(0), sin6_scope_id=0&#125;, 28) = 0listen(3, 128) = 0epoll_ctl(5, EPOLL_CTL_ADD, 3, &#123;EPOLLIN|EPOLLOUT|EPOLLRDHUP|EPOLLET, &#123;u32=657387272, u64=140708080971528&#125;&#125;) = 0getsockname(3, &#123;sa_family=AF_INET6, sin6_port=htons(9999), inet_pton(AF_INET6, \"::\", &amp;sin6_addr), sin6_flowinfo=htonl(0), sin6_scope_id=0&#125;, [112-&gt;28]) = 0openat(AT_FDCWD, \"/etc//localtime\", O_RDONLY) = 4read(4, \"TZif2\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\\0\\0\\3\\0\\0\\0\\0\"..., 4096) = 554read(4, \"\", 4096) = 0close(4) = 0write(2, \"2020/04/15 10:30:01 tcp listenin\"..., 47) = 47accept4(3, 0xc000085bc0, [112], SOCK_CLOEXEC|SOCK_NONBLOCK) = -1 EAGAIN (Resource temporarily unavailable)epoll_pwait(5, [], 128, 0, NULL, 0) = 0epoll_pwait(5, 0x7fffa12415e0, 128, -1, NULL, 0) = -1 EINTR (Interrupted system call)--- SIGWINCH &#123;si_signo=SIGWINCH, si_code=SI_KERNEL&#125; ---rt_sigreturn(&#123;mask=[]&#125;) = -1 EINTR (Interrupted system call)epoll_pwait(5, 0x7fffa12415e0, 128, -1, NULL, 0) = -1 EINTR (Interrupted system call)--- SIGWINCH &#123;si_signo=SIGWINCH, si_code=SI_KERNEL&#125; ---rt_sigreturn(&#123;mask=[]&#125;) = -1 EINTR (Interrupted system call)epoll_pwait(5, 0x7fffa12415e0, 128, -1, NULL, 0) = -1 EINTR (Interrupted system call)--- SIGWINCH &#123;si_signo=SIGWINCH, si_code=SI_KERNEL&#125; ---rt_sigreturn(&#123;mask=[]&#125;) = -1 EINTR (Interrupted system call)epoll_pwait(5, 0x7fffa12415e0, 128, -1, NULL, 0) = -1 EINTR (Interrupted system call)--- SIGWINCH &#123;si_signo=SIGWINCH, si_code=SI_KERNEL&#125; ---rt_sigreturn(&#123;mask=[]&#125;) = -1 EINTR (Interrupted system call)epoll_pwait(5, 0x7fffa12415e0, 128, -1, NULL, 0) = -1 EINTR (Interrupted system call)--- SIGWINCH &#123;si_signo=SIGWINCH, si_code=SI_KERNEL&#125; ---rt_sigreturn(&#123;mask=[]&#125;) = -1 EINTR (Interrupted system call)epoll_pwait(5, 0x7fffa12415e0, 128, -1, NULL, 0) = -1 EINTR (Interrupted system call)--- SIGWINCH &#123;si_signo=SIGWINCH, si_code=SI_KERNEL&#125; ---rt_sigreturn(&#123;mask=[]&#125;) = -1 EINTR (Interrupted system call)epoll_pwait(5, root 可以看到 134，137，140，144 行通过 clone 系统调用 创建新的线程 153，155 行分别调用 socket系统调用 创建了 socket，用于后续的 listen 一个是ipv4（fd=3） 一个是ipv6 (fd=4) 157，160 行分别调用了 bind系统调用 绑定监听的地址 167 行调用了 epoll_create系统调用 创建了 epoll 实例（fd = 5） 168，173，178 行分别调用 epoll_ctl系统调用 176 行调用了 bind系统调用 绑定9999端口 最后一行也可以看到调用了 epoll_wait 系统调用 等待连接","categories":[{"name":"jewellery","slug":"jewellery","permalink":"https://overtalk.site/categories/jewellery/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://overtalk.site/tags/linux/"},{"name":"systemcall","slug":"systemcall","permalink":"https://overtalk.site/tags/systemcall/"}]},{"title":"如何糅合各种网络协议？","slug":"net-design","date":"2020-04-14T11:20:54.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/04/14/net-design/","link":"","permalink":"https://overtalk.site/2020/04/14/net-design/","excerpt":"","text":"做服务器的开发工作也有一年了，得益于最近的业务工作没有那么的繁忙，让我有了些许的空闲时间来好好思考这一年时间的点点滴滴 虽然项目千奇百怪各不相同，但其实大部分的时候我们都是在做重复的事情，比如：网络，数据库。 刚好最近在研究 ARK 开源项目，从中的学习到了一些优秀的设计，今天在此记录一下 ARK 中的网络设计以及我自己的一些思考，以免我这榆木脑袋过几天就忘记了 核心问题？ 网络协议多而风格迥异，如何做到 高性能 + 业务层无感知（只需要配置使用那种协议？ 有关高性能的话题就涉及到一些底层的 epoll，multi-reactor 之类的话题，我自己也还在持续学习中，大家可以关注我的一些关于 io 的博客，在这儿就不赘述了，本文更多的侧重于如何设计好网络这部分，让各种网络协议可以通用的切换。 ARK 中的 Net 插件 首先是 ARK 中的三大基石，项目中的一些设计都是基于他们的 net message 所有的网络消息都会被解析成为如下的格式 对于流式的消息，先取包头进行解析，再解析body udp，ws 是 package 形式的消息，收到一个包就直接进行解析即可，解析成为如下的格式1234567891011struct AFNetMsg&#123; // head uint16 protocolID uint32 length uint64 actor_id_&#123;0&#125;; // Actor id uint32 src_bus_&#123;0&#125;; // Source bus id uint32 dst_bus_&#123;0&#125;; // Destination bus id // body char* data // 具体的业务数据&#125; net event 描述网络事件，新连接建立 &amp; 连接断开 这个目前正在考虑需不需要和 net message 进行合并 session 一个新连接建立会对应一个 session12345678910111213141516class AFSession&#123; uint32_t head_len_&#123;0&#125;; // 定义消息头的长度，收到的消息按照这个长度进行解析 conv_id_t session_id_&#123;0&#125;; // 每一个连接会对应一个 sessionID，连接进来就创建一个 id AFBuffer buffer_; // 对应流式数据（tcp），收到消息之后直接存入这个可自动伸缩的 buffer 中 // TODO: merge msg_queue and event_queue together? // cuz recv_msg is a event too. AFLockFreeQueue&lt;AFNetMsg*&gt; msg_queue_; AFLockFreeQueue&lt;AFNetEvent*&gt; event_queue_; const SessionPTR session_; // 具体的连接，源码中这个是一个范型 // 描述状态 volatile bool connected_&#123;false&#125;; volatile bool need_remove_&#123;false&#125;; &#125; 如何适配各种协议，来进行统一的管理呢？ 服务器这件事情其实说起来也很简单，就是与连接（笼统的说法，udp是没有连接的概念）进行发包 &amp; 收包 这儿就可以进行一次抽象，分成两层： 上层：每一个连接对应一个 session，我维护好所有的 session 即可，定期的遍历 session，处理每个session中的 msg &amp; event 这儿我有一个想法就是不遍历所有的session，有消息的才进行遍历（类似于epoll的做法） 下层：负责收包并且解析成上面所说的那种格式（AFNetMsg，并且可以进行发送数据 每个session中对应了一个 const SessionPTR session_ ，把这个部分抽象成一个 连接接口 即可, 类似于这样 123456class ConnInterface&#123; virtual Send() = 0; virtual Recive() = 0; virtual Close() = 0;&#125; 这样我可以各种协议类型的 server 只需要： 建立socket + bind port + listen accept 一个 ConnInterface + 创建session，抛到上层即可 这样我各种业务的处理函数可以在上层注册（协议号+处理函数） 这样就实现了业务和网络的分离，并且将各种协议糅合在一起，很棒","categories":[{"name":"jewellery","slug":"jewellery","permalink":"https://overtalk.site/categories/jewellery/"}],"tags":[{"name":"network","slug":"network","permalink":"https://overtalk.site/tags/network/"}]},{"title":"彻底弄懂IO这件事情 - 从5种io模型开始","slug":"io","date":"2020-04-13T09:24:29.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/04/13/io/","link":"","permalink":"https://overtalk.site/2020/04/13/io/","excerpt":"","text":"新人菜鸟，尝试讲清楚io这件事情 主要包括 bio，nio，select，epoll 可能也会包含一些 mmap，零拷贝 等一些系统调用 本文中的一些例子主要以 linux + 网络io 为主 闲扯淡 为啥要彻底弄懂IO这件事情？ 面试的时候问：redis网络模型是什么啊？nginx网络模型是什么啊？ epoll 啊，这就需要牵扯到IO的事情了 其实IO这就是就是一个成本的问题，因为用户进程不能直接操作硬件，无法直接从网卡读取数据，需要走 kernel 这一层，必须通过 systemcall（软中断），作用在 cpu 上 让kernel帮我们取到硬件上的数据，而这个操作就是成本所在，如何减少这一步的消耗，成为了网络吞吐的一个关键点，有关IO技术的发展，也都是基于这一个出发点的 操作系统的预备知识 有关这个部分的知识请看我的另外一篇文章用户态 内核态 我在这儿把重点列一下 操作系统启动之后的第一个进程是 kernel (操作系统内核) kernel 会注册 GDT kernel 运行在 Range0 级别，用户进程运行在 Range3 级别 内核 控制着计算机硬件资源（eg：磁盘，网卡） 用户进程需要进行 磁盘读写、网络通信等io事件的时候需要通过系统调用来实现，这个时候进程从 Ring3 切换到 Ring0 级别，完成相应的操作之后再切回 Ring3 除去上面说说的 io 事件需要进行 用户态 &amp; 内核态 的切换，例如申请内存之类的也是需要的 服务器架构图（无论什么语言） 系统调用 socket 得到一个文件描述符fd5 系统调用 bind 一个端口 系统调用 listen 文件描述符fd5 系统调用 accept(阻塞） fd5 接受连接，返回一个新的文件描述符 fd6，代表与客户端的连接 系统调用 read/rerecvfrom fd6 读取数据 五种 IO 模型 在神作《UNIX 网络编程》里，总结归纳了 5 种 I/O 模型，包括同步和异步 I/O： 阻塞 I/O (Blocking I/O) 非阻塞 I/O (Nonblocking I/O) I/O 多路复用 (I/O multiplexing) 信号驱动 I/O (Signal driven I/O) 异步 I/O (Asynchronous I/O) 操作系统上的 I/O 是用户空间和内核空间的数据交互，因此 I/O 操作通常包含以下两个步骤： 等待网络数据到达网卡(读就绪)/等待网卡可写(写就绪) –&gt; 读取/写入到内核缓冲区 从内核缓冲区复制数据 –&gt; 用户空间(读)/从用户空间复制数据 -&gt; 内核缓冲区(写) 而判定一个 I/O 模型是同步还是异步，主要看第二步：数据在用户和内核空间之间复制的时候是不是会阻塞当前进程，如果会，则是同步 I/O，否则，就是异步 I/O。基于这个原则，这 5 种 I/O 模型中只有一种异步 I/O 模型：Asynchronous I/O，其余都是同步 I/O 模型。 这 5 种 I/O 模型的对比如下： Bio block io 同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。 采用 BIO 通信模型 的服务端，通常由一个独立的 Acceptor 线程负责监听客户端的连接。我们一般通过在while(true) 循环中服务端会调用 accept() 方法等待接收客户端的连接的方式监听请求，请求一旦接收到一个连接请求，就可以建立通信套接字在这个通信套接字上进行读写操作，此时不能再接收其他客户端连接请求，只能等待同当前连接的客户端的操作执行完成， 不过可以通过多线程来支持多个客户端的连接，如上图所示。 123456789101112131415// 新建socketsocket = new Socket();for &#123; // socket 监听连接 conn = socket.accept(); // 单独的线程去处理这个连接 go func() &#123; for &#123; data = conn.read(); // logic conn.write(ret_data); &#125; &#125;&#125; Bio 中的问题？ 线程数量太多，创建线程也需要走系统调用clone出来，走软中断，系统调用多 线程消耗计算机资源：线程栈是独立的，堆是共享的 CPU在某个时间点只可以有一个线程执行，线程多的话会造成频繁切换 Bio 如何优化？ 总的来说，bio模型中就是因为 socket 是阻塞的模式，导致需要多线程去解决 系统调用 socket 也可以设置成 NONBLOCK（每次系统调用不阻塞，有数据返回数据，没数据直接返回） 这就有了后面的nio，一个线程就可以解决n多客户端的连接问题 Nio 有人称它为 new io, 也有人称为 non-block io 一种同步非阻塞的I/O模型 不用开设很多线程，是对 bio 的优化 nio 的问题是什么？ C10K/C100K 问题 ：很多客户端连接时候的问题，如果有1w个客户端，每次循环会依次去查询这1w个socket是否有数据 每次循环会有 O(n) 级别的系统调用（SC），但是可能只有 10 个连接中有数据，大量的系统调用，而且大部分都是无数据的 nio 如何优化？ 比如 n 个连接中有 m 个 socket 有数据，将原本 O(n) 级别的系统调用降低到 O(m) 级别？ 系统内核增加了一个系统调用 select Select 多路复用器（多条路/多个连接 复用了同一个系统调用） 同步模型 ： 多路复用器只是返回一个fd状态，具体的读/写还是得进程自己去操作，所以说是同步的 该系统调用允许程序监控一个/多个文件描述符，直到一个/多个文件描述符变成可用状态 1select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, const struct timespec *timeout, const sigset_t *sigmask); 在这种模型之下，服务器的模式就变成这样： 有1w个连接（1w个文件描述符），通过 select 系统调用返回可用的文件描述符 -&gt; 时间复杂度为O(1) 对于可用的m个文件描述符，进行读操作 -&gt; 时间复杂度为O(m) select 的问题是什么？ 假如有1w个连接（1w个文件描述符），每次循环一次调用一次selelct，每次select我需要将这一万个文件描述符传进去，内核对这1w个fd进行遍历，时间复杂度为 O(n)，但这与nio中的 O(n) 不同，后者是 O(n) 次系统调用。 每次 select 都需要大量传值（1w个fd） 每次 select 内核都需要 O(n) 的遍历 select 如何优化？ 如果内核中可以开辟一个空间，服务器每次 accept 到一个连接（产生一个文件描述符fd），服务器将fd传入内核，让内核保存，这样就可以减少传递的过程 内核事件驱动模式，网卡收到数据，内核将这些 fd 进行标记，后续服务器通过系统调用得到这些有数据的fd即可 上面说的这种事件驱动的实现是通过中断来实现 kernel 会为硬件驱动在内存中开辟 DMA 空间 网卡收到数据，会将数据放到 DMA 空间中 网卡通过硬中断，中断CPU，让CPU去 DMA 空间中读取数据，得到哪个文件描述符（哪个socket）有数据 这样内核就可以直到哪些 fd 中有数据 总的来说，上述的两点分别解决了select的 问题2 &amp; 问题3，为此，系统内核增加了系统调用 epoll epoll event poll 同步模型 ： 多路复用器只是返回一个fd状态，具体的读/写还是得进程自己去操作，所以说是同步的 多路复用器（多条路/多个连接 复用了同一个系统调用）1234#include &lt;sys/epoll.h&gt; int epoll_create(int size); // int epoll_create1(int flags);int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); epoll 使用的流程 通过 epoll_create 系统调用在内核创建一块区域，返回一个 fd 当有 连接建立/连接断开，通过 epoll_ctl 系统调用来对内核的这块空间进行修改 每次循环通过 epoll_wait 来获取网络数据/事件 epoll 的边缘触发(ET)和水平触发(LT) epoll的默认模式是水平触发。 先大概了解一下这两种触发模式有什么不同： 水平触发(Level Trigger,也称条件触发)：只要满足条件,就触发一个事件(只要有数据还未读完,就会一直触发) 边缘触发(Edge Trigger)：每当状态发生变化时就触发一个事件。 ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。 可能概念不容易理解,这里举一个例子大概就能明白两者的区别了：比如某个人让你去买几袋酱油,你只买了一袋回去,水平触发的做法就是他让你继续去把剩下的几袋酱油买回来,如果没有完成任务,就一直通知你;边缘触发的做法就是不管完没完成任务,反正他让你买了,买没买完就是你自己的事了,下次买酱油这件事他就不管了,会让你去做其它的事。 当我们使用边缘触发时,将对应的文件描述符设置为非阻塞即可。 因为 read 的时候可能一次性读不完，需要多次读数据,也就是一直读，直到读到EGAIN(EGAIN说明缓冲区已经空了)为止，如果是阻塞的话，会导致整个线程阻塞 设置方法 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); epoll的事件注册函数，它不同与select()是在监听事件时告诉内核要监听什么类型的事件，而是在这里先注册要监听的事件类型。 第一个参数是epoll_create()的返回值， 第二个参数表示动作，用三个宏来表示： EPOLL_CTL_ADD：注册新的fd到epfd中； EPOLL_CTL_MOD：修改已经注册的fd的监听事件； EPOLL_CTL_DEL：从epfd中删除一个fd； 第三个参数是需要监听的fd，第四个参数是告诉内核需要监听什么事，struct epoll_event结构如下： 1234struct epoll_event &#123;__uint32_t events; /* Epoll events /epoll_data_t data; / User data variable */&#125;; events可以是以下几个宏的集合： EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）； EPOLLOUT：表示对应的文件描述符可以写； EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）； EPOLLERR：表示对应的文件描述符发生错误； EPOLLHUP：表示对应的文件描述符被挂断； EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。 EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里。 小结 综合一下上面所说的几种网络模型，有这样的一个问题：不同网络模型中，CPU在执行什么？ select ： 部分时间是在调用select之后遍历fds，这部分时间就无法执行业务代码 epoll ：cpu无需遍历fds，只有在中断的时候（必定有数据到达）才去读数据 -&gt; 尽量不浪费cpu 几个IO相关的应用redis redis是nonblick的（轮询的），而 nginx 是阻塞的 redis 只有一个线程，这个线程除去要干io的事情需要干很多其他的事情（eg：客户端请求、LRU，LFU 的淘汰过滤、RDB/AOF） nginx 就是等待客户端请求，在进行后续操作，没有其他的工作 redis 是单线程，串行化 redis 使用了 epoll 解决io消息事件的问题，即无论多少连接，epoll会告诉我去读/写哪些fds 在redis 6.0 之前是纯单线程版本，一个线程不仅仅完成io数据的读写，还需要完成计算，并且返回客户端 redis 6.x 之后引入了多线程（IO threads） 通过epoll拿到多个可读写的fds redis允许多线程去读io（可以充分发挥CPU多核性能） 但是读取到数据之后的计算操作依旧是有同一个线程去完成的（保证了操作的原子性+串行化） 完成计算之后，需要返回客户端，这部操作可以由其他的线程完成 kafka 零拷贝（前提：数据不需要加工，数据就是我磁盘中的某个文件） 消息队列，支持持久化(存磁盘) 由于需要存磁盘，绕不开 kernel kafka 是分 segment 的，每一个 segment 的大小可以配置，每一个 segment 就是对于一个磁盘文件 生产者发送数据 通过 epoll + recvfrom/read系统调用 获取数据，给数据加头部 写数据的时候，如果直接通过 kernel，需要走系统调用，消耗很大 通过 mmap 系统调用完成 其实就是使用 kernel 的缓存页 消费者取数据 读取数据，kafka发现数据在磁盘中，一般流程是这样的： kafka进程通过系统调用去读磁盘，获得数据 kafka进程再通过 write系统调用 将数据写到socket中 有两次系统调用 kafka其实是通过另外一个系统调用 sendfile 1ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count); 通过上述系统调用，直接将两个 fd 传入（磁盘文件，socket），直接将数据发出 nginx 也使用了 sendfile","categories":[{"name":"jewellery","slug":"jewellery","permalink":"https://overtalk.site/categories/jewellery/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://overtalk.site/tags/linux/"},{"name":"io","slug":"io","permalink":"https://overtalk.site/tags/io/"}]},{"title":"随笔 - 开个好头","slug":"essay-20-4-12","date":"2020-04-12T17:31:30.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/04/12/essay-20-4-12/","link":"","permalink":"https://overtalk.site/2020/04/12/essay-20-4-12/","excerpt":"","text":"有关博客内容的一些想法 开始写博客也已经大半年了，看到文章数量蹭蹭的向上涨还是很开心的！ 在自己写的同时也一直有关注很多大佬的博客，给我最直观的感受是我写的东西不够深入，层次不够高。 就目前而言，我可能更加侧重于 语言层面的细节/第三方库 多一点，这部分的东西是干货，毕竟一些第三方库拿来就可以直接用，可以直接解决某个业务场景，但是如果一直停留在这个层次我觉得是不够的，时间久了不就成了CRUD Boy 了嘛。 近些日子的一些感悟 在这儿我真的很感谢 Nick大佬，虽然他没有直接教我写代码，但是平日里和他的交流就拔高了我的眼界层次，和优秀的人在一起你就会优秀起来。 我需要站在更高的层面去看待编程这件事，深入了解一些底层的通用设计，那些都是最精华的部分。虽然现在容器化技术大火，随便找个人都会和你聊到 k8s、servicemesh，甚至 severless 。这些东是时代发展的产物，确实解决了很多问题，很有了解学习的必要。但我觉得一些老而经典的东西（例如 : epoll、csp模型…）也是很值得我们去学习的。 拿近来蛮火爆的Go语言来说，其中的 goroutine 和 channel 的设计就是基于CSP模型的；goroutine的设计也是基于coroutine的。这些老而经典的东西确实值得去学习，它们是一种正确的指导思想，了解这些之后再回头看GO的设计，会有一种新的领悟。 最近我会抽时间把已经写了的文章进行整合，偏语言的东西会精简一下，可以合并的进行合并，不过我估计这个过程可能会持续蛮久的，毕竟这是个很无聊的工作😂。 第一次写随笔，以后多写写这种吧。总是写技术方面的东西感觉我就是一个没有思想的工具人，然而并不是这样😂，虽然程序员这个行业的从业者有一部分或者很大一部分的人都是技术至上的思想（“老子技术好就是流弊，再做的各位都是辣鸡”），然而实际上并不是这样，作为一名程序员，我希望大家都不要有这样的想法吧，毕竟在老板/资本看来，技术只是个工具而已，除去技术之外还有更多需要考虑的问题。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://overtalk.site/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://overtalk.site/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"go 深入剖析slice和array [精简版]","slug":"go-slice-1","date":"2020-04-12T16:41:09.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/04/12/go-slice-1/","link":"","permalink":"https://overtalk.site/2020/04/12/go-slice-1/","excerpt":"","text":"以前写过一篇关于 golang 中 slice &amp; array 的介绍，但是我觉得写的太复杂了，很多特性是日常开发中用不到的，今天就来精简一下 本文就挑几个重要的部分来讲 1. Slice 的本质 slice 是一种特殊的数据结构，如下： 12345type slice struct &#123; array unsafe.Pointer len int cap int&#125; 所以一般声明slice之后，使用 unsafe.Sizeof() 函数打印出来的大小应该是 24 (在64位机器上) 12slice1 := []int&#123;1, 2, 3, 4, 5&#125;fmt.Println(\"size of []int is : \", unsafe.Sizeof(slice1)) // 24 2. Array 不是指针 Go 语言的数组不同于 C/C++ 语言或者其他语言的数组，C/C++ 语言的数组变量是指向数组第一个元素的指针； 而 Go 语言的数组是一个值，Go 语言中的数组是值类型，一个数组变量就表示着整个数组。 意味着 Go 语言的数组在传递的时候，传递的是原数组的拷贝。 如果有必要可以传指针 *[4]int，不过感觉这样用的比较少，毕竟大多是用 slice 😂12345678910111213141516171819202122232425func modifyArr(arr1 [4]int) &#123; arr1[0] = 23 fmt.Println(\"in modify arr func, arr = \", arr1) // in modify arr func, arr = [23 2 3 4]&#125;func main() &#123; arr1 := [4]int&#123;1, 2, 3, 4&#125; fmt.Println(\"before modify, arr = \",arr1) // before modify, arr = [1 2 3 4] modifyArr(arr1) fmt.Println(\"after modify, arr = \",arr1) // after modify, arr = [1 2 3 4]&#125;``` ## 3. “切片”现有切片- 名字起得好，观众少不了 😂- 通过“切片”`现有切片或数组 (没错，数组也可以切切切)`来形成切片。 通过指定半开放范围来完成切片，其中两个索引用冒号分隔。 例如，表达式b [1：4]创建包括b的元素1到3的切片（得到的切片的索引将是0到2）。- 注意通过👆上面方法切出来的 `子切片` 和 `原切片` 共享同一个内存空间哦，下面仔细说说 1. 下面的例子中，`b` 的 `len` 和 `cap` 都是6，`b1` 的 `len` 和 `cap` 分别是 2 和 5 2. 这样就有一个特殊的情况：如果向 `b1` append 一个数据，由于 `cap(b1)=5`，这个时候是不会发生扩容的，因此 `b` 也会收到影响 3. 像上面这样切出来的 `子切片` 和 `原切片`，任意一个发生扩容的话，就不会互相影响了- 感觉上面 `2` 中说的情况可以出一个面试题 😂```gob := []byte&#123;'g', 'o', 'l', 'a', 'n', 'g'&#125; // len = 6, cap = 6b1 = b[1:4] // sharing the same storage as b， len = 2, cap = 5 copy 如果不想 子切片 和 原切片 互相作用的话，就直接使用 copy 即可1copy( destSlice, srcSlice []T) int 1234slice1 := []int&#123;1, 2, 3, 4, 5&#125;slice2 := []int&#123;5, 4, 3&#125;copy(slice2, slice1) // 只会复制slice1的前3个元素到slice2中copy(slice1, slice2) // 只会复制slice2的3个元素到slice1的前3个位置 3. 切片的 nil 值 感觉这一块也是知道就行，实际生产过程中涉及不到，面试可能会问（就是那种比较变态的面试官😂） slice 有三种状态：零切片、空切片、nil切片。 零切片 就是其元素值都是元素类型的零值的切片，如下所示：12s := make([]int, 9, 10)fmt.Println(s) // 9 10 [0 0 0 0 0 0 0 0 0] 空切片 就是数组指针不为nil，且 slice 的长度为0。 空切片可以理解就是切片的长度为0，就是说 slice 没有元素。 社区大多数解释空切片为引用底层数组为 zerobase 这个特殊的指针。但是从操作上看空切片所有的表现就是切片长度为0，如果容量也为零底层数组就会指向 zerobase ，这样就不会发生内存分配， 如果容量不会零就会指向底层数据，会有内存分配。123456789101112131415161718192021222324252627var s []ints1 := make([]int, 0)s2 := make([]int, 0, 0)s3 := make([]int, 0, 100)arr := [10]int&#123;&#125;s4 := arr[:0]fmt.Println(*(*reflect.SliceHeader)(unsafe.Pointer(&amp;s))) // &#123;0 0 0&#125;fmt.Println(s) // []fmt.Println(s == nil) // truefmt.Println(*(*reflect.SliceHeader)(unsafe.Pointer(&amp;s1))) // &#123;18438904 0 0&#125;fmt.Println(s1) // []fmt.Println(s1 == nil) // falsefmt.Println(*(*reflect.SliceHeader)(unsafe.Pointer(&amp;s2))) // &#123;18438904 0 0&#125;fmt.Println(s2) // []fmt.Println(s2 == nil) // falsefmt.Println(*(*reflect.SliceHeader)(unsafe.Pointer(&amp;s3))) // &#123;824634277888 0 100&#125;fmt.Println(s3) // []fmt.Println(s3 == nil) // falsefmt.Println(*(*reflect.SliceHeader)(unsafe.Pointer(&amp;s4))) // &#123;824633835680 0 10&#125;fmt.Println(s4) // []fmt.Println(s4 == nil) // false 以上示例中除了 s 其它的 slice 都是空切片，打印出来全部都是 []，s 是nil切片下一小节说。 要注意 s1 和 s2 的长度和容量都为0，且引用数组指针都是 18349960， 这点太重要了，因为他们都指向 zerobase 这个特殊的指针，是没有内存分配的。 nil切片 就是引用底层数组指针为 nil 的 slice。 什么是nil切片，这个名字说明nil切片没有引用任何底层数组，底层数组的地址为nil就是nil切片。 上一小节中的 s 就是一个nil切片，它的底层数组指针为0，代表是一个 nil 指针。 总结 操作上零切片、空切片和正常的切片都没有任何区别，但是nil切片会多两个特性，一个nil切片等于 nil 值，且进行 json 序列化时其值为 null，nil切片还可以通过赋值为 nil 获得。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"并发模型：Actors 与 CSP","slug":"async-actor-and-csp","date":"2020-04-12T16:07:06.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/04/12/async-actor-and-csp/","link":"","permalink":"https://overtalk.site/2020/04/12/async-actor-and-csp/","excerpt":"","text":"转自敬维 转自C++爱好者博客 写在前面 常见的七种并发模型：线程与锁，函数式编程，Clojure，Actor，通信顺序进程（CSP），数据级并行，Lambda架构。 这篇博文把Actor和CSP两种模型简单介绍一下。 Actors模型 传统的并发模型主要由两种实现的形式： 一是同一个进程下，多个线程天然的共享内存，由程序对读写做同步控制(有锁或无锁). 二是多个进程通过 进程间通讯 或者 内存映射 实现数据的同步. Actors模型更多的使用消息机制来实现并发，目标是让开发者不再考虑线程这种东西，每个Actor最多同时只能进行一样工作，Actor内部可以有自己的变量和数据. Actors模型避免了由操作系统进行任务调度的问题，在操作系统进程之上，多个Actor可能运行在同一个进程(或线程)中.这就节省了大量的Context切换. Actor模型，顾名思义，侧重的是Actor。每个Actor与其他Actor进行直接通信，不经过中介，且消息时异步发送和处理的。 123Actor1 --&gt; Actor2 --&gt; Actor3 ↓Actor4 这里隐含着这几种意思： 可以把每个过程（微进程，比如Elixir中的Process）当做一个Actor，能与其他的Actor互不干扰地并发运行。 如果Actor1想作用Actor2，必须通过发送消息的方式给Actor2发送”邮件“（地址直接填Actor2的地址），至于Actor2是否接受这份”邮件“，是Actor2的事情。 每个Actor有一个小邮箱，任意Actor可以向自己的地址发送的信息都会放置在这个邮箱里；信息的投递和读取是两个过程，这就把Actor之间的交互解耦了。 如果Actor1想给Actor4发送信息，必须要显式地把Actor4的地址（指针或者其他能找到Actor4的柄）给Actor1，否则Actor1是不知道把信息传到哪里去的。因此，如果用Actor模型编写代码，会有很多过程的Id要传递，顺理成章地也就有了父进程和子进程的说法。 CSP模型 CSP是 Communicating Sequential Processes(通信顺序进程) 的简称。 1Worker1 --&gt; Channel --&gt; Worker2 在CSP中，多了一个角色Channel，过程（比如goroutine，Worker1）与过程（Worker2）之间不直接通信，而是通过Channle进行通信。 这里面也隐含着几种意思： Channel是过程的中间媒介，Worker1想要跟Worker2发信息时，直接把信息放到Channel里（在程序中其实就是一块内存），然后Worker2在方便的时候到Channel里获取。 Worker1和Worker2之间可以存在很多个Channel；在Golang中每个Channel定义不同的数据类型，即发送不同类型的消息的时候会用到多个不同的Channel。 比较 和Actor模型比，CSP的Worker身上没有冗余的“信箱”；CSP模型把省下的内存空间都用来声明Channel了，所以不能说那种模型更节省内存。 Actor模型假设Actor之间是经常有通信的，把“小邮箱”安装在每个Actor的身上，更适合用来进行高并发通信的场合，比如Erlang、Elixir。 CSP模型，在解耦Worker之间通信的同时，提升了Worker的性能（没有小邮箱了，设计时不用考虑），比如Golang。 目前Golang（CSP模型）比Erlang以及Elixir（Actor模型）更火，后者比前者要小众一些。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://overtalk.site/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"彻底弄懂IO这件事情 - I/O 多路复用(select，poll，epoll)","slug":"io-multiplexing","date":"2020-04-09T09:46:16.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/04/09/io-multiplexing/","link":"","permalink":"https://overtalk.site/2020/04/09/io-multiplexing/","excerpt":"","text":"转自潘建锋 所谓 I/O 多路复用指的就是 select/poll/epoll 这一系列的多路选择器：支持单一线程同时监听多个文件描述符（I/O 事件），阻塞等待，并在其中某个文件描述符可读写时收到通知。 I/O 复用其实复用的不是 I/O 连接，而是复用线程，让一个 thread of control 能够处理多个连接（I/O 事件）。 select &amp; poll1234567891011121314#include &lt;sys/select.h&gt;/* According to earlier standards */#include &lt;sys/time.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);// 和 select 紧密结合的四个宏：void FD_CLR(int fd, fd_set *set);int FD_ISSET(int fd, fd_set *set);void FD_SET(int fd, fd_set *set);void FD_ZERO(fd_set *set); select 是 epoll 之前 Linux 使用的 I/O 事件驱动技术。 理解 select 的关键在于理解 fd_set，为说明方便，取 fd_set 长度为 1 字节，fd_set 中的每一 bit 可以对应一个文件描述符 fd，则 1 字节长的 fd_set 最大可以对应 8 个 fd。select 的调用过程如下： 执行 FD_ZERO(&amp;set), 则 set 用位表示是 0000,0000 若 fd＝5, 执行 FD_SET(fd, &amp;set); 后 set 变为 0001,0000(第 5 位置为 1) 再加入 fd＝2, fd=1，则 set 变为 0001,0011 执行 select(6, &amp;set, 0, 0, 0) 阻塞等待 若 fd=1, fd=2 上都发生可读事件，则 select 返回，此时 set 变为 0000,0011 (注意：没有事件发生的 fd=5 被清空) 基于上面的调用过程，可以得出 select 的特点： 可监控的文件描述符个数取决于 sizeof(fd_set) 的值。假设服务器上 sizeof(fd_set)＝512，每 bit 表示一个文件描述符，则服务器上支持的最大文件描述符是 512*8=4096。fd_set 的大小调整可参考 【原创】技术系列之 网络模型（二） 中的模型 2，可以有效突破 select 可监控的文件描述符上限 将 fd 加入 select 监控集的同时，还要再使用一个数据结构 array 保存放到 select 监控集中的 fd，一是用于在 select 返回后，array 作为源数据和 fd_set 进行 FD_ISSET 判断。二是 select 返回后会把以前加入的但并无事件发生的 fd 清空，则每次开始 select 前都要重新从 array 取得 fd 逐一加入（FD_ZERO 最先），扫描 array 的同时取得 fd 最大值 maxfd，用于 select 的第一个参数 可见 select 模型必须在 select 前循环 array（加 fd，取 maxfd），select 返回后循环 array（FD_ISSET 判断是否有事件发生） 所以，select 有如下的缺点： 最大并发数限制：使用 32 个整数的 32 位，即 32*32=1024 来标识 fd，虽然可修改，但是有以下第 2, 3 点的瓶颈 每次调用 select，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大 性能衰减严重：每次 kernel 都需要线性扫描整个 fd_set，所以随着监控的描述符 fd 数量增长，其 I/O 性能会线性下降 poll 的实现和 select 非常相似，只是描述 fd 集合的方式不同，poll 使用 pollfd 结构而不是 select 的 fd_set 结构，poll 解决了最大文件描述符数量限制的问题，但是同样需要从用户态拷贝所有的 fd 到内核态，也需要线性遍历所有的 fd 集合，所以它和 select 只是实现细节上的区分，并没有本质上的区别。 epoll epoll 是 Linux kernel 2.6 之后引入的新 I/O 事件驱动技术，I/O 多路复用的核心设计是 1 个线程处理所有连接的 等待消息准备好 I/O 事件，这一点上 epoll 和 select&amp;poll 是大同小异的。但 select&amp;poll 错误预估了一件事，当数十万并发连接存在时，可能每一毫秒只有数百个活跃的连接，同时其余数十万连接在这一毫秒是非活跃的。select&amp;poll 的使用方法是这样的： 返回的活跃连接 == select(全部待监控的连接) 。 什么时候会调用 select&amp;poll 呢？在你认为需要找出有报文到达的活跃连接时，就应该调用。所以，select&amp;poll 在高并发时是会被频繁调用的。这样，这个频繁调用的方法就很有必要看看它是否有效率，因为，它的轻微效率损失都会被 高频 二字所放大。它有效率损失吗？显而易见，全部待监控连接是数以十万计的，返回的只是数百个活跃连接，这本身就是无效率的表现。被放大后就会发现，处理并发上万个连接时，select&amp;poll 就完全力不从心了。这个时候就该 epoll 上场了，epoll 通过一些新的设计和优化，基本上解决了 select&amp;poll 的问题。 epoll 的 API 非常简洁，涉及到的只有 3 个系统调用： 1234#include &lt;sys/epoll.h&gt; int epoll_create(int size); // int epoll_create1(int flags);int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); 其中，epoll_create 创建一个 epoll 实例并返回 epollfd；epoll_ctl 注册 file descriptor 等待的 I/O 事件(比如 EPOLLIN、EPOLLOUT 等) 到 epoll 实例上；epoll_wait 则是阻塞监听 epoll 实例上所有的 file descriptor 的 I/O 事件，它接收一个用户空间上的一块内存地址 (events 数组)，kernel 会在有 I/O 事件发生的时候把文件描述符列表复制到这块内存地址上，然后 epoll_wait 解除阻塞并返回，最后用户空间上的程序就可以对相应的 fd 进行读写了： 123#include &lt;unistd.h&gt;ssize_t read(int fd, void *buf, size_t count);ssize_t write(int fd, const void *buf, size_t count); epoll 的工作原理如下： 与 select&amp;poll 相比，epoll 分清了高频调用和低频调用。例如，epoll_ctl 相对来说就是非频繁调用的，而 epoll_wait 则是会被高频调用的。所以 epoll 利用 epoll_ctl 来插入或者删除一个 fd，实现用户态到内核态的数据拷贝，这确保了每一个 fd 在其生命周期只需要被拷贝一次，而不是每次调用 epoll_wait 的时候都拷贝一次。 epoll_wait 则被设计成几乎没有入参的调用，相比 select&amp;poll 需要把全部监听的 fd 集合从用户态拷贝至内核态的做法，epoll 的效率就高出了一大截。 在实现上 epoll 采用红黑树来存储所有监听的 fd，而红黑树本身插入和删除性能比较稳定，时间复杂度 O(logN)。通过 epoll_ctl 函数添加进来的 fd 都会被放在红黑树的某个节点内，所以，重复添加是没有用的。当把 fd 添加进来的时候时候会完成关键的一步：该 fd 会与相应的设备（网卡）驱动程序建立回调关系，也就是在内核中断处理程序为它注册一个回调函数，在 fd 相应的事件触发（中断）之后（设备就绪了），内核就会调用这个回调函数，该回调函数在内核中被称为： ep_poll_callback ，这个回调函数其实就是把这个 fd 添加到 rdllist 这个双向链表（就绪链表）中。epoll_wait 实际上就是去检查 rdlist 双向链表中是否有就绪的 fd，当 rdlist 为空（无就绪 fd）时挂起当前进程，直到 rdlist 非空时进程才被唤醒并返回。 相比于 select&amp;poll 调用时会将全部监听的 fd 从用户态空间拷贝至内核态空间并线性扫描一遍找出就绪的 fd 再返回到用户态，epoll_wait 则是直接返回已就绪 fd，因此 epoll 的 I/O 性能不会像 select&amp;poll 那样随着监听的 fd 数量增加而出现线性衰减，是一个非常高效的 I/O 事件驱动技术。 由于使用 epoll 的 I/O 多路复用需要用户进程自己负责 I/O 读写，从用户进程的角度看，读写过程是阻塞的，所以 select&amp;poll&amp;epoll 本质上都是同步 I/O 模型，而像 Windows 的 IOCP 这一类的异步 I/O，只需要在调用 WSARecv 或 WSASend 方法读写数据的时候把用户空间的内存 buffer 提交给 kernel，kernel 负责数据在用户空间和内核空间拷贝，完成之后就会通知用户进程，整个过程不需要用户进程参与，所以是真正的异步 I/O。 延伸 另外，我看到有些文章说 epoll 之所以性能高是因为利用了 Linux 的 mmap 内存映射让内核和用户进程共享了一片物理内存，用来存放就绪 fd 列表和它们的数据 buffer，所以用户进程在 epoll_wait 返回之后用户进程就可以直接从共享内存那里读取/写入数据了，这让我很疑惑，因为首先看 epoll_wait 的函数声明： 1int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); 第二个参数：就绪事件列表，是需要在用户空间分配内存然后再传给 epoll_wait 的，如果内核会用 mmap 设置共享内存，直接传递一个指针进去就行了，根本不需要在用户态分配内存，多此一举。其次，内核和用户进程通过 mmap 共享内存是一件极度危险的事情，内核无法确定这块共享内存什么时候会被回收，而且这样也会赋予用户进程直接操作内核数据的权限和入口，非常容易出现大的系统漏洞，因此一般极少会这么做。所以我很怀疑 epoll 是不是真的在 Linux kernel 里用了 mmap，我就去看了下最新版本（5.3.9）的 Linux kernel 源码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/* * Implement the event wait interface for the eventpoll file. It is the kernel * part of the user space epoll_wait(2). */static int do_epoll_wait(int epfd, struct epoll_event __user *events, int maxevents, int timeout)&#123; // ... /* Time to fish for events ... */ error = ep_poll(ep, events, maxevents, timeout);&#125;// 如果 epoll_wait 入参时设定 timeout == 0, 那么直接通过 ep_events_available 判断当前是否有用户感兴趣的事件发生，如果有则通过 ep_send_events 进行处理// 如果设置 timeout &gt; 0，并且当前没有用户关注的事件发生，则进行休眠，并添加到 ep-&gt;wq 等待队列的头部；对等待事件描述符设置 WQ_FLAG_EXCLUSIVE 标志// ep_poll 被事件唤醒后会重新检查是否有关注事件，如果对应的事件已经被抢走，那么 ep_poll 会继续休眠等待static int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, long timeout)&#123; // ... send_events: /* * Try to transfer events to user space. In case we get 0 events and * there's still timeout left over, we go trying again in search of * more luck. */ // 如果一切正常, 有 event 发生, 就开始准备数据 copy 给用户空间了 // 如果有就绪的事件发生，那么就调用 ep_send_events 将就绪的事件 copy 到用户态内存中， // 然后返回到用户态，否则判断是否超时，如果没有超时就继续等待就绪事件发生，如果超时就返回用户态。 // 从 ep_poll 函数的实现可以看到，如果有就绪事件发生，则调用 ep_send_events 函数做进一步处理 if (!res &amp;&amp; eavail &amp;&amp; !(res = ep_send_events(ep, events, maxevents)) &amp;&amp; !timed_out) goto fetch_events; // ...&#125;// ep_send_events 函数是用来向用户空间拷贝就绪 fd 列表的，它将用户传入的就绪 fd 列表内存简单封装到// ep_send_events_data 结构中，然后调用 ep_scan_ready_list 将就绪队列中的事件写入用户空间的内存；// 用户进程就可以访问到这些数据进行处理static int ep_send_events(struct eventpoll *ep, struct epoll_event __user *events, int maxevents)&#123; struct ep_send_events_data esed; esed.maxevents = maxevents; esed.events = events; // 调用 ep_scan_ready_list 函数检查 epoll 实例 eventpoll 中的 rdllist 就绪链表， // 并注册一个回调函数 ep_send_events_proc，如果有就绪 fd，则调用 ep_send_events_proc 进行处理 ep_scan_ready_list(ep, ep_send_events_proc, &amp;esed, 0, false); return esed.res;&#125;// 调用 ep_scan_ready_list 的时候会传递指向 ep_send_events_proc 函数的函数指针作为回调函数，// 一旦有就绪 fd，就会调用 ep_send_events_proc 函数static __poll_t ep_send_events_proc(struct eventpoll *ep, struct list_head *head, void *priv)&#123; // ... /* * If the event mask intersect the caller-requested one, * deliver the event to userspace. Again, ep_scan_ready_list() * is holding ep-&gt;mtx, so no operations coming from userspace * can change the item. */ revents = ep_item_poll(epi, &amp;pt, 1); // 如果 revents 为 0，说明没有就绪的事件，跳过，否则就将就绪事件拷贝到用户态内存中 if (!revents) continue; // 将当前就绪的事件和用户进程传入的数据都通过 __put_user 拷贝回用户空间, // 也就是调用 epoll_wait 之时用户进程传入的 fd 列表的内存 if (__put_user(revents, &amp;uevent-&gt;events) || __put_user(epi-&gt;event.data, &amp;uevent-&gt;data)) &#123; list_add(&amp;epi-&gt;rdllink, head); ep_pm_stay_awake(epi); if (!esed-&gt;res) esed-&gt;res = -EFAULT; return 0; &#125; // ...&#125; 从 do_epoll_wait 开始层层跳转，我们可以很清楚地看到最后内核是通过 __put_user 函数把就绪 fd 列表和事件返回到用户空间，而 __put_user 正是内核用来拷贝数据到用户空间的标准函数。此外，我并没有在 Linux kernel 的源码中和 epoll 相关的代码里找到 mmap 系统调用做内存映射的逻辑，所以基本可以得出结论：epoll 在 Linux kernel 里并没有使用 mmap 来做用户空间和内核空间的内存共享，所以那些说 epoll 使用了 mmap 的文章都是误解。 Non-blocking I/O 什么叫非阻塞 I/O，顾名思义就是：所有 I/O 操作都是立刻返回而不会阻塞当前用户进程。I/O 多路复用通常情况下需要和非阻塞 I/O 搭配使用，否则可能会产生意想不到的问题。比如，epoll 的 ET(边缘触发) 模式下，如果不使用非阻塞 I/O，有极大的概率会导致阻塞 event-loop 线程，从而降低吞吐量，甚至导致 bug。 Linux 下，我们可以通过 fcntl 系统调用来设置 O_NONBLOCK 标志位，从而把 socket 设置成 non-blocking。当对一个 non-blocking socket 执行读操作时，流程是这个样子： 当用户进程发出 read 操作时，如果 kernel 中的数据还没有准备好，那么它并不会 block 用户进程，而是立刻返回一个 EAGAIN error。从用户进程角度讲 ，它发起一个 read 操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个 error 时，它就知道数据还没有准备好，于是它可以再次发送 read 操作。一旦 kernel 中的数据准备好了，并且又再次收到了用户进程的 system call，那么它马上就将数据拷贝到了用户内存，然后返回。 所以，non-blocking I/O 的特点是用户进程需要不断的主动询问 kernel 数据好了没有。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://overtalk.site/tags/linux/"},{"name":"io","slug":"io","permalink":"https://overtalk.site/tags/io/"},{"name":"epoll","slug":"epoll","permalink":"https://overtalk.site/tags/epoll/"}]},{"title":"go 类型断言的消耗","slug":"go-type-transform","date":"2020-04-09T09:20:56.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/04/09/go-type-transform/","link":"","permalink":"https://overtalk.site/2020/04/09/go-type-transform/","excerpt":"","text":"转载自达达的博客 在一些通用化的接口设计中，我们不得不用interface{}来代表任意类型，然后在接口内部用类型转换来判断具体类型，从而执行具体逻辑。但是类型判断是有性能代价的，如果能具像化的知道这个性能代价有多大，就可以帮助我们设计接口的时候判断应该怎么设计。 下面是实验代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package labs01import \"testing\"type InterfaceA interface &#123; AA()&#125;type InterfaceB interface &#123; BB()&#125;type A struct &#123; v int&#125;func (a *A) AA() &#123; a.v += 1&#125;type B struct &#123; v int&#125;func (b *B) BB() &#123; b.v += 1&#125;func TypeSwitch(v interface&#123;&#125;) &#123; switch v.(type) &#123; case InterfaceA: v.(InterfaceA).AA() case InterfaceB: v.(InterfaceB).BB() &#125;&#125;func NormalSwitch(a *A) &#123; a.AA()&#125;func InterfaceSwitch(v interface&#123;&#125;) &#123; v.(InterfaceA).AA()&#125;func Benchmark_TypeSwitch(b *testing.B) &#123; var a = new(A) for i := 0; i &lt; b.N; i++ &#123; TypeSwitch(a) &#125;&#125;func Benchmark_NormalSwitch(b *testing.B) &#123; var a = new(A) for i := 0; i &lt; b.N; i++ &#123; NormalSwitch(a) &#125;&#125;func Benchmark_InterfaceSwitch(b *testing.B) &#123; var a = new(A) for i := 0; i &lt; b.N; i++ &#123; InterfaceSwitch(a) &#125;&#125; 执行结果： 1234567dada-imac:misc dada$ go test -test.bench=\".*\" labs01testing: warning: no tests to runPASSBenchmark_TypeSwitch 50000000 33.0 ns/opBenchmark_NormalSwitch 2000000000 1.99 ns/opBenchmark_InterfaceSwitch 100000000 18.4 ns/opok labs 7.741s 结论：类型判断和类型转换这两个操作都比直接操作多几倍的消耗。","categories":[],"tags":[]},{"title":"go - fragment","slug":"fragment-go","date":"2020-04-03T10:22:54.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/04/03/fragment-go/","link":"","permalink":"https://overtalk.site/2020/04/03/fragment-go/","excerpt":"","text":"判断一个 struct 是否实现了某个 interface12345678910type IFace iterface &#123; Eat() string&#125;type Bird struct &#123; Eyes string Color int&#125;var _ IFace = new(Bird) 判断一个数是否为2的n次方1234// IsPowerOfTwo reports whether given integer is a power of two.func IsPowerOfTwo(n int) bool &#123; return n&amp;(n-1) == 0&#125; print 文件调用文件的路径12log.SetFlags(log.Llongfile)log.Println(111) How to best clear a slice: empty vs. nil yourbasic.org/golang Remove all elements To remove all elements, simply set the slice to nil. 123a := []string&#123;\"A\", \"B\", \"C\", \"D\", \"E\"&#125;a = nilfmt.Println(a, len(a), cap(a)) // [] 0 0 This will release the underlying array to the garbage collector (assuming there are no other references). Keep allocated memory To keep the underlying array, slice the slice to zero length.123a := []string&#123;\"A\", \"B\", \"C\", \"D\", \"E\"&#125;a = a[:0]fmt.Println(a, len(a), cap(a)) // [] 0 5 If the slice is extended again, the original data reappears.1fmt.Println(a[:2]) // [A B] Empty slice vs. nil slice In practice, nil slices and empty slices can often be treated in the same way: they can be used with the same effect in for loops and append functions, they have zero length and capacity, and they even look the same when printed.1234var a []int = nilfmt.Println(len(a)) // 0fmt.Println(cap(a)) // 0fmt.Println(a) // [] However, if needed, you can tell the difference. 12345678var a []int = nilvar a0 []int = make([]int, 0)fmt.Println(a == nil) // truefmt.Println(a0 == nil) // falsefmt.Printf(\"%#v\\n\", a) // []int(nil)fmt.Printf(\"%#v\\n\", a0) // []int&#123;&#125; The official Go wiki recommends using nil slices over empty slices. […] the nil slice is the preferred style. Note that there are limited circumstances where a non-nil but zero-length slice is preferred, such as when encoding JSON objects (a nil slice encodes to null, while []string{} encodes to the JSON array []). When designing interfaces, avoid making a distinction between a nil slice and a non-nil, zero-length slice, as this can lead to subtle programming errors.The Go wiki: Declaring empty slices","categories":[{"name":"fragment","slug":"fragment","permalink":"https://overtalk.site/categories/fragment/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"常见使用命令","slug":"command","date":"2020-04-02T10:08:34.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/04/02/command/","link":"","permalink":"https://overtalk.site/2020/04/02/command/","excerpt":"","text":"Git 相关 命令 用法 git reset HEAD~ 撤销本地的commit git commit --amend -m &quot;xxx&quot; 提交覆盖上一次提交记录和注释 git reset --hard commit_id 强制回退到上某次commit（文件&amp;commit记录都会被会退掉）, 一般再配合 push -f 使用回退到某个版本 git reset --soft commit_id 回退到上某次commit（commit记录都会被会退掉，但是文件不会被会退掉）, 通常使用在当你git commit -m “注释”提交了你修改的内容，但内容有点问题想撤销，又还要提交，就使用soft，相当于软着路 Linux 相关 命令 用法 `ps -ef grep hff sudo /sbin/ldconfig 重新寻找动态库（比如拷贝了一个新的动态库到机器上，需要执行这个命令） `find dir -name “*.txt” xargs rm -rf` nohup ./tcp-server &gt;&gt; /log.txt 2&gt;&amp;1 &amp; 后台启动并且将日志都重定向到 log.txt 中 man xxx(系统调用函数) 查看某个系统调用的文档（eg：man accept/socket/epoll） df -h 查看磁盘占用 du -shc * 查看当前目录所有 文件/文件夹 的大小 tar -zxvf ./×××.tar.gz 解压 ×××.tar.gz tar -jxvf ./×××.tar.bz2 解压 ×××.tar.bz2 tar -zcvf ./×××.tar.gz -C ./xxx 压缩 xxx文件夹 到 ×××.tar.gz tar -jcvf ./×××.tar.bz2 -C ./xxx 压缩 xxx文件夹 到 ×××.tar.bz2 nc 127.0.0.1 9090 与 127.0.0.1:9090 建立tcp连接 netstat -natp 打印Linux中网络的状态信息,命令参数 cat /proc/meminfo 查看内存信息 cat /proc/cpuinfo | grep &quot;physical id&quot; | sort | uniq | wc -l 查看物理的CPU数量 cat /proc/cpuinfo | grep &quot;cpu cores&quot; | uniq 查看CPU核数 cat /proc/cpuinfo | grep &quot;processor&quot; | wc -l 查看CPU线程数 cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 查看CPU型号 vim 的一些操作 命令 用法 /xxxx 搜索匹配的字符串（支持正则表达式） :1?XXXX 从文件末尾查找（ 1的意思是文件的第一行, ？的意思是反向查找,XXXX就是你要找的关键字） :set nu 显示行号 Docker 相关 命令 用法 docker rmi docker images | grep &quot;&lt;none&gt;&quot; | awk &#39;{print $3}&#39; 删除所有tag为none的镜像 docker build -t photon:udp -f ./Dockerfile . 编译镜像 docker run --name xxx -it photon:udp bash 运行容器 docker cp 本地文件路径 ID全称:容器路径 本地文件拷贝到运行的容器中 docker cp ID全称:容器文件路径 本地路径 运行的容器中文件拷贝到宿主机 docker run -it –rm … 运行一个容器，退出后自动删除 docker images | grep none | awk &#39;{print $3}&#39; | xargs docker rmi 删除没有tag的镜像 mac 的一些使用 mac 经常会使用 brew 安装一些软件，例如：mysql，redis，consul 等 可以使用以下的命令来启动/停止服务12345# 列出所有的servicebrew services listbrew services restart mysql@5.7brew services start mysql@5.7brew services stop mysql@5.7 顺道贴上一篇忘记 mysql 密码的解决方法","categories":[{"name":"jewellery","slug":"jewellery","permalink":"https://overtalk.site/categories/jewellery/"}],"tags":[{"name":"shell","slug":"shell","permalink":"https://overtalk.site/tags/shell/"},{"name":"docker","slug":"docker","permalink":"https://overtalk.site/tags/docker/"},{"name":"linux","slug":"linux","permalink":"https://overtalk.site/tags/linux/"},{"name":"git","slug":"git","permalink":"https://overtalk.site/tags/git/"}]},{"title":"c++ lambda 内 std::move 失效问题的思考","slug":"cpp-move","date":"2020-03-31T09:45:05.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/03/31/cpp-move/","link":"","permalink":"https://overtalk.site/2020/03/31/cpp-move/","excerpt":"","text":"转自编程沉思录 最近在写 C++ 时，有这样一个代码需求：在 lambda 中，将一个捕获参数 move 给另外一个变量。 看似一个很简单常规的操作，然而这个 move 动作却没有生效。 具体代码如下： 1234567std::vector&lt;int&gt; vec = &#123;1,2,3&#125;;auto func = [=]()&#123; auto vec2 = std::move(vec); std::cout &lt;&lt;vec.size() &lt;&lt; std::endl; // 输出：3 std::cout &lt;&lt;vec2.size() &lt;&lt; std::endl; // 输出：3&#125;; 我们期望的是，将对变量 vec 调用 std::move 后，数据将会移动至变量 vec2, 此时 vec 里面应该没有数据了。但是通过打印 vec.size() 发现 vec 中的数据并没有按预期移走。 这也就意味着，构造 vec2 时并没有按预期调用移动构造函数，而是调用了拷贝构造函数。 为什么会造成这个问题呢, 我们需要结合 std::move 和 lambda 的原理看下。 std::move 的本质 对于 std::move，有两点需要注意： std::move 中到底做了什么事情 std::move 是否可以保证数据一定能移动成功 对于第二点来说，答案显然是不能。这也是本文的问题所在。那么 std::move 实际上是做了什么事情呢？ 对于 std::move，其实现大致如下： 123456template&lt;typename T&gt;decltype(auto) move(T&amp;&amp; param)&#123; using ReturnType = remove_reference_t&lt;T&gt;&amp;&amp;; return static_cast&lt;ReturnType&gt;(param);&#125; 从代码可以看出，std::move 本质上是调用了 static_cast 做了一层强制转换，强制转换的目标类型是 remove_reference_t&lt;T&gt;&amp;&amp;，remove_reference_t 是为了去除类型本身的引用，例如左值引用。总结来说，std::move 本质上是将对象强制转换为了右值引用。 那么，为什么我们通常使用 std::move 实现移动语义，可以将一个对象的数据移给另外一个对象？ 这是因为 std::move 配合了移动构造函数使用，本质上是移动构造函数起了作用。移动构造函数的一般定义如下： 1234class A&#123;public: A(A &amp;&amp;);&#125;; 可以看到移动构造函数的参数就是个右值引用 A&amp;&amp;，因此 A a = std::move(b);, 本质上是先将 b 强制转化了右值引用 A&amp;&amp;, 然后触发了移动构造函数，在移动构造函数中，完成了对象 b 的数据到对象 a 的移动。 那么，在哪些情况下，A a = std::move(b); 会失效呢？ 显然是，当 std::move 强转后的类型不是 A&amp;&amp;，这样就不会命中移动构造函数。 例如： 12const std::string str = \"123\"std::string str2(std::move(str)); 这个时候，对 str 对象调用 std::move，强转出来的类型将会是 const string&amp;&amp;, 这样移动构造函数就不会起作用了，但是这个类型却可以令复制构造函数生效。 结合本文最初的问题，在 lambda 中 move 没有生效，显然也是 std::move 强转的类型不是 std::vector&lt;int&gt;&amp;&amp;, 才导致了没有 move 成功。 那么，为什么会出现这个问题呢，我们需要理解下 lambda 的工作原理。 lambda 闭包原理 对于 c++ 的 lambda，编译器会将 lambda 转化为一个独一无二的闭包类。而 lambda 对象最终会转化成这个闭包类的对象。 对于本文最初的这个 lambda 来说，最终实际上转化成了这么一个类型 1234567891011121314151617// 转换前auto func = [=]()&#123; auto vec2 = std::move(vec);&#125;;// 转换后class ClosureFunc&#123;public: void operator() const&#123; auto vec2 = std::move(vec); &#125;;private: std::vector&lt;int&gt; vec;&#125;;ClosureFunc func; 这里需要注意, lambda 的默认行为是，生成的闭包类的 operator() 默认被 const 修饰。 那么这里问题就来了，当调用 operator() 时, 该闭包类所有的成员变量也是被 const 修饰的，此时对成员变量调用 std::move 将会引发上文中提到的，强转出来的类型将会是 const string&amp;&amp; 问题。因此，移动构造函数将不会被匹配到。 我们最初的问题 lambda 中 std::move 失效的问题，也是因为这个原因。这也很符合 const 函数的语义: const 函数是不能修改成员变量的值。 解决方案 那么，这个应该怎么解决呢？答案是 mutable。即在 lambda 尾部声明一个 mutable，如下： 123auto func = [=]() mutable&#123; auto vec2 = std::move(vec);&#125;; 这样编译器生成的闭包类的 operator() 将会不带 const 了。我们的 std::move 也可以正常转换，实现移动语义了。 1234567std::vector&lt;int&gt; vec = &#123;1,2,3&#125;;auto func = [=]() mutable&#123; auto vec2 = std::move(vec); std::cout &lt;&lt;vec.size() &lt;&lt; std::endl; // 输出：0 std::cout &lt;&lt;vec2.size() &lt;&lt; std::endl; // 输出：3&#125;;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - bind","slug":"cpp-bind","date":"2020-03-30T12:46:23.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/03/30/cpp-bind/","link":"","permalink":"https://overtalk.site/2020/03/30/cpp-bind/","excerpt":"","text":"bind 作用 对可调用实体(函数指针，仿函数，lambda表达式)的一种封装，这种封装能起到预绑定参数的作用。 使用示例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include&lt;iostream&gt;#include&lt;functional&gt;void global_func(int a) &#123;//全局函数 std::cout &lt;&lt; \"call global_func:\" &lt;&lt; a &lt;&lt; std::endl;&#125;auto labmda = [](int a) &#123;std::cout &lt;&lt; \"lambda:\" &lt;&lt; a &lt;&lt; std::endl; &#125;;class ClassA &#123;public: void member_func(int a) &#123;//类成员函数 std::cout &lt;&lt; \"call ClassA::member_func:\" &lt;&lt; a &lt;&lt; std::endl; &#125; static void static_member_func(int a) &#123;//类静态函数 std::cout &lt;&lt; \"call ClassA::static_member_func:\" &lt;&lt; a &lt;&lt; std::endl; &#125;&#125;;class Functor &#123;//仿函数public: void operator()(int a) &#123; std::cout &lt;&lt; \"call Functor()\" &lt;&lt; a &lt;&lt; std::endl; &#125;&#125;;int main(int argc, const char* argv[]) &#123; std::function&lt;void(int)&gt; func; func = global_func; func(10); auto bindGlobalFunc = std::bind(global_func, 10); bindGlobalFunc(); func = labmda; func(11); auto bindLabmdaFunc = std::bind(labmda, 11); bindLabmdaFunc(); Functor testFunctor; func = testFunctor; func(12); auto bindFunctorFunc = std::bind(testFunctor, 12); bindFunctorFunc(); ClassA a_object; func = std::bind(&amp;ClassA::member_func, &amp;a_object, std::placeholders::_1); func(13); auto bindClassMemberFunc = std::bind(&amp;ClassA::member_func, &amp;a_object, 13); bindClassMemberFunc(); func = std::bind(&amp;ClassA::static_member_func, std::placeholders::_1); func(14); auto bindClassStaticFunc = std::bind(&amp;ClassA::static_member_func, 14); bindClassStaticFunc(); return 0;&#125; 输出结果：12345678910call global_func:10call global_func:10lambda:11lambda:11call Functor()12call Functor()12call ClassA::member_func:13，call ClassA::member_func:13call ClassA::static_member_func:14call ClassA::static_member_func:14 注意事项： 预绑定的参数是以**值传递**的形式 不预绑定的参数要用std::placeholders(占位符)的形式占位，从_1开始，依次递增，是以引用传递的形式 std::bind的返回值是可调用实体，可以直接赋给std::function 对于绑定的指针，引用类型参数，调用者需保证在调用之前生命周期还存在 std::placeholders表示新的可调用对象的第几个参数和原函数的第几个参数进行匹配","categories":[],"tags":[]},{"title":"C++ - 左值 & 右值","slug":"cpp-right-value","date":"2020-03-30T11:56:49.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/03/30/cpp-right-value/","link":"","permalink":"https://overtalk.site/2020/03/30/cpp-right-value/","excerpt":"","text":"关于左值和右值的定义 lvalue(locator value), 即左值，就是有名字的变量（对象），可以被赋值，可以在多条语句中使用。代表一个在内存中占有确定位置的对象，换句话说就是有一个地址。 而右值呢，就是临时变量（对象），没有名字，只能在一条语句中出现，不能被赋值。在内存中没有确切地址，它们只是在计算的周期临时储存在寄存器中。 简单的例子12345678int foo()&#123; return 1;&#125; int main()&#123; foo() = 2;&#125;` 我们编译时会得到报错： 1error: lvalue required as left operand of assignment 意思是赋值的左操作数需要是一个左值。 不是说foo() = 2这句一定是错的。当foo()返回的是左值的时候，这个赋值语句便是合法的。 12345678int g_var = 1;int &amp;foo()&#123; return g_var;&#125; int main()&#123; foo() = 2;&#125; 上面的代码就是合法的。foo()返回一个引用，这是一个左值。 C++的vector、map等容器重载的运算符[] 返回的也是左值，比如我们可以对map[“10086”]进行赋值。 左值引用1234int a = 1;int &amp;b = a;int &amp;c = 2;//错误string &amp;str = string();//错误 在上面的代码，第二行是正确的，b是一个左值引用，一个左值赋给左值引用，合法。第三行错误，因为2是右值，右值赋给左值引用非法。第四行同样。 右值引用(C++11) 我们有时会看到这样的函数声明： 1void Function(std::vector&lt;int&gt;&amp;&amp; nums); 在参数前面有’&amp;&amp;’符号。这表明nums是一个右值引用。 我们看一段代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include &lt;iostream&gt; class Intvec&#123;public: explicit Intvec(size_t num = 0): m_size(num), m_data(new int[m_size])&#123; log(\"构造函数\"); &#125; ~Intvec()&#123; log(\"析构函数\"); if(m_data)&#123; delete []m_data; m_data = NULL; &#125; &#125; Intvec(const Intvec&amp; other): m_size(other.m_size), m_data(new int[m_size])&#123; log(\"拷贝构造函数\"); for(int i = 0; i &lt; m_size; ++i) m_data[i] = other.m_data[i]; &#125; Intvec&amp; operator=(const Intvec&amp; other)&#123; log(\"赋值运算\"); Intvec tmp(other); std::swap(m_size, tmp.m_size); std::swap(m_data, tmp.m_data); return *this; &#125; private: void log(const char* msg)&#123; std::cout &lt;&lt; \"[\" &lt;&lt; this &lt;&lt; \"] \" &lt;&lt; msg &lt;&lt; std::endl; &#125; size_t m_size; int* m_data;&#125;;int main()&#123; Intvec v1(20); Intvec v2; printf(\"++++++++++++++++++\\n\"); v2 = v1; printf(\"*******************\\n\"); v2 = Intvec(33); printf(\"#####################\\n\");&#125;``` - 运行后，我们会看到如下结果：```c++[0x7fffffffe510] 构造函数[0x7fffffffe520] 构造函数++++++++++++++++++[0x7fffffffe520] 赋值运算[0x7fffffffe4e0] 拷贝构造函数[0x7fffffffe4e0] 析构函数*******************[0x7fffffffe530] 构造函数[0x7fffffffe520] 赋值运算[0x7fffffffe4e0] 拷贝构造函数[0x7fffffffe4e0] 析构函数[0x7fffffffe530] 析构函数#####################[0x7fffffffe520] 析构函数[0x7fffffffe510] 析构函数 可以看到，在第二次赋值时，执行了很多工作。尤其是，它有一对额外的构造/析构调用。不幸的是，这是个额外工作，没有任何用，因为在拷贝赋值运算符的内部，另一个临时拷贝的对象在被创建和析构。 在这里还有一个问题，左值引用的赋值函数，被一个右值作为参数也成功运行了。因为重载operator=的参数是一个常量左值引用。 左值引用只能绑定左值，右值引用只能绑定右值，如果绑定的不对，编译就会失败。但是，常量左值引用例外，它可以算是一个“万能”的引用类型，它可以绑定非常量左值、常量左值、右值，而且在绑定右值的时候，常量左值引用还可以像右值引用一样将右值的生命期延长，缺点是，只能读不能改。 我们添加另一个operator=到类中去： 1234567Intvec&amp; operator=(Intvec&amp;&amp; other)&#123; log(\"右值引用的赋值运算\"); std::swap(m_size, other.m_size); std::swap(m_data, other.m_data); return *this;&#125; 然后再执行相同的main函数，会得到 12345678910111213[0x7fffffffe510] 构造函数[0x7fffffffe520] 构造函数++++++++++++++++++[0x7fffffffe520] 赋值运算[0x7fffffffe4e0] 拷贝构造函数[0x7fffffffe4e0] 析构函数*******************[0x7fffffffe530] 构造函数[0x7fffffffe520] 右值引用的赋值运算[0x7fffffffe530] 析构函数#####################[0x7fffffffe520] 析构函数[0x7fffffffe510] 析构函数 &amp;&amp; 语法是新的右值引用。的确如它名字一样-给我们一个右值的引用，在调用之后将被析构。 我们再来尝试点有趣的事情，把左值引用的operator=注释掉，再编译，会得到： 1error: use of deleted function ‘Intvec&amp; Intvec::operator=(const Intvec&amp;)’ 错误指向的是”v2 = v1;”这是因为右值引用的operator=的参数只能是右值，不能是左值。 然后，我们将报错的这一行改成： 1v2 = std::move(v1); 编译运行成功，得到结果： 1234567891011[0x7fffffffe510] 构造函数[0x7fffffffe520] 构造函数++++++++++++++++++[0x7fffffffe520] 右值引用的赋值运算*******************[0x7fffffffe530] 构造函数[0x7fffffffe520] 右值引用的赋值运算[0x7fffffffe530] 析构函数#####################[0x7fffffffe520] 析构函数[0x7fffffffe510] 析构函数 因为我们在operator=中是使用std::swap来实现的，我们重写一个main函数，来看看右值引用对对象内容的变化： 12345678910111213int main()&#123; Intvec v1(20); Intvec v2; printf(\"++++++++++++++++++\\n\"); v2 = Intvec(33);//在右值引用运算符重载函数中，对象内容进行了交换。临时创建的Intvec(33)本来作为右值，是不能改变的，但是作为右值引用后，内容发生变化。 v1.m_data[0] = 5; v2.m_data[0] = 9; printf(\"#####################\\n\"); v2 = std::move(v1);//std::move作用：将左值转成右值。因为函数内部使用std::swap,这样做会导致v1与v2内容进行了交换 printf(\"-------------------\\n\"); printf(\"v1 size: %d v1 data[0]: %d v2 size: %d v2 data[0]: %d\\n\", v1.m_size, v1.m_data[0], v2.m_size, v2.m_data[0]);&#125; 结果： 1234567891011[0x7fffffffe510] 构造函数[0x7fffffffe520] 构造函数++++++++++++++++++[0x7fffffffe530] 构造函数[0x7fffffffe520] 右值引用的赋值运算[0x7fffffffe530] 析构函数#####################[0x7fffffffe520] 右值引用的赋值运算-------------------v1 size: 33 v1 data[0]: 9 v2 size: 20 v2 data[0]: 5[0x7fffffffe520] 析构函数 可以看到，右值引用可以对右值更改。 我们将右值引用写成swap而不是复制，是考虑到右值是本就该消亡的值，所以为提升性能，我们没有使用复制，而是将右值的内容”偷”了过来。 当一个左值马上要结束它的生命周期，我们又想将其赋给另一对象时，可以用std::move将其转成右值，再进行赋值，这时会优先调用右值引用的赋值函数，能够有效减少内存的复制。 右值引用和相关的移动语义是C++11标准中引入的最强大的特性之一。这里只是管中窥豹，只可见其一斑。要更深入理解，需要多去阅读源码，查阅资料。 右值引用的意义 直观意义：为临时变量续命，也就是为右值续命，因为右值在表达式结束后就消亡了，如果想继续使用右值，那就会动用昂贵的拷贝构造函数。（关于这部分，推荐一本书《深入理解C++11》） 右值引用是用来支持转移语义的。转移语义可以将资源 ( 堆，系统对象等 ) 从一个对象转移到另一个对象，这样能够减少不必要的临时对象的创建、拷贝以及销毁，能够大幅度提高 C++ 应用程序的性能。临时对象的维护 ( 创建和销毁 ) 对性能有严重影响。 转移语义是和拷贝语义相对的，可以类比文件的剪切与拷贝，当我们将文件从一个目录拷贝到另一个目录时，速度比剪切慢很多。 通过转移语义，临时对象中的资源能够转移其它的对象里。 在现有的 C++ 机制中，我们可以定义拷贝构造函数和赋值函数。要实现转移语义，需要定义转移构造函数，还可以定义转移赋值操作符。对于右值的拷贝和赋值会调用转移构造函数和转移赋值操作符。如果转移构造函数和转移拷贝操作符没有定义，那么就遵循现有的机制，拷贝构造函数和赋值操作符会被调用。 普通的函数和操作符也可以利用右值引用操作符实现转移语义。 但是这几点总结的不错 std::move执行一个无条件的转化到右值。它本身并不移动任何东西； std::forward把其参数转换为右值，仅仅在那个参数被绑定到一个右值时； std::move和std::forward在运行时（runtime）都不做任何事。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"minio","slug":"minio","date":"2020-03-30T09:40:38.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/03/30/minio/","link":"","permalink":"https://overtalk.site/2020/03/30/minio/","excerpt":"","text":"minio是一个对象存储服务。它兼容亚马逊s3云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从几kb到最大5t不等。 启动minio1234$ docker run -d -p 9000:9000 --rm \\ -v /Users/ssli/mnt/data:/data \\ -v /Users/ssli/mnt/config:/root/.minio \\ minio/minio server /data 登录minio的dashboard 浏览器打开http://localhost:9000/minio/login， 默认access key和secret key如下： 12minioadminminioadmin access key和secret key也可以在启动minio时通过环境变量指定。成功登录后，先创建bucket，然后就可以正常上传文件bucket，上传的文件可以分享给其他人下载。 使用客户端mc 安装minio客户端命令行工具mc，配置对象存储的url、access key和secret key后，可以查看不同对象存储的bucket，例如： 查看本地bucket 1234$ mc config host add local http://localhost:9000 minioadmin minioadmin S3v4Added `local` successfully.$ mc ls local[2020-03-24 13:32:30 CST] 0B test/ 查看s3的bucket 1234$ mc config host add s3 https://s3.amazonaws.com aws-access-key aws-secret-key S3v4Added `s3` successfully.$ mc ls s3[2020-03-24 13:33:30 CST] 0B s3-test/ mc配置对象存储服务的方式如下： 1mc config host add &lt;alias&gt; &lt;your-s3-endpoint&gt; &lt;your-access-key&gt; &lt;your-secret-key&gt; &lt;api-signature&gt; alias：对象存储的别名，如s3、gcs和local your-s3-endpoint：对象存储的访问url，如果是aws s3输入：https://s3.amazonaws.com， 如果是本地搭建的输入：http://localhost:9000 ，如果是gcs输入：https://storage.googleapis.com your-access-key：访问s3的key your-secret-key：访问s3的secret key api-signature：api签名，比如s3的s3v4，gcs的S3v2 你也可以直接使用docker版的客户端命令行mc，如下所示： 123456789$ docker run -it --entrypoint=/bin/sh minio/mc/ # mc config host add local http://172.17.0.4:9000 minioadmin minioadmin S3v4mc: Configuration written to `/root/.mc/config.json`. Please update your access credentials.mc: Successfully created `/root/.mc/share`.mc: Initialized share uploads `/root/.mc/share/uploads.json` file.mc: Initialized share downloads `/root/.mc/share/downloads.json` file.Added `local` successfully./ # mc ls local[2020-03-24 05:32:30 UTC] 0B test/ ref https://docs.min.io/cn/minio-client-quickstart-guide.html https://docs.min.io/cn/minio-docker-quickstart-guide.html","categories":[{"name":"minio","slug":"minio","permalink":"https://overtalk.site/categories/minio/"}],"tags":[{"name":"个人网盘","slug":"个人网盘","permalink":"https://overtalk.site/tags/%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%9B%98/"}]},{"title":"C++ - char* 与 char[]","slug":"cplus-char","date":"2020-03-28T12:49:21.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/03/28/cplus-char/","link":"","permalink":"https://overtalk.site/2020/03/28/cplus-char/","excerpt":"","text":"C/C++初学者很可能会以为这两个是一样的，其实如果不需要去修改字符串的话，那它们的效果的确是一样的。那它们的区别到底在哪儿呢？ char* s1=”abc”; s1是一个指针，这个指针可以被修改，它可以指向新的地址。现在它指向的是字符串常量“abc”，字符串常量存储在constant section里，不可被修改。如果修改内容，比如s1 = “ddf”, 其实修改的并不是“abc”这个内容，而是将s1指向了新的地址空间。利用printf(“%p”, s1); 可以查看s1的地址改变。 char s2[10]=”abc”; s2是数组指针，指针指向的位置就是数组的第一个元素所在的位置，一经分配是不能被修改的了。然后它的空间是在栈里面分配的，当前存储的是字符串”abc”,它的内容是可以被重新修改赋值的。例如s2[0]=’F’;就可以将第一个字符改成F。 char* p=s2; p和s1是一样的，可以指向s2指向的地址，所以数据在栈里面，所以p是可以修改字符串的。 Summary： char* s1=”abc”; 是指针可以被修改，指向的字符串常量不可以修改。 char s2[10]=”abc”; abc是在栈里面，数值可以被修改。但是s2作为数组指针不能指向其他地址空间。 char* p=s2; p是和s1一样的指针，可以指向其他地址，因为给它赋值为s2，所以当前指向的区域是可以被修改的。如果再让p=”dfg”; 那p就变成和s1一样了。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - NULL 和 nullptr","slug":"cplus-null","date":"2020-03-27T22:58:44.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/03/27/cplus-null/","link":"","permalink":"https://overtalk.site/2020/03/27/cplus-null/","excerpt":"","text":"在编写C程序的时候只看到过NULL，而在C++的编程中，我们可以看到NULL和nullptr两种关键字，其实nullptr是C++11版本中新加入的，它的出现是为了解决NULL表示空指针在C++中具有二义性的问题，为了弄明白这个问题，我查找了一些资料，总结如下。 C程序中的NULL 在C语言中，NULL通常被定义为：#define NULL ((void *)0) 所以说NULL实际上是一个空指针，如果在C语言中写入以下代码，编译是没有问题的，因为在C语言中把空指针赋给int和char指针的时候，发生了隐式类型转换，把void指针转换成了相应类型的指针。 12int *pi = NULL;char *pc = NULL; C++程序中的NULL 但是问题来了，以上代码如果使用C++编译器来编译则是会出错的，因为C++是强类型语言，void*是不能隐式转换成其他类型的指针的，所以实际上编译器提供的头文件做了相应的处理： 123456#ifdef __cplusplus#define NULL 0#else#define NULL ((void *)0)#endif 可见，在C++中，NULL实际上是0.因为C++中不能把void*类型的指针隐式转换成其他类型的指针，所以为了结果空指针的表示问题，C++引入了0来表示空指针，这样就有了上述代码中的NULL宏定义。 但是实际上，用NULL代替0表示空指针在函数重载时会出现问题，程序执行的结果会与我们的想法不同，举例如下： 12345678910111213141516171819#include &lt;iostream&gt;using namespace std; void func(void* i)&#123; cout &lt;&lt; \"func1\" &lt;&lt; endl;&#125; void func(int i)&#123; cout &lt;&lt; \"func2\" &lt;&lt; endl;&#125; void main(int argc,char* argv[])&#123; func(NULL); func(nullptr); getchar();&#125; 输出结果如下所示： 12func2func1 在这段代码中，我们对函数func进行可重载，参数分别是void*类型和int类型，但是运行结果却与我们使用NULL的初衷是相违背的，因为我们本来是想用NULL来代替空指针，但是在将NULL输入到函数中时，它却选择了int形参这个函数版本，所以是有问题的，这就是用NULL代替空指针在C++程序中的二义性。 C++中的nullptr 为解决NULL代指空指针存在的二义性问题，在C++11版本(2011年发布)中特意引入了nullptr这一新的关键字来代指空指针，从上面的例子中我们可以看到，使用nullptr作为实参，确实选择了正确的以void*作为形参的函数版本。 总结： NULL在C++中就是0，这是因为在C++中void* 类型是不允许隐式转换成其他类型的，所以之前C++中用0来代表空指针，但是在重载整形的情况下，会出现上述的问题。所以，C++11加入了nullptr，可以保证在任何情况下都代表空指针，而不会出现上述的情况，因此，建议以后还是都用nullptr替代NULL吧，而NULL就当做0使用。 其他：在没有C++ 11的nullptr的时候，我们怎么解决避免这个问题呢？ 1234567891011121314const class nullptr_t&#123;public: template&lt;class T&gt; inline operator T*() const &#123; return 0; &#125; template&lt;class C, class T&gt; inline operator T C::*() const &#123; return 0; &#125; private:void operator&amp;() const;&#125; nullptr = &#123;&#125;;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - void*","slug":"cplus-void","date":"2020-03-27T22:47:01.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/03/27/cplus-void/","link":"","permalink":"https://overtalk.site/2020/03/27/cplus-void/","excerpt":"","text":"void* 的用法 void可以指向任何类型的地址，但是带类型的指针不能指向void的地址 正常来说如果两个指针类型不一样的话，两个指针变量是不可以直接相等的。例如int* a, float* b，假如令a = b，会直接发生编译错误。 而 void* 指针可以等于任何类型的指针。但是反过来不可以。 也就是说一个有类型的指针不能指向一个 void* 类型的变量（哪怕此时void*变量已经指向了一个有类型的地址）。1234float f = 5.5;float* pf = &amp;f;void* pv = pf;float* pf2 = pv;//编译错误，有类型的指针变量不能指向void*变量 void*指针只有强制类型转换以后才可以正常取值12345678910111213int main(int argc, const char * argv[]) &#123; float f = 5.5; float* pf = &amp;f; void* pv; pv = pf; //这句是可以的 cout&lt;&lt;*pv&lt;&lt;endl; //编译错误，这样直接对pv取值是错误的 cout&lt;&lt;*(float*)pv&lt;&lt;endl; //强制类型转换后可以取值 return 0;&#125; 在令pv = pf后，此时pv和pf指向的是同一个地址，值相同，但是两者的类型是不一样的。 pf作为浮点型指针，是可以直接取到浮点数的，但是pv必须要强制类型转换以后才可以取值。 也就是说一个void*的指针必须要经过强制类型转换以后才有意义。1234567891011121314int main(int argc, const char * argv[]) &#123; float f = 5.5; float* pf = &amp;f; void* pv; pv = pf; cout&lt;&lt;*(float*)pv&lt;&lt;endl; //强制类型转换后可以取值,值为5.5 cout&lt;&lt;*(int*)pv&lt;&lt;endl; //强制类型转换，值为1085276160 cout&lt;&lt;(int)(*(float*)pv)&lt;&lt;endl;//取值后再次类型转换，值为5 return 0;&#125; 如果把一个指向 float* 的值的 void* 指针，强制转换成 int* 也是不对的。 也就是说地址保存了什么样的变量，就要转化成哪种类型的指针，否则就会出错。 void*指针变量和普通指针一样可以通过等于0或者NULL来初始化，表示一个空指针1234void* pv = 0;void* pv2 = NULL;cout&lt;&lt;pv &lt;&lt;endl; //值为0x0cout&lt;&lt;pv2&lt;&lt;endl; //值为0x0 当void*指针作为函数的输入和输出时，表示可以接受任意类型的输入指针和输出任意类型的指针1234567891011121314void* test(void* a)&#123; return a;&#125;int main() &#123; static int a = 5; int* pi = &amp;a; cout&lt;&lt;pi&lt;&lt;endl; //值为0x100001060 cout&lt;&lt;test(pi)&lt;&lt;endl; //值为0x100001060 cout&lt;&lt;test((void*)pi)&lt;&lt;endl; //值为0x100001060&#125; 如果函数的输入类型为void*，在调用时由于是值传递，所以函数实际接收到的应该就是一个地址值。这个值可以是任意类型。1234567891011int a = 5;int* pi = &amp;a;void* test()&#123; return pi;&#125;int main() &#123; cout&lt;&lt;test()&lt;&lt;endl; //值为0x100001060&#125; 输出时同样也是值传递，因此可以输出任意类型指针指向的地址。 总结： void*类型的指针其实本质就是一个过渡型的指针状态，必须要赋予类型（强制类型转换）才能正常使用。 只能单向类型转换。void* 可以转化成其他类型，但是有类型的不能转化成 void*。 在函数调用过程中的使用作为输入输出参数也非常好用，可以灵活使用任意类型的指针，避免只能使用固定类型的指针。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"golang 之 bitset","slug":"go-bitset","date":"2020-03-21T00:26:04.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/03/21/go-bitset/","link":"","permalink":"https://overtalk.site/2020/03/21/go-bitset/","excerpt":"","text":"hashset 是一种非常高效的数据结构，插入和查询的复杂度都是 O(1)，基本上能满足大部分场景的性能需求，但在一些特殊的场景下，频次非常高的调用依然会成为性能瓶颈（用 pprof 分析），比如广告里面的定向逻辑，在一次请求中过滤逻辑可能会执行上千次，而其中有些过滤刚好都是一些枚举值，比如性别定向，年龄定向等等，对于这种可以用枚举表示的值可以用 bitset 优化，能有20多倍的性能提升 bitset 的本质也是一种 hashset，只不过哈希桶用一个 uint64 来表示了，uint64 中的每一位用来代表一个元素是否存在，如果为1表示存在，为0表示不存在，而插入和查询操作就变成了位运算 bitset 实现 bitset 的实现比较容易，下面这个是一个只支持枚举值不超过64的版本，当然也可以拓展到任意长度，使用一个 uint64 数组作为 hash 桶即可 123456789101112type BitSet struct &#123; bit uint64&#125;func (bs *BitSet) Add(i uint64) &#123; bs.bit |= 1 &lt;&lt; i&#125;func (bs *BitSet) Del(i uint64) &#123; bs.bit &amp;= ^(1 &lt;&lt; i)&#125;func (bs BitSet) Has(i uint64) bool &#123; return bs.bit&amp;(1&lt;&lt;i) != 0&#125; 性能测试12345678910111213141516171819202122func BenchmarkSetContains(b *testing.B) &#123; bitset := NewBitSet() hashset := map[uint64]struct&#123;&#125;&#123;&#125; for _, i := range []uint64&#123;1, 2, 4, 10&#125; &#123; bitset.Add(i) hashset[i] = struct&#123;&#125;&#123;&#125; &#125; b.Run(\"bitset\", func(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; for i := uint64(0); i &lt; uint64(10); i++ &#123; _ = bitset.Has(i) &#125; &#125; &#125;) b.Run(\"hashset\", func(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; for i := uint64(0); i &lt; uint64(10); i++ &#123; _, _ = hashset[i] &#125; &#125; &#125;)&#125; 12BenchmarkSetContains/bitset-8 500000000 3.81 ns/op 0 B/op 0 allocs/opBenchmarkSetContains/hashset-8 20000000 89.4 ns/op 0 B/op 0 allocs/op 可以看到 bitset 相比 hashset 有20多倍的性能提升 ##参考链接 代码地址：https://github.com/hatlonely/easygolang/blob/master/datastruct/bitset.go","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"k8s 拉取私有镜像仓库","slug":"k8s-imagePull","date":"2020-03-20T18:14:53.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/03/20/k8s-imagePull/","link":"","permalink":"https://overtalk.site/2020/03/20/k8s-imagePull/","excerpt":"","text":"k8s 部署的时候如何拉去私有镜像库的镜像？ 简介 通常 deployment / statefulset 中是这样的 这儿的 imagePullSecrets 就指定了拉取密钥1234567spec: containers: - name: xxx image: registry.cn-shanghai.aliyuncs.com/xxx/xxxx:latest imagePullPolicy: Always imagePullSecrets: - name: aliyun-docker 密钥如何生成？ 创建一个 secret:1kubectl create secret docker-registry regsecret --docker-server=&lt;your-registry-server&gt; --docker-username=&lt;your-name&gt; --docker-password=&lt;your-pword&gt; --docker-email=&lt;your-email&gt; 在这里: 是你的私有仓库的FQDN. 是你的 Docker 用户名. 是你的 Docker 密码. 是你的 Docker 邮箱. 导出密钥1kubectl get secret regsecret --output=yaml 输出类似这样: 123456789apiVersion: v1data: .dockercfg: eyJodHRwczovL2luZGV4L ... J0QUl6RTIifX0=kind: Secretmetadata: ... name: regsecret ...type: kubernetes.io/dockercfg .dockercfg 的值是一个经过 base64 加密的数据。 把这串 base64 加密的数据复制到一个名为 secret64 的文件里. 重要: 确保你的 secret64 的文件内容没有任何换行。 想知道 .dockercfg 的内容是什么意思，只要将 secret 数据转换成可读格式即可： 1base64 -d secret64 输出类似这样: 1&#123;\"yourprivateregistry.com\":&#123;\"username\":\"janedoe\",\"password\":\"xxxxxxxxxxx\",\"email\":\"jdoe@example.com\",\"auth\":\"c3R...zE2\"&#125;&#125; 注意到 secret 数据其实包含了你的 config.json 文件里的验证口令。 tips 建议先通过 kubectl create secret 命令本地生成密钥，然后再通过 kubectl get secret xxx --output=yaml 命令将其导出。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://overtalk.site/tags/k8s/"}]},{"title":"四层负载？七层负载？","slug":"loadbalancer","date":"2020-03-16T13:58:12.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/03/16/loadbalancer/","link":"","permalink":"https://overtalk.site/2020/03/16/loadbalancer/","excerpt":"","text":"常常说负载均衡，其中负载均衡有两种方案:选用四层负载均衡还是七层负载均衡呢？四层与七层的主要区别在哪里呢？ OSI（Open System Interconnection）七层参考模型，是参考模型是国际标准化组织（ISO）制定的一个用于计算机或通信系统间互联的标准体系。它从低到高分别是：物理层、数据链路层、网络层、传输层、会话层、表示层和应用层。四层工作在OSI第四层，也就是传输层；七层工作在最高层，也就是应用层。 从技术实现原理上 所谓四层负载均衡就是使用IP加端口的方式进行路由转发；七层负载均衡一般是基于请求URL地址的方式进行代理转发。同理，还有基于MAC地址信息(虚拟MAC地址到真实MAC地址)进行转发的二层负载均衡和基于IP地址(虚拟IP到真实IP)的三层负载均衡。 四层负载均衡具体实现方式为：通过报文中的IP地址和端口，再加上负载均衡设备所采用的负载均衡算法，最终确定选择后端哪台下游服务器。 以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。 七层负载均衡工作在OSI模型的应用层，应用层协议较多，常用http、radius、dns等 七层服务均衡在应用层选择服务器，只能先与负载均衡设备进行TCP连接，然后负载均衡设备再与后端服务器建立另外一条TCP连接通道。因此，七层设备在网络性能损耗会更多一些。 从安全视角上 四层负载均衡与服务器直接建立起TCP连接，很容易遭受SYN Flood攻击。SYN Flood是一种广为人知的DDoS（分布式拒绝服务攻击）的方式之一，这是一种利用TCP协议缺陷，发送大量伪造的TCP连接请求，从而使得被攻击方资源耗尽的攻击方式。从技术实现原理上可以看出，四层负载均衡很容易将垃圾流量转发至后台服务器，而七层设备则可以过滤这些恶意并清洗这些流量，但要求设备本身具备很强的抗DDOS流量的能力。 常见四层和七层负载均衡设备 四层: F5、LVS等 七层: nginx、apache等","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"loadbalance","slug":"loadbalance","permalink":"https://overtalk.site/tags/loadbalance/"}]},{"title":"用户态 内核态","slug":"linux-status","date":"2020-03-16T12:18:55.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/03/16/linux-status/","link":"","permalink":"https://overtalk.site/2020/03/16/linux-status/","excerpt":"","text":"用户态和内核态的区别 内核态： 运行操作系统程序，操作硬件 cpu可以访问内存的所有数据，包括外围设备，例如硬盘，网卡，cpu也可以将自己从一个程序切换到另一个程序 用户态： 运行用户程序 只能受限的访问内存，且不允许访问外围设备，占用cpu的能力被剥夺，cpu资源可以被其他程序获取 为什么要有用户态和内核态？ 由于需要限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络, CPU划分出两个权限等级 – 用户态和内核态。 对于任何操作系统来说，创建一个进程是核心功能。创建进程要做很多工作，会消耗很多物理资源。比如分配物理内存，父子进程拷贝信息，拷贝设置页目录页表等等，这些工作得由特定的进程去做，所以就有了特权级别的概念。最关键的工作必须交给特权级最高的进程去执行，这样可以做到集中管理，减少有限资源的访问和使用冲突。inter x86 架构的 cpu 一共有四个级别，0-3 级，0 级特权级最高，3 级特权级最低。 特权级的概念linux 进程有 4GB 地址空间，如图所示： 3G-4G 大部分是共享的，是内核态的地址空间。这里存放整个内核的代码和所有的内核模块以及内核所维护的数据。 概念 当一个进程在执行用户自己的代码时处于用户运行态（用户态），此时特权级最低，为 3 级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态。 Ring3 状态不能访问 Ring0 的地址空间，包括代码和数据；当一个进程因为系统调用陷入内核代码中执行时处于内核运行态（内核态），此时特权级最高，为 0 级。 执行的内核代码会使用当前进程的内核栈，每个进程都有自己的内核栈。 用户运行一个程序，该程序创建的进程开始时运行自己的代码，处于用户态。如果要执行文件操作、网络数据发送等操作必须通过 write、send 等系统调用，这些系统调用会调用内核的代码。 进程会切换到 Ring0，然后进入 3G-4G 中的内核地址空间去执行内核代码来完成相应的操作。内核态的进程执行完后又会切换到 Ring3，回到用户态。这样，用户态的程序就不能随意操作内核地址空间，具有一定的安全保护作用。这说的保护模式是指通过内存页表操作等机制，保证进程间的地址空间不会互相冲突，一个进程的操作不会修改另一个进程地址空间中的数据。 用户态和内核态的切换 当在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成一些用户态自己没有特权和能力完成的操作时就会切换到内核态。 状态切换可以通过三种方式 系统调用 系统调用, 在CPU中的实现称之为陷阱指令(Trap Instruction)，他们的工作流程如下: 用户态程序将一些数据值放在寄存器中, 或者使用参数创建一个堆栈(stack frame), 以此表明需要操作系统提供的服务. 用户态程序执行陷阱指令 CPU切换到内核态, 并跳到位于内存指定位置的指令, 这些指令是操作系统的一部分, 他们具有内存保护, 不可被用户态程序访问 这些指令称之为陷阱(trap)或者系统调用处理器(system call handler). 他们会读取程序放入内存的数据参数, 并执行程序请求的服务 系统调用完成后, 操作系统会重置CPU为用户态并返回系统调用的结果 这是用户态进程主动要求切换到内核态的一种方式。用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。 例如 fork（）就是执行了一个创建新进程的系统调用。系统调用的机制和新是使用了操作系统为用户特别开放的一个中断来实现，如 Linux 的 int 80h 中断。 例如 C库接口malloc申请动态内存，malloc的实现内部最终还是会调用brk（）或者mmap（）系统调用来分配内存。 异常 当 cpu 在执行运行在用户态下的程序时，发生了一些没有预知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关进程中，也就是切换到了内核态，如缺页异常。 外围设备的中断 当外围设备完成用户请求的操作后，会向 CPU 发出相应的中断信号，这时 CPU 会暂停执行下一条即将要执行的指令而转到与中断信号对应的处理程序去执行，如果前面执行的指令时用户态下的程序，那么转换的过程自然就会是 由用户态到内核态的切换。如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后边的操作等。 这三种方式是系统在运行时由用户态切换到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。从触发方式上看，切换方式都不一样，但从最终实际完成由用户态到内核态的切换操作来看，步骤有事一样的，都相当于执行了一个中断响应的过程。系统调用实际上最终是中断机制实现的，而异常和中断的处理机制基本一致。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://overtalk.site/tags/linux/"}]},{"title":"聊聊协程","slug":"linux-thread","date":"2020-03-15T12:49:54.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/03/15/linux-thread/","link":"","permalink":"https://overtalk.site/2020/03/15/linux-thread/","excerpt":"","text":"进程/线程上下文切换会用掉你多少CPU？ 进程是操作系统的伟大发明之一，对应用程序屏蔽了CPU调度、内存管理等硬件细节，而抽象出一个进程的概念，让应用程序专心于实现自己的业务逻辑既可。 而且在有限的CPU上可以“同时”进行许多个任务。但是它为用户带来方便的同时，也引入了一些额外的开销。如下图，在进程运行中间的时间里，虽然CPU也在忙于干活，但是却没有完成任何的用户工作，这就是进程机制带来的额外开销。 在进程A切换到进程B的过程中，先保存A进程的上下文，以便于等A恢复运行的时候，能够知道A进程的下一条指令是啥。 然后将要运行的B进程的上下文恢复到寄存器中。这个过程被称为上下文切换。 上下文切换开销在进程不多、切换不频繁的应用场景下问题不大。但是现在Linux操作系统被用到了高并发的网络程序后端服务器。在单机支持成千上万个用户请求的时候，这个开销就得拿出来说道说道了。因为用户进程在请求Redis、Mysql数据等网络IO阻塞掉的时候，或者在进程时间片到了，都会引发上下文切换。 进程上下文切换开销都有哪些 那么上下文切换的时候，CPU的开销都具体有哪些呢？开销分成两种，一种是直接开销、一种是间接开销。 直接开销就是在切换时，cpu必须做的事情，包括： 切换页表全局目录 切换内核态堆栈 切换硬件上下文（进程恢复前，必须装入寄存器的数据统称为硬件上下文） ip(instruction pointer)：指向当前执行指令的下一条指令 bp(base pointer): 用于存放执行中的函数对应的栈帧的栈底地址 sp(stack poinger): 用于存放执行中的函数对应的栈帧的栈顶地址 cr3:页目录基址寄存器，保存页目录表的物理地址 …… 刷新TLB 系统调度器的代码执行 间接开销主要指的是虽然切换到一个新进程后，由于各种缓存并不热，速度运行会慢一些。 如果进程始终都在一个CPU上调度还好一些，如果跨CPU的话，之前热起来的TLB、L1、L2、L3因为运行的进程已经变了，所以以局部性原理cache起来的代码、数据也都没有用了，导致新进程穿透到内存的IO会变多。 其实我们上面的实验并没有很好地测量到这种情况，所以实际的上下文切换开销可能比3.5us要大。 协程究竟比线程能省多少开销？ 为了避免频繁的上下文切换，还有一种异步非阻塞的开发模型。那就是用一个进程或线程去接收一大堆用户的请求，然后通过IO多路复用的方式来提高性能（进程或线程不阻塞，省去了上下文切换的开销）。Nginx和Node Js就是这种模型的典型代表产品。平心而论，从程序运行效率上来，这种模型最为机器友好，运行效率是最高的（比下面提到的协程开发模型要好）。所以Nginx已经取代了Apache成为了Web Server里的首选。但是这种编程模型的问题在于开发不友好，说白了就是过于机器化，离进程概念被抽象出来的初衷背道而驰。人类正常的线性思维被打乱，应用层开发们被逼得以非人类的思维去编写代码，代码调试也变得异常困难。 于是就有一些聪明的脑袋们继续在应用层又动起了主意，设计出了不需要进程/线程上下文切换的“线程”，协程。用协程去处理高并发的应用场景，既能够符合进程涉及的初衷，让开发者们用人类正常的线性的思维去处理自己的业务，也同样能够省去昂贵的进程/线程上下文切换的开销。因此可以说，协程就是Linux处理海量请求应用场景里的进程模型的一个很好的的补丁。 背景介绍完了，那么我想说的是，毕竟协程的封装虽然轻量，但是毕竟还是需要引入了一些额外的代价的。那么我们来看看这些额外的代价具体多小吧。 协程开销测试 协程切换CPU开销 测试过程是不断在协程之间让出CPU。核心代码如下。 1234567891011121314151617181920func cal() &#123; for i :=0 ; i&lt;1000000 ;i++&#123; runtime.Gosched() &#125;&#125;func main() &#123; runtime.GOMAXPROCS(1) currentTime:=time.Now() fmt.Println(currentTime) go cal() for i :=0 ; i&lt;1000000 ;i++&#123; runtime.Gosched() &#125; currentTime=time.Now() fmt.Println(currentTime)&#125; 编译运行 12345# cd tests/test05/src/main/; # go build # ./main 2019-08-08 22:35:13.415197171 +0800 CST m=+0.0002860592019-08-08 22:35:13.655035993 +0800 CST m=+0.240124923 平均每次协程切换的开销是（655035993-415197171)/2000000=120ns。进程切换开销大约3.5us，大约是其的三十分之一。比系统调用的造成的开销还要低。 协程内存开销 在空间上，协程初始化创建的时候为其分配的栈有2KB。而线程栈要比这个数字大的多，可以通过ulimit 命令查看，一般都在几兆，作者的机器上是10M。如果对每个用户创建一个协程去处理，100万并发用户请求只需要2G内存就够了，而如果用线程模型则需要10T。 12# ulimit -a stack size (kbytes, -s) 10240 小结 协程由于是在用户态来完成上下文切换的，所以切换耗时只有区区100ns多一些，比进程切换要高30倍。单个协程需要的栈内存也足够小，只需要2KB。所以，近几年来协程大火，在互联网后端的高并发场景里大放光彩。 无论是空间还是时间性能都比进程（线程）好这么多，那么Linux为啥不把它在操作系统里实现了多好？操作系统为了实现实时性更好的目的，对一些优先级比较高的进程是会抢占其它进程的CPU的。而协程无法实现这一点，还得依赖于挡前使用CPU的协程主动释放，于操作系统的实现目的不相吻合。所以协程的高效是以牺牲可抢占性为代价的。 由于go的协程调用起来太方便了，所以一些go的程序员就很随意地go来go去。要知道go这条指令在切换到协程之前，得先把协程创建出来。而一次创建加上调度开销就涨到400ns，差不多相当于一次系统调用的耗时了。虽然协程很高效，但是也不要乱用，否则go祖师爷Rob Pike花大精力优化出来的性能，被你随意一go又给葬送掉了。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://overtalk.site/tags/linux/"}]},{"title":"Golang - GMP模型","slug":"golang-runtime","date":"2020-03-14T13:07:08.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/03/14/golang-runtime/","link":"","permalink":"https://overtalk.site/2020/03/14/golang-runtime/","excerpt":"","text":"转自learnku Golang 调度器的由来单进程时代不需要调度器 我们知道，一切的软件都是跑在操作系统上，真正用来干活 (计算) 的是 CPU。早期的操作系统每个程序就是一个进程，知道一个程序运行完，才能进行下一个进程，就是 “单进程时代” 一切的程序只能串行发生。 早期的单进程操作系统，面临 2 个问题： 单一的执行流程，计算机只能一个任务一个任务处理。2. 进程阻塞所带来的 CPU 时间浪费。 那么能不能有多个进程来宏观一起来执行多个任务呢？ 后来操作系统就具有了最早的并发能力：多进程并发，当一个进程阻塞的时候，切换到另外等待执行的进程，这样就能尽量把 CPU 利用起来，CPU 就不浪费了。 多进程 / 线程时代有了调度器需求 在多进程 / 多线程的操作系统中，就解决了阻塞的问题，因为一个进程阻塞 cpu 可以立刻切换到其他进程中去执行，而且调度 cpu 的算法可以保证在运行的进程都可以被分配到 cpu 的运行时间片。这样从宏观来看，似乎多个进程是在同时被运行。 但新的问题就又出现了，进程拥有太多的资源，进程的创建、切换、销毁，都会占用很长的时间，CPU 虽然利用起来了，但如果进程过多，CPU 有很大的一部分都被用来进行进程调度了。 怎么才能提高 CPU 的利用率呢？ 但是对于 Linux 操作系统来讲，cpu 对进程的态度和线程的态度是一样的。 很明显，CPU 调度切换的是进程和线程。尽管线程看起来很美好，但实际上多线程开发设计会变得更加复杂，要考虑很多同步竞争等问题，如锁、竞争冲突等。 协程来提高 CPU 利用率 多进程、多线程已经提高了系统的并发能力，但是在当今互联网高并发场景下，为每个任务都创建一个线程是不现实的，因为会消耗大量的内存 (进程虚拟内存会占用 4GB [32 位操作系统], 而线程也要大约 4MB)。 大量的进程 / 线程出现了新的问题 高内存占用 调度的高消耗 CPU 好了，然后工程师们就发现，其实一个线程分为 “内核态 “线程和” 用户态 “线程。 一个 “用户态线程” 必须要绑定一个 “内核态线程”，但是 CPU 并不知道有 “用户态线程” 的存在，它只知道它运行的是一个 “内核态线程”(Linux 的 PCB 进程控制块)。 这样，我们再去细化去分类一下，内核线程依然叫 “线程 (thread)”，用户线程叫 “协程 (co-routine)”. 看到这里，我们就要开脑洞了，既然一个协程 (co-routine) 可以绑定一个线程 (thread)，那么能不能多个协程 (co-routine) 绑定一个或者多个线程 (thread) 上呢。 之后，我们就看到了有 3 中协程和线程的映射关系： N:1 关系 N 个协程绑定 1 个线程，优点就是协程在用户态线程即完成切换，不会陷入到内核态，这种切换非常的轻量快速。但也有很大的缺点，1 个进程的所有协程都绑定在 1 个线程上 缺点： 某个程序用不了硬件的多核加速能力 一旦某协程阻塞，造成线程阻塞，本进程的其他协程都无法执行了，根本就没有并发的能力了。 1:1 关系 1 个协程绑定 1 个线程，这种最容易实现。协程的调度都由 CPU 完成了，不存在 N:1 缺点， 缺点： 协程的创建、删除和切换的代价都由 CPU 完成，有点略显昂贵了。 M:N 关系 M 个协程绑定 N 个线程，是 N:1 和 1:1 类型的结合，克服了以上 2 种模型的缺点，但实现起来最为复杂。 协程跟线程是有区别的，线程由 CPU 调度是抢占式的，协程由用户态调度是协作式的，一个协程让出 CPU 后，才执行下一个协程。 Go 语言的协程 goroutine Go 为了提供更容易使用的并发方法，使用了 goroutine 和 channel。goroutine 来自协程的概念，让一组可复用的函数运行在一组线程之上，即使有协程阻塞，该线程的其他协程也可以被 runtime 调度，转移到其他可运行的线程上。最关键的是，程序员看不到这些底层的细节，这就降低了编程的难度，提供了更容易的并发。 Go 中，协程被称为 goroutine，它非常轻量，一个 goroutine 只占几 KB，并且这几 KB 就足够 goroutine 运行完，这就能在有限的内存空间内支持大量 goroutine，支持了更多的并发。虽然一个 goroutine 的栈只占几 KB，但实际是可伸缩的，如果需要更多内容，runtime 会自动为 goroutine 分配。 Goroutine 特点： 占用内存更小（几 kb） 调度更灵活 (runtime 调度) 被废弃的 goroutine 调度器 ​ 好了，既然我们知道了协程和线程的关系，那么最关键的一点就是调度协程的调度器的实现了。 Go 目前使用的调度器是 2012 年重新设计的，因为之前的调度器性能存在问题，所以使用 4 年就被废弃了，那么我们先来分析一下被废弃的调度器是如何运作的？ 1大部分文章都是会用 G 来表示 Goroutine，用 M 来表示线程，那么我们也会用这种表达的对应关系。 下面我们来看看被废弃的 golang 调度器是如何实现的？ M 想要执行、放回 G 都必须访问全局 G 队列，并且 M 有多个，即多线程访问同一资源需要加锁进行保证互斥 / 同步，所以全局 G 队列是有互斥锁进行保护的。 老调度器有几个缺点： 创建、销毁、调度 G 都需要每个 M 获取锁，这就形成了激烈的锁竞争。 M 转移 G 会造成延迟和额外的系统负载。比如当 G 中包含创建新协程的时候，M 创建了 G’，为了继续执行 G，需要把 G’交给 M’执行，也造成了很差的局部性，因为 G’和 G 是相关的，最好放在 M 上执行，而不是其他 M’。 系统调用 (CPU 在 M 之间的切换) 导致频繁的线程阻塞和取消阻塞操作增加了系统开销。 Goroutine 调度器的 GMP 模型的设计思想 面对之前调度器的问题，Go 设计了新的调度器。 在新调度器中，出列 M (thread) 和 G (goroutine)，又引进了 P (Processor)。 Processor，它包含了运行 goroutine 的资源，如果线程想运行 goroutine，必须先获取 P，P 中还包含了可运行的 G 队列。 GMP 模型 在 Go 中，线程是运行 goroutine 的实体，调度器的功能是把可运行的 goroutine 分配到工作线程上。 全局队列（Global Queue）：存放等待运行的 G。 P 的本地队列：同全局队列类似，存放的也是等待运行的 G，存的数量有限，不超过 256 个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。 P 列表：所有的 P 都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。 M：线程想运行任务就得获取 P，从 P 的本地队列获取 G，P 队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。 Goroutine 调度器和 OS 调度器是通过 M 结合起来的，每个 M 都代表了 1 个内核线程，OS 调度器负责把内核线程分配到 CPU 的核上执行。 有关 P 和 M 的个数问题 P 的数量： 由启动时环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行。 M 的数量: go 语言本身的限制：go 程序启动时，会设置 M 的最大数量，默认 10000. 但是内核很难支持这么多的线程数，所以这个限制可以忽略。 runtime/debug 中的 SetMaxThreads 函数，设置 M 的最大数量 一个 M 阻塞了，会创建新的 M。 M 与 P 的数量没有绝对关系，一个 M 阻塞，P 就会去创建或者切换另一个 M，所以，即使 P 的默认数量是 1，也有可能会创建很多个 M 出来。 P 和 M 何时会被创建 P 何时创建：在确定了 P 的最大数量 n 后，运行时系统会根据这个数量创建 n 个 P。 M 何时创建：没有足够的 M 来关联 P 并运行其中的可运行的 G。比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。 调度器的设计策略 复用线程：避免频繁的创建、销毁线程，而是对线程的复用。 work stealing 机制 当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。 hand off 机制 当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。 利用并行：GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行。 抢占：在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。 全局 G 队列：在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。 go func () 调度流程 从上图我们可以分析出几个结论： 我们通过 go func () 来创建一个 goroutine； 有两个存储 G 的队列，一个是局部调度器 P 的本地队列、一个是全局 G 队列。新创建的 G 会先保存在 P 的本地队列中，如果 P 的本地队列已经满了就会保存在全局的队列中； G 只能运行在 M 中，一个 M 必须持有一个 P，M 与 P 是 1：1 的关系。M 会从 P 的本地队列弹出一个可执行状态的 G 来执行，如果 P 的本地队列为空，就会想其他的 MP 组合偷取一个可执行的 G 来执行； 一个 M 调度 G 执行的过程是一个循环机制； 当 M 执行某一个 G 时候如果发生了 syscall 或则其余阻塞操作，M 会阻塞，如果当前有一些 G 在执行，runtime 会把这个线程 M 从 P 中摘除 (detach)，然后再创建一个新的操作系统的线程 (如果有空闲的线程可用就复用空闲线程) 来服务于这个 P； 当 M 系统调用结束时候，这个 G 会尝试获取一个空闲的 P 执行，并放入到这个 P 的本地队列。如果获取不到 P，那么这个线程 M 变成休眠状态， 加入到空闲线程中，然后这个 G 会被放入全局队列中。 调度器的生命周期 特殊的 M0 和 G0M0 M0 是启动程序后的编号为 0 的主线程，这个 M 对应的实例会在全局变量 runtime.m0 中，不需要在 heap 上分配，M0 负责执行初始化操作和启动第一个 G， 在之后 M0 就和其他的 M 一样了。 G0 G0 是每次启动一个 M 都会第一个创建的 gourtine，G0 仅用于负责调度的 G，G0 不指向任何可执行的函数，每个 M 都会有一个自己的 G0。在调度或系统调用时会使用 G0 的栈空间，全局变量的 G0 是 M0 的 G0。 我们来跟踪一段代码 1234567package mainimport \"fmt\"func main() &#123; fmt.Println(\"Hello world\")&#125; 接下来我们来针对上面的代码对调度器里面的结构做一个分析。 也会经历如上图所示的过程： runtime 创建最初的线程 m0 和 goroutine g0，并把 2 者关联。 调度器初始化：初始化 m0、栈、垃圾回收，以及创建和初始化由 GOMAXPROCS 个 P 构成的 P 列表。 示例代码中的 main 函数是 main.main，runtime 中也有 1 个 main 函数 ——runtime.main，代码经过编译后，runtime.main 会调用 main.main，程序启动时会为 runtime.main 创建 goroutine，称它为 main goroutine 吧，然后把 main goroutine 加入到 P 的本地队列。 启动 m0，m0 已经绑定了 P，会从 P 的本地队列获取 G，获取到 main goroutine。 G 拥有栈，M 根据 G 中的栈信息和调度信息设置运行环境 M 运行 G G 退出，再次回到 M 获取可运行的 G，这样重复下去，直到 main.main 退出，runtime.main 执行 Defer 和 Panic 处理，或调用 runtime.exit 退出程序。 调度器的生命周期几乎占满了一个 Go 程序的一生，runtime.main 的 goroutine 执行之前都是为调度器做准备工作，runtime.main 的 goroutine 运行，才是调度器的真正开始，直到 runtime.main 结束而结束。 可视化 GMP 编程 有 2 种方式可以查看一个程序的 GMP 的数据。 Go tool trace trace 记录了运行时的信息，能提供可视化的 Web 页面。 简单测试代码：main 函数创建 trace，trace 会运行在单独的 goroutine 中，然后 main 打印”Hello World” 退出。 12345678910111213141516171819202122232425262728package mainimport ( \"os\" \"fmt\" \"runtime/trace\")func main() &#123; //创建trace文件 f, err := os.Create(\"trace.out\") if err != nil &#123; panic(err) &#125; defer f.Close() //启动trace goroutine err = trace.Start(f) if err != nil &#123; panic(err) &#125; defer trace.Stop() //main fmt.Println(\"Hello World\")&#125; 运行结果 12$ go run trace.go Hello World 会得到一个 trace.out 文件，然后我们可以用一个工具打开，来分析这个文件。 1234$ go tool trace trace.out 2020/02/23 10:44:11 Parsing trace...2020/02/23 10:44:11 Splitting trace...2020/02/23 10:44:11 Opening browser. Trace viewer is listening on http://127.0.0.1:33479 我们可以通过浏览器打开 http://127.0.0.1:33479网址，点击 view trace 能够看见可视化的调度流程。 G信息 点击 Goroutines 那一行可视化的数据条，我们会看到一些详细的信息。 1一共有两个G在程序中，一个是特殊的G0，是每个M必须有的一个初始化的G，这个我们不必讨论。 其中 G1 应该就是 main goroutine (执行 main 函数的协程)，在一段时间内处于可运行和运行的状态。 M信息 点击 Threads 那一行可视化的数据条，我们会看到一些详细的信息。 一共有两个 M 在程序中，一个是特殊的 M0，用于初始化使用，这个我们不必讨论。 G1 中调用了 main.main，创建了 trace goroutine g18。G1 运行在 P1 上，G18 运行在 P0 上。 这里有两个 P，我们知道，一个 P 必须绑定一个 M 才能调度 G。 我们在来看看上面的 M 信息。 我们会发现，确实 G18 在 P0 上被运行的时候，确实在 Threads 行多了一个 M 的数据，点击查看如下： 多了一个 M2 应该就是 P0 为了执行 G18 而动态创建的 M2. Debug trace12345678910111213package mainimport ( \"fmt\" \"time\")func main() &#123; for i := 0; i &lt; 5; i++ &#123; time.Sleep(time.Second) fmt.Println(\"Hello World\") &#125;&#125; 编译 1$ go build trace2.go 通过 Debug 方式运行 1234567891011$ GODEBUG=schedtrace=1000 ./trace2 SCHED 0ms: gomaxprocs=2 idleprocs=0 threads=4 spinningthreads=1 idlethreads=1 runqueue=0 [0 0]Hello WorldSCHED 1003ms: gomaxprocs=2 idleprocs=2 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0]Hello WorldSCHED 2014ms: gomaxprocs=2 idleprocs=2 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0]Hello WorldSCHED 3015ms: gomaxprocs=2 idleprocs=2 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0]Hello WorldSCHED 4023ms: gomaxprocs=2 idleprocs=2 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0]Hello World SCHED：调试信息输出标志字符串，代表本行是 goroutine 调度器的输出； 0ms：即从程序启动到输出这行日志的时间； gomaxprocs: P 的数量，本例有 2 个 P, 因为默认的 P 的属性是和 cpu 核心数量默认一致，当然也可以通过 GOMAXPROCS 来设置； idleprocs: 处于 idle 状态的 P 的数量；通过 gomaxprocs 和 idleprocs 的差值，我们就可知道执行 go 代码的 P 的数量； threads: os threads/M 的数量，包含 scheduler 使用的 m 数量，加上 runtime 自用的类似 sysmon 这样的 thread 的数量； spinningthreads: 处于自旋状态的 os thread 数量； idlethread: 处于 idle 状态的 os thread 的数量； runqueue=0： Scheduler 全局队列中 G 的数量； [0 0]: 分别为 2 个 P 的 local queue 中的 G 的数量。 下一篇，我们来继续详细的分析 GMP 调度原理的一些场景问题。 Go 调度器调度场景过程全解析场景 1 P 拥有 G1，M1 获取 P 后开始运行 G1，G1 使用 go func() 创建了 G2，为了局部性 G2 优先加入到 P1 的本地队列。 场景 2 G1 运行完成后 (函数：goexit)，M 上运行的 goroutine 切换为 G0，G0 负责调度时协程的切换（函数：schedule）。从 P 的本地队列取 G2，从 G0 切换到 G2，并开始运行 G2 (函数：execute)。实现了线程 M1 的复用。 场景 3 假设每个 P 的本地队列只能存 3 个 G。G2 要创建了 6 个 G，前 3 个 G（G3, G4, G5）已经加入 p1 的本地队列，p1 本地队列满了。 场景 4 G2 在创建 G7 的时候，发现 P1 的本地队列已满，需要执行负载均衡 (把 P1 中本地队列中前一半的 G，还有新创建 G 转移到全局队列)1（实现中并不一定是新的 G，如果 G 是 G2 之后就执行的，会被保存在本地队列，利用某个老的 G 替换新 G 加入全局队列） 这些 G 被转移到全局队列时，会被打乱顺序。所以 G3,G4,G7 被转移到全局队列。 场景 5 G2 创建 G8 时，P1 的本地队列未满，所以 G8 会被加入到 P1 的本地队列。 G8 加入到 P1 点本地队列的原因还是因为 P1 此时在与 M1 绑定，而 G2 此时是 M1 在执行。所以 G2 创建的新的 G 会优先放置到自己的 M 绑定的 P 上。 场景 6 规定：在创建 G 时，运行的 G 会尝试唤醒其他空闲的 P 和 M 组合去执行。 假定 G2 唤醒了 M2，M2 绑定了 P2，并运行 G0，但 P2 本地队列没有 G，M2 此时为自旋线程（没有 G 但为运行状态的线程，不断寻找 G）。 场景 7 M2 尝试从全局队列 (简称 “GQ”) 取一批 G 放到 P2 的本地队列（函数：findrunnable()）。M2 从全局队列取的 G 数量符合下面的公式：1n = min(len(GQ)/GOMAXPROCS + 1, len(GQ/2)) 至少从全局队列取 1 个 g，但每次不要从全局队列移动太多的 g 到 p 本地队列，给其他 p 留点。这是从全局队列到 P 本地队列的负载均衡。 假定我们场景中一共有 4 个 P（GOMAXPROCS 设置为 4，那么我们允许最多就能用 4 个 P 来供 M 使用）。所以 M2 只从能从全局队列取 1 个 G（即 G3）移动 P2 本地队列，然后完成从 G0 到 G3 的切换，运行 G3。 场景 8 假设 G2 一直在 M1 上运行，经过 2 轮后，M2 已经把 G7、G4 从全局队列获取到了 P2 的本地队列并完成运行，全局队列和 P2 的本地队列都空了，如场景 8 图的左半部分。 全局队列已经没有 G，那 m 就要执行 work stealing (偷取)：从其他有 G 的 P 哪里偷取一半 G 过来，放到自己的 P 本地队列。P2 从 P1 的本地队列尾部取一半的 G，本例中一半则只有 1 个 G8，放到 P2 的本地队列并执行。 场景 9 G1 本地队列 G5、G6 已经被其他 M 偷走并运行完成，当前 M1 和 M2 分别在运行 G2 和 G8，M3 和 M4 没有 goroutine 可以运行，M3 和 M4 处于自旋状态，它们不断寻找 goroutine。 为什么要让 m3 和 m4 自旋，自旋本质是在运行，线程在运行却没有执行 G，就变成了浪费 CPU. 为什么不销毁现场，来节约 CPU 资源。因为创建和销毁 CPU 也会浪费时间，我们希望当有新 goroutine 创建时，立刻能有 M 运行它，如果销毁再新建就增加了时延，降低了效率。当然也考虑了过多的自旋线程是浪费 CPU，所以系统中最多有 GOMAXPROCS 个自旋的线程 (当前例子中的 GOMAXPROCS=4，所以一共 4 个 P)，多余的没事做线程会让他们休眠。 场景 10 ​ 假定当前除了 M3 和 M4 为自旋线程，还有 M5 和 M6 为空闲的线程 (没有得到 P 的绑定，注意我们这里最多就只能够存在 4 个 P，所以 P 的数量应该永远是 M&gt;=P, 大部分都是 M 在抢占需要运行的 P)，G8 创建了 G9，G8 进行了阻塞的系统调用，M2 和 P2 立即解绑，P2 会执行以下判断：如果 P2 本地队列有 G、全局队列有 G 或有空闲的 M，P2 都会立马唤醒 1 个 M 和它绑定，否则 P2 则会加入到空闲 P 列表，等待 M 来获取可用的 p。本场景中，P2 本地队列有 G9，可以和其他空闲的线程 M5 绑定。 场景 11 G8 创建了 G9，假如 G8 进行了非阻塞系统调用。 ​ M2 和 P2 会解绑，但 M2 会记住 P2，然后 G8 和 M2 进入系统调用状态。当 G8 和 M2 退出系统调用时，会尝试获取 P2，如果无法获取，则获取空闲的 P，如果依然没有，G8 会被记为可运行状态，并加入到全局队列，M2 因为没有 P 的绑定而变成休眠状态 (长时间休眠等待 GC 回收销毁)。 小结 总结，Go 调度器很轻量也很简单，足以撑起 goroutine 的调度工作，并且让 Go 具有了原生（强大）并发的能力。Go 调度本质是把大量的 goroutine 分配到少量线程上去执行，并利用多核并行，实现更强大的并发。","categories":[],"tags":[]},{"title":"istio 初体验","slug":"istio","date":"2020-03-10T14:59:01.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/03/10/istio/","link":"","permalink":"https://overtalk.site/2020/03/10/istio/","excerpt":"","text":"istio 初体验 使用虚拟机搭建 minikube + istio，体验 istio设置 cpu 2 核，内存 4G Istio 知识图 虚拟机 使用 VMWare，镜像为 centos7 安装步骤关闭防火墙 关闭防火墙12$ systemctl disable firewalld$ systemctl stop firewalld 安装 Docker1234567891011121314$ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2$ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo$ sudo yum update -y$ sudo yum install docker-ce -y$ systemctl enable docker$ systemctl start docker 安装 kubectl12345$ curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl$ install kubectl /usr/local/bin/kubectl$ which kubectl 安装 minikube123456$ curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\ &amp;&amp; sudo install minikube-linux-amd64 /usr/local/bin/minikube$ which minikube$ minikube start --vm-driver=none 安装 istioctl1$ curl -L https://git.io/getLatestIstio | sh - 安装 istio 核心 进入到上一步下载的文件夹中执行如下操作 1234# 安装istio自定义的一些 k8s crd$ for i in install/kubernetes/helm/istio-init/files/crd*yaml; do kubectl apply -f $i; done$ kubectl apply -f install/kubernetes/istio-demo.yaml 验证安装： 12$ kubectl get svc -n istio-system$ kubectl get pods -n istio-system 运行bookinfo示例 参考官方文档 部署服务12345678# 给 default namespace 打标签，启动 istio reject$ kubectl label namespace default istio-injection=enabled$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml# 验证$ kubectl get services$ kubectl get pods 部署 gateway1$ kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml 要确认Bookinfo应用程序正在运行，请通过curl某个Pod中的命令向其发送请求，例如ratings：12$ kubectl exec -it $(kubectl get pod -l app=ratings -o jsonpath='&#123;.items[0].metadata.name&#125;') -c ratings -- curl productpage:9080/productpage | grep -o \"&lt;title&gt;.*&lt;/title&gt;\"&lt;title&gt;Simple Bookstore App&lt;/title&gt; 确定入口IP和端口 官方文档 确定了ip &amp; 端口，可以从外部访问 Istio的一些简单功能 基于上述的demo，测试一些 istio 的简单功能 基于权重的路由 通过CRD DestinationRule创建3 个reviews 子版本: 1$ kubectl apply -f samples/bookinfo/networking/destination-rule-reviews.yaml 通过CRD VirtualService 调整个 reviews 服务子版本的流量比例, 设置 v1 和 v3 各占 50% 1$ kubectl apply -f samples/bookinfo/networking/virtual-service-reviews-50-v3.yaml 刷新页面, 可以看到无法再看到reviews v2的内容, 页面在v1和v3之间切换. 基于内容路由 修改reviews CRD, 将jason 登录的用户版本路由到v2, 其他用户路由到版本v3. 1$ kubectl apply -f samples/bookinfo/networking/virtual-service-reviews-jason-v2-v3.yaml 刷新页面, 使用jason登录的用户, 将看到v2 黑色星星版本, 其他用户将看到v3 红色星星版本.","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"service mesh","slug":"service-mesh","permalink":"https://overtalk.site/tags/service-mesh/"}]},{"title":"iptables","slug":"network-iptables","date":"2020-03-04T17:00:58.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/03/04/network-iptables/","link":"","permalink":"https://overtalk.site/2020/03/04/network-iptables/","excerpt":"","text":"重温了一下网络，感觉大学时期等于白学（😂） 从头来记录一下我们是怎么上网的吧 PPPoE 家里办了宽带要上网，没有 ip 就没法上网，所以第一步就是 pppoe pppoe是拨号获得IP，并且每次拨号后你的IP都会发生变化 一般是运营商提供的光猫进行拨号 一般获得ip的方式有如下几种 拔号 ：以账号和密码为依据，获得IP不固定 静态 ：设置好ip 动态（DHCP）：自动获取IP地址，只在局域网内才会用得到 DHCP 家里路由器好了之后，电脑网线插入路由器，发现本机上没有任何 IP 数据设定，就会通过 DHCP 协议获取一个ip 具体过程 ARP 地址解析协议， 用于实现从 IP 地址到 MAC 地址的映射，即询问目标IP对应的MAC地址。 在网络通信中，主机和主机通信的数据包需要依据OSI模型从上到下进行数据封装，当数据封装完整后，再向外发出。所以在局域网的通信中，不仅需要源目IP地址的封装，也需要源目MAC的封装。 当上层协议需要IP对IP通信时,请求主机需要构造数据包.但在此之前,请求主机还需要发送一个ARP请求包,向同一广播域中的所有主机请求被请求主机的MAC地址.随后,请求主机将数据包构造完成后发送给此广播域的二层设备,由它根据MAC地址决定此数据包的去向 这个请求主机发送的ARP请求,基本上就是在问:”大家好,我的IP地址是XX.XX.XX.XX,MAC地址是XX.XX.XX.XX.XX.XX,我需要向IP地址为YY.YY.YY.YY的家伙发些东西,但我不知道它的硬件地址,你们谁有这个IP地址的,可否回复给我你的MAC地址?” 请求主机发送的ARP数据包将被广播给同一广播域的所有设备.不是这个IP地址的设备将简单地丢弃这个数据包,而拥有这个IP地址的设备将发送一个ARP响应.就像是说:”你好,我就是你所找的那个拥有IP地址为YY.YY.YY.YY的,我的MAC地址为YY.YY.YY.YY.YY.YY.” 这样就可以进行通信了 具体过程 route表 详情 访问某个ip时候，就会去查路由表，如果路由表中有匹配该ip的路由，则从对应条目后面标记的网卡出去。 如果没有匹配的项，则走网关（Flags 字段为 UG） 例如我们自己在家中局域网访问百度，这个ip在局域网内部肯定是没有的，则会将流量发送给关（路由器），路由器一般会有两个网卡，将我们的流量通过另外一张连接到公网的网卡发送出去。 路由器收到上述数据，会进行数据转发，这儿就需要提到一个liunx内核的一个参数 net.ipv4.ip_forward 出于安全考虑，Linux系统默认是禁止数据包转发的。所谓转发即当主机拥有多于一块的网卡时，其中一块收到数据包，根据数据包的目的ip地址将数据包发往本机另一块网卡，该网卡根据路由表继续发送数据包。这通常是路由器所要实现的功能。 这个参数指定了Linux系统当前对路由转发功能的支持情况；其值为0时表示禁止进行IP转发；如果是1,则说明IP转发功能已经打开。 NAT 详细内容 顺道讲一讲 iptables 具体操作 iptables的原理主要是对数据包的控制，如下图： 一个数据包进入网卡时，它首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转发出去。 如果数据包就是进入本机的，它就会沿着图向下移动，到达INPUT链。数据包到了INPUT链后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包会经 过OUTPUT链，然后到达POSTROUTING链输出。 如果数据包是要转发出去的，且内核允许转发，数据包就会如图所示向右移动，经过 FORWARD链，然后到达POSTROUTING链输出。 规则、表和链规则（rules） 规则（rules）其实就是网络管理员预定义的条件，规则一般的定义为“如果数据包头符合这样的条件，就这样处理这个数据包”。规则存储在内核空间的信息包过滤表中，这些规则分别指定了源地址、目的地址、传输协议（如TCP、UDP、ICMP）和服务类型（如HTTP、FTP和SMTP）等。当数据包与规则匹配时，iptables就根据规则所定义的方法来处理这些数据包，如放行（accept）、拒绝（reject）和丢弃（drop）等。配置防火墙的主要工作就是添加、修改和删除这些规则。 链（chains） 链（chains）是数据包传播的路径，每一条链其实就是众多规则中的一个检查清单，每一条链中可以有一条或数条规则。当一个数据包到达一个链时，iptables就会从链中第一条规则开始检查，看该数据包是否满足规则所定义的条件。如果满足，系统就会根据该条规则所定义的方法处理该数据包；否则iptables将继续检查下一条规则，如果该数据包不符合链中任一条规则，iptables就会根据该链预先定义的默认策略来处理数据包。 表（tables） 表（tables）提供特定的功能，iptables内置了4个表，即raw表、filter表、nat表和mangle表，分别用于实现包过滤，网络地址转换和包重构的功能。 RAW表 只使用在PREROUTING链和OUTPUT链上,因为优先级最高，从而可以对收到的数据包在连接跟踪前进行处理。一但用户使用了RAW表,在 某个链上,RAW表处理完后,将跳过NAT表和 ip_conntrack处理,即不再做地址转换和数据包的链接跟踪处理了. filter表 主要用于过滤数据包，该表根据系统管理员预定义的一组规则过滤符合条件的数据包。对于防火墙而言，主要利用在filter表中指定的规则来实现对数据包的过滤。Filter表是默认的表，如果没有指定哪个表，iptables 就默认使用filter表来执行所有命令，filter表包含了INPUT链（处理进入的数据包），RORWARD链（处理转发的数据包），OUTPUT链（处理本地生成的数据包）在filter表中只能允许对数据包进行接受，丢弃的操作，而无法对数据包进行更改 nat表 主要用于网络地址转换NAT，该表可以实现一对一，一对多，多对多等NAT 工作，iptables就是使用该表实现共享上网的，NAT表包含了PREROUTING链（修改即将到来的数据包），POSTROUTING链（修改即将出去的数据包），OUTPUT链（修改路由之前本地生成的数据包） mangle表 主要用于对指定数据包进行更改，在内核版本2.4.18 后的linux版本中该表包含的链为：INPUT链（处理进入的数据包），RORWARD链（处理转发的数据包），OUTPUT链（处理本地生成的数据包）POSTROUTING链（修改即将出去的数据包），PREROUTING链（修改即将到来的数据包） 规则表之间的优先顺序： 1Raw——mangle——nat——filter 规则链之间的优先顺序（分三种情况）： 第一种情况：入站数据流向 从外界到达防火墙的数据包，先被PREROUTING规则链处理（是否修改数据包地址等），之后会进行路由选择（判断该数据包应该发往何处），如果数据包 的目标主机是防火墙本机（比如说Internet用户访问防火墙主机中的web服务器的数据包），那么内核将其传给INPUT链进行处理（决定是否允许通 过等），通过以后再交给系统上层的应用程序（比如Apache服务器）进行响应。 第二冲情况：转发数据流向 来自外界的数据包到达防火墙后，首先被PREROUTING规则链处理，之后会进行路由选择，如果数据包的目标地址是其它外部地址（比如局域网用户通过网 关访问QQ站点的数据包），则内核将其传递给FORWARD链进行处理（是否转发或拦截），然后再交给POSTROUTING规则链（是否修改数据包的地 址等）进行处理。 第三种情况：出站数据流向 防火墙本机向外部地址发送的数据包（比如在防火墙主机中测试公网DNS服务器时），首先被OUTPUT规则链处理，之后进行路由选择，然后传递给POSTROUTING规则链（是否修改数据包的地址等）进行处理。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"iptables","slug":"iptables","permalink":"https://overtalk.site/tags/iptables/"}]},{"title":"C++ - map与unordered_map的区别","slug":"cpp-map","date":"2020-03-02T11:04:40.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/03/02/cpp-map/","link":"","permalink":"https://overtalk.site/2020/03/02/cpp-map/","excerpt":"","text":"转自wolfrevoda 头文件 map: #include &lt; map &gt; unordered_map: #include &lt; unordered_map &gt; 内部实现机理 map： map内部实现了一个红黑树，该结构具有自动排序的功能，因此map内部的所有元素都是有序的，红黑树的每一个节点都代表着map的一个元素，因此，对于map进行的查找，删除，添加等一系列的操作都相当于是对红黑树进行这样的操作，故红黑树的效率决定了map的效率。 unordered_map: unordered_map内部实现了一个哈希表，因此其元素的排列顺序是杂乱的，无序的 优缺点以及适用处map 优点： 有序性，这是map结构最大的优点，其元素的有序性在很多应用中都会简化很多的操作 红黑树，内部实现一个红黑书使得map的很多操作在lgnlgn的时间复杂度下就可以实现，因此效率非常的高 缺点： 空间占用率高，因为map内部实现了红黑树，虽然提高了运行效率，但是因为每一个节点都需要额外保存父节点，孩子节点以及红/黑性质，使得每一个节点都占用大量的空间 适用处，对于那些有顺序要求的问题，用map会更高效一些 unordered_map 优点： 因为内部实现了哈希表，因此其查找速度非常的快 缺点： 哈希表的建立比较耗费时间 适用处，对于查找问题，unordered_map会更加高效一些，因此遇到查找问题，常会考虑一下用unordered_map note: 对于unordered_map或者unordered_set容器，其遍历顺序与创建该容器时输入元素的顺序是不一定一致的，遍历是按照哈希表从前往后依次遍历的 unordered_map 和 map 都不是线程安全的 一些基本的用法map123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include&lt;iostream&gt;#include&lt;map&gt;#include&lt;string&gt; using namespace std; int main()&#123; // 构造函数 map&lt;string, int&gt; dict; // 插入数据的三种方式 dict.insert(pair&lt;string,int&gt;(\"apple\",2)); dict.insert(map&lt;string, int&gt;::value_type(\"orange\",3)); dict[\"banana\"] = 6; // 判断是否有元素 if(dict.empty()) cout&lt;&lt;\"该字典无元素\"&lt;&lt;endl; else cout&lt;&lt;\"该字典共有\"&lt;&lt;dict.size()&lt;&lt;\"个元素\"&lt;&lt;endl; // 遍历 map&lt;string, int&gt;::iterator iter; for(iter=dict.begin();iter!=dict.end();iter++) cout&lt;&lt;iter-&gt;first&lt;&lt;ends&lt;&lt;iter-&gt;second&lt;&lt;endl; // 查找 if((iter=dict.find(\"banana\"))!=dict.end()) // 返回一个迭代器指向键值为key的元素，如果没找到就返回end() cout&lt;&lt;\"已找到banana,其value为\"&lt;&lt;iter-&gt;second&lt;&lt;\".\"&lt;&lt;endl; else cout&lt;&lt;\"未找到banana.\"&lt;&lt;endl; if(dict.count(\"watermelon\")==0) // 返回键值等于key的元素的个数 cout&lt;&lt;\"watermelon不存在\"&lt;&lt;endl; else cout&lt;&lt;\"watermelon存在\"&lt;&lt;endl; pair&lt;map&lt;string, int&gt;::iterator, map&lt;string, int&gt;::iterator&gt; ret; ret = dict.equal_range(\"banana\"); // 查找键值等于 key 的元素区间为[start,end)，指示范围的两个迭代器以 pair 返回 cout&lt;&lt;ret.first-&gt;first&lt;&lt;ends&lt;&lt;ret.first-&gt;second&lt;&lt;endl; cout&lt;&lt;ret.second-&gt;first&lt;&lt;ends&lt;&lt;ret.second-&gt;second&lt;&lt;endl; iter = dict.lower_bound(\"boluo\"); // 返回一个迭代器，指向键值&gt;=key的第一个元素。 cout&lt;&lt;iter-&gt;first&lt;&lt;endl; iter = dict.upper_bound(\"boluo\"); // 返回一个迭代器，指向值键值&gt;key的第一个元素。 cout&lt;&lt;iter-&gt;first&lt;&lt;endl; return 0; unordered_map123456789101112131415161718192021222324252627282930313233343536373839#include&lt;string&gt; #include&lt;iostream&gt; #include&lt;unordered_map&gt;using namespace std; int main()&#123; unordered_map&lt;string, int&gt; dict; // 声明unordered_map对象 // 插入数据的三种方式 dict.insert(pair&lt;string,int&gt;(\"apple\",2)); dict.insert(unordered_map&lt;string, int&gt;::value_type(\"orange\",3)); dict[\"banana\"] = 6; // 判断是否有元素 if(dict.empty()) cout&lt;&lt;\"该字典无元素\"&lt;&lt;endl; else cout&lt;&lt;\"该字典共有\"&lt;&lt;dict.size()&lt;&lt;\"个元素\"&lt;&lt;endl; // 遍历 unordered_map&lt;string, int&gt;::iterator iter; for(iter=dict.begin();iter!=dict.end();iter++) cout&lt;&lt;iter-&gt;first&lt;&lt;ends&lt;&lt;iter-&gt;second&lt;&lt;endl; // 查找 if(dict.count(\"boluo\")==0) cout&lt;&lt;\"can't find boluo!\"&lt;&lt;endl; else cout&lt;&lt;\"find boluo!\"&lt;&lt;endl; if((iter=dict.find(\"banana\"))!=dict.end()) cout&lt;&lt;\"banana=\"&lt;&lt;iter-&gt;second&lt;&lt;endl; else cout&lt;&lt;\"can't find boluo!\"&lt;&lt;endl; return 0;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"cpp - shared_ptr详解","slug":"cpp-shared-ptr","date":"2020-02-29T13:21:57.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/02/29/cpp-shared-ptr/","link":"","permalink":"https://overtalk.site/2020/02/29/cpp-shared-ptr/","excerpt":"","text":"转自守望的个人博客 shared_ptr 在 cpp - unique_ptr详解 说到，如果有可能就使用unique_ptr，然后很多时候对象是需要共享的，因此shared_ptr也就会用得很多。shared_ptr允许多个指针指向同一个对象，当指向对象的最后一个shared_ptr销毁时，该对象也就会自动销毁。 基本使用 它的很多操作与unique_ptr类似。例如： 123456shared_ptr&lt;int&gt; sp; //声明一个指向int类型的智能指针sp.reset(new int(42));auto sp1 = make_shared&lt;string&gt;(\"hello\"); //sp1是一个智能指针shared_ptr sp2(new int(42); 而 make_shared 方式是推荐的一种，它使用一次分配，比较安全。 哪些操作会改变计数 我们都知道，当引用计数为0时，shared_ptr所管理的对象自动销毁，那么那些情况会影响引用计数呢？ 赋值 例如： 1auto sp = make_shared&lt;int&gt;(1024);//sp的引用计数为1 再比如： 123auto sp1 = make_shared&lt;string&gt;(\"obj1\");auto sp2 = make_shared&lt;string&gt;(\"obj2\");auto sp1 = sp2; 该操作会减少sp1的引用计数，增加sp2的引用计数。有的人可能不理解，为什么这样还会减少sp1的引用计数？ 试想一下，sp1指向对象obj1，sp2指向对象obj2，那么赋值之后，sp1也会指向obj2，那就是说指向obj1的就少了，指向obj2的就会多，如果此时没有其他shared_ptr指向obj1，那么obj1将会销毁。 拷贝 例如： 12auto sp2 = make_shared&lt;int&gt;(1024);auto sp1(sp2); 该操作会使得sp1和sp2都指向同一个对象。 而关于拷贝比较容易忽略的就是作为参数传入函数： 12auto sp2 = make_shared&lt;int&gt;(1024);func(sp2); //func的执行会增加其引用计数 可以看一个具体的例子： 1234567891011121314151617#include&lt;iostream&gt;#include&lt;memory&gt;void func0(std::shared_ptr&lt;int&gt; sp)&#123; std::cout&lt;&lt;\"fun0:\"&lt;&lt;sp.use_count()&lt;&lt;std::endl;&#125;void func1(std::shared_ptr&lt;int&gt; &amp;sp)&#123; std::cout&lt;&lt;\"fun1:\"&lt;&lt;sp.use_count()&lt;&lt;std::endl;&#125;int main()&#123; auto sp = std::make_shared&lt;int&gt;(1024); func0(sp); func1(sp); return 0;&#125; 其运行输出结果为： 12fun0:2 fun1:1 很显然，fun0，拷贝了shard_ptr sp，而fun1，并没有拷贝，因此前者会增加引用计数，而后者并不影响。 reset 调用reset会减少计数： 1sp.reset() 而如果sp是唯一指向该对象的，则该对象被销毁。 应当注意使用的方式 虽然shared_ptr能很大程度避免内存泄漏，但是使用不当，仍然可能导致意外发生。 存放于容器中的shared_ptr 如果你的容器中存放的时shared_ptr，而你后面又不再需要它时，记得使用erase删除那些不要的元素，否则由于引用计数一直存在，其对象将始终得不到销毁，除非容器本身销毁。 不要使用多个裸指针初始化多个shared_ptr 注意，下面方式是不该使用的： 12345678910#include&lt;iostream&gt;#include&lt;memory&gt;int main()&#123; auto *p = new std::string(\"hello\"); std::shared_ptr&lt;std::string&gt; sp1(p); /*不要这样做！！*/ std::shared_ptr&lt;std::string&gt; sp2(p); return 0;&#125; 这样会导致两个shared_ptr管理同一个对象，当其中一个被销毁时，其管理的对象会被销毁，而另外一个销毁时，对象会二次销毁，然而实际上，对象已经不在了，最终造成严重后果。 而与这种情况类似的，就是使用get()获取裸指针，然后去初始化另外一个shared_ptr，或者delete get返回的指针： 12345678910#include&lt;iostream&gt;#include&lt;memory&gt;int main()&#123; auto sp = std::make_shared&lt;std::string&gt;(\"wechat:shouwangxiansheng\"); std::string *p = sp.get(); std::shared_ptr&lt;std::string&gt; sp2(p);/*不要这样做!!*/ delete p;/*不要这样做*/ return 0;&#125; 如果对象不是new分配的，请传递删除器 与unique_ptr类似，它可以指定删除器，默认是使用delete。例如：12345678910111213#include&lt;iostream&gt;#include&lt;unistd.h&gt;#include&lt;memory&gt;void myClose(int *fd)&#123; close(*fd);&#125;int main()&#123; int socketFd = 10;//just for example std::shared_ptr&lt;int&gt; up(&amp;socketFd,myClose); return 0;&#125; 与unique_ptr的区别 首先最明显的区别自然是它们一个是专享对象，一个是共享对象。而正是由于共享，包括要维护引用计数等，它带来的开销相比于unique_ptr来说要大。 另外，shared_ptr无法直接处理数组，因为它使用delete来销毁对象，而对于数组，需要用delete[]。因此，需要指定删除器： 12345678910#include&lt;iostream&gt;#include&lt;memory&gt;int main()&#123; auto sp = std::make_shared&lt;std::string&gt;(\"wechat:shouwangxiansheng\"); std::string *p = sp.get(); //std::shared_ptr&lt;int&gt; sp1(new int[10]);//不能这样 std::shared_ptr&lt;int&gt; sp1(new int[10],[](int *p)&#123;delete[] p;&#125;); return 0;&#125; 示例中使用了lambda表达式。 不过一般来说，好好的容器不用，为什么要用动态数组呢？ 总结 以上就是shared_ptr基本内容，一般来说，规范使用shared_ptr能很大程度避免内存泄露。注意，shared_ptr提供，*，-&gt;操作，不直接提供指针运算和[]。 enable_shared_from_this std::enable_shared_from_this 能让一个对象（假设其名为 t ，且已被一个 std::shared_ptr 对象 pt 管理）安全地生成其他额外的 std::shared_ptr 实例（假设名为 pt1, pt2, … ） ，它们与 pt 共享对象 t 的所有权。 若一个类 T 继承 std::enable_shared_from_this ，则会为该类 T 提供成员函数： shared_from_this 。 当 T 类型对象 t 被一个为名为 pt 的 std::shared_ptr 类对象管理时，调用 T::shared_from_this 成员函数，将会返回一个新的 std::shared_ptr 对象，它与 pt 共享 t 的所有权。 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;#include &lt;memory&gt;class Test : public std::enable_shared_from_this&lt;Test&gt;&#123;public: Test(int a) : a(a) , b(\"sdf\") &#123; &#125; void show() &#123; std::cout &lt;&lt; a &lt;&lt; b &lt;&lt; std::endl; &#125; int a; char* b;&#125;;int main()&#123; auto t = std::make_shared&lt;Test&gt;(1); auto t2 = t-&gt;shared_from_this(); t-&gt;show(); t2-&gt;show(); t-&gt;a = 23; t-&gt;show(); t2-&gt;show();&#125; 当 t 的值发生变化的时候，t2 的值也会变化","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"cpp - unique_ptr详解","slug":"cpp-unique-ptr","date":"2020-02-29T11:18:58.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/02/29/cpp-unique-ptr/","link":"","permalink":"https://overtalk.site/2020/02/29/cpp-unique-ptr/","excerpt":"","text":"转自守望的个人博客 unique_ptr 一个unique_ptr独享它指向的对象。 也就是说，同时只有一个unique_ptr指向同一个对象，当这个unique_ptr被销毁时，指向的对象也随即被销毁。 使用它需要包含下面的头文件：1#include&lt;memory&gt; 基本使用 常见方式有：123//可以指向int的unique_ptr，不过是空的std::unique_ptr&lt;int&gt; up; up = std::unique_ptr&lt;int&gt;(new int(22)); 123// 也可以指向一个new出来的对象。std::unique_ptr&lt;string&gt; up1(new string(\"xd\"));std::unique_ptr&lt;int[]&gt; up2(new int[10]);//数组需要特别注意 你也可以结合上面两种方式，如： 123std::unique_ptr&lt;int&gt; up;//声明空的unique_ptrint *p= new int(1111);up.reset(p);//令up指向新的对象，p为内置指针 通常来说，在销毁对象的时候，都是使用delete来销毁，但是也可以使用指定的方式进行销毁。举个简单的例子，假如你打开了一个连接，获取到了一个文件描述符，现在你想通过unique_ptr来管理，希望在不需要的时候，能够借助unique_ptr帮忙关闭它。 1234567891011121314151617181920212223#include&lt;iostream&gt;#include&lt;memory&gt;void closeSocket(int* fd)&#123; std::cout &lt;&lt; \"mock close socket!\" &lt;&lt; std::endl; delete fd;&#125;int* newSocket()&#123; return new(std::nothrow) int(21);&#125;int main()&#123; int* socket = newSocket();//just for example std::unique_ptr&lt;int, decltype(closeSocket)*&gt; up(socket, closeSocket); /*下面是另外两种写法，后面一种是使用lambda表达式*/ //std::unique_ptr&lt;int,void(*)(int*)&gt; up(&amp;socketFd,myClose); //std::unique_ptr&lt;int,void(*)(int*)&gt; ip(&amp;socketFd,[](int *fd)&#123;close(*fd);&#125;); return 0;&#125; 它的用法如下： 12std::unique_ptr&lt;T,D&gt; up(t,d);std::unique_ptr&lt;T,D&gt; up(d);//空的unique_ptr 含义分别如下： T unique_ptr管理的对象类型 D 删除器类型 t unique_ptr管理的对象 d 删除器函数/function对象等，用于释放对象指针 这里使用了decltype(myClose)用于获取closeSocket函数的类型，表明它是一个指针类型，即函数指针，它传入参数是int*。你也可以使用注释中的方式。 即便后面执行出现异常时，这个socket连接也能够正确关闭。 后面我们也可以看到，与shared_ptr不同，unique_ptr在编译时绑定删除器，避免了运行时开销。 释放指向的对象 一般来说，unique_ptr被销毁时（如离开作用域），对象也就自动释放了，也可以通过其他方式下显示释放对象。如： 123up = nullptr;//置为空，释放up指向的对象up.release();//放弃控制权，返回裸指针，并将up置为空up.reset();//释放up指向的对象 可以看到release和reset的区别在于，前者会释放控制权，返回裸指针，你还可以继续使用。而后者直接释放了指向对象。 unique_ptr不支持普通的拷贝和赋值 需要特别注意的是，由于unique_ptr“独有”的特点，它不允许进行普通的拷贝或赋值，例如：1234std::unique_ptr&lt;int&gt; up0;std::unique_ptr&lt;int&gt; up1(new int(1111));up0 = up1 //错误，不可赋值std::unique_ptr&lt;int&gt; up2(up1);//错误，不支持拷贝 总之记住，既然unique_ptr是独享对象，那么任何可能被共享的操作都是不允许的，但是可以移动。 移动unique_ptr的对象 虽然unique_ptr独享对象，但是也可以移动，即转移控制权。如： 12std::unique_ptr&lt;int&gt; up1(new int(42));std::unique_ptr&lt;int&gt; up2(up1.release()); up2接受up1 release之后的指针，或者： 123std::unique_ptr&lt;int&gt; up1(new int(42));std::unique_ptr&lt;int&gt; up2;up2.reset(up1.release()); 或者使用move： 12std::unique_ptr&lt;int&gt; up1(new int(42));std::unique_ptr&lt;int&gt; up2(std::move(up1)); 在函数中的使用 既然unique_ptr独享对象，那么就无法直接作为参数，应该怎么办呢？ 作为参数 如果函数以unique_ptr作为参数呢？如果像下面这样直接把unique_ptr作为参数肯定就报错了，因为它不允许被复制： 123456789101112131415#include&lt;iostream&gt;#include&lt;memory&gt;void test(std::unique_ptr&lt;int&gt; p)&#123; *p = 10;&#125;int main()&#123; std::unique_ptr&lt;int&gt; up(new int(42)); test(up);//试图传入unique_ptr，编译报错 std::cout&lt;&lt;*up&lt;&lt;std::endl; return 0;&#125; 上面的代码编译将直接报错。 当然我们可以向函数中传递普通指针，使用get函数就可以获取，如： 123456789101112131415#include&lt;iostream&gt;#include&lt;memory&gt;void test(int *p)&#123; *p = 10;&#125;int main()&#123; std::unique_ptr&lt;int&gt; up(new int(42)); test(up.get());//传入裸指针作为参数 std::cout&lt;&lt;*up&lt;&lt;std::endl;//输出10 return 0;&#125; 或者使用引用作为参数： 123456789101112131415#include&lt;iostream&gt;#include&lt;memory&gt;void test(std::unique_ptr&lt;int&gt; &amp;p)&#123; *p = 10;&#125;int main()&#123; std::unique_ptr&lt;int&gt; up(new int(42)); test(up); std::cout&lt;&lt;*up&lt;&lt;std::endl;//输出10 return 0;&#125; 当然如果外部不再需要使用了，那么你完全可以转移，将对象交给你调用的函数管理，这里可以使用move函数： 12345678910111213#include&lt;iostream&gt;#include&lt;memory&gt;void test(std::unique_ptr&lt;int&gt; p)&#123; *p = 10;&#125;int main()&#123; std::unique_ptr&lt;int&gt; up(new int(42)); test(std::unique_ptr&lt;int&gt;(up.release())); //test(std::move(up));//这种方式也可以 return 0;&#125; 作为返回值 unique_ptr可以作为参数返回： 123456789101112131415#include&lt;iostream&gt;#include&lt;memory&gt;std::unique_ptr&lt;int&gt; test(int i)&#123; return std::unique_ptr&lt;int&gt;(new int(i));&#125;int main()&#123; std::unique_ptr&lt;int&gt; up = test(10); //std::shared_ptr&lt;int&gt; up = test(10); std::cout&lt;&lt;*up&lt;&lt;std::endl; return 0;&#125; 你还可以把unique_ptr转换为shared_ptr使用，如注释行所示。 为什么优先选用unique_ptr 回到标题的问题，问什么优先选用unique_ptr。 避免内存泄露 避免更大开销 第一点相信很好理解，自动管理，不需要时即释放，甚至可以防止下面这样的情况： 123int * p = new int(1111);/*do something*/delete p; 如果在do something的时候，出现了异常，退出了，那delete就永远没有执行的机会，就会造成内存泄露，而如果使用unique_ptr就不会有这样的困扰了。 第二点为何这么说？因为相比于shared_ptr，它的开销更小，甚至可以说和裸指针相当，它不需要维护引用计数的原子操作等等。 所以说，如果有可能，优先选用unique_ptr。 总结 本文介绍了uniqueptr的基本使用情况和使用场景，它能够有效地避免内存泄露并且效率可控，因此如果能够满足需求，则优先选择unique\\ptr。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"cpp - weak_ptr详解","slug":"cpp-weak-ptr","date":"2020-02-29T11:18:58.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/02/29/cpp-weak-ptr/","link":"","permalink":"https://overtalk.site/2020/02/29/cpp-weak-ptr/","excerpt":"","text":"转自dsw846 为什么需要weak_ptr？ 在正式介绍weak_ptr之前，我们先来回忆一下shared_ptr的一些知识。我们知道shared_ptr是采用引用计数的智能指针，多个shared_ptr实例可以指向同一个动态对象，并维护了一个共享的引用计数器。 对于引用计数法实现的计数，总是避免不了循环引用（或环形引用）的问题，shared_ptr也不例外。 我们先来看看下面这个例子： 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;memory&gt;#include &lt;vector&gt;using namespace std;class ClassB;class ClassA &#123;public: ClassA() &#123; cout &lt;&lt; \"ClassA Constructor...\" &lt;&lt; endl; &#125; ~ClassA() &#123; cout &lt;&lt; \"ClassA Destructor...\" &lt;&lt; endl; &#125; shared_ptr&lt;ClassB&gt; pb; // 在A中引用B&#125;;class ClassB &#123;public: ClassB() &#123; cout &lt;&lt; \"ClassB Constructor...\" &lt;&lt; endl; &#125; ~ClassB() &#123; cout &lt;&lt; \"ClassB Destructor...\" &lt;&lt; endl; &#125; shared_ptr&lt;ClassA&gt; pa; // 在B中引用A&#125;;int main() &#123; shared_ptr&lt;ClassA&gt; ptr_a = make_shared&lt;ClassA&gt;(); shared_ptr&lt;ClassB&gt; ptr_b = make_shared&lt;ClassB&gt;(); ptr_a-&gt;pb = ptr_b; ptr_b-&gt;pa = ptr_a; std::cout &lt;&lt; \"spa use_count:\" &lt;&lt; ptr_a.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; \"spb use_count:\" &lt;&lt; ptr_b.use_count() &lt;&lt; std::endl;&#125; 上面代码的输出如下： 1234ClassA Constructor...ClassB Constructor...spa use_count:2spb use_count:2 从上面代码中，ClassA和ClassB间存在着循环引用，从运行结果中我们可以看到：当main函数运行结束后，spa和spb管理的动态资源并没有得到释放，产生了内存泄露。为了解决类似这样的问题，C++11引入了weak_ptr，来打破这种循环引用。 weak_ptr是什么？ weak_ptr是为了配合shared_ptr而引入的一种智能指针，它指向一个由shared_ptr管理的对象而不影响所指对象的生命周期 也就是将一个weak_ptr绑定到一个shared_ptr不会改变shared_ptr的引用计数。 不论是否有weak_ptr指向，一旦最后一个指向对象的shared_ptr被销毁，对象就会被释放。从这个角度看，weak_ptr更像是shared_ptr的一个助手而不是智能指针。 weak_ptr如何使用？ 接下来，我们来看看weak_ptr的简单用法。 如何创建weak_ptr实例 当我们创建一个weak_ptr时，需要用一个shared_ptr实例来初始化weak_ptr，由于是弱共享，weak_ptr的创建并不会影响shared_ptr的引用计数值。示例：1234567891011121314151617181920212223&#123; std::shared_ptr&lt;int&gt; fsPtr(new int(5)); std::weak_ptr&lt;int&gt; fwPtr = fsPtr; //weak_ptr不会改变shared_ptr，但是会和shared_ptr的引用保持一致 std::cout &lt;&lt; \"fsPtr use_count:\" &lt;&lt; fsPtr.use_count() &lt;&lt; \" fwPtr use_count:\" &lt;&lt; fwPtr.use_count() &lt;&lt; std::endl; //fwPtr.lock()后会该变shared_ptr的引用计数(+1) //std::shared_ptr&lt;int&gt; fsPtr2 = fwPtr.lock(); //std::cout &lt;&lt; \"fsPtr use_count:\" &lt;&lt; fsPtr.use_count() &lt;&lt; \" fwPtr use_count:\" &lt;&lt; fwPtr.use_count() &lt;&lt; std::endl; //编译报错，weak_ptr没有重载*，-&gt;操作符，因此不可直接通过weak_ptr使用对象,只能通过lock()使用shared_ptr来操作 //std::cout &lt;&lt; \" number is \" &lt;&lt; *fwPtr &lt;&lt; std::endl; fsPtr.reset(); if (fwPtr.expired()) &#123; std::cout &lt;&lt; \"shared_ptr object has been destory\" &lt;&lt; std::endl; &#125; std::shared_ptr&lt;int&gt; fsPtr3 = fwPtr.lock(); //fsPtr3为NULL std::cout &lt;&lt; \" number is \" &lt;&lt; *fsPtr3 &lt;&lt; std::endl; //运行时中断&#125; 如何判断weak_ptr指向对象是否存在 既然weak_ptr并不改变其所共享的shared_ptr实例的引用计数，那就可能存在weak_ptr指向的对象被释放掉这种情况。这时，我们就不能使用weak_ptr直接访问对象。那么我们如何判断weak_ptr指向对象是否存在呢？C++中提供了lock函数来实现该功能。如果对象存在，lock()函数返回一个指向共享对象的shared_ptr，否则返回一个空shared_ptr。示例： 1234567891011121314151617181920212223class A&#123;public: A() : a(3) &#123; cout &lt;&lt; \"A Constructor...\" &lt;&lt; endl; &#125; ~A() &#123; cout &lt;&lt; \"A Destructor...\" &lt;&lt; endl; &#125; int a;&#125;;int main() &#123; shared_ptr&lt;A&gt; sp(new A()); weak_ptr&lt;A&gt; wp(sp); //sp.reset(); if (shared_ptr&lt;A&gt; pa = wp.lock()) &#123; cout &lt;&lt; pa-&gt;a &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; \"wp指向对象为空\" &lt;&lt; endl; &#125;&#125; 试试把sp.reset()这行的注释去掉看看结果有什么不同。 除此之外，weak_ptr还提供了expired()函数来判断所指对象是否已经被销毁。 示例： 123456789101112131415class A&#123;public: A() : a(3) &#123; cout &lt;&lt; \"A Constructor...\" &lt;&lt; endl; &#125; ~A() &#123; cout &lt;&lt; \"A Destructor...\" &lt;&lt; endl; &#125; int a;&#125;;int main() &#123; shared_ptr&lt;A&gt; sp(new A()); weak_ptr&lt;A&gt; wp(sp); sp.reset(); // 此时sp被销毁 cout &lt;&lt; wp.expired() &lt;&lt; endl; // true表示已被销毁，否则为false&#125; 代码输入如下：12A Constructor...A Destructor... 如何使用weak_ptr weak_ptr并没有重载operator-&gt;和operator *操作符，因此不可直接通过weak_ptr使用对象，典型的用法是调用其lock函数来获得shared_ptr示例，进而访问原始对象。 最后，我们来看看如何使用weak_ptr来改造最前面的代码，打破循环引用问题。 12345678910111213141516171819202122232425class ClassB;class ClassA&#123;public: ClassA() &#123; cout &lt;&lt; \"ClassA Constructor...\" &lt;&lt; endl; &#125; ~ClassA() &#123; cout &lt;&lt; \"ClassA Destructor...\" &lt;&lt; endl; &#125; weak_ptr&lt;ClassB&gt; pb; // 在A中引用B&#125;;class ClassB&#123;public: ClassB() &#123; cout &lt;&lt; \"ClassB Constructor...\" &lt;&lt; endl; &#125; ~ClassB() &#123; cout &lt;&lt; \"ClassB Destructor...\" &lt;&lt; endl; &#125; weak_ptr&lt;ClassA&gt; pa; // 在B中引用A&#125;;int main() &#123; shared_ptr&lt;ClassA&gt; spa = make_shared&lt;ClassA&gt;(); shared_ptr&lt;ClassB&gt; spb = make_shared&lt;ClassB&gt;(); spa-&gt;pb = spb; spb-&gt;pa = spa; // 函数结束，思考一下：spa和spb会释放资源么？因为没改变shared_ptr的引用计数，此时引用计数为1，超过作用域后自动释放&#125; 输出结果如下 12345ClassA Constructor...ClassB Constructor...ClassA Destructor...ClassB Destructor...Program ended with exit code: 0 从运行结果可以看到spa和spb指向的对象都得到释放！","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - 命令行参数","slug":"cpp-flags","date":"2020-02-27T09:47:27.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/02/27/cpp-flags/","link":"","permalink":"https://overtalk.site/2020/02/27/cpp-flags/","excerpt":"","text":"本篇博客主要介绍一个 c++ 命令行参数工具 简介 args 安装 安装教程 其实只需要导入 args.hxx 文件即可 当作依赖放到 dep 目录中，在项目中使用，具体如何导入请看这儿 使用 使用教程12345678910111213141516171819202122232425262728293031323334353637383940414243#include&lt;iostream&gt;#include&lt;args/args.hxx&gt;int main(int argc, char** argv)&#123; args::ArgumentParser parser(\"This is a test program.\", \"This goes after the options.\"); args::HelpFlag help(parser, \"help\", \"Display this help menu\", &#123; 'h', \"help\" &#125;); args::ValueFlag&lt;bool&gt; bar(parser, \"flag\", \"flag\", &#123; 'b' &#125;); args::ValueFlag&lt;int&gt; integer(parser, \"port\", \"The http port\", &#123; 'i' &#125;); args::ValueFlagList&lt;char&gt; characters(parser, \"char list\", \"The character flag\", &#123; 'c' &#125;); args::Positional&lt;std::string&gt; foo(parser, \"string\", \"The foo position\", &#123; 'h' &#125;); args::PositionalList&lt;double&gt; numbers(parser, \"numbers\", \"The numbers position list\", &#123; 'd' &#125;); // start parse argument list try &#123; parser.ParseCLI(argc, argv); &#125; catch (args::Help &amp; help) &#123; std::cout &lt;&lt; parser &lt;&lt; \", error = \" &lt;&lt; help.what() &lt;&lt; std::endl; return false; &#125; catch (args::ParseError &amp; e) &#123; std::cout &lt;&lt; parser &lt;&lt; \", error = \" &lt;&lt; e.what() &lt;&lt; std::endl; return false; &#125; catch (args::ValidationError &amp; e) &#123; std::cout &lt;&lt; parser &lt;&lt; \", error = \" &lt;&lt; e.what() &lt;&lt; std::endl; return false; &#125; if (bar) &#123; std::cout &lt;&lt; \"bar\" &lt;&lt; std::endl; &#125; if (integer) &#123; std::cout &lt;&lt; \"i: \" &lt;&lt; args::get(integer) &lt;&lt; std::endl; &#125; if (characters) &#123; for (const auto ch : args::get(characters)) &#123; std::cout &lt;&lt; \"c: \" &lt;&lt; ch &lt;&lt; std::endl; &#125; &#125; if (foo) &#123; std::cout &lt;&lt; \"f: \" &lt;&lt; args::get(foo) &lt;&lt; std::endl; &#125; if (numbers) &#123; for (const auto nm : args::get(numbers)) &#123; std::cout &lt;&lt; \"n: \" &lt;&lt; nm &lt;&lt; std::endl; &#125; &#125; return 0;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - vs studio 的使用","slug":"cpp-vs","date":"2020-02-26T22:41:19.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/02/26/cpp-vs/","link":"","permalink":"https://overtalk.site/2020/02/26/cpp-vs/","excerpt":"","text":"本文主要是一些有关 vs 的使用经验 项目结构 使用vs创建空项目 test，注意不要勾选 将解决方案和项目放在统一目录中 空项目的目录结构如下所示： 在test目录之下有一个 test.sln 文件，是整个项目的解决方案 除去test.sln 文件，有一个默认名为 test 的解决方案（单独的一个文件夹，在vs中，一个项目可以有多个解决方案） 在 test 解决方案文件夹下有三个vs配置文件 一般对于每一个单独的解决方案，我喜欢新建一个名为 src 的文件夹，将所有的源代码都放入其中，如下所示： 尝试编译整个项目 再次查看目录结构 编译产物路径有两个，入上图所示的两个 Debug 目录 第一个 Debug 目录中存放可执行文件（.exe） 第二个 Debug 目录中存放中间产物（.obj等等） 默认的上述路径很奇怪，不方便管理，我一般将他们放到 .sln 同级别目录下的 bin 中 需要的设置如下所示： 按照如下进行设置 输出目录 和 中间目录 的设置如下： 12345# 输出目录$(SolutionDir)bin\\$(Platform)\\$(Configuration)\\# 中间目录$(SolutionDir)bin\\inetrmediates\\$(Platform)\\$(Configuration)\\ $(SolutionDir) 就是指 .sln 文件所在的目录 $(Platform) 会根据编译时的平台（x86，x64）而改变 $(Configuration) 是一些配置（Debug/Release） 设置完毕之后，删除原先的两个 Debug目录，重新编译一次，目录结果如下： 按照上述操作重新编译之后，解决方案的编译产物全在 bin 目录之下 第三方依赖 当我们需要使用第三方库的时候，可行的方案有： 源文件 静态链接（lib） 动态链接（dll/so） 对于这些第三方依赖，我一般将其放到 .sln文件 所在目录的同级目录 dep 之下 这个时候无论使用上述三种方法中的哪一种，都需要导入相应的文件（头文件） 导入源文件 以导入源文件为例子来讲解，我在 dep 目录之下导入了一个 args 文件夹，我现在需要去使用该文件夹中的源文件 首先来看目录结构： 接下来进行设置，打开解决方案的设置，并且按照如下进行设置： 这样就可以在我的 main.cpp 中使用该文件了 上述 main.cpp 中导入了 args.hxx，并且没有报错，可以正常使用","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"shadowsocks 原理详解","slug":"network-shadowsocks","date":"2020-02-25T23:17:50.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/02/25/network-shadowsocks/","link":"","permalink":"https://overtalk.site/2020/02/25/network-shadowsocks/","excerpt":"","text":"shadowsocks 原理详解 详解 这个东西用的人不少，知道原理的人却不多，本文主要分析Shadowsocks实现的技术原理。 Shadowsocks的架构 Shadowsocks（后文缩写为SS）由两部分组成，客户端和服务器端。常用的客户端有shadowsocks-win、ShadowsocksX-NG、shadowsocks-Qt5、shadowsocks-android…；常用的服务器端有Python版本，Go语言版本，C、C++……。客户端启动后会开启一个本地代理（SOCKS5 / HTTP Proxy），通过修改操作系统配置或者浏览器配置把访问请求转发给本地代理。当我们通过浏览器访问某个地址的时候，数据会被转发到本地代理，由本地代理加密后转发到服务器端，服务器端处理完请求后把数据加密后返回给客户端的本地代理，本地代理再次返回给浏览器。 要澄清两点：1. SS协议和Http Proxy、Socks5没有半毛钱关系，这两个协议是浏览器或者操作系统所支持的标准代理协议，SS的架构中只是用这两种协议作为“获取用户请求”的手段而已。2. SS协议中没有任何控制流，本地代理获取用户原始TCP/UDP数据包获取之后会直接取出Data部分，重新构造一个IP数据包（可能是TCP或者UDP，和用户原始请求是TCP还是UDP有关系。），目标地址和端口是服务器地址，数据包的Data部分是加密后的用户原始Data。 协议详解socks5 协议 请见 socks5 详解 该协议主要用于客户端流量代理到 ss-local shadowsocks 协议 官方文档 用户实际请求的数据包。通过 ss-local 发送到 ss-server 的格式十分简陋，由两部分组成： 1[target address][payload] ss-server 接收加密的数据流，解密并解析前导目标地址(target address)。然后，将有效载荷数据转发给目标。ss-server 接收来自目标的回复，进行加密并将其转发回 ss-local。 其中地址部分（target address）格式如下所示： 1[1-byte type][variable-length host][2-byte port] 定义了以下地址类型： 0x01：主机是一个4字节的IPv4地址。 0x03：host是一个可变长度的字符串，从1字节长度开始，后跟最多255字节域名。 0x04：host是一个16字节的IPv6地址。 端口号是2字节的big-endian无符号整数。 数据传输 本部分将从本地流量产生出发，详细介绍整个流量转发的过程，可以根据转发流量的协议分成两种：tcp/udp 在shadowsocks的golang版本源码中，ss-server 在同一个端口监听tcp/udp TCP 流量 本地 tcp包 首先通过 socks5 协议发送到 ss-local ss-local 将本地的tcp包数据加上 target addr，封装成 shadowsocks 协议包，发给 ss-server 的tcp端口 ss-server 解包，与target addr建立tcp连接，将数据包发送给 target addr ss-server 将 target addr 回的数据包通过原tcp连接返回给 ss-local ss-local 通过 socks5 返回数据包 UDP udp 的整个流程和 tcp 类似，但是不同的是 udp 不是面对连接的，需要维持一个 nat map 当 ss-server 收到udp包时，回记录发送者的addr，为此创建一个 udp socket，并记录到 nat map 中 通过上述 udp socket 发送/接受数据，收到数据时，根据nat map将数据发送给对应的 ss-local","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"shadowsocks","slug":"shadowsocks","permalink":"https://overtalk.site/tags/shadowsocks/"}]},{"title":"redis持久化的两种方法","slug":"redis-backup","date":"2020-02-25T15:13:15.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/02/25/redis-backup/","link":"","permalink":"https://overtalk.site/2020/02/25/redis-backup/","excerpt":"","text":"Redis 持久化流程 既然redis的数据可以保存在磁盘上，那么这个流程是什么样的呢？ 要有下面五个过程： 客户端向服务端发送写操作(数据在客户端的内存中)。 数据库服务端接收到写请求的数据(数据在服务端的内存中)。 服务端调用write这个系统调用，将数据往磁盘上写(数据在系统内存的缓冲区中)。 操作系统将缓冲区中的数据转移到磁盘控制器上(数据在磁盘缓存中)。 磁盘控制器将数据写到磁盘的物理介质中(数据真正落到磁盘上)。 这5个过程是在理想条件下一个正常的保存流程，但是在大多数情况下，我们的机器等等都会有各种各样的故障，这里划分了两种情况： Redis数据库发生故障，只要在上面的第三步执行完毕，那么就可以持久化保存，剩下的两步由操作系统替我们完成。 操作系统发生故障，必须上面5步都完成才可以。 在这里只考虑了保存的过程可能发生的故障，其实保存的数据也有可能发生损坏，需要一定的恢复机制，不过在这里就不再延伸了。现在主要考虑的是redis如何来实现上面5个保存磁盘的步骤。它提供了两种策略机制，也就是RDB和AOF。 Redis 的落地策略 Redis 的落地策略其实就是持久化(Persistence)，主要有以下2种策略： RDB: 定时快照方式(snapshot) AOF: 基于语句追加文件的方式 RDB RDB 文件非常紧凑，它保存了 Redis 某个时间点上的数据集。 RDB 恢复大数据集时速度要比 AOF 快。但是 RDB 不适合那些对时效性要求很高的业务，因为它只保存了快照，在进行恢复时会导致一些时间内的数据丢失。 实际在进行备份时，Redis 主要依靠 rdbSave() 函数，然后有两个命令会调用这个函数 SAVE 和 BGSAVE，前者会同步调用，阻塞主进程导致会有短暂的 Redis-server 停止工作，后者会 fork 出子进程异步处理。 在调用 SAVE 或者 BGSAVE 时，只有发布和订阅功能的命令可以正常执行，因为这个模块和服务器的其他模块是隔离的。 下面的命令表示： “60 秒内有至少有 1000 个键被改动”时进行RDB文件备份。 1redis-server&gt; SAVE 60 1000 RDB 文件的结构 开头的 REDIS 表示这是一个 RDB 文件，然后紧跟着 redis 的版本号，SELECT-DB 和 KEY-VALUES-PAIRS 构成了对一个数据库中的所有数据记录，其中 KEY-VALUES-PAIRS 具体结构如下，后面两个就不用说了。 其中对于不同的类型，RDB文件中有不同的 layout，具体就不写出来了。 AOF AOF 可以通过设置的 fsync 策略配置，如果未设置 fsync ，AOF 的默认策略为每秒钟 fsync 一次，在这种配置下， fsync 会在后台线程执行，所以主线程不会受到打扰。但是像 AOF 这种策略会导致追加的文件非常大，而且在恢复大数据时非常缓慢，因为要把所有会导致写数据库的命令都重新执行一遍。AOF文件中实际存储的是 Redis 协议下的命令记录，因此非常易读。 当然 Redis 考虑到了 AOF 文件过大的问题，因此引入了 BGREWRITEAOF 命令进行重建 AOF 文件，保证可以减少大量无用的重复写操作。重建命令并不会去分析已有的 AOF 文件，而是将当前数据库的快照保存。 在 AOF 文件重写时，Redis 的具体逻辑如下： Redis 首先 fork 出一个子进程，子进程将新 AOF 文件的内容写入到临时文件。 对于所有新执行的写入命令，父进程一边将它们累积到一个缓存中，一边将这些改动追加到现有 AOF 文件的末尾： 这样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。 当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将缓存中的所有数据追加到新 AOF 文件的末尾。 现在 Redis 原子地用新文件替换旧文件，之后所有命令都会直接追加到新 AOF 文件的末尾。 Redis 会维持一个默认的AOF重写策略，当当前的AOF文件比上次重写之后的文件大小增大了一倍时，就会自动在后台重写AOF。 参考链接 Redis两种持久化机制RDB和AOF详解","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://overtalk.site/tags/Redis/"}]},{"title":"redis - 哈希槽","slug":"redis-hash-slot","date":"2020-02-25T14:37:48.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/02/25/redis-hash-slot/","link":"","permalink":"https://overtalk.site/2020/02/25/redis-hash-slot/","excerpt":"","text":"简介 前几天面试有被面试官问到 redis集群 hash槽的相关问题，今天在此记录一下。 Redis 集群的键空间被分割为 16384 hash个槽（slot）， 集群的最大节点数量也是 16384 个 关系:cluster&gt;node&gt;slot&gt;key 解答 Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点。 Redis 集群没有使用一致性hash, 而是引入了哈希槽的概念。 Redis 集群有16384个哈希槽,每个key通过CRC16校验后对16384取模来决定放置哪个槽.集群的每个节点负责一部分hash槽。这种结构很容易添加或者删除节点，并且无论是添加删除或者修改某一个节点，都不会造成集群不可用的状态。 优点方便的添加或移除节点 当需要增加节点时，只需要把其他节点的某些哈希槽挪到新节点就可以了； 当需要移除节点时，只需要把移除节点上的哈希槽挪到其他节点就行了； 在这一点上，由于从一个节点将哈希槽移动到另一个节点并不会停止服务,所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态，即我们以后新增或移除节点的时候不用先停掉所有的 redis 服务。 数据迁移 数据迁移可以理解为slot(槽)和key的迁移，这个功能很重要，极大地方便了集群做线性扩展，以及实现平滑的扩容或缩容。 现在要将Master A节点中编号为1、2、3的slot迁移到Master B节点中，在slot迁移的中间状态下，slot 1、2、3在Master A节点的状态表现为MIGRATING（迁移）,在Master B节点的状态表现为IMPORTING（入口）。 此时并不刷新node的映射关系 IMPORTING状态 被迁移slot 在目标Master B节点中出现的一种状态，准备迁移slot从Mater A到Master B的时候，被迁移slot的状态首先变为IMPORTING状态。 键空间迁移 键空间迁移是指当满足了slot迁移前提的情况下，通过相关命令将slot 1、2、3中的键空间从Master A节点转移到Master B节点。此时刷新node的映射关系。 一些问题 “用了哈希槽的概念，而没有用一致性哈希算法，不都是哈希么？这样做的原因是为什么呢？” Redis Cluster是自己做的crc16的简单hash算法，没有用一致性hash。Redis的作者认为它的crc16(key) mod 16384的效果已经不错了，虽然没有一致性hash灵活，但实现很简单，节点增删时处理起来也很方便。 “为了动态增删节点的时候，不至于丢失数据么？” 节点增删时不丢失数据和hash算法没什么关系，不丢失数据要求的是一份数据有多个副本。 “还有集群总共有2的14次方，16384个哈希槽，那么每一个哈希槽中存的key 和 value是什么？” 当你往Redis Cluster中加入一个Key时，会根据crc16(key) mod 16384计算这个key应该分布到哪个hash slot中，一个hash slot中会有很多key和value。你可以理解成表的分区，使用单节点时的redis时只有一个表，所有的key都放在这个表里；改用Redis Cluster以后会自动为你生成16384个分区表，你insert数据时会根据上面的简单算法来决定你的key应该存在哪个分区，每个分区里有很多key。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://overtalk.site/tags/Redis/"}]},{"title":"mysql - 删除数据","slug":"mysql-delete","date":"2020-02-25T14:27:46.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2020/02/25/mysql-delete/","link":"","permalink":"https://overtalk.site/2020/02/25/mysql-delete/","excerpt":"","text":"简介 前几天面试有被面试官问到mysql的一些基础问题。其中一个就是删除数据有哪些关键字，有什么区别？ DELETE语句 ： 通过WHERE对要删除的记录进行选择 TRUNCATE TABLE ： 删除表中的所有数据 他们两者有什么区别？ 如果要清空表中的所有记录，可以使用下面的两种方法： 12DELETE FROM table1TRUNCATE TABLE table1 其中第二条记录中的TABLE是可选的。 如果要删除表中的部分记录，只能使用DELETE语句。 1DELETE FROM table1 WHERE ...; 如果DELETE不加WHERE子句，那么它和TRUNCATE TABLE是一样的，但它们有一点不同，那就是DELETE可以返回被删除的记录数，而TRUNCATE TABLE返回的是0。 如果一个表中有自增字段，使用TRUNCATE TABLE和没有WHERE子句的DELETE删除所有记录后，这个自增字段将起始值恢复成1.如果你不想这样做的话，可以在DELETE语句中加上永真的WHERE，如WHERE 1或WHERE true。 1DELETE FROM table1 WHERE 1; 上面的语句在执行时将扫描每一条记录。但它并不比较，因为这个WHERE条件永远为true。这样做虽然可以保持自增的最大值，但由于它是扫描了所有的记录，因此，它的执行成本要比没有WHERE子句的DELETE大得多。 DELETE和TRUNCATE TABLE的最大区别是DELETE可以通过WHERE语句选择要删除的记录。但执行得速度不快。而且还可以返回被删除的记录数。而TRUNCATE TABLE无法删除指定的记录，而且不能返回被删除的记录。但它执行得非常快。 和标准的SQL语句不同，DELETE支持ORDER BY和LIMIT子句，通过这两个子句，我们可以更好地控制要删除的记录。如当我们只想删除WHERE子句过滤出来的记录的一部分，可以使用LIMIB，如果要删除后几条记录，可以通过ORDER BY和LIMIT配合使用。假设我们要删除users表中name等于”Mike”的前6条记录。可以使用如下的DELETE语句： 1DELETE FROM users WHERE name = 'Mike' LIMIT 6; 一般MySQL并不确定删除的这6条记录是哪6条，为了更保险，我们可以使用ORDER BY对记录进行排序。1DELETE FROM users WHERE name = 'Mike' ORDER BY id DESC LIMIT 6;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://overtalk.site/tags/mysql/"}]},{"title":"golang 中序列化方案","slug":"go-serialize","date":"2020-02-20T10:12:44.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/02/20/go-serialize/","link":"","permalink":"https://overtalk.site/2020/02/20/go-serialize/","excerpt":"","text":"本文主要介绍二进制协议gob及msgpack的基本使用。Go语言中的json包在序列化空接口存放的数字类型（整型、浮点型等）都序列化成float64类型。 Json 从下面的例子就可以看出 json 序列化的时候会将空接口存放的数字类型（整型、浮点型等）都序列化成float64类型。 123456789101112131415161718192021222324func jsonDemo() &#123; test1 := map[string]interface&#123;&#125;&#123; \"count\": 1, &#125; data1, err := json.Marshal(test1) if err != nil &#123; log.Fatal(err) return &#125; fmt.Println(data1) test2 := make(map[string]interface&#123;&#125;) if err := json.Unmarshal(data1, &amp;test2); err != nil &#123; log.Fatal(err) return &#125; for _, v := range test2 &#123; fmt.Printf(\"value : %v, type = %T\\n\", v, v) &#125;&#125; 输出的结果为： 可以看出原本 int 类型的 interface{} 被转化成为了 float64 12[123 34 99 111 117 110 116 34 58 49 125]value : 1, type = float64 Gob 标准库gob是golang提供的“私有”的编解码方式，它的效率会比json，xml等更高，特别适合在Go语言程序间传递数据。 但是它序列化之后的结果会比json要大一些 1234567891011121314151617181920212223242526func gobDemo() &#123; test1 := map[string]interface&#123;&#125;&#123; \"count\": int64(12), &#125; // encode buf := new(bytes.Buffer) enc := gob.NewEncoder(buf) err := enc.Encode(test1) if err != nil &#123; log.Fatal(err) &#125; b := buf.Bytes() fmt.Println(b) test2 := make(map[string]interface&#123;&#125;) dec := gob.NewDecoder(bytes.NewBuffer(b)) err = dec.Decode(&amp;test2) if err != nil &#123; log.Fatal(err) &#125; for _, v := range test2 &#123; fmt.Printf(\"value : %v, type = %T\\n\", v, v) &#125;&#125; 输出的结果为： 12[14 255 129 4 1 2 255 130 0 1 12 1 16 0 0 20 255 130 0 1 5 99 111 117 110 116 5 105 110 116 54 52 4 2 0 24]value : 12, type = int64 使用gob的一些特殊情况 在使用gob序列化一些特殊的数据结构（例如：[]interface{}）的时候，使用前需要先注册，使用的时候需要特别注意这一点12345678910111213141516171819202122232425262728package mainimport ( \"bytes\" \"encoding/gob\" \"fmt\" \"log\")func main() &#123; // 如果这一行被注释掉，程序会崩溃 // gob.Register([]interface&#123;&#125;&#123;&#125;) input := map[string]interface&#123;&#125;&#123;\"X\": []interface&#123;&#125;&#123;1, 2&#125;&#125; buff := new(bytes.Buffer) enc := gob.NewEncoder(buff) if err := enc.Encode(input); err != nil &#123; log.Panic(\"e1: \", err) &#125; b1 := buff.Bytes() output := map[string]interface&#123;&#125;&#123;&#125; if err := gob.NewDecoder(bytes.NewReader(b1)).Decode(&amp;output); err != nil &#123; log.Panic(\"e2: \", err) &#125; fmt.Println(output)&#125; MsgPack MessagePack是一种高效的二进制序列化格式。它允许你在多种语言(如JSON)之间交换数据。但它更快更小。 它和json存在类似的问题就是 序列化的时候会将空接口存放的 int都序列化成 int64 类型。安装1go get -u github.com/vmihailenco/msgpack 示例123456789101112131415161718192021222324252627282930313233package mainimport ( \"fmt\" \"log\" \"github.com/vmihailenco/msgpack\")func main() &#123; test1 := map[string]interface&#123;&#125;&#123; \"count\": 1, &#125; data1, err := msgpack.Marshal(test1) if err != nil &#123; log.Fatal(err) return &#125; fmt.Println(data1) test2 := make(map[string]interface&#123;&#125;) if err := msgpack.Unmarshal(data1, &amp;test2); err != nil &#123; log.Fatal(err) return &#125; for _, v := range test2 &#123; fmt.Printf(\"value : %v, type = %T\\n\", v, v) &#125;&#125; 输出结果如下：12[129 165 99 111 117 110 116 211 0 0 0 0 0 0 0 1]value : 1, type = int64 总结 json序列化空接口存放的数字类型（整型、浮点型等）都序列化成float64类型。 msgpack序列化空接口存放的 int 都序列化成 int64 类型。 从序列化之后的体积来看 msgpack &lt; json &lt; gob， 但是gob对于 空接口interface{} 的数据类型有比较好的复原 使用建议：在不涉及interface{}的情况下，使用体积较小的，如果使用了interface{}并且对数据类型要求较高的情况下，推荐使用gob","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"golang - 发送邮件","slug":"go-email","date":"2020-02-17T10:59:38.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/02/17/go-email/","link":"","permalink":"https://overtalk.site/2020/02/17/go-email/","excerpt":"","text":"email 库主要涉及 golang 中邮件的发送 email GitHub 仓库 转自大俊 简介 程序中时常有发送邮件的需求。有异常情况了需要通知管理员和负责人，用户下单后可能需要通知订单信息，电商平台、中国移动和联通都有每月账单，这些都可以通过邮件来推送。还有我们平时收到的垃圾邮件大都也是通过这种方式发送的😭。那么如何在 Go 语言发送邮件？本文我们介绍一下email库的使用。 快速使用 这个库的使用快不了，为什么呢？ 先安装库，这个自不必说： 1$ go get github.com/jordan-wright/email 我们需要额外一些工作。我们知道邮箱使用SMTP/POP3/IMAP等协议从邮件服务器上拉取邮件。邮件并不是直接发送到邮箱的，而是邮箱请求拉取的。 所以，我们需要配置SMTP/POP3/IMAP服务器。从头搭建固然可行，而且也有现成的开源库，但是比较麻烦。现在一般的邮箱服务商都开放了SMTP/POP3/IMAP服务器。 我这里拿 126 邮箱来举例，使用SMTP服务器。当然，用 QQ 邮箱也可以。 首先，登录邮箱； 点开顶部的设置，选择POP3/SMTP/IMAP； 点击开启IMAP/SMTP服务，按照步骤开启即可，有个密码设置，记住这个密码，后面有用。 然后就可以编码了: 1234567891011121314151617181920package mainimport ( \"log\" \"net/smtp\" \"github.com/jordan-wright/email\")func main() &#123; e := email.NewEmail() e.From = \"dj &lt;xxx@126.com&gt;\" e.To = []string&#123;\"935653229@qq.com\"&#125; e.Subject = \"Awesome web\" e.Text = []byte(\"Text Body is, of course, supported!\") err := e.Send(\"smtp.126.com:25\", smtp.PlainAuth(\"\", \"xxx@126.com\", \"yyy\", \"smtp.126.com\")) if err != nil &#123; log.Fatal(err) &#125;&#125; 这里为了我的信息安全，我把真实信息都隐藏了。代码中xxx替换成你的邮箱账号，yyy替换成上面设置的密码。 代码步骤比较简单清晰： 先调用NewEmail创建一封邮件； 设置From发送方，To接收者，Subject邮件主题（标题），Text设置邮件内容； 然后调用Send发送，参数1是 SMTP 服务器的地址，参数2为验证信息。 运行程序将会向我的 QQ 邮箱发送一封邮件： 有的邮箱会把这种邮件放在垃圾箱中，例如 QQ😭。如果收件箱找不到，记得到垃圾箱瞅瞅。 抄送 平常我们发邮件的时候可能会抄送给一些人，还有一些人要秘密抄送😄，即 CC（Carbon Copy）和 BCC （Blind Carbon Copy）。 email我们也可以设置这两个参数： 12345678910111213141516171819202122package mainimport ( \"log\" \"net/smtp\" \"github.com/jordan-wright/email\")func main() &#123; e := email.NewEmail() e.From = \"dj &lt;xxx@126.com&gt;\" e.To = []string&#123;\"935653229@qq.com\"&#125; e.Cc = []string&#123;\"test1@126.com\", \"test2@126.com\"&#125; e.Bcc = []string&#123;\"secret@126.com\"&#125; e.Subject = \"Awesome web\" e.Text = []byte(\"Text Body is, of course, supported!\") err := e.Send(\"smtp.126.com:25\", smtp.PlainAuth(\"\", \"xxx@126.com\", \"yyy\", \"smtp.126.com\")) if err != nil &#123; log.Fatal(err) &#125;&#125; 还是一样的，抄送的邮箱自己替换test1/test2/secret用自己的。 运行程序将会向我的 QQ 邮件发送一封邮件，同时抄送一封到我另一个 126 邮箱： HTML 格式 发送纯文本，邮件不太美观。email支持发送 HTML 格式的内容。与发送纯文本类似，直接设置对象的HTML字段： 1234567891011121314151617181920212223242526272829303132package mainimport ( \"log\" \"net/smtp\" \"github.com/jordan-wright/email\")func main() &#123; e := email.NewEmail() e.From = \"dj &lt;xxx@126.com&gt;\" e.To = []string&#123;\"935653229@qq.com\"&#125; e.Cc = []string&#123;\"xxx@126.com\"&#125; e.Subject = \"Go 每日一库\" e.HTML = []byte(` &lt;ul&gt;&lt;li&gt;&lt;a \"https://darjun.github.io/2020/01/10/godailylib/flag/\"&gt;Go 每日一库之 flag&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a \"https://darjun.github.io/2020/01/10/godailylib/go-flags/\"&gt;Go 每日一库之 go-flags&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a \"https://darjun.github.io/2020/01/14/godailylib/go-homedir/\"&gt;Go 每日一库之 go-homedir&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a \"https://darjun.github.io/2020/01/15/godailylib/go-ini/\"&gt;Go 每日一库之 go-ini&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a \"https://darjun.github.io/2020/01/17/godailylib/cobra/\"&gt;Go 每日一库之 cobra&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a \"https://darjun.github.io/2020/01/18/godailylib/viper/\"&gt;Go 每日一库之 viper&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a \"https://darjun.github.io/2020/01/19/godailylib/fsnotify/\"&gt;Go 每日一库之 fsnotify&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a \"https://darjun.github.io/2020/01/20/godailylib/cast/\"&gt;Go 每日一库之 cast&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt; `) err := e.Send(\"smtp.126.com:25\", smtp.PlainAuth(\"\", \"xxx@126.com\", \"yyy\", \"smtp.126.com\")) if err != nil &#123; log.Fatal(\"failed to send email:\", err) &#125;&#125; 发送结果： 注意，126 的 SMTP 服务器检测比较严格，加上 HTML 之后，很容易被识别为垃圾邮件不让发送，这时 CC 自己就 OK 了。 附件 添加附件也很容易，直接调用AttachFile即可： 123456789101112131415161718192021package mainimport ( \"log\" \"net/smtp\" \"github.com/jordan-wright/email\")func main() &#123; e := email.NewEmail() e.From = \"dj &lt;xxx@126.com&gt;\" e.To = []string&#123;\"935653229@qq.com\"&#125; e.Subject = \"Go 每日一库\" e.Text = []byte(\"请看附件\") e.AttachFile(\"test.txt\") err := e.Send(\"smtp.126.com:25\", smtp.PlainAuth(\"\", \"xxx@126.com\", \"yyy\", \"smtp.126.com\")) if err != nil &#123; log.Fatal(\"failed to send email:\", err) &#125;&#125; 收到的邮件： 连接池 实际上每次调用Send时都会和 SMTP 服务器建立一次连接，如果发送邮件很多很频繁的话可能会有性能问题。email提供了连接池，可以复用网络连接： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package mainimport ( \"fmt\" \"log\" \"net/smtp\" \"os\" \"sync\" \"time\" \"github.com/jordan-wright/email\")func main() &#123; ch := make(chan *email.Email, 10) p, err := email.NewPool( \"smtp.126.com:25\", 4, smtp.PlainAuth(\"\", \"leedarjun@126.com\", \"358942617ldj\", \"smtp.126.com\"), ) if err != nil &#123; log.Fatal(\"failed to create pool:\", err) &#125; var wg sync.WaitGroup wg.Add(4) for i := 0; i &lt; 4; i++ &#123; go func() &#123; defer wg.Done() for e := range ch &#123; err := p.Send(e, 10*time.Second) if err != nil &#123; fmt.Fprintf(os.Stderr, \"email:%v sent error:%v\\n\", e, err) &#125; &#125; &#125;() &#125; for i := 0; i &lt; 10; i++ &#123; e := email.NewEmail() e.From = \"dj &lt;leedarjun@126.com&gt;\" e.To = []string&#123;\"935653229@qq.com\"&#125; e.Subject = \"Awesome web\" e.Text = []byte(fmt.Sprintf(\"Awesome Web %d\", i+1)) ch &lt;- e &#125; close(ch) wg.Wait()&#125; 上面程序中，我们创建 4 goroutine 共用一个连接池发送邮件，发送 10 封邮件后程序退出。为了等邮件都发送完成或失败，程序才退出，我们使用了sync.WaitGroup。 邮箱被轰炸了： 由于使用了 goroutine，邮件顺序不能保证。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"golang 动态解析 protobuf","slug":"golang-dynamic-protobuf","date":"2020-02-13T21:09:18.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/02/13/golang-dynamic-protobuf/","link":"","permalink":"https://overtalk.site/2020/02/13/golang-dynamic-protobuf/","excerpt":"","text":"golang dynamic protobuf golang 无需编译proto文件，直接使用proto文件对pb进行反序列化 详情请见 Github","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"来，控制一下 goroutine 的并发数量","slug":"golang-thread-pool","date":"2020-02-10T21:56:47.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/02/10/golang-thread-pool/","link":"","permalink":"https://overtalk.site/2020/02/10/golang-thread-pool/","excerpt":"","text":"对 golang 中的 goroutine 数量进行控制 简介 在 golang 中开启一个 goroutine 是一件很便捷的事情 但是如果不对其进行控制，则可能造成 goroutine 泛滥成灾 本文就对如何控制 goroutine 数量进行一个尝试 主要思路是通过 chan 实现，取一个协程就向 chan 中写入，如果协程被取完则会阻塞，用完一个协程就从通道中拿出一个即可 代码 for 循环中不停的开启新的协程 每隔一秒钟打印当前的协程数 没有协程池1234567891011121314151617181920212223242526272829package mainimport ( \"fmt\" \"runtime\" \"time\")func main() &#123; withoutGoroutinePool()&#125;func withoutGoroutinePool() &#123; ticker := time.NewTicker(time.Second) for &#123; select &#123; case &lt;-ticker.C: fmt.Println(time.Now().String(), runtime.NumGoroutine()) break default: go sleep() &#125; &#125;&#125;func sleep() &#123; time.Sleep(100 * time.Millisecond)&#125; 输出结果如下所示，可以看出 Goroutine 的数量超多，在几十万之多，可能会瞬间打满 cpu1234567891011➜ aaa git:(dev) ✗ go run main.go2020-02-10 22:21:07.708449 +0800 CST m=+1.075829140 2587342020-02-10 22:21:08.63268 +0800 CST m=+2.000078344 3401302020-02-10 22:21:09.63266 +0800 CST m=+3.000079432 3944762020-02-10 22:21:10.632632 +0800 CST m=+4.000071378 4189462020-02-10 22:21:11.632619 +0800 CST m=+5.000079498 4063322020-02-10 22:21:12.632586 +0800 CST m=+6.000066992 4061572020-02-10 22:21:13.632612 +0800 CST m=+7.000113855 3665072020-02-10 22:21:14.632658 +0800 CST m=+8.000180030 3696272020-02-10 22:21:15.632572 +0800 CST m=+9.000114252 397764^Csignal: interrupt 有协程池123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package mainimport ( \"fmt\" \"runtime\" \"time\")type goroutinePool struct &#123; c chan interface&#123;&#125;&#125;var pool *goroutinePoolfunc newGoroutinePool(size int) *goroutinePool &#123; return &amp;goroutinePool&#123;c: make(chan interface&#123;&#125;, size)&#125;&#125;func (goroutinePool *goroutinePool) Get() &#123; goroutinePool.c &lt;- struct&#123;&#125;&#123;&#125;&#125;func (goroutinePool *goroutinePool) Release() &#123; &lt;-goroutinePool.c&#125;func withGoroutinePool() &#123; pool = newGoroutinePool(100) ticker := time.NewTicker(time.Second) for &#123; select &#123; case &lt;-ticker.C: fmt.Println(time.Now().String(), runtime.NumGoroutine()) break default: pool.Get() go func() &#123; sleep() pool.Release() &#125;() &#125; &#125;&#125;func main() &#123; withGoroutinePool()&#125;func sleep() &#123; time.Sleep(100 * time.Millisecond)&#125; 输出结果如下所示，可以看出 Goroutine 的数量在 100 左右1234567891011➜ aaa git:(dev) ✗ go run main.go2020-02-10 22:23:57.4038 +0800 CST m=+1.017452302 452020-02-10 22:23:58.420406 +0800 CST m=+2.034076062 382020-02-10 22:23:59.450896 +0800 CST m=+3.064585392 862020-02-10 22:24:00.463936 +0800 CST m=+4.077642981 802020-02-10 22:24:01.480972 +0800 CST m=+5.094697456 712020-02-10 22:24:02.398438 +0800 CST m=+6.012179639 1012020-02-10 22:24:03.416983 +0800 CST m=+7.030743402 882020-02-10 22:24:04.444314 +0800 CST m=+8.058093131 32020-02-10 22:24:05.457963 +0800 CST m=+9.071760019 78^Csignal: interrupt","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"golang - cast 库的使用","slug":"go-cast","date":"2020-02-05T12:58:04.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/02/05/go-cast/","link":"","permalink":"https://overtalk.site/2020/02/05/go-cast/","excerpt":"","text":"cast 库主要涉及 golang 中数据的转换 cast GitHub 仓库 转自大俊 简介 今天我们再来介绍 spf13 大神的另一个库cast。cast是一个小巧、实用的类型转换库，用于将一个类型转为另一个类型。 最初开发cast是用在hugo中的。 快速使用先安装：1$ go get github.com/spf13/cast 后使用：123456789101112131415161718192021222324252627282930package mainimport ( \"fmt\" \"github.com/spf13/cast\")func main() &#123; // ToString fmt.Println(cast.ToString(\"leedarjun\")) // leedarjun fmt.Println(cast.ToString(8)) // 8 fmt.Println(cast.ToString(8.31)) // 8.31 fmt.Println(cast.ToString([]byte(\"one time\"))) // one time fmt.Println(cast.ToString(nil)) // \"\" var foo interface&#123;&#125; = \"one more time\" fmt.Println(cast.ToString(foo)) // one more time // ToInt fmt.Println(cast.ToInt(8)) // 8 fmt.Println(cast.ToInt(8.31)) // 8 fmt.Println(cast.ToInt(\"8\")) // 8 fmt.Println(cast.ToInt(true)) // 1 fmt.Println(cast.ToInt(false)) // 0 var eight interface&#123;&#125; = 8 fmt.Println(cast.ToInt(eight)) // 8 fmt.Println(cast.ToInt(nil)) // 0&#125; 实际上，cast实现了多种常见类型之间的相互转换，返回最符合直觉的结果。例如： nil转为string的结果为””，而不是”nil”； true转为string的结果为”true”，而true转为int的结果为1； interface{}转为其他类型，要看它里面存储的值类型。 这些类型包括所有的基本类型（整形、浮点型、布尔值和字符串）、空接口、nil，时间（time.Time）、时长（time.Duration）以及它们的切片类型， 还有map[string]Type（其中Type为前面提到的类型）： 1234byte bool float32 float64 string int8 int16 int32 int64 intuint8 uint16 uint32 uint64 uintinterface&#123;&#125; time.Time time.Duration nil 高级转换 cast提供了两组函数： ToType（其中Type可以为任何支持的类型），将参数转换为Type类型。如果无法转换，返回Type类型的零值或nil； ToTypeE以 E 结尾，返回转换后的值和一个error。这组函数可以区分参数中实际存储了零值，还是转换失败了。 实现上大部分代码都类似，ToType在内部调用ToTypeE函数，返回结果并忽略错误。ToType函数的实现在文件cast.go中， 而ToTypeE函数的实现在文件caste.go中。 1234567891011// cast/cast.gofunc ToBool(i interface&#123;&#125;) bool &#123; v, _ := ToBoolE(i) return v&#125;// ToDuration casts an interface to a time.Duration type.func ToDuration(i interface&#123;&#125;) time.Duration &#123; v, _ := ToDurationE(i) return v&#125; ToTypeE函数都接受任意类型的参数（interface{}），然后使用类型断言根据具体的类型来执行不同的转换。如果无法转换，返回错误。1234567891011121314151617181920// cast/caste.gofunc ToBoolE(i interface&#123;&#125;) (bool, error) &#123; i = indirect(i) switch b := i.(type) &#123; case bool: return b, nil case nil: return false, nil case int: if i.(int) != 0 &#123; return true, nil &#125; return false, nil case string: return strconv.ParseBool(i.(string)) default: return false, fmt.Errorf(\"unable to cast %#v of type %T to bool\", i, i) &#125;&#125; 首先调用indirect函数将参数中可能的指针去掉。如果类型本身不是指针，那么直接返回。否则返回指针指向的值。 循环直到返回一个非指针的值： 123456789101112131415// cast/caste.gofunc indirect(a interface&#123;&#125;) interface&#123;&#125; &#123; if a == nil &#123; return nil &#125; if t := reflect.TypeOf(a); t.Kind() != reflect.Ptr &#123; // Avoid creating a reflect.Value if it's not a pointer. return a &#125; v := reflect.ValueOf(a) for v.Kind() == reflect.Ptr &amp;&amp; !v.IsNil() &#123; v = v.Elem() &#125; return v.Interface()&#125; 所以，下面代码输出都是 8： 12345678910111213141516package mainimport ( \"fmt\" \"github.com/spf13/cast\")func main() &#123; p := new(int) *p = 8 fmt.Println(cast.ToInt(p)) // 8 pp := &amp;p fmt.Println(cast.ToInt(pp)) // 8&#125; 时间和时长转换 时间类型的转换代码如下： 123456789101112131415161718192021222324func ToTimeE(i interface&#123;&#125;) (tim time.Time, err error) &#123; i = indirect(i) switch v := i.(type) &#123; case time.Time: return v, nil case string: return StringToDate(v) case int: return time.Unix(int64(v), 0), nil case int64: return time.Unix(v, 0), nil case int32: return time.Unix(int64(v), 0), nil case uint: return time.Unix(int64(v), 0), nil case uint64: return time.Unix(int64(v), 0), nil case uint32: return time.Unix(int64(v), 0), nil default: return time.Time&#123;&#125;, fmt.Errorf(\"unable to cast %#v of type %T to Time\", i, i) &#125;&#125; 根据传入的类型执行不同的处理： 如果是time.Time，直接返回； 如果是整型，将参数作为时间戳（自 UTC 时间1970.01.01 00:00:00到现在的秒数）调用time.Unix生成时间。Unix接受两个参数，第一个参数指定秒，第二个参数指定纳秒； 如果是字符串，调用StringToDate函数依次尝试以下面这些时间格式调用time.Parse解析该字符串。如果某个格式解析成功，则返回获得的time.Time。否则解析失败，返回错误； 其他任何类型都无法转换为time.Time。 字符串转换为时间： 1234567891011121314151617181920212223242526272829303132333435363738// cast/caste.gofunc StringToDate(s string) (time.Time, error) &#123; return parseDateWith(s, []string&#123; time.RFC3339, \"2006-01-02T15:04:05\", // iso8601 without timezone time.RFC1123Z, time.RFC1123, time.RFC822Z, time.RFC822, time.RFC850, time.ANSIC, time.UnixDate, time.RubyDate, \"2006-01-02 15:04:05.999999999 -0700 MST\", // Time.String() \"2006-01-02\", \"02 Jan 2006\", \"2006-01-02T15:04:05-0700\", // RFC3339 without timezone hh:mm colon \"2006-01-02 15:04:05 -07:00\", \"2006-01-02 15:04:05 -0700\", \"2006-01-02 15:04:05Z07:00\", // RFC3339 without T \"2006-01-02 15:04:05Z0700\", // RFC3339 without T or timezone hh:mm colon \"2006-01-02 15:04:05\", time.Kitchen, time.Stamp, time.StampMilli, time.StampMicro, time.StampNano, &#125;)&#125;func parseDateWith(s string, dates []string) (d time.Time, e error) &#123; for _, dateType := range dates &#123; if d, e = time.Parse(dateType, s); e == nil &#123; return &#125; &#125; return d, fmt.Errorf(\"unable to parse date: %s\", s)&#125; 时长类型的转换代码如下： 12345678910111213141516171819202122232425// cast/caste.gofunc ToDurationE(i interface&#123;&#125;) (d time.Duration, err error) &#123; i = indirect(i) switch s := i.(type) &#123; case time.Duration: return s, nil case int, int64, int32, int16, int8, uint, uint64, uint32, uint16, uint8: d = time.Duration(ToInt64(s)) return case float32, float64: d = time.Duration(ToFloat64(s)) return case string: if strings.ContainsAny(s, \"nsuµmh\") &#123; d, err = time.ParseDuration(s) &#125; else &#123; d, err = time.ParseDuration(s + \"ns\") &#125; return default: err = fmt.Errorf(\"unable to cast %#v of type %T to Duration\", i, i) return &#125;&#125; 根据传入的类型进行不同的处理： 如果是time.Duration类型，直接返回； 如果是整型或浮点型，将其数值强制转换为time.Duration类型，单位默认为ns； 如果是字符串，分为两种情况：如果字符串中有时间单位符号nsuµmh，直接调用time.ParseDuration解析；否则在字符串后拼接ns再调用time.ParseDuration解析； 其他类型解析失败。 示例： 12345678910111213141516171819202122232425262728package mainimport ( \"fmt\" \"time\" \"github.com/spf13/cast\")func main() &#123; now := time.Now() timestamp := 1579615973 timeStr := \"2020-01-21 22:13:48\" fmt.Println(cast.ToTime(now)) // 2020-01-22 06:31:50.5068465 +0800 CST m=+0.000997701 fmt.Println(cast.ToTime(timestamp)) // 2020-01-21 22:12:53 +0800 CST fmt.Println(cast.ToTime(timeStr)) // 2020-01-21 22:13:48 +0000 UTC d, _ := time.ParseDuration(\"1m30s\") ns := 30000 strWithUnit := \"130s\" strWithoutUnit := \"130\" fmt.Println(cast.ToDuration(d)) // 1m30s fmt.Println(cast.ToDuration(ns)) // 30µs fmt.Println(cast.ToDuration(strWithUnit)) // 2m10s fmt.Println(cast.ToDuration(strWithoutUnit)) // 130ns&#125; 转换为切片 实际上，这些函数的实现基本类似。使用类型断言判断类型。如果就是要返回的类型，直接返回。否则根据类型进行相应的转换。 我们主要分析两个实现：ToIntSliceE和ToStringSliceE。ToBoolSliceE/ToDurationSliceE与ToIntSliceE基本相同。 首先是ToIntSliceE：123456789101112131415161718192021222324252627func ToIntSliceE(i interface&#123;&#125;) ([]int, error) &#123; if i == nil &#123; return []int&#123;&#125;, fmt.Errorf(\"unable to cast %#v of type %T to []int\", i, i) &#125; switch v := i.(type) &#123; case []int: return v, nil &#125; kind := reflect.TypeOf(i).Kind() switch kind &#123; case reflect.Slice, reflect.Array: s := reflect.ValueOf(i) a := make([]int, s.Len()) for j := 0; j &lt; s.Len(); j++ &#123; val, err := ToIntE(s.Index(j).Interface()) if err != nil &#123; return []int&#123;&#125;, fmt.Errorf(\"unable to cast %#v of type %T to []int\", i, i) &#125; a[j] = val &#125; return a, nil default: return []int&#123;&#125;, fmt.Errorf(\"unable to cast %#v of type %T to []int\", i, i) &#125;&#125; 根据传入参数的类型： 如果是nil，直接返回错误； 如果是[]int，不用转换，直接返回； 如果传入类型为切片或数组，新建一个[]int，将切片或数组中的每个元素转为int放到该[]int中。最后返回这个[]int； 其他情况，不能转换。 ToStringSliceE：1234567891011121314151617181920212223func ToStringSliceE(i interface&#123;&#125;) ([]string, error) &#123; var a []string switch v := i.(type) &#123; case []interface&#123;&#125;: for _, u := range v &#123; a = append(a, ToString(u)) &#125; return a, nil case []string: return v, nil case string: return strings.Fields(v), nil case interface&#123;&#125;: str, err := ToStringE(v) if err != nil &#123; return a, fmt.Errorf(\"unable to cast %#v of type %T to []string\", i, i) &#125; return []string&#123;str&#125;, nil default: return a, fmt.Errorf(\"unable to cast %#v of type %T to []string\", i, i) &#125;&#125; 根据传入的参数类型： 如果是[]interface{}，将该参数中每个元素转为string，返回结果切片； 如果是[]string，不需要转换，直接返回； 如果是interface{}，将参数转为string，返回只包含这个值的切片； 如果是string，调用strings.Fields函数按空白符将参数拆分，返回拆分后的字符串切片； 其他情况，不能转换。 示例： 12345678910111213141516171819202122232425package mainimport ( \"fmt\" \"github.com/spf13/cast\")func main() &#123; sliceOfInt := []int&#123;1, 3, 7&#125; arrayOfInt := [3]int&#123;8, 12&#125; // ToIntSlice fmt.Println(cast.ToIntSlice(sliceOfInt)) // [1 3 7] fmt.Println(cast.ToIntSlice(arrayOfInt)) // [8 12 0] sliceOfInterface := []interface&#123;&#125;&#123;1, 2.0, \"darjun\"&#125; sliceOfString := []string&#123;\"abc\", \"dj\", \"pipi\"&#125; stringFields := \" abc def hij \" any := interface&#123;&#125;(37) // ToStringSliceE fmt.Println(cast.ToStringSlice(sliceOfInterface)) // [1 2 darjun] fmt.Println(cast.ToStringSlice(sliceOfString)) // [abc dj pipi] fmt.Println(cast.ToStringSlice(stringFields)) // [abc def hij] fmt.Println(cast.ToStringSlice(any)) // [37]&#125; 转为map[string]Type类型 cast库能将传入的参数转为map[string]Type类型，Type为上面支持的类型。 其实只需要分析一个ToStringMapStringE函数就可以了，其他的实现基本一样。ToStringMapStringE返回map[string]string类型的值。 12345678910111213141516171819202122232425262728func ToStringMapStringE(i interface&#123;&#125;) (map[string]string, error) &#123; var m = map[string]string&#123;&#125; switch v := i.(type) &#123; case map[string]string: return v, nil case map[string]interface&#123;&#125;: for k, val := range v &#123; m[ToString(k)] = ToString(val) &#125; return m, nil case map[interface&#123;&#125;]string: for k, val := range v &#123; m[ToString(k)] = ToString(val) &#125; return m, nil case map[interface&#123;&#125;]interface&#123;&#125;: for k, val := range v &#123; m[ToString(k)] = ToString(val) &#125; return m, nil case string: err := jsonStringToObject(v, &amp;m) return m, err default: return m, fmt.Errorf(\"unable to cast %#v of type %T to map[string]string\", i, i) &#125;&#125; 根据传入的参数类型： 如果是map[string]string，不用转换，直接返回； 如果是map[string]interface{}，将每个值转为string存入新的 map，最后返回新的 map； 如果是map[interface{}]string，将每个键转为string存入新的 map，最后返回新的 map； 如果是map[interface{}]interface{}，将每个键和值都转为string存入新的 map，最后返回新的 map； 如果是string类型，cast将它看成一个 JSON 串，解析这个 JSON 到map[string]string，然后返回结果； 其他情况，返回错误。 示例： 12345678910111213141516171819202122232425262728293031323334353637package mainimport ( \"fmt\" \"github.com/spf13/cast\")func main() &#123; m1 := map[string]string &#123; \"name\": \"darjun\", \"job\": \"developer\", &#125; m2 := map[string]interface&#123;&#125; &#123; \"name\": \"jingwen\", \"age\": 18, &#125; m3 := map[interface&#123;&#125;]string &#123; \"name\": \"pipi\", \"job\": \"designer\", &#125; m4 := map[interface&#123;&#125;]interface&#123;&#125; &#123; \"name\": \"did\", \"age\": 29, &#125; jsonStr := `&#123;\"name\":\"bibi\", \"job\":\"manager\"&#125;` fmt.Println(cast.ToStringMapString(m1)) // map[job:developer name:darjun] fmt.Println(cast.ToStringMapString(m2)) // map[age:18 name:jingwen] fmt.Println(cast.ToStringMapString(m3)) // map[job:designer name:pipi] fmt.Println(cast.ToStringMapString(m4)) // map[job:designer name:pipi] fmt.Println(cast.ToStringMapString(jsonStr)) // map[job:manager name:bibi]&#125; 总结 cast库能在几乎所有常见类型之间转换，使用非常方便。代码量也很小，有时间建议读读源码。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"golang http 服务基于 ip 的访问频率限制","slug":"go-http-access-frequency","date":"2020-02-04T18:06:37.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/02/04/go-http-access-frequency/","link":"","permalink":"https://overtalk.site/2020/02/04/go-http-access-frequency/","excerpt":"","text":"转自learnku 简介 如果你运行 HTTP 服务，并且希望限制 HTTP 的访问频率，那么你可以借助一些比较稳定的工具，例如： tollbooth。不过如果你构建的应用比较简单，也可以自己来实现。 我们可以使用一个现有的 Go 包 x/time/rate。 本课程，我们将创建一个简单的中间件实现基于 IP 限制 HTTP 访问频率。 简单的 HTTP 服务 让我们从创建一个简单的 HTTP 服务开始，它有非常简单的终端。 但是，因为它的访问频率可能非常高，因此我们要为它添加频率限制。 1234567891011121314151617181920package mainimport ( \"log\" \"net/http\")func main() &#123; mux := http.NewServeMux() mux.HandleFunc(\"/\", okHandler) if err := http.ListenAndServe(\":8888\", mux); err != nil &#123; log.Fatalf(\"unable to start server: %s\", err.Error()) &#125;&#125;func okHandler(w http.ResponseWriter, r *http.Request) &#123; // 某些消耗很高的数据库请求 w.Write([]byte(\"alles gut\"))&#125; 通过 main.go 我们启动服务，监听 :8888 端口，这样我们就有了一个简单的终端 /。 golang.org/x/time/rate 我们将使用名为 x/time/rate 的 Go 包，它提供了一个令牌桶速率限制器算法。rate#Limiter 控制允许事件发生的频率。它实现了一个大小为 b 的「令牌桶」，最初是满的，并以每秒 r 的速度重新填充令牌。通俗地讲，就是在任何足够大的时间间隔内，限制器将速率限制为每秒 r 个令牌，最大突发大小为 b 个事件。 由于我们希望实现每个 IP 地址的速率限制器，我们还需要维护一个限制器映射。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package mainimport ( \"sync\" \"golang.org/x/time/rate\")// IPRateLimiter .type IPRateLimiter struct &#123; ips map[string]*rate.Limiter mu *sync.RWMutex r rate.Limit b int&#125;// NewIPRateLimiter .func NewIPRateLimiter(r rate.Limit, b int) *IPRateLimiter &#123; i := &amp;IPRateLimiter&#123; ips: make(map[string]*rate.Limiter), mu: &amp;sync.RWMutex&#123;&#125;, r: r, b: b, &#125; return i&#125;// AddIP 创建了一个新的速率限制器，并将其添加到 ips 映射中,// 使用 IP地址作为密钥func (i *IPRateLimiter) AddIP(ip string) *rate.Limiter &#123; i.mu.Lock() defer i.mu.Unlock() limiter := rate.NewLimiter(i.r, i.b) i.ips[ip] = limiter return limiter&#125;// GetLimiter 返回所提供的IP地址的速率限制器(如果存在的话).// 否则调用 AddIP 将 IP 地址添加到映射中func (i *IPRateLimiter) GetLimiter(ip string) *rate.Limiter &#123; i.mu.Lock() limiter, exists := i.ips[ip] if !exists &#123; i.mu.Unlock() return i.AddIP(ip) &#125; i.mu.Unlock() return limiter&#125; NewIPRateLimiter 创建一个 IP 限制器实例，HTTP 服务器必须调用这个实例的 GetLimiter 来获得指定 IP 的限制器 (从映射或生成一个新的)。 中间件 让我们升级的 HTTP 服务并将中间件添加到所有端点，如果 IP 达到限制，它将响应 429 Too Many Requests，否则，它将继续该请求。 每一个经过中间件的请求，我们都会调用 limitMiddleware 函数中的全局方法 Allow()。如果存储桶中没有令牌了，该方法会返回 false，该请求会收到 429 Too Many Requests 的响应。否则 Allow() 方法将消耗一个令牌，并将请求传递给下一个程序。 12345678910111213141516171819202122232425262728293031323334package mainimport ( \"log\" \"net/http\")var limiter = NewIPRateLimiter(1, 5)func main() &#123; mux := http.NewServeMux() mux.HandleFunc(\"/\", okHandler) if err := http.ListenAndServe(\":8888\", limitMiddleware(mux)); err != nil &#123; log.Fatalf(\"unable to start server: %s\", err.Error()) &#125;&#125;func limitMiddleware(next http.Handler) http.Handler &#123; return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; limiter := limiter.GetLimiter(r.RemoteAddr) if !limiter.Allow() &#123; http.Error(w, http.StatusText(http.StatusTooManyRequests), http.StatusTooManyRequests) return &#125; next.ServeHTTP(w, r) &#125;)&#125;func okHandler(w http.ResponseWriter, r *http.Request) &#123; // 非常重要的数据请求（译者注：这句话没理解到位） w.Write([]byte(\"alles gut\"))&#125; 编译 &amp; 执行123go get golang.org/x/time/ratego build -o server ../server 测试 这是我喜欢使用的一个非常好的来进行 HTTP 负载测试的工具，它叫做 vegeta (它也是用 Go 编写的)。 1brew install vegeta 我们需要创建一个简单的配置文件，来展示我们希望生成的请求。 1GET http://localhost:8888/ 然后运行攻击 10 秒，每个时间单位 100 个请求。 1vegeta attack -duration=10s -rate=100 -targets=vegeta.conf | vegeta report 结果，您将看到一些请求返回了 200，但是大多数都返回了 429。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"C++ 内存对齐","slug":"cpp-memory-alignment","date":"2020-01-23T14:09:55.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/01/23/cpp-memory-alignment/","link":"","permalink":"https://overtalk.site/2020/01/23/cpp-memory-alignment/","excerpt":"","text":"c++ 内存对齐 写出一个struct,然后sizeof,你会不会经常对结果感到奇怪?sizeof的结果往往都比你声明的变量总长度要大, 这是怎么回事呢? 讲讲字节对齐吧. 前言 计算机的内存都是以字节为单位来划分的，CPU一般都是通过地址总线来访问内存的，一次能处理几个字节，就命令地址总线去访问几个字节， 32位的CPU一次能处理4个字节，就命令地址总线一次读取4个字节，读少了浪费主频，读多了也处理不了。 64位的CPU一般读取8个字节。 例如一个 int 类型的数据，如果地址为 8，那么很好办，对编号为 8 的内存寻址一次就可以。如果编号为 10，就比较麻烦，CPU需要先对编号为 8 的内存寻址，读取4个字节，得到该数据的前半部分，然后再对编号为 12 的内存寻址，读取4个字节，得到该数据的后半部分，再将这两部分拼接起来，才能取得数据的值。将一个数据尽量放在一个步长之内，避免跨步长存储，这称为内存对齐。在32位编译模式下，默认以4字节对齐；在64位编译模式下，默认以8字节对齐。 所以说内存对齐就是 时间 &amp; 空间 的一种博弈 规则 数据成员对齐规则：结构(struct)(或联合(union))的数据成员，第一个数据成员放在offset为0的地方，以后每个数据成员存储的起始位置要从 该成员大小 的整数倍开始(比如int在 32位机为４字节,则要从４的整数倍地址开始存储。 结构体作为成员：如果一个结构里有某些结构体成员,则结构体成员要从其内部最大元素大小的整数倍地址开始存储.(struct a里存有struct b,b里有char,int ,double等元素,那b应该从8的整数倍开始存储.) 收尾工作:结构体的总大小,也就是sizeof的结果,.必须是其内部最大成员的整数倍.不足的要补齐. demo1234567891011121314151617181920212223typedef struct bb&#123; int id; //[0]....[3] double weight; //[8].....[15] 原则１ float height; //[16]..[19],总长要为８的整数倍,补齐[20]...[23] 原则３&#125;BB;typedef struct aa&#123; char name[2]; //[0],[1] int id; //[4]...[7] 原则１ double score; //[8]....[15] short grade; //[16],[17] BB b; //[24]......[47] 原则２&#125;AA;int main()&#123; AA a; cout&lt;&lt;sizeof(a)&lt;&lt;\" \"&lt;&lt;sizeof(BB)&lt;&lt;endl; // 48 24 return 0;&#125; #pragma pack(). 在代码前加一句#pragma pack(1),你会很高兴的发现,上面的代码输出为 132 16 bb是4+8+4=16,aa是2+4+8+2+16=32; 这不是理想中的没有内存对齐的世界吗.没错,#pragma pack(1),告诉编译器,所有的对齐都按照1的整数倍对齐,换句话说就是没有对齐规则. 一些其他的运算符 alignof ：该运算符返回指定类型的对齐方式（以字节为单位）","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - cmake学习笔记","slug":"cplus-cmake","date":"2020-01-19T11:33:56.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/01/19/cplus-cmake/","link":"","permalink":"https://overtalk.site/2020/01/19/cplus-cmake/","excerpt":"","text":"cmake 内置命令是不区分大小写的 但是注意区分变量的大小写 aux_source_directory 在目录中查找所有源文件1aux_source_directory(&lt;dir&gt; &lt;variable&gt;) 例子 工程格式 1234567./Demo2 | +--- main.cc | +--- MathFunctions.cc | +--- MathFunctions.h 写法1 12345678# CMake 最低版本号要求cmake_minimum_required (VERSION 2.8)# 项目信息project (Demo2)# 指定生成目标add_executable(Demo main.cc MathFunctions.cc) 写法2 123456789101112# CMake 最低版本号要求cmake_minimum_required (VERSION 2.8)# 项目信息project (Demo2)# 查找当前目录下的所有源文件# 并将名称保存到 DIR_SRCS 变量aux_source_directory(. DIR_SRCS)# 指定生成目标add_executable(Demo $&#123;DIR_SRCS&#125;) 打印变量 status 表示这是一般的打印信息12set(USER_KEY, \"Hello World\")message( STATUS \"this var key = $&#123;USER_KEY&#125;.\") Set 的用法 官方文档 Set赋值给一般变量(normal variables) 什么是一般变量，一般变量和代码中变量相似，仅在自身所在作用域起作用，除非后面使用PARENT_SCOPE。 每一个新的目录或者函数都会创建新的作用域，当在新的作用域创建一般变量且后面加上PARENT_SCOPE，该变量可以在父目录或者调用新函数的函数上起作用。 举个栗子： 12set(FOO “x”)。 //FOO作用域为当前作用域.set(FOO \"x\" PARENT_SCOPE) //FOO作用域跳上一级. Set赋值给缓存变量(cache variables) 什么是缓存变量，缓存变量可以理解为当第一次运行cmake时，这些变量缓存到一份文件中(即编译目录下的CMakeCache.txt)。当再次运行cmake时，这些变量会直接使用缓存值，可以利用ccmake或者cmake-gui等工具来重新赋值。缓存变量在整个cmake运行过程中都可以起作用。 当使用CACHE时，且缓存(cache)中没有该变量时，变量被创建并存入缓存(cache)中，如果原缓存(cache)中有该变量，也不会改变原缓存中该变量的值，除非后面使用FORCE。 举个栗子： 123set(FOO, \"x\" CACHE &lt;type&gt;)//原缓存中没有FOO则将FOO赋值为x且存入cache中。//原缓存中有FOO则不做任何改变，即便原cache中FOO存的不是x。 1234set(FOO, \"x\" CACHE &lt;type&gt;&lt;docstring&gt; FORCE) //即便原cache中存在FOO也会创建另一个FOO，官方文档原话(If FORCE is specified, the value of the cache variable//is set, even if the variable is already in the cache.This should normally be avoided, as it will//remove any changes to the cache variable’s value by the user.)，小弟笨拙没有搞懂。 使用CACHE的同时，要设定&lt;type&gt;和&lt;docstring&gt;，&lt;type&gt;可以理解为所存入变量类型，&lt;docstring&gt;为变量的描述。 &lt;type&gt;分为以下几种类型： 12345FILEPATH = File chooser dialog.PATH = Directory chooser dialog.STRING = Arbitrary string.BOOL = Boolean ON/OFF checkbox.INTERNAL = No GUI entry (used for persistent variables). 其中INTERNAL将变量为内部变量，即cmake-gui不会向用户显示这类变量，而其它类型的缓存变量用户都可以通cmake-gui按照特定的类型改变。 例子： 如果编译的时候没有带 CMAKE_BUILD_TYPE 参数的话，则会默认为 Release12345678#---------------------------------------------------------------------------------------# Set default build type to release#---------------------------------------------------------------------------------------if (UNIX) if (NOT CMAKE_BUILD_TYPE) set(CMAKE_BUILD_TYPE \"Release\" CACHE STRING \"Choose Release or Debug\" FORCE) endif ()endif () 注意 CACHE 与 PARENT_SCOPE 不能一起使用 同一名称(例FOO)的一般变量和缓存变量可以同时存在，但在调用该变量时(${FOO})会在先取一般变量的值，一般变量中没有再取缓存变量的值。 1234set(FOO “x”) //设置一般变量FOO，不会触及cache，但是会隐藏cache中的FOO。set(FOO “x” CACHE ...) //忽视相同名称的一般变量，在cache中检查FOO是否存在， //如果不存在则存入cache中，存在也不会对cache中FOO重新赋值。 当改变cache中的变量时，同名的一般变量会被删除。一般不建议使用相同名称的一般变量和缓存变量。 然而在有些工程中可以很好的借助这一交互例如： 一个工程利用ADD_SUBDIRECTOTY()添加子工程，子工程有它自己的CMakeList.txt。如果在父工程和子工程中都对同一缓存变量赋值，cmake时父工程率先将变量存入cache中，子工程直接在cache中调用该值，保证了父子工程的一致性。当父工程需要改变该变量，而子程序需要利用原值时，可以直接在父工程中设置同名称的一般变量即可。 Option 的用法 使用场景 : 编译脚本传递参数 -&gt; CMake脚本接收option -&gt; 源代码宏 编译脚本传入参数123#!/bin/shcmake -DTEST_DEBUG=ON .cmake --build . CMake脚本接收option cmake 脚本定义TEST_DEBUG 默认关闭OFF12345678project(test)option(TEST_DEBUG \"option for debug\" OFF)\\if (TEST_DEBUG) add_definitions(-DTEST_DEBUG)endif ()... 源代码宏 test.c12345#include \"test.h\"#ifdef TEST_DEBUG...#endif add_subdirectory 的用法 一般情况下，我们的项目各个子项目都在一个总的项目根目录下，但有的时候，我们需要使用外部的文件夹，怎么办呢？ add_subdirectory命令，可以将指定的文件夹加到build任务列表中。 add_library 使用指定的源文件向工程中添加一个库 123add_library(&lt;name&gt; [STATIC | SHARED | MODULE] [EXCLUDE_FROM_ALL] source1 source2 ... sourceN) 其中表示库文件的名字，该库文件会根据命令里列出的源文件来创建。而 STATIC、SHARED 和 MODULE 的作用是指定生成的库文件的类型。 STATIC库是目标文件的归档文件，在链接其它目标的时候使用。 SHARED库会被动态链接（动态链接库），在运行时会被加载。 MODULE库是一种不会被链接到其它目标中的插件，但是可能会在运行时使用dlopen-系列的函数。 默认状态下，库文件将会在于源文件目录树的构建目录树的位置被创建，该命令也会在这里被调用。 而语法中的 source1 source2 分别表示各个源文件。 使用下述格式，add_library命令也可以用来创建导入的库目标：1add_library($&#123;PROJECT_NAME&#125; SHARED src/track/Tracking.cpp) link_directories 该指令的作用主要是指定要链接的库文件的路径，该指令有时候不一定需要。因为find_package和find_library指令可以得到库文件的绝对路径。 不过你自己写的动态库文件放在自己新建的目录下时，可以用该指令指定该目录的路径以便工程能够找到。 例子如下：123link_directiories( lib) target_link_libraries 该指令的作用为将目标文件与库文件进行链接。该指令的语法如下：12target_link_libraries(&lt;target&gt; [item1] [item2] [...] [[debug|optimized|general] &lt;item&gt;] ...) 上述指令中的是指通过 add_executable() 和 add_library() 指令生成已经创建的目标文件。而 [item] 表示库文件没有后缀的名字。 默认情况下，库依赖项是传递的。当这个目标链接到另一个目标时，链接到这个目标的库也会出现在另一个目标的连接线上。 这个传递的接口存储在interface_link_libraries的目标属性中，可以通过设置该属性直接重写传递接口 例子如下：1234567891011121314link_directiories( $&#123;svo_SOURCE_DIR&#125;/include/svo $&#123;svo_SOURCE_DIR&#125;/include/svo/track)add_library($&#123;PROJECT_NAME&#125; SHARED src/track/Tracking.cpp)add_executable($&#123;PROJECT_NAME&#125;_node src/svo_node.cpp src/system.cpp)target_link_libraries($&#123;PROJECT_NAME&#125;_node $&#123;PROJECT_NAME&#125;) include_directories 设置头文件位置 一些关键字 UNIX : 在所有的类UNIX平台为TRUE，包括OS X和cygwin WIN32 : 在所有的win32平台为TRUE，包括cygwin","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"gpg","slug":"gpg","date":"2020-01-19T11:02:53.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/01/19/gpg/","link":"","permalink":"https://overtalk.site/2020/01/19/gpg/","excerpt":"","text":"在 macOS 中使用 GPG 密钥提交代码至 Github","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"gpg","slug":"gpg","permalink":"https://overtalk.site/tags/gpg/"}]},{"title":"C++ - fragment","slug":"fragment-cpp","date":"2020-01-14T18:47:44.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2020/01/14/fragment-cpp/","link":"","permalink":"https://overtalk.site/2020/01/14/fragment-cpp/","excerpt":"","text":"std 中的 map 和 unordered_map 在 insert 的时候都会进行拷贝一个小陷阱123456789101112#include &lt;iostream&gt;int main()&#123; char* temp = \"sdf\"; auto name = new char[10]; name = temp; // 这样赋值是错误的，因为 name 指是指向内存堆区的，如果使用 name = temp; 会造成指针指向改变不是指向堆区而是指向栈区，导致在后面调用析构函数 delete 释放空间出错！ std::cout &lt;&lt; name &lt;&lt; std::endl; delete[] name; return 0;&#125; 获取 class 的名称1234567891011121314151617181920212223#include&lt;iostream&gt;class AAAA&#123;public: void Test() &#123; &#125;&#125;;int main()&#123; AAAA a; const char* name = typeid(a).name(); std::cout &lt;&lt; name &lt;&lt; std::endl; // 输出结果 ： class AAAA // 这个方法不仅仅可以用于 class，还可以用于类方法 // 可以看出是那个类的方法 std::cout &lt;&lt; typeid(&amp;AAAA::Test).name() &lt;&lt; std::endl; // 输出结果 ：void (__thiscall AAAA::*)(void) return 0;&#125; 判断 一个类 是不是 另外一个类 的子类1234567891011121314151617#include&lt;type_traits&gt;#include&lt;iostream&gt;class BaseClass&#123;&#125;;class SubClass : public BaseClass&#123;&#125;;int main()&#123; bool flag = std::is_base_of&lt;BaseClass, SubClass&gt;::value; // true bool flag1 = std::is_base_of&lt;SubClass, BaseClass&gt;::value; // false std::cout &lt;&lt; flag &lt;&lt; std::endl; std::cout &lt;&lt; flag1 &lt;&lt; std::endl; return 0;&#125; 生命周期 超出生命周期范围就会被析构 推荐使用智能指针1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;iostream&gt;class Test&#123;public: Test(int a, bool b) :a(a),b(b) &#123; &#125; void show() &#123; std::cout &lt;&lt; a &lt;&lt; \" - \" &lt;&lt; b &lt;&lt; std::endl; &#125; int a; bool b;&#125;;std::shared_ptr&lt;Test&gt; GetTestPrtInHeap1()&#123; // 先 new 出来，再进行赋值 Test* t = new Test(1, true); std::shared_ptr&lt;Test&gt; ret(t); return ret;&#125;std::shared_ptr&lt;Test&gt; GetTestPrtInHeap2()&#123; // 推荐方法 return std::make_shared&lt;Test&gt;(2, false);&#125;std::shared_ptr&lt;Test&gt; GetTestPrtInStack()&#123; // 先构造出来，但是是再 stack 中 // 函数结束就会被析构 Test t(3, false); std::shared_ptr&lt;Test&gt; ret(&amp;t); return ret;&#125;int main()&#123; auto ptr1 = GetTestPrtInHeap1(); ptr1-&gt;show(); ////////////////////// auto ptr2 = GetTestPrtInHeap2(); ptr2-&gt;show(); ////////////////////// auto empty_ptr = GetTestPrtInStack(); empty_ptr-&gt;show(); return 0;&#125; C++ 一个类的成员函数可以是模板函数么？ 不仅仅一个类的成员函数可以是 模板函数，一个模版类的成员函数也可以是 模板函数1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;class Print&#123;public: template &lt;typename T&gt; static void print(const T&amp; value) &#123; std::cout &lt;&lt; typeid(value).name() &lt;&lt; \" - \" &lt;&lt; value &lt;&lt; std::endl; &#125;&#125;;template &lt;typename T1&gt;class SuperPrint&#123;public: template &lt;typename T2&gt; static void print(const T2&amp; value) &#123; std::cout &lt;&lt; \"super print -&gt;\" &lt;&lt; typeid(value).name() &lt;&lt; \" - \" &lt;&lt; value &lt;&lt; std::endl; &#125;&#125;;int main()&#123; Print::print(12); SuperPrint&lt;int&gt;::print(12); return 0;&#125; typeid 关键字 TypeId 返回一个变量或数据类型的“类型”。123cout&lt;&lt;typeid(int).name()&lt;&lt;endl; // intint a;cout&lt;&lt;typeid(a).name()&lt;&lt;endl; // int 多个返回值 C++ 多返回值函数12345678910111213141516171819202122#include &lt;iostream&gt;std::tuple&lt;int, std::string, char*&gt; testFunc()&#123; int ret_int = 12; std::string ret_str = \"ret_str\"; char* ret_char_ptr = \"ret_char_ptr\"; return std::make_tuple(ret_int, ret_str, ret_char_ptr);&#125;int main() &#123; int ret_int; std::string ret_str; char* ret_char_ptr; tie(ret_int, ret_str, ret_char_ptr) = testFunc(); std::cout &lt;&lt; ret_int &lt;&lt; std::endl; std::cout &lt;&lt; ret_str &lt;&lt; std::endl; std::cout &lt;&lt; ret_char_ptr &lt;&lt; std::endl; return 0;&#125;","categories":[{"name":"fragment","slug":"fragment","permalink":"https://overtalk.site/categories/fragment/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - 单例模式","slug":"cpp-singleton","date":"2020-01-14T15:49:21.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/01/14/cpp-singleton/","link":"","permalink":"https://overtalk.site/2020/01/14/cpp-singleton/","excerpt":"","text":"C++ 学习笔记 C++ 中单例模式的实现 简介 c++ 类 有复制构造函数，今天来介绍一些如何让一个类没有办法被 copy 普通的类, 可以通过复制构造函数类进行 copy 12345678910111213141516class Copyable&#123;&#125;;int main()&#123; Copyable c1; Copyable c2 = c1; Copyable c3(c1); Copyable&amp; ref = c1; Copyable c4 = ref; Copyable c5(ref); return 0;&#125; 删除一些 拷贝构造函数, 这样就不可以被 copy 了 123456789101112131415161718192021222324252627282930313233343536373839#include&lt;iostream&gt;class Noncopyable&#123;public: Noncopyable() = default; Noncopyable(const Noncopyable&amp;) = delete; Noncopyable&amp; operator=(const Noncopyable&amp;) = delete; Noncopyable(Noncopyable&amp;&amp;) = delete; Noncopyable&amp; operator=(Noncopyable&amp;&amp;) = delete;&#125;;class Copyable&#123;&#125;;int main()&#123; Copyable c1; Copyable c2 = c1; Copyable c3(c1); Copyable&amp; ref = c1; Copyable c4 = ref; Copyable c5(ref); // ----------------- Noncopyable n1; Noncopyable n2 = n1; // error Noncopyable n3(n1); // error Noncopyable&amp; n_ref = n1; Noncopyable n4 = n_ref; // error Noncopyable n5(n_ref); // error return 0;&#125; 一些骚操作 借助于上面的例子，可以实现单个例模式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;class Noncopyable&#123;public: Noncopyable() = default; Noncopyable(const Noncopyable&amp;) = delete; Noncopyable&amp; operator=(const Noncopyable&amp;) = delete; Noncopyable(Noncopyable&amp;&amp;) = delete; Noncopyable&amp; operator=(Noncopyable&amp;&amp;) = delete;&#125;;template&lt;typename T&gt;class SingleTon : public Noncopyable&#123;public: static T* instance() &#123; std::call_once(once_, &amp;SingleTon&lt;T&gt;::Init); return instance_; &#125; static T&amp; get_instance() &#123; return *instance(); &#125; static void ShutDown() &#123; delete instance_; &#125;private: static void Init() &#123; instance_ = new T(); &#125; static std::once_flag once_; static T* instance_;&#125;;template&lt;typename T&gt;std::once_flag SingleTon&lt;T&gt;::once_;template&lt;typename T&gt;T* SingleTon&lt;T&gt;::instance_ = nullptr;// 单例class SingleDemo final : public SingleTon&lt;SingleDemo&gt;&#123;public: int data;&#125;;int main()&#123; SingleDemo* demo1 = SingleDemo::instance(); demo1-&gt;data = 1; std::cout &lt;&lt; demo1-&gt;data &lt;&lt; std::endl; demo1-&gt;data = 2; SingleDemo* demo2 = SingleDemo::instance(); std::cout &lt;&lt; demo1-&gt;data &lt;&lt; std::endl; return 0;&#125; 上面这个例子的输出结果为 1212","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - 虚构造函数","slug":"cpp-virtual-destructor","date":"2020-01-11T23:31:59.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/01/11/cpp-virtual-destructor/","link":"","permalink":"https://overtalk.site/2020/01/11/cpp-virtual-destructor/","excerpt":"","text":"C++ 学习笔记 C++ 虚构造函数 简介 首先来看一段代码，以及其执行的结果 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;class Base&#123;public: Base() &#123; std::cout &lt;&lt; \"Base Constructor. \\n\"; &#125;; ~Base() &#123; std::cout &lt;&lt; \"Base Destructor. \\n\"; &#125;;&#125;;class Derived : public Base&#123;public: Derived() &#123; std::cout &lt;&lt; \"Derived Constructor. \\n\"; &#125;; ~Derived() &#123; std::cout &lt;&lt; \"Derived Destructor. \\n\"; &#125;;&#125;;int main()&#123; Base* base = new Base(); delete base; std::cout &lt;&lt; \"--------\\n\"; Derived* derived = new Derived(); delete derived; std::cout &lt;&lt; \"--------\\n\"; Base* ploy = new Derived(); delete ploy; // 可能会导致内存泄漏 return 0;&#125; 执行结果如下所示 1234567891011Base Constructor. Base Destructor. --------Base Constructor. Derived Constructor. Derived Destructor. Base Destructor. --------Base Constructor. Derived Constructor. Base Destructor. 前面两段代码的执行结果可以理解 最后一段代码只执行来 Base 类的析构函数，这样就有可能造成内存泄露 如何解决？ 在 Base 类的析构函数上加上 virtual 关键字就可以了","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - union","slug":"cpp-unions","date":"2020-01-11T18:47:58.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/01/11/cpp-unions/","link":"","permalink":"https://overtalk.site/2020/01/11/cpp-unions/","excerpt":"","text":"C++ 学习笔记 C++ union 简介 联合体 union 中所有的变量公用一个内存地址 如果一个 union 中有五个 int 变量：a,b,c,d,e ，当我设置a为2时，所有的变量都是2 union 不可以有方法 可以理解成 ： 使用union是为了用不同的名称去访问同一个内存地址 1234567891011121314151617#include &lt;iostream&gt;struct Union&#123; union &#123; float a; int b; &#125;;&#125;;int main()&#123; Union u; u.a = 3.4f; std:: cout &lt;&lt; u.a &lt;&lt; \",\" &lt;&lt; u.b &lt;&lt; std::endl;&#125; 进阶一点的demo12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;struct vector2&#123; float x, y;&#125;;struct vector4&#123; union &#123; struct &#123; float x, y, z, w; &#125;; struct &#123; // a 和 （x, y）公用内存 // b 和 （z, w）公用内存 vector2 a, b; &#125;; &#125;;&#125;;void PrintVector2(const vector2&amp; v)&#123; std::cout &lt;&lt; v.x &lt;&lt; \",\" &lt;&lt; v.y &lt;&lt; std::endl;&#125;int main()&#123; vector4 v = &#123;1.1f, 1.2f, 1.3f, 1.4f &#125;; PrintVector2(v.a); PrintVector2(v.b); return 0;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - 排序","slug":"cpp-sort","date":"2020-01-11T00:36:21.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/01/11/cpp-sort/","link":"","permalink":"https://overtalk.site/2020/01/11/cpp-sort/","excerpt":"","text":"C++ 学习笔记 C++ 排序 简介 使用 std 标准库中的排序 12345678910111213141516171819202122#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;iostream&gt;int main()&#123; std::vector&lt;int&gt; values = &#123;9,4,56,32,34&#125;; std::sort(values.begin(), values.end()); for (int value : values) std::cout &lt;&lt; value &lt;&lt; std::endl; std::cout &lt;&lt; std::endl; std::sort(values.begin(), values.end(), [](int a, int b)&#123; return a &gt; b; &#125;); for (int value : values) std::cout &lt;&lt; value &lt;&lt; std::endl; return 0;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - 多维数组","slug":"cpp-multidimensional-arrays","date":"2020-01-10T22:41:54.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/01/10/cpp-multidimensional-arrays/","link":"","permalink":"https://overtalk.site/2020/01/10/cpp-multidimensional-arrays/","excerpt":"","text":"C++ 学习笔记 C++ 多维数组 简介 多维度数组就是 array of array 内存中存放了一个连续的指针数组，每一个数组变量都是一个指针，指向另外一个数组 多维数组12345678910111213141516171819202122232425262728#include &lt;iostream&gt;int main()&#123; // 堆栈变量 int* array = new int[50]; int** a2d = new int*[50]; int*** a3d = new int**[50]; array[0] = 0; // 这儿是int a2d[0] = nullptr; // 这儿是指针， int 的指针 // 给二维数组申请空间 for (int i = 0; i &lt; 50; ++i) a2d[i] = new int[50]; // 给三维数组申请空间 for (int i = 0; i &lt; 50; ++i) &#123; a3d[i] = new int*[50]; for (int j = 0; j &lt; 50; ++j) a3d[i][j] = new int[50]; &#125; std::cin.get(); return 0;&#125; 空间释放 上面的例子中，所有的内存都是在 heap 上的，需要手动删除12345678910111213// 删除二维数组for (int i = 0; i &lt; 50; ++i) delete[] a2d[i];delete[] a2d;// 删除三维数组申请空间for (int i = 0; i &lt; 50; ++i)&#123; for (int j = 0; j &lt; 50; ++j) delete[] a3d[i][j]; delete[] a3d[i];&#125;delete[] a3d;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - time","slug":"cpp-time","date":"2020-01-10T00:36:12.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/01/10/cpp-time/","link":"","permalink":"https://overtalk.site/2020/01/10/cpp-time/","excerpt":"","text":"简介 c++中有关时间的处理1234567891011121314151617#include &lt;chrono&gt;#include &lt;thread&gt;#include &lt;iostream&gt;int main()&#123; using namespace std::literals::chrono_literals; auto start = std::chrono::high_resolution_clock::now(); std::this_thread::sleep_for(1s); auto end = std::chrono::high_resolution_clock::now(); std::chrono::duration&lt;float&gt; duration = end - start; std::cout &lt;&lt; duration.count() &lt;&lt; \"s\" &lt;&lt; std::endl; return 0;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - 多线程","slug":"cpp-thread","date":"2020-01-09T23:20:59.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/01/09/cpp-thread/","link":"","permalink":"https://overtalk.site/2020/01/09/cpp-thread/","excerpt":"","text":"C++ 学习笔记 C++ namespace 简介 多线程的用处我就不多介绍了，直接上代码 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;thread&gt;static bool is_finished = false;void DoWork()&#123; while (!is_finished) &#123; using namespace std::literals::chrono_literals; std::cout &lt;&lt; \"working...\\n\"; std::this_thread::sleep_for(1s); &#125;&#125;int main()&#123; std::thread worker(DoWork); std::cin.get(); is_finished = true; worker.join(); std::cout &lt;&lt; \"Finished!\" &lt;&lt; std::endl; std::cin.get(); return 0;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - 函数指针","slug":"cpp-func-ptr","date":"2020-01-09T00:31:10.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/01/09/cpp-func-ptr/","link":"","permalink":"https://overtalk.site/2020/01/09/cpp-func-ptr/","excerpt":"","text":"简介 函数指针就是 分配一个函数到一个变量中 这样就可以传一个函数作为入参到另外一个函数中 顺道说一下 c++ 中的 using 关键字的用法，类似于 golang 中的 type 关键字 123456789101112131415161718#include&lt;iostream&gt;using MY_FUNC = void(*)(int a);void Print(int a)&#123; std::cout &lt;&lt; a &lt;&lt; std::endl;&#125;void DoMyJob(MY_FUNC job) &#123; job(34);&#125;int main()&#123; DoMyJob(Print);&#125; demo123456789101112131415161718192021222324252627282930313233343536 #include &lt;string&gt;#include &lt;vector&gt;#include &lt;iostream&gt;#include &lt;functional&gt;void PrintHello(int value)&#123; std::cout &lt;&lt; \"value = \" &lt;&lt; value &lt;&lt; std::endl;&#125;void ForEach(const std::vector&lt;int&gt;&amp; vv, std::function&lt;void(int)&gt; func)&#123; for (int v : vv) func(v);&#125;// 程序的主函数int main()&#123; void(*func1)(int) = PrintHello; auto func = PrintHello; func(1); func1(3); std::vector&lt;int&gt; values = &#123;1,2,3,4&#125;; ForEach(values, func); // 如果这个函数只用一次，写一个定义很麻烦 // 这个时候就需要用到lambda表达式，类似go中的匿名函数 std::vector&lt;int&gt; values2 = &#123;1,2,3,4&#125;; auto l = [](int value)&#123; std::cout &lt;&lt; \"value = \" &lt;&lt; value &lt;&lt; std::endl; &#125;; ForEach(values2, l); std::cout &lt;&lt; \"ok\" &lt;&lt; std::endl; return 0;&#125; lambda表达式 正常定义 1auto lambda = [](int value )&#123; std::cout &lt;&lt; \"value = \" &lt;&lt; value &lt;&lt; std::endl; 如果我需要用到上下文的一些变量呢？可以通过前面的那个 [] 传入 12// 这个 lambda表达式 中， a就是一个上下文的变量，不是入参auto lambda = [](int value )&#123; std::cout &lt;&lt; \"value = \" &lt;&lt; value &lt;&lt; \", a = \" &lt;&lt; a &lt;&lt; std::endl; 解决方案 [=] : 上下文所有拷贝传入 [&amp;] : 上下文所有引用传入 [a] : a 拷贝传入 [&amp;a] : a 引用传入 123int a = 90;auto lambda = [&amp;a](int value )&#123; std::cout &lt;&lt; \"value = \" &lt;&lt; value &lt;&lt; \", a = \" &lt;&lt; a &lt;&lt; std::endl;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - 宏","slug":"cpp-macros","date":"2020-01-01T23:15:45.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2020/01/01/cpp-macros/","link":"","permalink":"https://overtalk.site/2020/01/01/cpp-macros/","excerpt":"","text":"C++ 学习笔记 C++ 中的宏 预处理 - preprocessor 当我们尝试去编译一个 C++ 程序的时候，第一件事情就是预处理 预处理 可以理解成一个代码文本修改的过程，我们可以预先写好一些宏，用来替换一些代码 12345678910111213141516#include &lt;string&gt;#include &lt;iostream&gt;// 如果是 DEBUG_MODE，就打印，否则不打印日志#ifdef DEBUG_MODE#define LOG(x) std::cout &lt;&lt; x &lt;&lt; std::endl#else#define LOG(x)#endif// 程序的主函数int main()&#123; LOG(\"hello\"); return 0;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - heap & stack","slug":"cpp-mem","date":"2019-12-31T22:36:06.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/12/31/cpp-mem/","link":"","permalink":"https://overtalk.site/2019/12/31/cpp-mem/","excerpt":"","text":"C++ 学习笔记 C++ heap内存 &amp; stack内存 它们是什么？ 其是它们就是我们计算机 RAM 中两块内存 stack : 其大小是在程序运行之后 预定义 好的，其大小大概为 两百万字节 heap : 也是 预定义 好的，但是其大小会随程序的增长而改变 区别 当在 stack 上申请变量的时候，stack ptr（top of the stack）会移动相应的大小，用来给申请的变量 通常 stack 会很快 new 关键字会调用 malloc函数 来申请内存，会调用底层操作系统的特定接口 new 关键字会向操作系统申请真实的物理内存，程序会维持一个 free list （保存这些物理内存地址）","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - 箭头运算符","slug":"cpp-arrow-operator","date":"2019-12-29T10:53:59.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/12/29/cpp-arrow-operator/","link":"","permalink":"https://overtalk.site/2019/12/29/cpp-arrow-operator/","excerpt":"","text":"C++ 学习笔记 C++ 中的箭头运算符 简介 本篇将讨论箭头运算符 both in class &amp; struct 用法1 箭头函数最通常的用法就是用于 object 调用其函数/共有变量、123456789101112131415161718192021#include &lt;string&gt;#include &lt;iostream&gt;class Entity&#123;public: void Print() const &#123; std::cout &lt;&lt; \"Hello!\" &lt;&lt; std::endl;&#125;&#125;;// 程序的主函数int main()&#123; Entity e; e.Print(); Entity* e1 = new Entity(); // 指针调用函数，需要使用到箭头函数 e1-&gt;Print(); delete e1; return 0;&#125; 重载箭头运算符 ScopePtr 的析构函数中会删除 Entity，相当于一个智能指针 如果不使用运算符重载的话，可能需要写一个 GetEntity 方法来返回 ScopePtr 中的 Entity 指针 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;string&gt;#include &lt;iostream&gt;class Entity&#123;public: void Print() const &#123; std::cout &lt;&lt; \"Hello!\" &lt;&lt; std::endl;&#125;&#125;;class ScopePtr&#123;private: Entity* obj;public: ScopePtr(Entity* e) : obj(e) &#123;&#125; ~ScopePtr() &#123; delete obj; &#125; Entity* operator-&gt;() &#123; return obj; &#125; const Entity* operator-&gt;() const &#123; return obj; &#125;&#125;;// 程序的主函数int main()&#123; Entity e; e.Print(); Entity* e1 = new Entity(); // 指针调用函数，需要使用到箭头函数 e1-&gt;Print(); delete e1; const ScopePtr ptr = new Entity; ptr-&gt;Print(); ScopePtr ptr1 = new Entity; ptr1-&gt;Print(); return 0;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - 操作符 & 操作法重载","slug":"cpp-operator","date":"2019-12-28T18:25:26.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/12/28/cpp-operator/","link":"","permalink":"https://overtalk.site/2019/12/28/cpp-operator/","excerpt":"","text":"C++ 学习笔记 C++ 操作符及其重载 简介 操作符 可以看作是一种函数的简化写法 操作符 不仅仅包括数学的（+，-，*，/ …）,还有其他的例如：new, delete, &amp;, +=, ::,指针的 -&gt; 操作符 重载就是重新定义这些操作符的算法函数 demo1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#include &lt;string&gt;#include &lt;iostream&gt;struct Vector2&#123; float x, y; Vector2(float x, float y) : x(x), y(y) &#123;&#125; // 如果没有运算符重载，可能两个向量相加的写法就是这样的 Vector2 Add(const Vector2&amp; other) const &#123; // 也可以写成 // this 其实也是一个关键字 // return *this + other; // return operator+(other); return Vector2(x + other.x, y + other.y); &#125; // 如果没有运算符重载，可能两个向量相乘的写法就是这样的 Vector2 Multiply(const Vector2&amp; other) const &#123; // 也可以写成 // return *this * other; // return operator*(other); return Vector2(x * other.x, y * other.y); &#125; // =====运算符重载部分===== Vector2 operator+(const Vector2&amp; other) const &#123; return Vector2(x + other.x, y + other.y); &#125; Vector2 operator*(const Vector2&amp; other) const &#123; return Vector2(x * other.x, y * other.y); &#125; bool operator==(const Vector2&amp; other) const &#123; return x == other.x &amp;&amp; y == other.y; &#125; bool operator!=(const Vector2&amp; other) const &#123; return !(*this == other); &#125;&#125;;// 重载 ostream 的 &lt;&lt; 的运算符std::ostream&amp; operator&lt;&lt;(std::ostream&amp; stream, const Vector2&amp; other)&#123; stream &lt;&lt; other.x &lt;&lt; \" , \" &lt;&lt; other.y; return stream;&#125;// 程序的主函数int main()&#123; Vector2 pos(4.0f, 4.0f); Vector2 speed(0.5f, 1.5f); Vector2 powerUp(0.5f, 1.5f); // 阅读起来很麻烦 Vector2 result = pos.Add(speed.Multiply(powerUp)); Vector2 result1 = pos + speed * powerUp; if (result == result1) &#123; &#125; std::cout &lt;&lt; result &lt;&lt; std::endl; return 0;&#125; this 关键字 在上面的操作符重载的栗子中，有出现了 this 关键字，就在这儿稍微记录一下吧 this 关键字只有在 class 的成员函数 中出现，this 就是指向当前实例的指针","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - 隐式构造","slug":"cpp-implicit-conversion","date":"2019-12-28T18:02:36.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/12/28/cpp-implicit-conversion/","link":"","permalink":"https://overtalk.site/2019/12/28/cpp-implicit-conversion/","excerpt":"","text":"C++ 学习笔记C++ 隐式构造 &amp; explicit 关键字 概述 主要讲的是类的另外一种定义方法 隐式构造 主要用于简化代码 个人觉得还是少用，这儿就当记录一下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;string&gt;#include &lt;iostream&gt;class Entity&#123;private: std::string name; int age;public: Entity(const std::string&amp; n) : name(n), age(-1) &#123;&#125; Entity(int age) : name(\"Unknown\"), age(age) &#123;&#125; const std::string&amp; GetName() const &#123; return name; &#125; int GetAge() const &#123; return age; &#125;&#125;;void PrintEntity(const Entity&amp; e)&#123; std::cout &lt;&lt; e.GetName() &lt;&lt; std::endl; std::cout &lt;&lt; e.GetAge() &lt;&lt; std::endl;&#125;// 程序的主函数int main()&#123; // 这儿其实是调用 Entity 的构造函数了 PrintEntity(2); // 上面的语句等价于下面这一句 PrintEntity(Entity(2)); Entity a(\"qinhan\"); Entity aa = std::string(\"qinhan\"); Entity b(22); Entity b1 = 22; return 0;&#125; explicit 关键字 关键字放在 构造函数 的前面 表示改构造函数不可以用于 隐式构造","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - 构造对象的两种方法","slug":"cpp-object-create","date":"2019-12-28T10:43:42.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/12/28/cpp-object-create/","link":"","permalink":"https://overtalk.site/2019/12/28/cpp-object-create/","excerpt":"","text":"C++ 学习笔记 C++ 构造对象 简介 任何 class 的 的对象都会占用空间，就算没有任何成员变量，也至少会占用 1 byte 不同的构造方法会使得内存在不同的地方，显然：stack &amp; heap stack 上的对象有自动的生命周期，让程序跳出生命周期的scope，对象就会被自动释放 heap 上的对象只有主动删除才会被释放 尽可能的创建 stack 上的对象，因为这样会更快，更好管理 在 heap 上创建对象会耗费更长的时间，而且需要手动 delete stack 上的对象123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;#include &lt;string&gt;class Entity&#123;private: std::string name;public: Entity() : name(\"Unknown\") &#123;&#125; Entity(const std::string&amp; n) : name(n) &#123;&#125; const std::string&amp; GetName() const &#123; return name; &#125;&#125;;// 程序的主函数int main()&#123; Entity e(\"qinhan\"); std::cout &lt;&lt; e.GetName() &lt;&lt; std::endl; Entity* e1; &#123; Entity test(\"qinhan\"); e1 = &amp;test; // e1 的 name 是 \"qinhan\" std::cout &lt;&lt; test.GetName() &lt;&lt; std::endl; &#125; // 在这儿，e1 的 name 是空字符串 // 因为e1 指向的是 stack 上的对象，生命周期结束之后，就会被回首 return 0;&#125; heap 上的对象123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;#include &lt;string&gt;class Entity&#123;private: std::string name;public: Entity() : name(\"Unknown\") &#123;&#125; Entity(const std::string&amp; n) : name(n) &#123;&#125; const std::string&amp; GetName() const &#123; return name; &#125;&#125;;// 程序的主函数int main()&#123; Entity e(\"qinhan\"); std::cout &lt;&lt; e.GetName() &lt;&lt; std::endl; Entity* e1; &#123; Entity test(\"aaa\"); e1 = &amp;test; // 在这儿，e 的 name 是 \"qinhan\" std::cout &lt;&lt; test.GetName() &lt;&lt; std::endl; &#125; // 在这儿，e 的 name 是空字符串 // 因为e 指向的是 stack 上的对象，生命周期结束之后，就会被回首 std::cout &lt;&lt; e1-&gt;GetName() &lt;&lt; std::endl; &#123; Entity* test = new Entity(\"asdf\"); e1 = test; // 在这儿，e 的 name 是 \"qinhan\" std::cout &lt;&lt; test-&gt;GetName() &lt;&lt; std::endl; &#125; std::cout &lt;&lt; e1-&gt;GetName() &lt;&lt; std::endl; delete(e1); return 0;&#125; new 关键字 main purpose of the word new is to allocate memory in the heap 返回指针 12345678910111213141516171819202122232425262728293031323334353637#include &lt;string&gt;class Entity&#123;private: std::string name;public: Entity() : name(\"Unknown\") &#123;&#125; Entity(const std::string&amp; n) : name(n) &#123;&#125; const std::string&amp; GetName() const &#123; return name; &#125;&#125;;// 程序的主函数int main()&#123; int a = 2; int* b = new int; int* c = new int[2]; Entity* e1 = new Entity; // new 关键字其实就是申请空间，可以用一下的写法所代替呢 // 但是不同的是，上面那种写法会执行构造函数，而下面这种写法只会申请空间，并不会执行构造函数 Entity* anOtherE = (Entity*)malloc(sizeof(Entity)); Entity* e2 = new Entity(\"qinhan\"); Entity* e3 = new Entity[50]; // 千万记得 delete delete e1; delete anOtherE; delete e2; // 注意这是删除数组的方式哦 delete[] e3; return 0;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - notes","slug":"cpp-notes","date":"2019-12-26T23:08:15.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/12/26/cpp-notes/","link":"","permalink":"https://overtalk.site/2019/12/26/cpp-notes/","excerpt":"","text":"cout 输出 uint8_t 整形值在C++中我们一般用std::cout输出到屏幕，但如果直接用cout输出uint8_t类型的无符号整形数的话却不能得到我们想到的整形值，比如下例代码： 1234567#include &lt;iostream&gt;#include &lt;stdint.h&gt;int main()&#123; uint8_t a = 98; std::cout &lt;&lt; a &lt;&lt; std::endl; return 0;&#125; 我们希望输出“98”，但是显示的却是“b”。这是因为uint8_t的定义是unsigned char，而&lt;&lt;操作符有一个重载版本是 ostream&amp; operator&lt;&lt;(ostream&amp;, unsigned char)，它会将unsigned char类型的参数经过ASCII码转换输出对应的字符，上例中字符’b’的ASCII值就是98。 要是想输出整形值而非字符，其实也很简单，在输出的时候将uint8_t转换成unsigned int类型就可以了，可以用下面的输出语句： 1std::cout &lt;&lt; unsigned(a) &lt;&lt; std::endl; 或者12std::cout &lt;&lt; +a &lt;&lt; std::endl;std::cout &lt;&lt; a+0 &lt;&lt; std::endl;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - mutable关键字","slug":"cpp-mutable","date":"2019-12-26T23:08:15.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/12/26/cpp-mutable/","link":"","permalink":"https://overtalk.site/2019/12/26/cpp-mutable/","excerpt":"","text":"C++ 学习笔记 C++ mutable 总的来说 mutable 有两种用法，让我们来看看 用法1 用于修饰 class 的成员变量，使其在const函数中也可以修改12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;string&gt;class Entity&#123;private: std::string name; mutable int count = 0; // 用于记录GetName函数被调用类多少次public: const std::string&amp; GetName() const &#123; count++; // 这个函数为const， 如果 count 不是mutable， 则不可以++ return name; &#125;&#125;;// 程序的主函数int main( )&#123; const Entity e; std::cout &lt;&lt; e.GetName() &lt;&lt; std::endl; std::cin.get(); return 0;&#125; 用法1 配合 lambda 使用 lambda 表达式用于定义并创建匿名的函数对象 这个不怎么用得到123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;string&gt;class Entity&#123;private: std::string name; mutable int count = 0; // 用于记录GetName函数被调用类多少次public: const std::string&amp; GetName() const &#123; count++; // 这个函数为const， 如果 count 不是mutable， 则不可以++ return name; &#125;&#125;;// 程序的主函数int main( )&#123; const Entity e; std::cout &lt;&lt; e.GetName() &lt;&lt; std::endl; int x = 8; auto f = [=]() mutable &#123; x++; std::cout &lt;&lt; \"Hello\" &lt;&lt; std::endl; std::cout &lt;&lt; x &lt;&lt; std::endl; &#125;; f(); // x=8; 上面函数是对x的一个拷贝 std::cin.get(); return 0;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ 中的 static & const关键字","slug":"cpp-const&satic","date":"2019-12-26T00:37:00.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/12/26/cpp-const&satic/","link":"","permalink":"https://overtalk.site/2019/12/26/cpp-const&satic/","excerpt":"","text":"C++ const &amp; static 关键字 const用法1 : 修饰基本数据类型12345678910#include &lt;iostream&gt;#include &lt;string&gt;// 程序的主函数int main( )&#123; const int a = 5; a = 3; // this is a error return 0;&#125; 用法2 : const修饰指针变量*及引用变量&amp;2.1 : 指针*1234const int* a = &amp; [1] //非常量数据的常量指针 指针常量int const *a = &amp; [2] //非常量数据的常量指针 a is a pointer to the constant char variableint* const a = &amp; [3] //常量数据的非常量指针指针常量 常量指针 a is a constant pointer to the (non-constant) char variableconst int* const a = &amp; [4] //常量数据的常量指针 如果const位于星号*的左侧，则const就是用来修饰指针所指向的变量，即指针指向为常量； 如果const位于星号*的右侧，const就是修饰指针本身，即指针本身是常量。 因此，[1]和[2]的情况相同，都是指针所指向的内容为常量，这种情况下不允许对内容进行更改操作，如不能*a = 3 ； [3]为指针本身是常量，而指针所指向的内容不是常量，这种情况下不能对指针本身进行更改操作，如a++是错误的； [4]为指针本身和指向的内容均为常量。 2.2 : 引用&amp;123int const &amp;a=x;const int &amp;a=x;int &amp;const a=x;//这种方式定义是C、C++编译器未定义，虽然不会报错，但是该句效果和int &amp;a一样。 这两种定义方式是等价的，此时的引用a不能被更新。如：a++ 这是错误的。 用法3 : const应用到函数中3.1 : 作为参数的const修饰符 void fun0(const A* a ); void fun1(const A&amp; a) 调用函数的时候，用相应的变量初始化const常量，则在函数体中，按照const所修饰的部分进行常量化，如形参为const A* a， 则不能对传递进来的指针的内容进行改变，保护了原指针所指向的内容；如形参为const A&amp; a，则不能对传递进来的引用对象进行改变，保护了原对象的属性。 [注意]：参数const通常用于参数为指针或引用的情况; 3.2 : 作为函数返回值的const修饰符 const A fun2( ); const A* fun3() 这样声明了返回值后，const按照”修饰原则”进行修饰，起到相应的保护作用。 返回值不可以被修改 3.3 : 配合 class 使用 不能修改所在类的的任何变量 mutable 关键字1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;iostream&gt;class Entity&#123;private: int m_X; int* m_Y; // 加入一个小插曲 int* m_Z, m_M; // 这两个值中，第一个 m_Z 是指针，而第二个是 int 数，需要改成 int* m_Z, *m_M; 这样两个都是指针 mutable int var;public: // 这种 const 用法只可以在 class 的 function 中使用 int GetX() const &#123; m_X = 34; // error， 无法修改其值 var = 1; // mutable 关键字修饰，就可以进行修改 return m_X; &#125; // 返回一个 int 指针，其指向 &amp; 具体数值都不可以改变 // 最后一个 const 表示无法在函数中修改值 const int* const GetY() const &#123; return m_Y; &#125; int* GetZ() &#123; return m_Z; &#125;&#125;;// 此处函数对 e 进行只读操作，传入 const reference， 无需拷贝void Print(const Entity&amp; e)&#123; std::cout &lt;&lt; e.GetX() &lt;&lt; std::endl; std::cout &lt;&lt; *e.GetY() &lt;&lt; std::endl; std::cout &lt;&lt; *e.GetZ() &lt;&lt; std::endl; // error， 因为传入的 e 是 const，因此只只可以调用 GetX,GetY&#125;// 程序的主函数int main( )&#123; Entity e; std::cin.get(); return 0;&#125; 其他用法class 中使用 const 对const成员变量的初始化，不能在变量声明的地方，必须在类的构造函数的初始化列表中完成，即使是在构造函数内部赋值也是不行的。1234567891011class Test&#123;private: const int a; const int b;public: Test(int a) :a(a), b(12) &#123; &#125;&#125; 使用static const123456789101112131415161718192021#include &lt;iostream&gt;class Year&#123;private: int y;public: static int const Inity;public: Year() &#123; y=Inity; &#125;&#125;;int const Year::Inity=1997;//静态变量的赋值方法,注意必须放在类外定义int main()&#123; std::cout &lt;&lt; Year::Inity &lt;&lt; std::endl;//注意调用方式，这里是用类名调用的。&#125; static static 可以修饰 变量 &amp; 函数 static 可以出现在 class内部 &amp; class外部 在 class/struct 内部 static修饰的 类成员(包括变量 &amp; 函数) 属于类，不属于对象 修饰类中成员 - 类的共享数据 static类对象必须要在类外进行初始化123456789101112131415161718192021222324#include &lt;iostream&gt;using namespace std;class Entity&#123;public: static int x; void print() &#123; cout &lt;&lt; x &lt;&lt; endl; &#125;&#125;;int Entity::x; // static类对象的初始化int main()&#123; Entity e1; Entity e2; e1.x=1; e2.x=2; e1.print(); e2.print();&#125; 修饰类中成员函数 由于static修饰的类成员属于类，不属于对象，因此static类成员函数是没有this指针的，this指针是指向本对象的指针。 正因为没有this指针，所以static类成员函数，不能访问非static的类成员，只能访问 static修饰的类成员。 在 class/struct 外部 表示只在当前的编译单元引用 static 出现在 .cpp 文件中 在demo1.cpp中 1static int x = 7; 在demo2.cpp中 123456789#include &lt;iostream&gt;using namespace std;int x;function main()&#123; cout &lt;&lt; x &lt;&lt; endl;&#125; 编译的时候就会报错，因为x只在demo1.cpp中才可以被使用 类似的，function 和 var 有类似的用法，static 的 function 只可以在当前的解释单元被使用 static 出现在 .h 文件中 如果在 头文件 中申明 static变量 那么每一个include的文件都会有一个单独的 static 变量，因为 include 就相当于将这段代码copy进去 局部 static变量 主要关注点变量的生命周期 注意 static 关键字在 function 中的用法 demo1123456function test()&#123; static int x = 0; // 静态局部变量 x++; cout &lt;&lt; x &lt;&lt; endl;&#125; x变量只会创建一次 每次调用test函数，x都会增加，打印的值也会增加 静态局部变量在全局/静态区分配内存空间 静态局部变量在程序执行到该对象的声明处时被首次初始化，之后的函数调用不再进行初始化 静态局部变量一般在声明处初始化，若没有显式初始化，会被OS自动初始化为0 它始终驻留在全局/静态区，直到程序运行结束，但其作用域为局部作用域，也就是不能在函数体外面使用它 Tips 全局数据中的变量 如果没有显示的初始化会自动被程序初始化为0(这个特性非静态全局变量也有),而在函数体内声明的变量如果不显示初始化则会使一个随机值","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"golang build 的一些参数","slug":"go-build","date":"2019-12-25T15:41:58.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/12/25/go-build/","link":"","permalink":"https://overtalk.site/2019/12/25/go-build/","excerpt":"","text":"ldflags -w 为去掉调试信息（无法使用gdb调试） -s 为去掉符号表（暂未清楚具体作用） 1go build -ldflags \"-w -s\" ./hello.go 编译的时候注入版本信息12345678910111213141516171819package mainimport ( \"fmt\" \"os\" \"runtime\")var buildstamp = \"\"var githash = \"\"func main() &#123; args := os.Args if len(args) == 2 &amp;&amp; (args[1] == \"--version\" || args[1] == \"-v\") &#123; fmt.Printf(\"Git Commit Hash: %s\\n\", githash) fmt.Printf(\"UTC Build Time : %s\\n\", buildstamp) return &#125;&#125; 然后编译的时候，通过链接选项 -X 来动态传入版本信息：12flags=\"-X main.buildstamp=`date -u '+%Y-%m-%d_%I:%M:%S%p'` -X main.githash=`git describe --long --dirty --abbrev=14`\"go build -ldflags \"$flags\" -x -o build-version main.go","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"C++ - 字符串","slug":"cpp-string","date":"2019-12-24T22:33:38.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/12/24/cpp-string/","link":"","permalink":"https://overtalk.site/2019/12/24/cpp-string/","excerpt":"","text":"C++ 学习笔记 C++ String char 8 bits string char 的数组 字符串有一个结尾的 char（零值 ） char* name = &quot;qinhan&quot;; 123456789101112131415#include &lt;iostream&gt;// 程序的主函数int main(s)&#123; char* name = \"test\"; char name2[4] = &#123;'t','e','s','t'&#125;; char name3[5] = &#123;'t','e','s','t','\\0'&#125;; std::cout &lt;&lt; name &lt;&lt; std::endl; std::cout &lt;&lt; name2 &lt;&lt; std::endl; std::cout &lt;&lt; name3 &lt;&lt; std::endl; return 0;&#125; 运行结果 string 包 需要 #include &lt;string&gt; 实际上它是一个类，有各种各样的方法12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;string&gt;// 程序的主函数int main( )&#123; std::string name = \"test\"; // name 是一个 const char array std::cout &lt;&lt; name &lt;&lt; std::endl; std::cout &lt;&lt; name.size() &lt;&lt; std::endl; // error, 因为 std::string 是一个 const char array // std::string name1 = \"test\" + \"test\"; std::string name1 = \"test\"; name1 += \"test\"; // string append bool contains = name1.find(\"no\") != std::string::npos; return 0;&#125;// 当string作为 只读参数 的时候，需要以 `const reference` 的形式，否则会进行拷贝// 如果 需要对参数进行修改并且需要影响原值的话，去掉 constvoid PrintStr(const std::string&amp; str)&#123; std::cout &lt;&lt; str &lt;&lt; std::endl;&#125; string literals 存储于只读内存中 12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;string&gt;// 程序的主函数int main( )&#123; using namespace std::string_literals; std::string name0 = \"jack\"s + \"tom\"; // \"jack\"s 经过函数运算返回 std::string, 这儿的 s 是运算符重载 std::wstring name00 = L\"jack\"s + L\"tom\"; std::u32string name000 = U\"jack\"s + U\"tom\"; const char* name = u8\"jack\"; // 1 byte char const wchar_t* name2 = L\"jack\"; // white char, 2 byte char on win, 4 byte on linux const char16_t* name3 = u\"jack\"; // 2 byte char const char32_t* name4 = U\"jack\"; // 4 byte char // 可以换行 const char* name5 = R\"(Line1Line2Line3Line4)\"; std::cin.get(); return 0;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"golang 中 json 解析的一些坑","slug":"go-json","date":"2019-12-19T11:50:45.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/12/19/go-json/","link":"","permalink":"https://overtalk.site/2019/12/19/go-json/","excerpt":"","text":"encoding/json包在开发的过程中，占据着相当重要的角色。然而角色有多重，坑就有多大。下面记录的便是在踩json雷中的辛酸泪(&gt;﹏&lt;) 反序列化时的数值处理及float64精度问题 众所周知（其实是最近才知道），golang原生的encoding/json在反序列化的时候，默认情况下会把所有数值类型转成float64 1234567891011121314151617import ( \"encoding/json\" \"fmt\")func test_std_json()&#123; var m []interface&#123;&#125; if err := json.Unmarshal([]byte(`[100, null, 1.2, \"1234\"]`), &amp;m); err == nil &#123; for _, v := range m &#123; fmt.Printf(\"type: %T, value: %v\\n\",v, v ) &#125; &#125; else &#123; fmt.Println(\"Unmarshal error: \", err) &#125;&#125; 输出 1234type: float64, value: 100type: &lt;nil&gt;, value: &lt;nil&gt;type: float64, value: 1.2type: string, value: 1234 分析 重点在于 json.Unmarshal 这个方法.它的类型转换是这么搞的： To unmarshal JSON into an interface value, Unmarshal stores one of these in the interface value: 123456bool, for JSON booleansfloat64, for JSON numbersstring, for JSON strings[]interface&#123;&#125;, for JSON arraysmap[string]interface&#123;&#125;, for JSON objectsnil for JSON null 以上解释摘自官方文档 一般情况下是不会有什么问题的，但是，如果我们传进去的是一个大整型（超过float64定义的范围），那么就粗大事了。举个栗子： 123456789101112func test_std_json_large()&#123; var m []interface&#123;&#125; if err := json.Unmarshal([]byte(`[100, 1234567890123456789, null, 1.2, \"1234\"]`), &amp;m); err == nil &#123; for _, v := range m &#123; fmt.Printf(\"type: %T, value: %v\\n\",v, v ) &#125; &#125; else &#123; fmt.Println(\"Unmarshal error: \", err) &#125;&#125; 输出 12345type: float64, value: 100type: float64, value: 1.2345678901234568e+18type: &lt;nil&gt;, value: &lt;nil&gt;type: float64, value: 1.2type: string, value: 1234 注意到了吗？上面的数字1234567890123456789是一个在int64范围内，但是在float64之外的数值。 反序列化之后，这个值变成了123456789012345678！！！试想一下，本来你手头有1234567890个亿，经过json.Unmarshal，就只剩123456789个亿了┭┮﹏┭┮ 但是没关系，此事并非不可解。下面我们来看看两种解决方案。 方法一 ：使用标准库的json.Decoder golang的标准json库提供了一种方案：将数值类型直接转成json.Number类型，让用户稍后自己根据需要转成数值。具体的实现是利用json库提供的Decoder：123456789101112func Decoder(jsonStr string) &#123; var result map[string]interface&#123;&#125; decoder := json.NewDecoder(bytes.NewReader([]byte(jsonStr))) //seNumber causes the Decoder to unmarshal a number into an interface&#123;&#125; as a Number instead of as a float64. decoder.UseNumber() decoder.Decode(&amp;result) fmt.Printf(\"反序列化后：\\t%#v\\n\", result) pid := result[\"config\"].(map[string]interface&#123;&#125;)[\"pid\"] fmt.Printf(\"PID类型：\\t%T \\nPID值：\\t%v\\n\", pid, pid) pidValue, _ := pid.(json.Number).Int64() fmt.Printf(\"Int64：%d\", pidValue)&#125; 输出 1234反序列化后： map[string]interface &#123;&#125;&#123;\"userID\":\"1\", \"config\":map[string]interface &#123;&#125;&#123;\"target_type\":\"1\", \"pid\":\"1234567890123456789\"&#125;&#125;PID类型： json.NumberPID值： 1234567890123456789Int64：1234567890123456789 这样，我们的1234567890个亿还是1234567890个亿。可以把json.Number当成字符串，标准库对于这个类型还提供了一些方便的方法来取出数值。 具体可以参考json.Number","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"go 深入剖析slice和array","slug":"go-slice","date":"2019-12-18T14:31:21.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/12/18/go-slice/","link":"","permalink":"https://overtalk.site/2019/12/18/go-slice/","excerpt":"","text":"array 和 slice 看似相似，却有着极大的不同。 slice 是动态数组，是基于 array 实现的 Array array 是存储在一段连续的内存中，每个元素的类型相同，即是每个元素的宽度相同，可以根据元素的宽度计算元素存储的位置。 分配在连续的内存地址上 元素类型一致，元素存储宽度一致 空间大小固定，不能修改 可以通过索引计算出元素对应存储的位置（只需要知道数组内存的起始位置和数据元素宽度即可） 会出现数据溢出的问题（下标越界） Array 不是指针 Go 语言的数组不同于 C 语言或者其他语言的数组，C 语言的数组变量是指向数组第一个元素的指针； 而 Go 语言的数组是一个值，Go 语言中的数组是值类型，一个数组变量就表示着整个数组，意味着 Go 语言的数组在传递的时候，传递的是原数组的拷贝。123456789101112131415func modifyArr(arr1 [4]int) &#123; arr1[0] = 23 fmt.Println(\"in modify arr func, arr = \", arr1) // in modify arr func, arr = [23 2 3 4]&#125;func TestArray(t *testing.T) &#123; arr1 := [4]int&#123;1, 2, 3, 4&#125; fmt.Println(\"before modify, arr = \",arr1) // before modify, arr = [1 2 3 4] modifyArr(arr1) fmt.Println(\"after modify, arr = \",arr1) // after modify, arr = [1 2 3 4]&#125;// 输出结果如下：// before modify, arr = [1 2 3 4]// in modify arr func, arr = [23 2 3 4]// after modify, arr = [1 2 3 4] Array 的构造 在程序中数组的初始化有两种方法 arr := [10]int{} 或 var arr [10]int，但是不能使用 make 来创建，数组这节结束时再探讨一下这个问题。 使用 unsafe来看一下在内存中都是如何存储的吧： 123456789101112131415161718192021package mainimport ( \"fmt\" \"unsafe\")func main() &#123; var arr = [3]int&#123;1, 2, 3&#125; fmt.Println(unsafe.Sizeof(arr)) // 12 size := unsafe.Sizeof(arr[0]) // 获取数组指定索引元素的值 fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;arr[0])) + 1*size))) // 2 // 设置数组指定索引元素的值 *(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;arr[0])) + 1*size)) = 10 fmt.Println(arr[1]) // 10&#125; 这段代码的输出如下： 12312210 首先说 12 是 fmt.Println(unsafe.Sizeof(arr)) 输出的，unsafe.Sizeof 用来计算当前变量的值在内存中的大小，12 这个代表一个 int 有4个字节，3 * 4 就是 12。 这是在32位平台上运行得出的结果， 如果在64位平台上运行数组的大小是 24。从这里可以看出 [3]int 在内存中由3个连续的 int 类型组成，且有 12 个字节那么长，这就说明了数组在内存中没有存储多余的数据，只存储元素本身。 size := unsafe.Sizeof(arr[0]) 用来计算单个元素的宽度，int在32位平台上就是4个字节，uintptr(unsafe.Pointer(&amp;arr[0])) 用来计算数组起始位置的指针，1size 用来获取索引为1的元素相对数组起始位置的偏移，unsafe.Pointer(uintptr(unsafe.Pointer(&amp;arr[0])) + 1*size)) 获取索引为1的元素指针，(*int) 用来转换指针位置的数据类型， 因为 int 是4个字节，所以只会读取4个字节的数据，由元素类型限制数据宽度，来确定元素的结束位置，因此得到的结果是 2。 上一个步骤获取元素的值，其中先获取了元素的指针，赋值的时候只需要对这个指针位置设置值就可以了， (int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;arr[0])) + 1*size)) = 10 就是用来给指定下标元素赋值。 123456789101112package mainimport ( \"fmt\" \"unsafe\")func main() &#123; n:= 10 var arr = [n]int&#123;&#125; fmt.Println(arr)&#125; 如上代码，动态的给数组设定长度，会导致编译错误 non-constant array bound n， 由此推导数组的所有操作都是编译时完成的，会转成对应的指令，通过这个特性知道数组的长度是数组类型不可或缺的一部分，并且必须在编写程序时确定。可以通过 GOOS=linux GOARCH=amd64 go tool compile -S array.go 来获取对应的汇编代码，在 array.go 中做一些数组相关的操作，查看转换对应的指令。 之前的疑问，为什么数组不能用 make 创建？ 上面分析了解到数组操作是在编译时转换成对应指令的，而 make 是在运行时处理（特殊状态下会做编译器优化，make可以被优化，下面 slice 分析时来讲）。 Slice 因为数组是固定长度且是值传递，很不灵活，所以在 Go 程序中很少看到数组的影子。 然而 slice 无处不在，slice 以数组为基础，提供强大的功能和遍历性。 slice 的类型规范是[]T，slice T元素的类型。与数组类型不同，slice 类型没有指定的长度。 slice 本质12345type slice struct &#123; array unsafe.Pointer len int cap int&#125; ** slice 申明的几种方法：** 1234s := []int&#123;1, 2, 3&#125; 简短的赋值语句var s []int var 申明make([]int, 3, 8) 或 make([]int, 3) make 内置方法创建s := ss[:5] 从切片或者数组创建 ** slice 有两个内置函数来获取其属性：** 12len 获取 slice 的长度cap 获取 slice 的容量 slice 的属性，这东西是什么，还需借助 unsafe 来探究一下。 1234567891011121314151617181920package mainimport ( \"fmt\" \"unsafe\")func main() &#123; s := make([]int, 10, 20) s[2] = 100 s[9] = 200 size := unsafe.Sizeof(0) fmt.Printf(\"%x\\n\", *(*uintptr)(unsafe.Pointer(&amp;s))) // c00007ce90，底层存储的数组的地址 fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + size))) // 10 fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + size*2))) // 20 fmt.Println(*(*[20]int)(unsafe.Pointer(*(*uintptr)(unsafe.Pointer(&amp;s))))) // [0 0 100 0 0 0 0 0 0 200 0 0 0 0 0 0 0 0 0 0]&#125; 这段输出除了第一个，剩余三个好像都能看出点什么， 10 不是创建 slice 的长度吗，20 不就是指定的容量吗， 最后这个看起来有点像 slice 里面的数据，但是数量貌似有点多，从第三个元素和第十个元素来看，正好是给 slice 索引 2 和 10 指定的值，但是切片不是长度是 10 个吗，难道这个是容量，容量刚好是 20个。 第二和第三个输出很好弄明白，就是 slice 的长度和容量， 最后一个其实是 slice 引用底层数组的数据，因为创建容量为 20，所以底层数组的长度就是 20，从这里了解到切片是引用底层数组上的一段数据，底层数组的长度就是 slice 的容量，由于数组长度不可变的特性，当 slice 的长度达到容量大小之后就需要考虑扩容，不是说数组长度不能变吗，那 slice 怎么实现扩容呢， 其实就是在内存上分配一个更大的数组，把当前数组上的内容拷贝到新的数组上， slice 来引用新的数组，这样就实现扩容了。 1234567891011121314151617181920212223242526272829303132333435363738package mainimport ( \"fmt\" \"unsafe\")func main() &#123; arr := [10]int&#123;1, 2, 3&#125; arr[7] = 100 arr[9] = 200 fmt.Println(arr) // [1 2 3 0 0 0 0 100 0 200] s1 := arr[:] s2 := arr[2:8] size := unsafe.Sizeof(0) fmt.Println(\"----------s1---------\") fmt.Printf(\"%x\\n\", *(*uintptr)(unsafe.Pointer(&amp;s1))) // c00001c0a0 fmt.Printf(\"%x\\n\", uintptr(unsafe.Pointer(&amp;arr[0]))) // c00001c0a0 fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s1)) + size))) // 10 fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s1)) + size*2))) // 10 fmt.Println(s1) // [1 2 3 0 0 0 0 100 0 200] fmt.Println(*(*[10]int)(unsafe.Pointer(*(*uintptr)(unsafe.Pointer(&amp;s1))))) // [1 2 3 0 0 0 0 100 0 200] fmt.Println(\"----------s2---------\") fmt.Printf(\"%x\\n\", *(*uintptr)(unsafe.Pointer(&amp;s2))) // c00001c0b0 fmt.Printf(\"%x\\n\", uintptr(unsafe.Pointer(&amp;arr[0]))+size*2) // c00001c0b0 fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s2)) + size))) // 6 fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s2)) + size*2))) // 8 fmt.Println(s2) // [3 0 0 0 0 100] fmt.Println(*(*[8]int)(unsafe.Pointer(*(*uintptr)(unsafe.Pointer(&amp;s2))))) // [3 0 0 0 0 100 0 200]&#125; 这段输出看起来有点小复杂，第一行输出就不用说了吧，这个是打印整个数组的数据。先分析一下 s1 变量的下面的输出吧，s1 := arr[:] 引用了整个数组，所以在第5、6行输出都是10，因为数组长度为10，所有 s1 的长度和容量都为10，那第3、4行输出是什么呢，他们怎么都一样呢，之前分析数组的时候 通过 uintptr(unsafe.Pointer(&amp;arr[0])) 来获取数组起始位置的指针的，那么第4行打印的就是数组的指针，这么就了解了第三行输出的是上面了吧，就是数组起始位置的指针，所以 (uintptr)(unsafe.Pointer(&amp;s1)) 获取的就是引用数组的指针，但是这个并不是数组起始位置的指针，而是 slice 引用数组元素的指针，为什么这么说呢？ 接着看 s2 变量下面的输出吧，s2 := arr[2:8] 引用数组第3~8的元素，那么 s2 的长度就是 6。 根据经验可以知道 s2 变量输出下面第3行就是 slice 的长度，但是为啥第4行是 8 呢，slice 应用数组的指定索引起始位置到数组结尾就是 slice 的容量， 所以 所以从第3个位置到末尾，就是8个容量。在看第1行和第2行的输出，之前分析数组的时候通过 uintptr(unsafe.Pointer(&amp;arr[0]))+size2 来获取数组指定索引位置的指针，那么这段第2行就是数组索引为2的元素指针，(*uintptr)(unsafe.Pointer(&amp;s2)) 是获取切片的指针，第1行和第2行输出一致，所以 slice 实际是引用数组元素位置的指针，并不是数组起始位置的指针。 ** 总结：** slice 是的起始位置是引用数组元素位置的指针。 slice 的长度是引用数组元素起始位置到结束位置的长度。 slice 的容量是引用数组元素起始位置到数组末尾的长度。 经过上面一轮分析了解到 slice 有三个属性，引用数组元素位置指针、长度和容量。实际上 slice 的结构像下图一样： slice 增长 slice 是如何增长的，用 unsafe 分析一下看看：1234567891011121314151617181920212223package mainimport ( \"fmt\" \"unsafe\")func main() &#123; s := make([]int, 9, 10) // 引用底层的数组地址 fmt.Printf(\"%x\\n\", *(*uintptr)(unsafe.Pointer(&amp;s))) s = append(s, 1) // 引用底层的数组地址 fmt.Printf(\"%x\\n\", *(*uintptr)(unsafe.Pointer(&amp;s))) s = append(s, 1) // 引用底层的数组地址 fmt.Printf(\"%x\\n\", *(*uintptr)(unsafe.Pointer(&amp;s)))&#125; 以上代码的输出 123456c000082e909 10c000082e9010 10c00009a00011 20 从结果上看前两次地址是一样的，初始化一个长度为9，容量为10的 slice，当第一次 append 的时候容量是足够的，所以底层引用数组地址未发生变化，此时 slice 的长度和容量都为10，之后再次 append 的时候发现底层数组的地址不一样了，因为 slice 的长度超过了容量，但是新的 slice 容量并不是11而是20，这要说 slice 的机制了，因为数组长度不可变，想扩容 slice就必须分配一个更大的数组，并把之前的数据拷贝到新数组，如果一次只增加1个长度，那就会那发生大量的内存分配和数据拷贝，这个成本是很大的，所以 slice 是有一个增长策略的。 ** 总结 ** 当 slice 的长度超过其容量，会分配新的数组，并把旧数组上的值拷贝到新的数组 逐个元素添加到 slice 并操过其容量， 如果 selic 的容量小于1024个元素，那么扩容的时候 slice 的 cap 就翻番，乘以2；一旦元素个数超过1024个元素，增长因子就变成1.25，即每次增加原来容量的四分之一。 批量添加元素，当新的容量高于旧容量的两倍，就会分配比新容量稍大一些，并不会按上面第二条的规则扩容。 当 slice 发生扩容，引用新数组后，slice 操作不会再影响旧的数组，而是新的数组（社区经常讨论的传递 slice 容量超出后，修改数据不会作用到旧的数据上），所以往往设计函数如果会对长度调整都会返回新的 slice，例如 append 方法。 slice 是引用类型？ slice 不发生扩容，所有的修改都会作用在原数组上，那如果把 slice 传递给一个函数或者赋值给另一个变量会发生什么呢，slice 是引用类型，会有新的内存被分配吗。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package mainimport ( \"fmt\" \"strings\" \"unsafe\")func main() &#123; s := make([]int, 10, 20) size := unsafe.Sizeof(0) fmt.Printf(\"%p\\n\", &amp;s) fmt.Printf(\"%x\\n\", *(*uintptr)(unsafe.Pointer(&amp;s))) fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + size))) fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + size*2))) slice(s) s1 := s fmt.Printf(\"%p\\n\", &amp;s1) fmt.Printf(\"%x\\n\", *(*uintptr)(unsafe.Pointer(&amp;s1))) fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s1)) + size))) fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s1)) + size*2))) fmt.Println(strings.Repeat(\"-\", 50)) *(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s1)) + size)) = 20 fmt.Printf(\"%x\\n\", *(*uintptr)(unsafe.Pointer(&amp;s))) fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + size))) fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + size*2))) fmt.Printf(\"%x\\n\", *(*uintptr)(unsafe.Pointer(&amp;s1))) fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s1)) + size))) fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s1)) + size*2))) fmt.Println(s) fmt.Println(s1) fmt.Println(strings.Repeat(\"-\", 50)) s2 := s s2 = append(s2, 1) fmt.Println(len(s), cap(s), s) fmt.Println(len(s1), cap(s1), s1) fmt.Println(len(s2), cap(s2), s2)&#125;func slice(s []int) &#123; size := unsafe.Sizeof(0) fmt.Printf(\"%p\\n\", &amp;s) fmt.Printf(\"%x\\n\", *(*uintptr)(unsafe.Pointer(&amp;s))) fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + size))) fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + size*2)))&#125; 这个例子比较长就不逐一分析了，在这个例子里面调用函数传递 slice 其变量的地址发生了变化， 但是引用数组的地址，slice 的长度和容量都没有变化， 这说明是对 slice 的浅拷贝，拷贝 slice 的三个属性创建一个新的变量，虽然引用底层数组还是一个，但是变量并不是一个。 第二个创建 s1 变量，使用 s 为其赋值，发现 s1 和函数调用一样也是 s 的浅拷贝，之后修改 s1 的长度发现 s1 的长度发生变化，但是 s 的长度保持不变， 这也说明 s1 就是 s 的浅拷贝。 这样设计有什么优势呢，第三步创建 s2 变量， 并且 append 一个元素， 发现 s2 的长度发生变化了， s 并没有，虽然这个数据就在底层数组上，但是用常规的方法 s 是看不到第11个位置上的数据的， s1 因为长度覆盖到第11个元素，所有能够看到这个数据的变化。这里能看到采用浅拷贝的方式可以使得切片的属性各自独立，而不会相互影响，这样可以有一定的隔离性，缺点也很明显，如果两个变量都引用同一个数组，同时 append， 在不发生扩容的情况下，总是最后一个 append 的结果被保留，可能引起一些编程上疑惑。 ** 总结 ** slice 是引用类型，但是和 C 传引用是有区别的， C 里面的传引用是在编译器对原变量数据引用， 并不会发生内存分配，而 Go 里面的引用类型传递和赋值会进行浅拷贝，在32位平台上有12个字节的内存分配， 在64位上有24字节的内存分配。 传引用和引用类型是有区别的， slice 是引用类型。* slice 的三种状态 slice 有三种状态：零切片、空切片、nil切片。 零切片 所有的类型都有零值，如果 slice 所引用数组元素都没有赋值，就是所有元素都是类型零值，那这就是零切片。 1234567891011121314package mainimport \"fmt\"func main() &#123; var s = make([]int, 10) fmt.Println(s) var s1 = make([]*int, 10) fmt.Println(s1) var s2 = make([]string, 10) fmt.Println(s2)&#125; 以上代码输出 123[0 0 0 0 0 0 0 0 0 0][ ][ ] 零切片很好理解，数组元素都为类型零值即为零切片，这种状态下的 slice 和正常的 slice 操作没有任何区别。 空切片 空切片可以理解就是切片的长度为0，就是说 slice 没有元素。 社区大多数解释空切片为引用底层数组为 zerobase 这个特殊的指针。但是从操作上看空切片所有的表现就是切片长度为0，如果容量也为零底层数组就会指向 zerobase ，这样就不会发生内存分配， 如果容量不会零就会指向底层数据，会有内存分配。 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( \"fmt\" \"reflect\" \"strings\" \"unsafe\")func main() &#123; var s []int s1 := make([]int, 0) s2 := make([]int, 0, 0) s3 := make([]int, 0, 100) arr := [10]int&#123;&#125; s4 := arr[:0] fmt.Println(strings.Repeat(\"--s--\", 10)) fmt.Println(*(*reflect.SliceHeader)(unsafe.Pointer(&amp;s))) fmt.Println(s) fmt.Println(s == nil) fmt.Println(strings.Repeat(\"--s1--\", 10)) fmt.Println(*(*reflect.SliceHeader)(unsafe.Pointer(&amp;s1))) fmt.Println(s1) fmt.Println(s1 == nil) fmt.Println(strings.Repeat(\"--s2--\", 10)) fmt.Println(*(*reflect.SliceHeader)(unsafe.Pointer(&amp;s2))) fmt.Println(s2) fmt.Println(s2 == nil) fmt.Println(strings.Repeat(\"--s3--\", 10)) fmt.Println(*(*reflect.SliceHeader)(unsafe.Pointer(&amp;s3))) fmt.Println(s3) fmt.Println(s3 == nil) fmt.Println(strings.Repeat(\"--s4--\", 10)) fmt.Println(*(*reflect.SliceHeader)(unsafe.Pointer(&amp;s4))) fmt.Println(s4) fmt.Println(s4 == nil)&#125; 以上代码输出 123456789101112131415–s—-s—-s—-s—-s—-s—-s—-s—-s—-s–&#123;0 0 0&#125;[]–s1—-s1—-s1—-s1—-s1—-s1—-s1—-s1—-s1—-s1–&#123;18349960 0 0&#125;[]–s2—-s2—-s2—-s2—-s2—-s2—-s2—-s2—-s2—-s2–&#123;18349960 0 0&#125;[]–s3—-s3—-s3—-s3—-s3—-s3—-s3—-s3—-s3—-s3–&#123;824634269696 0 100&#125;[]–s4—-s4—-s4—-s4—-s4—-s4—-s4—-s4—-s4—-s4–&#123;824633835680 0 10&#125;[] 以上示例中除了 s 其它的 slice 都是空切片，打印出来全部都是 []，s 是nil切片下一小节说。要注意 s1 和 s2 的长度和容量都为0，且引用数组指针都是 18349960， 这点太重要了，因为他们都指向 zerobase 这个特殊的指针，是没有内存分配的。 NIL切片 什么是nil切片，这个名字说明nil切片没有引用任何底层数组，底层数组的地址为nil就是nil切片。上一小节中的 s 就是一个nil切片，它的底层数组指针为0，代表是一个 nil 指针。 总结 零切片就是其元素值都是元素类型的零值的切片。 空切片就是数组指针不为nil，且 slice 的长度为0。 nil切片就是引用底层数组指针为 nil 的 slice。 操作上零切片、空切片和正常的切片都没有任何区别，但是nil切片会多两个特性，一个nil切片等于 nil 值，且进行 json 序列化时其值为 null，nil切片还可以通过赋值为 nil 获得。 数组与 slice 大比拼 对数组和 slice 做了性能测试。 对不同容量和数组和切片做性能测试，代码如下，分为：100、1000、10000、100000、1000000、10000000 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123package testimport \"testing\"func BenchmarkSlice100(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; s := make([]int, 100) for i, v := range s &#123; s[i] = 1 + i _ = v &#125; &#125;&#125;func BenchmarkArray100(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; a := [100]int&#123;&#125; for i, v := range a &#123; a[i] = 1 + i _ = v &#125; &#125;&#125;func BenchmarkSlice1000(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; s := make([]int, 1000) for i, v := range s &#123; s[i] = 1 + i _ = v &#125; &#125;&#125;func BenchmarkArray1000(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; a := [1000]int&#123;&#125; for i, v := range a &#123; a[i] = 1 + i _ = v &#125; &#125;&#125;func BenchmarkSlice10000(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; s := make([]int, 10000) for i, v := range s &#123; s[i] = 1 + i _ = v &#125; &#125;&#125;func BenchmarkArray10000(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; a := [10000]int&#123;&#125; for i, v := range a &#123; a[i] = 1 + i _ = v &#125; &#125;&#125;func BenchmarkSlice100000(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; s := make([]int, 100000) for i, v := range s &#123; s[i] = 1 + i _ = v &#125; &#125;&#125;func BenchmarkArray100000(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; a := [100000]int&#123;&#125; for i, v := range a &#123; a[i] = 1 + i _ = v &#125; &#125;&#125;func BenchmarkSlice1000000(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; s := make([]int, 1000000) for i, v := range s &#123; s[i] = 1 + i _ = v &#125; &#125;&#125;func BenchmarkArray1000000(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; a := [1000000]int&#123;&#125; for i, v := range a &#123; a[i] = 1 + i _ = v &#125; &#125;&#125;func BenchmarkSlice10000000(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; s := make([]int, 10000000) for i, v := range s &#123; s[i] = 1 + i _ = v &#125; &#125;&#125;func BenchmarkArray10000000(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; a := [10000000]int&#123;&#125; for i, v := range a &#123; a[i] = 1 + i _ = v &#125; &#125;&#125; 测试结果如下: 1234567891011121314151617goos: darwingoarch: amd64pkg: github.com/thinkeridea/example/array_slice/testBenchmarkSlice100-8 20000000 69.8 ns/op 0 B/op 0 allocs/opBenchmarkArray100-8 20000000 69.0 ns/op 0 B/op 0 allocs/opBenchmarkSlice1000-8 5000000 318 ns/op 0 B/op 0 allocs/opBenchmarkArray1000-8 5000000 316 ns/op 0 B/op 0 allocs/opBenchmarkSlice10000-8 200000 9024 ns/op 81920 B/op 1 allocs/opBenchmarkArray10000-8 500000 3143 ns/op 0 B/op 0 allocs/opBenchmarkSlice100000-8 10000 114398 ns/op 802816 B/op 1 allocs/opBenchmarkArray100000-8 20000 61856 ns/op 0 B/op 0 allocs/opBenchmarkSlice1000000-8 2000 927946 ns/op 8003584 B/op 1 allocs/opBenchmarkArray1000000-8 5000 342442 ns/op 0 B/op 0 allocs/opBenchmarkSlice10000000-8 100 10555770 ns/op 80003072 B/op 1 allocs/opBenchmarkArray10000000-8 50 22918998 ns/op 80003072 B/op 1 allocs/opPASSok github.com/thinkeridea/example/array_slice/test 23.333s 从上面的结果可以发现数组和 slice 在1000以内的容量上时性能机会一致，而且都没有内存分配，这应该是编译器对 slice 的特殊优化。 从10000~1000000容量时数组的效率就比slice好了一倍有余，主要原因是数组在没有内存分配做了编译优化，而 slice 有内存分配。 但是10000000容量往后数组性能大幅度下降，slice 是数组性能的两倍，两个都在运行时做了内存分配，其实这么大的数组还真是不常见，也没有比较做编译器优化了。 slice 与数组的应用场景总结 slice 和数组有些差别，特别是应用层上，特性差别很大，那什么时间使用数组，什么时间使用切片呢。 之前做了性能测试，在1000以内性能几乎一致，只有10000~1000000时才会出现数组性能好于 slice，由于数组在编译时确定长度，也就是再编写程序时必须确认长度，所有往常不会用到更大的数组，大多数都在1000以内的长度。我认为如果在编写程序是就已经确定数据长度，建议用数组，而且竟可能是局部使用的位置建议用数组（避免传递产生值拷贝），比如一天24小时，一小时60分钟，ip是4个 byte这种情况是可以用时数组的。 为什么推荐用数组，只要能在编写程序是确定数据长度我都会用数组，因为其类型会帮助阅读理解程序，dayHour := [24]Data 一眼就知道是按小时切分数据存储的，如要传递数组时可以考虑传递数组的指针，当然会带来一些操作不方便，往常我使用数组都是不需要传递给其它函数的，可能会在 struct 里面保存数组，然后传递 struct 的指针，或者用 unsafe 来反解析数组指针到新的数组，也不会产生数据拷贝，并且只增加一句转换语句。slice 会比数组多存储三个 int 的属性，而且指针引用会增加 GC 扫描的成本，每次传递都会对这三个属性进行拷贝，如果可以也可以考虑传递 slice 的指针，指针只有一个 int 的大小。 ** 对于不确定大小的数据只能用 slice， 否则就要自己做扩容很麻烦， 对于确定大小的集合建议使用数组。**","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"golang 共享内存","slug":"go-shm","date":"2019-12-18T10:56:43.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/12/18/go-shm/","link":"","permalink":"https://overtalk.site/2019/12/18/go-shm/","excerpt":"","text":"golang 中使用共享内存 简介 故事起源于要搭一个高性能的日志中心。当然使用了elk这一套。但是，对于logstash来说，它主要使用的是文件日志的方式了捕捉log。而写文件日志的话会非常慢。对于实时日志要处理滚动的日志更是这样，每次检查是否需要流动日志，然后打开日志，然后写入，然后关闭，当然这中间可以优化。这一切都是那么慢，发起了n个系统调用，硬盘寻道等。这时候想到了用共享内存来通信。 共享内存的基本知识 要使用共享内存要执行以下几步： 1.发起一个系统调用，让系统帮你生产一块内存，或者取得一块已经存在的内存来使用。 2.把内存attach到当前进程，让当前进程可以使用。大家都知道，我们在进程中访问的是虚拟内存地址，系统会把它映射到物理内存中。如果没有这一步，第1步创建的内存就不能在当前进程访问。 3.这时就可以对内存进程读写操作了。 4.进程结束的时候要把上面attach的内存给释放。 系统调用的基础知识 什么是系统调用? 1系统调用（英语：system call），又称为系统呼叫，指运行在使用者空间的程序向操作系统内核请求需要更高权限运行的服务。系统调用提供用户程序与操作系统之间的接口。 以上引自维基百科。 对于每个系统调用，都一个编号。内核收到编号后，就根据编号去找到对应的内核函数函数来执行。然后返回给应用程序。 系统调用是怎么发起的？以下以linux为例。 1.应用程序以系统调用号和对应的参数传给系统调用api 2.系统调用api将系统调用号存到eax中，然后发起0x80的中断号进行中断 3.内核中的中断处理函数根据系统调用号，调用对应的内核函数（系统调用） 4.系统调用完成相应功能，将返回值存入 eax，返回到中断处理函数 5.中断处理函数返回到 API 中 6.API 将 eax 返回给应用程序 7.以上就完成了系统调用。 在golang中使用共享内存 了解了系统调用之后，下面就开始使用了。第一步当然是去找golang有没有直接提供共享内存的api了。几经折腾后，发现它并没有提供直接的api。而其他很多系统调用都提供了直接的api。究其原因，我想应该是因为这句话吧： 1“不要通过共享内存来通信，而应该通过通信来共享内存” golang不提供使用共享内存来通信。所以直接不提供了，折腾死你们，让你们用不了。 于是乎，google一下解决方案，都是通过cgo来调c语言来实现的。stackoverflow的答案也都是这样。 回来再来看一下golang的syscall的文档。它提供了Syscall函数。声明如下： 1func Syscall(trap, a1, a2, a3 uintptr) (r1, r2 uintptr, err Errno) 很显示trap是中断号，a1, a2, a3是系统调用相关的参数。 对于中断号，在文档中可以看到，所有的系统都已经定义了常量了。而我们要用到的系统调用有： SYS_SHMGET: 创建或者取得共享内存。 SYS_SHMAT: 将共享内存attach到当前进程空间。 SYS_SHMDT: 将共享内存从当前进程中deattach。 具体这三个函数的使用，我们可以参考linux的shmget, shmat, shmdt函数。可以看到这三个函数跟上面三个系统调用号的常量名字一样的。 以下是这三个函数的声明： 123int shmget(key_t key, size_t size, int shmflg); void *shmat(int shm_id, const void *shm_addr, int shmflg); int shmdt(const void *shmaddr); 以下简单介绍一下这三个函数，具体可以直接去linux上man对应的文档。 shmget函数 key，这个参数的类型key_y其实只是一个数字类型。这个参数命名了这一块内存。不要提供0值就行了，0值是private的，不能在进程间共享。 size，提供了共享内存的大小。 shmflg，权限标志，它的作用与open函数的mode参数一样。如果需要在内存不存在时创建它，则需要指定IPC_CREAT。 在golang的文档中可以看到，它并没定义IPC_CREATE的值。所以我们只能去找到它的值了。在linux的man文档中，它也没有说明。于是乎，直接把linux的代码clone下来进行了grep(我用ag，速度非常快的文档查找工具)。从结果中找到了IPC_CREATE是一个宏，它的值定义成了00001000。一个8进制的数字。低三位都是0，因为低三位是用来标志权限位的。 下面我们直接来发起这个系统调用看一下效果，把调用c的参数一一对应到a1, a2, a3中： 1shmid, _, err := syscall.Syscall(syscall.SYS_SHMGET, 2, 4, IpcCreate|0600) Syscall函数返回了两个值和一个error字段。而c的shmget只返回了一个int值，因为这个函数把结果错误和结果都通过返回值来承载了，如果是小于0的，则是错误，这时对应到go中应该是err的值，没有错误的时候，我们只需要一个返回值，第二个返回值会一直是0。第一个返回值就是给shmat调用的第一个参数。 shmat函数 shm_id, 这是shmget返回id，以标志了要attach的是这一块内存 shm_addr，这个标志需要把它attach到的内存地址，通常填0，让系统去选择地址来attach shmflg，这个可以值SHM_RDONLY表示只读，其他值为可以读写，我们直接传0就好。 1shmaddr, _, err := syscall.Syscall(syscall.SYS_SHMAT, shmid, 0, 0) c函数返回了进程空间地址，这个调用也是只返回了一个值，所我们只接收第一个值。在c中，如果调用失败，会返回-1。在go中，我们只要直接处理err的值就好了。 shmdt函数 shmaddr, 这个参数表示deattach的地址值，是从shmat中返回的。 我们在go中直接用defer来调用就好了：1defer syscall.Syscall(syscall.SYS_SHMDT, shmaddr, 0, 0) Golang 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394package mainimport ( \"errors\" \"flag\" \"fmt\" \"os\" \"sync\" \"syscall\" \"time\" \"unsafe\")const ( // IpcCreate create if key is nonexistent IpcCreate = 00001000 capacity = 1000000)type SHM struct &#123; mutex sync.Mutex head int count int queue [capacity]int&#125;func (s *SHM) Append(item int) error &#123; s.mutex.Lock() defer s.mutex.Unlock() if s.count &gt;= capacity &#123; return errors.New(\"the capacity is full\") &#125; s.queue[(s.head+s.count)%capacity] = item s.count++ return nil&#125;func (s *SHM) Consume() []int &#123; s.mutex.Lock() defer s.mutex.Unlock() var ret []int for i := 0; i &lt; s.count; i++ &#123; ret = append(ret, s.queue[(s.head+i)%capacity]) &#125; s.count = 0 s.head = 0 return ret&#125;var ( mode = flag.Int(\"mode\", 0, \"0:write 1:read\"))func main() &#123; flag.Parse() shmid, _, err := syscall.Syscall(syscall.SYS_SHMGET, 2, 10000, IpcCreate|0600) if err != 0 &#123; fmt.Printf(\"syscall error, err: %v\\n\", err) os.Exit(-1) &#125; fmt.Printf(\"shmid: %v\\n\", shmid) shmaddr, _, err := syscall.Syscall(syscall.SYS_SHMAT, shmid, 0, 0) if err != 0 &#123; fmt.Printf(\"syscall error, err: %v\\n\", err) os.Exit(-2) &#125; fmt.Printf(\"shmaddr: %v\\n\", shmaddr) defer syscall.Syscall(syscall.SYS_SHMDT, shmaddr, 0, 0) shm := (*SHM)(unsafe.Pointer(uintptr(shmaddr))) if *mode == 0 &#123; fmt.Println(\"write mode\") i := 0 for &#123; fmt.Println(\"增加数据：\", i) shm.Append(i) i++ time.Sleep(1 * time.Second) &#125; &#125; else &#123; fmt.Println(\"read mode\") for &#123; fmt.Println(\"消费数据：\", shm.Consume()) time.Sleep(2 * time.Second) &#125; &#125;&#125; 需要注意的一点就是：自定义类型的数据中不可以使用 slice，因为slice进行数据append的时候会涉及到扩容，会出现一些问题，后续有待调研 mac 上的查看共享内存1234# 查看 shmipcs -m# 删除 shmipcrm -m pid","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"Golang 字符串拼接效率","slug":"go-string","date":"2019-12-16T11:57:01.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/12/16/go-string/","link":"","permalink":"https://overtalk.site/2019/12/16/go-string/","excerpt":"","text":"字符串拼接效率对比 下面代码，分别比较了 fmt.Sprintf，string +，strings.Join，bytes.Buffer，方法是循环若干次比较总时间。 性能由高到低依次是(bytes.Buffer) &gt; (string +) &gt; (fmt.Sprintf) &gt; strings.Join 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package mainimport ( \"bytes\" \"fmt\" \"strings\" \"time\")func benchmarkStringFunction(n int, index int) (d time.Duration) &#123; v := \"abcd efg hijk lmn\" var s string var buf bytes.Buffer t0 := time.Now() for i := 0; i &lt; n; i++ &#123; switch index &#123; case 0: // fmt.Sprintf s = fmt.Sprintf(\"%s[%s]\", s, v) case 1: // string + s = s + \"[\" + v + \"]\" case 2: // strings.Join s = strings.Join([]string&#123;s, \"[\", v, \"]\"&#125;, \"\") case 3: // temporary bytes.Buffer b := bytes.Buffer&#123;&#125; b.WriteString(\"[\") b.WriteString(v) b.WriteString(\"]\") s = b.String() case 4: // stable bytes.Buffer buf.WriteString(\"[\") buf.WriteString(v) buf.WriteString(\"]\") &#125; if i == n-1 &#123; if index == 4 &#123; // for stable bytes.Buffer s = buf.String() &#125; fmt.Println(len(s)) // consume s to avoid compiler optimization &#125; &#125; t1 := time.Now() d = t1.Sub(t0) fmt.Printf(\"time of way(%d)=%v\\n\", index, d) return d&#125;func main() &#123; k := 5 d := [5]time.Duration&#123;&#125; for i := 0; i &lt; k; i++ &#123; d[i] = benchmarkStringFunction(10000, i) &#125; for i := 0; i &lt; k-1; i++ &#123; fmt.Printf(\"way %d is %6.1f times of way %d\\n\", i, float32(d[i])/float32(d[k-1]), k-1) &#125;&#125; 运行结果1234567891011121314190000time of way(0)=159.079378ms190000time of way(1)=59.071507ms190000time of way(2)=77.812168ms19time of way(3)=576.325µs190000time of way(4)=263.649µsway 0 is 603.4 times of way 4way 1 is 224.1 times of way 4way 2 is 295.1 times of way 4way 3 is 2.2 times of way 4","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"C++ - 可见性","slug":"cpp-visibility","date":"2019-12-13T22:49:24.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/12/13/cpp-visibility/","link":"","permalink":"https://overtalk.site/2019/12/13/cpp-visibility/","excerpt":"","text":"C++ 学习笔记 C++ 类中成员/方法的可见性 关键字 三种可见性 public private protected 注意： class 的默认可见性为 private，struct 的默认可见性public 详解 关键字 备注 private 当前类的函数中可以访问，类实例/子类都不可以访问，friend也可以 protected 当前类/子类 中可以访问，但是类实例是不可以访问的 public 大家都可以访问","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"go 日志库使用","slug":"go-zap","date":"2019-12-13T10:15:13.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/12/13/go-zap/","link":"","permalink":"https://overtalk.site/2019/12/13/go-zap/","excerpt":"","text":"zap logrus","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"golang 中的插件使用","slug":"go-plugin","date":"2019-12-11T15:43:16.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/12/11/go-plugin/","link":"","permalink":"https://overtalk.site/2019/12/11/go-plugin/","excerpt":"","text":"golang 中 plugin 的使用 简介 golang 是一门静态编译的语言，想要实现动态热更新是相对比较困难的 从 go 1.8 版本之后，官方提供了 plugin 包来进行动态加载 他可以动态的加载so和执行导出的方法，并且仅仅提供了两个方法：打开模块和提取符号，甚至连关闭都没有(-_-)。 使用场景 可插拔：有了Plugin，我的程序可以根据需要随时替换其中某些部件而不用修改我的程序； 动态加载的需要：有些模块只有在运行时才能确定，需要动态加载外部的功能模块； 独立开发：Plugin 可以和主程序独立建设，主程序只需要制定好框架，实现默认（模版）功能。Plugin 可根据用户需求随时自行扩展开发，运行时随意替换，提高了程序的可定制性； 使用注意事项 Plguin 需要有自己的 main package 编译的时候，使用 go build -buildmode=plugin file.go 来编译 使用 plugin.Open(path string) 来打开.so文件，同一插件只能打开一次，重复打开会报错 使用 plugin.LookUp(name string) 来获取插件中对外暴露的方法或者类型 使用类型断言，断言后执行相应的方法 简单例子插件 plugin.go 123456789package mainimport \"fmt\"func main() &#123;&#125;func GetProductBasePrice(basePrice int) int &#123; return basePrice + 200&#125; go build -buildmode=plugin plugin.go 命令编译出 plugin.so 插件 调用 main.go1234567891011121314151617181920package mainimport ( \"fmt\" \"plugin\")func main() &#123; p, err := plugin.Open(\"plugin.so\") if err != nil &#123; panic(err) &#125; m, err := p.Lookup(\"GetProductBasePrice\") if err != nil &#123; panic(err) &#125; res := m.(func(int) int)(30) fmt.Println(res)&#125; 注意几点问题： 插件中定义的 struct 无法暴露出来，可以让主程序和插件程序import公共的 package 来解决 私有方法、变量不会被暴露出来","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"golang 测试中的 读/写 文件操作","slug":"go-test","date":"2019-12-11T12:17:18.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/12/11/go-test/","link":"","permalink":"https://overtalk.site/2019/12/11/go-test/","excerpt":"","text":"golang 测试中的一些文件操作 简介 在编写 golang 测试的时候，有时候会涉及到一些文件/文件夹的操作 有什么方法可以不产生多余的文件呢？ 临时文件/文件夹临时文件1234567891011func TestTempFile(t *testing.T) &#123; // gen temp file tmpFile, err := ioutil.TempFile(\"\", \"temp_file\") if err != nil &#123; t.Fatal(err) &#125; defer os.Remove(tmpFile.Name()) // clean up // TODO: your test code &#125; 临时文件夹1234567891011func TestTempDir(t *testing.T) &#123; tempDir, err := ioutil.TempDir(os.TempDir(), \"temp_dir\") if err != nil &#123; t.Error(err) return &#125; defer os.RemoveAll(tempDir) // TODO: your test code &#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"golang 二进制协议处理的一种方式","slug":"go-bin-msg","date":"2019-12-11T09:51:39.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/12/11/go-bin-msg/","link":"","permalink":"https://overtalk.site/2019/12/11/go-bin-msg/","excerpt":"","text":"一种golang二进制协议处理接口映射方式 简介 在写服务器程序时，特别是业务向的服务（比如游戏服务器），经常会遇到处理许多客户端协议的情况，如果是http服务，那么定义好处理接口，剩下的交给web服务器就可以了。但是二进制协议就没有这么方便了。 通常的自定义二进制协议规则都是固定长度消息头+变长消息体构成，在消息头中会有消息长度，消息id等字段。（基于TCP流式协议），服务器接收到客户端消息后，首先读取消息头，解析得到消息长度，再按照指定长度获取到完整的消息体的二进制数据。 在写具体业务逻辑时，需要面临从网络层获取到的原始数据，怎么映射到内存数据结构并调用相应处理接口的问题。前面所说的二进制消息体的格式多种多样，大家都有自己的做法，这里以protobuf为例，构建服务器端接收到原始数据后，通过消息id映射生成对应的protobuf结构体，并调用处理接口。 golang种有一个reflect包，可以对类型进行反射，动态生成相应结构体，具体做法就是，将protobuf消息结构通过interface类型和消息id注册到一个自定义map中，在map中保存结构体的类型。 具体实现网关层 主要负责接受网络数据，然后将数据进行解析，分发到各个业务处理模块123456789101112131415161718192021222324252627282930313233343536373839404142434445package gateimport ( \"errors\" \"reflect\" \"github.com/golang/protobuf/proto\")type MessageHandler func(msgID uint16, msg interface&#123;&#125;)type MessageInfo struct &#123; msgType reflect.Type msgHandler MessageHandler&#125;type Gate struct &#123; msgHandlerMap map[uint16]MessageInfo&#125;func NewGate() *Gate &#123; return &amp;Gate&#123; msgHandlerMap: make(map[uint16]MessageInfo), &#125;&#125;func (g *Gate) RegisterMessage(msgID uint16, msg interface&#123;&#125;, handler MessageHandler) &#123; var info MessageInfo info.msgType = reflect.TypeOf(msg.(proto.Message)) info.msgHandler = handler g.msgHandlerMap[msgID] = info&#125;func (g *Gate) HandleRawData(msgID uint16, data []byte) error &#123; if info, ok := g.msgHandlerMap[msgID]; ok &#123; msg := reflect.New(info.msgType.Elem()).Interface() err := proto.Unmarshal(data, msg.(proto.Message)) if err != nil &#123; return err &#125; info.msgHandler(msgID, msg) return err &#125; return errors.New(\"not found msgID\")&#125; 模块A 业务逻辑模块需要向网关注册各个协议 Register 方法向网关注册协议 导入的 &quot;test/protocol&quot; 为 proto 编译之后的 go 文件12345678910111213141516package module1import ( \"fmt\" \"test/gate\" pb \"test/protocol\")func Register(g *gate.Gate) &#123; g.RegisterMessage(1, &amp;pb.Player&#123;&#125;, PlayerHandler)&#125;func PlayerHandler(msgID uint16, msg interface&#123;&#125;) &#123; p := msg.(*pb.Player) fmt.Println(\"player handler msgid:\", msgID, \" body:\", p)&#125; 主函数 主函数工作流程为 初始化网关 各个模块向网关注册服务 启动服务 本例只是一个测试，因此我给网关 gate 增加了一个 HandleRawData 的方法，模拟接受到网络数据之后的流程 1234567891011121314151617181920212223242526272829303132package mainimport ( \"github.com/golang/protobuf/proto\" \"test/gate\" \"test/module1\" \"test/module2\" pb \"test/protocol\")func main() &#123; g := gate.NewGate() module1.Register(g) module2.Register(g) // test data 1 player := &amp;pb.Player&#123; OpenId: \"openid\", Nickname: \"nickname\", Sex: 1, &#125; data, _ := proto.Marshal(player) g.HandleRawData(1, data) // test data 2 time := &amp;pb.Time&#123; EventTime: \"xxxxxx\", &#125; data, _ = proto.Marshal(time) g.HandleRawData(2, data)&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"golang 编译静态库","slug":"go-staticlib","date":"2019-12-04T14:32:04.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/12/04/go-staticlib/","link":"","permalink":"https://overtalk.site/2019/12/04/go-staticlib/","excerpt":"","text":"Golang 静态库的编译 &amp; 使用 使用场景 我开发第一个库，给第三方使用，但是不想直接提供源代码给他们，就可以直接编译一个静态文件给他们使用 Demo环境介绍 系统为 mac os x $GOPATH 为 /Users/qinhan/go 准备工作 首先我在 $GOPATH/src 下建立一个名为 test 的目录 该目录下只有一个名为 test.go 的文件，只有一个名为 Show 的函数 1234567891011121314151617➜ test echo $GOPATH/Users/qinhan/go➜ test pwd/Users/qinhan/go/src/test➜ test lstest.go➜ test cat test.gopackage testimport \"fmt\"func Show() &#123; fmt.Println(\"hello!\")&#125; 然后我在 $GOPATH 下有一个 main.go 主函数调用了 $GOPATH/src/test/test.go 中的 Show 函数 1234567891011121314➜ src echo $GOPATH/Users/qinhan/go➜ src pwd/Users/qinhan/go/src➜ src cat main.gopackage mainimport \"test\"func main() &#123; test.Show()&#125; 运行12➜ src go run ./main.gohello! 编译静态库test.a 接下来我们进入 $GOPATH/src 目录下 将 test 库编译成静态库 1go install test 这样会在 $GOPATH/pkg 的相应目录下生成静态库 因为我的平台为 mac, 因此路径为 $GOPATH/pkg/darwin_amd64/test.a win 平台路径一般为 $GOPATH\\pkg\\windows_amd64\\test.a 编译main.go 进入main.go所在目录，编译main.go： 1234567891011➜ src pwd/Users/qinhan/go/src➜ src ls | grep mainmain.go➜ src go tool compile -I $GOPATH/pkg/darwin_amd64 main.go➜ src ls | grep mainmain.gomain.o 可以看到生成了名字 main.o 的目标文件 链接main.o -L 选项指定了静态库 test.a 的路径，即 $GOPATH/pkg/darwin_amd64 目录，链接成功后会生成相应的可执行文件 main 12345678910111213➜ src pwd/Users/qinhan/go/src➜ src ls | grep mainmain.gomain.o➜ src go tool link -o main -L $GOPATH/pkg/darwin_amd64 main.o➜ src ls | grep mainmainmain.gomain.o 运行main12345678910➜ src pwd/Users/qinhan/go/src➜ src ls | grep mainmainmain.gomain.o➜ src ./mainhello! 现在，就算把 $GOPATH/src/test 目录删除，再次编译链接 main.go，也能正确生成 main 但是，如果删除了静态库 test.a, 就不能编译 main.go","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"Go - 内存对齐","slug":"go-memory-alignment","date":"2019-11-27T14:28:46.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/11/27/go-memory-alignment/","link":"","permalink":"https://overtalk.site/2019/11/27/go-memory-alignment/","excerpt":"","text":"原文地址 问题1234567type Part1 struct &#123; a bool b int32 c int8 d int64 e byte&#125; 在开始之前，希望你计算一下 Part1 共占用的大小是多少呢？ 12345678func main() &#123; fmt.Printf(\"bool size: %d\\n\", unsafe.Sizeof(bool(true))) fmt.Printf(\"int32 size: %d\\n\", unsafe.Sizeof(int32(0))) fmt.Printf(\"int8 size: %d\\n\", unsafe.Sizeof(int8(0))) fmt.Printf(\"int64 size: %d\\n\", unsafe.Sizeof(int64(0))) fmt.Printf(\"byte size: %d\\n\", unsafe.Sizeof(byte(0))) fmt.Printf(\"string size: %d\\n\", unsafe.Sizeof(\"EDDYCJY\"))&#125; 输出结果： 123456bool size: 1int32 size: 4int8 size: 1int64 size: 8byte size: 1string size: 16 这么一算，Part1 这一个结构体的占用内存大小为 1+4+1+8+1 = 15 个字节。相信有的小伙伴是这么算的，看上去也没什么毛病 真实情况是怎么样的呢？我们实际调用看看，如下： 12345678910111213type Part1 struct &#123; a bool b int32 c int8 d int64 e byte&#125;func main() &#123; part1 := Part1&#123;&#125; fmt.Printf(\"part1 size: %d, align: %d\\n\", unsafe.Sizeof(part1), unsafe.Alignof(part1))&#125; 输出结果： 1part1 size: 32, align: 8 最终输出为占用 32 个字节。这与前面所预期的结果完全不一样。这充分地说明了先前的计算方式是错误的。为什么呢？ 在这里要提到 “内存对齐” 这一概念，才能够用正确的姿势去计算，接下来我们详细的讲讲它是什么 内存对齐 有的小伙伴可能会认为内存读取，就是一个简单的字节数组摆放 上图表示一个坑一个萝卜的内存读取方式。但实际上 CPU 并不会以一个一个字节去读取和写入内存。相反 CPU 读取内存是一块一块读取的，块的大小可以为 2、4、6、8、16 字节等大小。块大小我们称其为内存访问粒度。如下图： 在样例中，假设访问粒度为 4。 CPU 是以每 4 个字节大小的访问粒度去读取和写入内存的。这才是正确的姿势 为什么要关心对齐 你正在编写的代码在性能（CPU、Memory）方面有一定的要求 你正在处理向量方面的指令 某些硬件平台（ARM）体系不支持未对齐的内存访问 另外作为一个工程师，你也很有必要学习这块知识点哦 :) 为什么要做对齐 平台（移植性）原因：不是所有的硬件平台都能够访问任意地址上的任意数据。例如：特定的硬件平台只允许在特定地址获取特定类型的数据，否则会导致异常情况 性能原因：若访问未对齐的内存，将会导致 CPU 进行两次内存访问，并且要花费额外的时钟周期来处理对齐及运算。而本身就对齐的内存仅需要一次访问就可以完成读取动作 在上图中，假设从 Index 1 开始读取，将会出现很崩溃的问题。因为它的内存访问边界是不对齐的。因此 CPU 会做一些额外的处理工作。如下： CPU 首次读取未对齐地址的第一个内存块，读取 0-3 字节。并移除不需要的字节 0 CPU 再次读取未对齐地址的第二个内存块，读取 4-7 字节。并移除不需要的字节 5、6、7 字节 合并 1-4 字节的数据 合并后放入寄存器 从上述流程可得出，不做 “内存对齐” 是一件有点 “麻烦” 的事。因为它会增加许多耗费时间的动作 而假设做了内存对齐，从 Index 0 开始读取 4 个字节，只需要读取一次，也不需要额外的运算。这显然高效很多，是标准的空间换时间做法 默认系数 在不同平台上的编译器都有自己默认的 “对齐系数”，可通过预编译命令 #pragma pack(n) 进行变更，n 就是代指 “对齐系数”。一般来讲，我们常用的平台的系数如下： 32 位：4 64 位：8 另外要注意，不同硬件平台占用的大小和对齐值都可能是不一样的。因此本文的值不是唯一的，调试的时候需按本机的实际情况考虑 成员对齐123456789func main() &#123; fmt.Printf(\"bool align: %d\\n\", unsafe.Alignof(bool(true))) fmt.Printf(\"int32 align: %d\\n\", unsafe.Alignof(int32(0))) fmt.Printf(\"int8 align: %d\\n\", unsafe.Alignof(int8(0))) fmt.Printf(\"int64 align: %d\\n\", unsafe.Alignof(int64(0))) fmt.Printf(\"byte align: %d\\n\", unsafe.Alignof(byte(0))) fmt.Printf(\"string align: %d\\n\", unsafe.Alignof(\"EDDYCJY\")) fmt.Printf(\"map align: %d\\n\", unsafe.Alignof(map[string]string&#123;&#125;))&#125; 输出结果: 1234567bool align: 1int32 align: 4int8 align: 1int64 align: 8byte align: 1string align: 8map align: 8 在 Go 中可以调用 unsafe.Alignof 来返回相应类型的对齐系数。通过观察输出结果，可得知基本都是 2^n，最大也不会超过 8。这是因为我手提（64 位）编译器默认对齐系数是 8，因此最大值不会超过这个数 整体对齐 在上小节中，提到了结构体中的成员变量要做字节对齐。那么想当然身为最终结果的结构体，也是需要做字节对齐的 对齐规则 结构体的成员变量，第一个成员变量的偏移量为 0。往后的每个成员变量的对齐值必须为编译器默认对齐长度（#pragma pack(n)）或当前成员变量类型的长度（unsafe.Sizeof），取最小值作为当前类型的对齐值。其偏移量必须为对齐值的整数倍 结构体本身，对齐值必须为编译器默认对齐长度（#pragma pack(n)）或结构体的所有成员变量类型中的最大长度，取最大数的最小整数倍作为对齐值 结合以上两点，可得知若编译器默认对齐长度（#pragma pack(n)）超过结构体内成员变量的类型最大长度时，默认对齐长度是没有任何意义的 分析流程 接下来我们一起分析一下，“它” 到底经历了些什么，影响了 “预期” 结果 成员变量 类型 偏移量 自身占用 a bool 0 1 字节对齐 无 1 3 b int32 4 4 c int8 8 1 字节对齐 无 9 7 d int64 16 8 e byte 24 1 字节对齐 无 25 7 总占用大小 - - 32 成员对齐 第一个成员 a 类型为 bool 大小/对齐值为 1 字节 初始地址，偏移量为 0。占用了第 1 位 第二个成员 b 类型为 int32 大小/对齐值为 4 字节 根据规则 1，其偏移量必须为 4 的整数倍。确定偏移量为 4，因此 2-4 位为 Padding。而当前数值从第 5 位开始填充，到第 8 位。如下：axxx|bbbb 第三个成员 c 类型为 int8 大小/对齐值为 1 字节 根据规则 1，其偏移量必须为 1 的整数倍。当前偏移量为 8。不需要额外对齐，填充 1 个字节到第 9 位。如下：axxx|bbbb|c… 第四个成员 d 类型为 int64 大小/对齐值为 8 字节 根据规则 1，其偏移量必须为 8 的整数倍。确定偏移量为 16，因此 9-16 位为 Padding。而当前数值从第 17 位开始写入，到第 24 位。如下：axxx|bbbb|cxxx|xxxx|dddd|dddd 第五个成员 e 类型为 byte 大小/对齐值为 1 字节 根据规则 1，其偏移量必须为 1 的整数倍。当前偏移量为 24。不需要额外对齐，填充 1 个字节到第 25 位。如下：axxx|bbbb|cxxx|xxxx|dddd|dddd|e… 整体对齐 在每个成员变量进行对齐后，根据规则 2，整个结构体本身也要进行字节对齐，因为可发现它可能并不是 2^n，不是偶数倍。显然不符合对齐的规则 根据规则 2，可得出对齐值为 8。现在的偏移量为 25，不是 8 的整倍数。因此确定偏移量为 32。对结构体进行对齐 结果 Part1 内存布局：axxx|bbbb|cxxx|xxxx|dddd|dddd|exxx|xxxx 小结 通过本节的分析，可得知先前的 “推算” 为什么错误？ 是因为实际内存管理并非 “一个萝卜一个坑” 的思想。而是一块一块。通过空间换时间（效率）的思想来完成这块读取、写入。另外也需要兼顾不同平台的内存操作情况 巧妙的结构体 在上一小节，可得知根据成员变量的类型不同，其结构体的内存会产生对齐等动作。那假设字段顺序不同，会不会有什么变化呢？我们一起来试试吧 :-) 1234567891011121314151617181920212223type Part1 struct &#123; a bool b int32 c int8 d int64 e byte&#125;type Part2 struct &#123; e byte c int8 a bool b int32 d int64&#125;func main() &#123; part1 := Part1&#123;&#125; part2 := Part2&#123;&#125; fmt.Printf(\"part1 size: %d, align: %d\\n\", unsafe.Sizeof(part1), unsafe.Alignof(part1)) fmt.Printf(\"part2 size: %d, align: %d\\n\", unsafe.Sizeof(part2), unsafe.Alignof(part2))&#125; 输出结果： 12part1 size: 32, align: 8part2 size: 16, align: 8 通过结果可以惊喜的发现，只是 “简单” 对成员变量的字段顺序进行改变，就改变了结构体占用大小 接下来我们一起剖析一下 Part2，看看它的内部到底和上一位之间有什么区别，才导致了这样的结果？ 分析流程 成员变量 类型 偏移量 自身占用 e byte 0 1 c int8 1 1 a bool 2 1 字节对齐 无 3 1 b int32 4 4 d int64 8 8 总占用大小 - - 16 成员对齐 第一个成员 e 类型为 byte 大小/对齐值为 1 字节 初始地址，偏移量为 0。占用了第 1 位 第二个成员 c 类型为 int8 大小/对齐值为 1 字节 根据规则 1，其偏移量必须为 1 的整数倍。当前偏移量为 2。不需要额外对齐 第三个成员 a 类型为 bool 大小/对齐值为 1 字节 根据规则 1，其偏移量必须为 1 的整数倍。当前偏移量为 3。不需要额外对齐 第四个成员 b 类型为 int32 大小/对齐值为 4 字节 根据规则 1，其偏移量必须为 4 的整数倍。确定偏移量为 4，因此第 3 位为 Padding。而当前数值从第 4 位开始填充，到第 8 位。如下：ecax|bbbb 第五个成员 d 类型为 int64 大小/对齐值为 8 字节 根据规则 1，其偏移量必须为 8 的整数倍。当前偏移量为 8。不需要额外对齐，从 9-16 位填充 8 个字节。如下：ecax|bbbb|dddd|dddd 整体对齐 符合规则 2，不需要额外对齐 结果 Part2 内存布局：ecax|bbbb|dddd|dddd 总结 通过对比 Part1 和 Part2 的内存布局，你会发现两者有很大的不同。如下： Part1：axxx|bbbb|cxxx|xxxx|dddd|dddd|exxx|xxxx Part2：ecax|bbbb|dddd|dddd 仔细一看，Part1 存在许多 Padding。显然它占据了不少空间，那么 Padding 是怎么出现的呢？ 通过本文的介绍，可得知是由于不同类型导致需要进行字节对齐，以此保证内存的访问边界 那么也不难理解，为什么调整结构体内成员变量的字段顺序就能达到缩小结构体占用大小的疑问了，是因为巧妙地减少了 Padding 的存在。让它们更 “紧凑” 了。这一点对于加深 Go 的内存布局印象和大对象的优化非常有帮 当然了，没什么特殊问题，你可以不关注这一块。但你要知道这块知识点 😄","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"数据仓库是什么","slug":"dw","date":"2019-11-26T17:49:33.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/11/26/dw/","link":"","permalink":"https://overtalk.site/2019/11/26/dw/","excerpt":"","text":"数据库 与 数据仓库的区别是什么？数据库- 传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。数据仓库- 数据仓库系统的主要应用主要是OLAP（On-Line Analytical Processing），支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。具体的事例 拿电商行业来说好了。基本每家电商公司都会经历，从只需要业务数据库到要数据仓库的阶段。 电商早期启动非常容易，入行门槛低。找个外包团队，做了一个可以下单的网页前端 + 几台服务器 + 一个MySQL，就能开门迎客了。这好比手工作坊时期。 第二阶段，流量来了，客户和订单都多起来了，普通查询已经有压力了，这个时候就需要升级架构变成多台服务器和多个业务数据库（量大+分库分表），这个阶段的业务数字和指标还可以勉强从业务数据库里查询。初步进入工业化。 第三个阶段，一般需要 3-5 年左右的时间，随着业务指数级的增长，数据量的会陡增，公司角色也开始多了起来，开始有了 CEO、CMO、CIO，大家需要面临的问题越来越复杂，越来越深入。高管们关心的问题，从最初非常粗放的：“昨天的收入是多少”、“上个月的 PV、UV 是多少”，逐渐演化到非常精细化和具体的用户的集群分析，特定用户在某种使用场景中，例如“20~30岁女性用户在过去五年的第一季度化妆品类商品的购买行为与公司进行的促销活动方案之间的关系”。 这类非常具体，且能够对公司决策起到关键性作用的问题，基本很难从业务数据库从调取出来。原因在于：业务数据库中的数据结构是为了完成交易而设计的，不是为了而查询和分析的便利设计的。业务数据库大多是读写优化的，即又要读（查看商品信息），也要写（产生订单，完成支付）。因此对于大量数据的读（查询指标，一般是复杂的只读类型查询）是支持不足的。 而怎么解决这个问题，此时我们就需要建立一个数据仓库了，公司也算开始进入信息化阶段了。数据仓库的作用在于：数据结构为了分析和查询的便利；只读优化的数据库，即不需要它写入速度多么快，只要做大量数据的复杂查询的速度足够快就行了。那么在这里前一种业务数据库（读写都优化）的是业务性数据库，后一种是分析性数据库，即数据仓库。 总结 数据库 比较流行的有：MySQL, Oracle, SqlServer等 数据仓库 比较流行的有：AWS Redshift, Greenplum, Hive等 这样把数据从业务性的数据库中提取、加工、导入分析性的数据库就是传统的 ETL 工作。现在也有一些新的方法，这展开说又是另一件事情了，有机会再详细说说。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"dw","slug":"dw","permalink":"https://overtalk.site/tags/dw/"}]},{"title":"golang 调用shell 脚本","slug":"go-shell","date":"2019-11-15T22:58:33.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/11/15/go-shell/","link":"","permalink":"https://overtalk.site/2019/11/15/go-shell/","excerpt":"","text":"通过golang执行shell脚本 简介 记 golang 的一个扩展用法 main.go 1234567891011121314151617181920package mainimport ( \"bytes\" \"fmt\" \"log\" \"os/exec\")func main() &#123; cmd := exec.Command(\"/bin/bash\", \"-c\", \"./test.sh\") var out bytes.Buffer cmd.Stdout = &amp;out err := cmd.Run() if err != nil &#123; log.Fatal(err) &#125; fmt.Printf(\"%s\", out.String())&#125; test.sh 123#! /bin/bashecho '通过golang来执行shell脚本' 执行结果 记得将脚本权限设置可执行12345678~ ls -ltotal 4568-rwxr-xr-x 1 qinhan staff 2327696 Nov 15 22:54 main-rw-r--r-- 1 qinhan staff 258 Nov 15 22:54 main.go-rwxr-xr-x 1 qinhan staff 53 Nov 15 22:57 test.sh~ ./main 通过golang来执行shell脚本","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"shell","slug":"shell","permalink":"https://overtalk.site/tags/shell/"},{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"vmware-fusion","slug":"vmware-fusion","date":"2019-11-07T19:18:46.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/11/07/vmware-fusion/","link":"","permalink":"https://overtalk.site/2019/11/07/vmware-fusion/","excerpt":"","text":"给mac上的虚拟机固定 ip 原文","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"mac","slug":"mac","permalink":"https://overtalk.site/tags/mac/"}]},{"title":"golang 中有关reflect的一些使用总结","slug":"go-reflect","date":"2019-11-04T17:06:04.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/11/04/go-reflect/","link":"","permalink":"https://overtalk.site/2019/11/04/go-reflect/","excerpt":"","text":"go 中 reflect 基本介绍 &amp; 一些使用技巧 反射中几个注意事项 反射包中主要的三个类型：Type（类型），Value，Kind（类别） Type &amp; Kind 的区别主要是：1234567891011121314type Foo struct &#123; A int B string&#125;func main() &#123; test := Foo&#123;&#125; fmt.Println(reflect.TypeOf(test)) fmt.Println(reflect.TypeOf(test).Kind())&#125;// 输出结果为// Type : main.Foo// Kind : struct reflect 中的 Type Type 的本质就是一个 interface1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071type Type interface &#123; // Kind返回该接口的具体分类 Kind() Kind // Name返回该类型在自身包内的类型名，如果是未命名类型会返回\"\" Name() string // PkgPath返回类型的包路径，即明确指定包的import路径，如\"encoding/base64\" // 如果类型为内建类型(string, error)或未命名类型(*T, struct&#123;&#125;, []int)，会返回\"\" PkgPath() string // 返回类型的字符串表示。该字符串可能会使用短包名（如用base64代替\"encoding/base64\"） // 也不保证每个类型的字符串表示不同。如果要比较两个类型是否相等，请直接用Type类型比较。 String() string // 返回要保存一个该类型的值需要多少字节；类似unsafe.Sizeof Size() uintptr // 返回当从内存中申请一个该类型值时，会对齐的字节数 Align() int // 返回当该类型作为结构体的字段时，会对齐的字节数 FieldAlign() int // 如果该类型实现了u代表的接口，会返回真 Implements(u Type) bool // 如果该类型的值可以直接赋值给u代表的类型，返回真 AssignableTo(u Type) bool // 如该类型的值可以转换为u代表的类型，返回真 ConvertibleTo(u Type) bool // 返回该类型的字位数。如果该类型的Kind不是Int、Uint、Float或Complex，会panic Bits() int // 返回array类型的长度，如非数组类型将panic Len() int // 返回该类型的元素类型，如果该类型的Kind不是Array、Chan、Map、Ptr或Slice，会panic Elem() Type // 返回map类型的键的类型。如非映射类型将panic Key() Type // 返回一个channel类型的方向，如非通道类型将会panic ChanDir() ChanDir // 返回struct类型的字段数（匿名字段算作一个字段），如非结构体类型将panic NumField() int // 返回struct类型的第i个字段的类型，如非结构体或者i不在[0, NumField())内将会panic Field(i int) StructField // 返回索引序列指定的嵌套字段的类型， // 等价于用索引中每个值链式调用本方法，如非结构体将会panic FieldByIndex(index []int) StructField // 返回该类型名为name的字段（会查找匿名字段及其子字段）， // 布尔值说明是否找到，如非结构体将panic FieldByName(name string) (StructField, bool) // 返回该类型第一个字段名满足函数match的字段，布尔值说明是否找到，如非结构体将会panic FieldByNameFunc(match func(string) bool) (StructField, bool) // 如果函数类型的最后一个输入参数是\"...\"形式的参数，IsVariadic返回真 // 如果这样，t.In(t.NumIn() - 1)返回参数的隐式的实际类型（声明类型的切片） // 如非函数类型将panic IsVariadic() bool // 返回func类型的参数个数，如果不是函数，将会panic NumIn() int // 返回func类型的第i个参数的类型，如非函数或者i不在[0, NumIn())内将会panic In(i int) Type // 返回func类型的返回值个数，如果不是函数，将会panic NumOut() int // 返回func类型的第i个返回值的类型，如非函数或者i不在[0, NumOut())内将会panic Out(i int) Type // 返回该类型的方法集中方法的数目 // 匿名字段的方法会被计算；主体类型的方法会屏蔽匿名字段的同名方法； // 匿名字段导致的歧义方法会滤除 NumMethod() int // 返回该类型方法集中的第i个方法，i不在[0, NumMethod())范围内时，将导致panic // 对非接口类型T或*T，返回值的Type字段和Func字段描述方法的未绑定函数状态 // 对接口类型，返回值的Type字段描述方法的签名，Func字段为nil Method(int) Method // 根据方法名返回该类型方法集中的方法，使用一个布尔值说明是否发现该方法 // 对非接口类型T或*T，返回值的Type字段和Func字段描述方法的未绑定函数状态 // 对接口类型，返回值的Type字段描述方法的签名，Func字段为nil MethodByName(string) (Method, bool) // 内含隐藏或非导出方法&#125; 下面这段代码主要演示了 Implements &amp; ConvertibleTo 接口，这两个接口我觉得比较重要 判断某个 struct 是否实现了某个接口1234567891011121314151617181920212223242526272829303132package mainimport ( \"fmt\" \"reflect\")// test interfacetype TestInterface interface &#123; aa()&#125;// test structtype TestStruct struct &#123;&#125;func (t *TestStruct) aa() &#123;&#125;// 可以学习一下，如何获得 struct / interface 的 Typevar TestStructName = reflect.TypeOf((*TestStruct)(nil)).Elem()var TestInterfaceName = reflect.TypeOf((*TestInterface)(nil)).Elem()func main() &#123; fmt.Println(TestInterfaceName, TestStructName) a := TestStruct&#123;&#125; ptrType := reflect.TypeOf(&amp;a) t := reflect.TypeOf(a) fmt.Println(ptrType.Implements(TestInterfaceName)) fmt.Println(t.ConvertibleTo(TestStructName))&#125; reflect 中的 Value reflect.Value 的主要作用就是 读取，设置或创建值 首先，需要使用 refVal := reflect.ValueOf(var) 为变量创建一个 reflect.Value 实例。如果希望能够使用反射来修改值，则必须使用 refPtrVal := reflect.ValueOf(＆var); 获得指向变量的指针。如果不这样做，则可以使用反射来读取该值，但不能对其进行修改。 一旦有了 reflect.Value 实例就可以使用 Type() 方法获取变量的 reflect.Type。 如果要修改值，请记住它必须是一个指针，并且必须首先对其进行解引用。使用 refPtrVal.Elem().Set(newRefVal) 来修改值，并且传递给 Set() 的值也必须是 reflect.Value。 如果要创建一个新值，可以使用函数 newPtrVal := reflect.New(varType) 来实现，并传入一个 reflect.Type。这将返回一个指针值，然后可以像上面那样使用 Elem().Set() 对其进行修改。 最后，你可以通过调用 Interface() 方法从 reflect.Value 回到普通变量值。由于 Go 没有泛型，因此变量的原始类型会丢失；该方法返回类型为 interface{} 的值。如果创建了一个指针以便可以修改该值，则需要使用 Elem().Interface() 解引用反射的指针。在这两种情况下，都需要将空接口转换为实际类型才能使用它。 12345678910111213141516171819202122232425type Foo struct &#123; A int `tag1:\"First Tag\" tag2:\"Second Tag\"` B string&#125;func main() &#123; greeting := \"hello\" f := Foo&#123;A: 10, B: \"Salutations\"&#125; gVal := reflect.ValueOf(greeting) // not a pointer so all we can do is read it fmt.Println(gVal.Interface()) gpVal := reflect.ValueOf(&amp;greeting) // it’s a pointer, so we can change it, and it changes the underlying variable gpVal.Elem().SetString(\"goodbye\") fmt.Println(greeting) fType := reflect.TypeOf(f) fVal := reflect.New(fType) fVal.Elem().Field(0).SetInt(20) fVal.Elem().Field(1).SetString(\"Greetings\") f2 := fVal.Elem().Interface().(Foo) fmt.Printf(\"%+v, %d, %s\\n\", f2, f2.A, f2.B)&#125; 输出结果如下所示：123hellogoodbye&#123;A:20 B:Greetings&#125;, 20, Greetings 反射创建引用类型的实例 除了生成内置类型和用户定义类型的实例之外，还可以使用反射来生成通常需要 make 函数的实例。可以使用 reflect.MakeSlice，reflect.MakeMap 和 reflect.MakeChan 函数制作切片，Map 或通道。在所有情况下，都提供一个 reflect.Type，然后获取一个 reflect.Value，可以使用反射对其进行操作，或者可以将其分配回一个标准变量。 1234567891011121314151617181920212223242526func main() &#123; // 定义变量 intSlice := make([]int, 0) mapStringInt := make(map[string]int) // 获取变量的 reflect.Type sliceType := reflect.TypeOf(intSlice) mapType := reflect.TypeOf(mapStringInt) // 使用反射创建类型的新实例 intSliceReflect := reflect.MakeSlice(sliceType, 0, 0) mapReflect := reflect.MakeMap(mapType) // 将创建的新实例分配回一个标准变量 v := 10 rv := reflect.ValueOf(v) intSliceReflect = reflect.Append(intSliceReflect, rv) intSlice2 := intSliceReflect.Interface().([]int) fmt.Println(intSlice2) k := \"hello\" rk := reflect.ValueOf(k) mapReflect.SetMapIndex(rk, rv) mapStringInt2 := mapReflect.Interface().(map[string]int) fmt.Println(mapStringInt2)&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"docker 网络模型","slug":"docker-network","date":"2019-11-04T14:19:54.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/11/04/docker-network/","link":"","permalink":"https://overtalk.site/2019/11/04/docker-network/","excerpt":"","text":"本文介绍一下k8s的网络模型 概述 docker默认提供了4种网络模型，供容器启动的时候选择。分别为none、host、container、bridge。本文是这四种网络模型的学习记录。 none模式 使用none模式，Docker 容器拥有自己的 Network Namespace，但是，并不为Docker 容器进行任何网络配置。也就是说，这个 Docker 容器没有网卡、IP、路由等信息。需要我们自己为 Docker 容器添加网卡、配置 IP 等。 123456789建立一个none模式的容器docker run -itd --net=none --name test6 busybox进入到容器中去docker exec -it test6 sh查看网络信息ifconfigroute -n bridge模式 当Docker进程启动时，会在主机上创建一个名为docker0的虚拟网桥，此主机上启动的Docker容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。从docker0子网中分配一个 IP 给容器使用，并设置 docker0 的 IP 地址为容器的默认网关。在主机上创建一对虚拟网卡veth pair设备，Docker 将 veth pair 设备的一端放在新创建的容器中，并命名为eth0（容器的网卡），另一端放在主机中，以vethxxx这样类似的名字命名，并将这个网络设备加入到 docker0 网桥中。 bridge模式是 docker 的默认网络模式，不写–net参数，就是bridge模式。使用docker run -p时，docker 实际是在iptables做了DNAT规则，实现端口转发功能。可以使用iptables -t nat -vnL查看。 下面先创建一个新的 Docker 网络。 12docker network create -d bridge my-net-d 参数是指定docker网络类型. 复制代码运行一个容器并连接到新建的my-net网络. 1docker run -it --name test1 --network my-net busybox sh 复制代码打开新的终端,再运行一个容器并加入到my-net网络 1docker run -it --name test2 --network my-net busybox sh 复制代码再打开一个新的终端查看容器信息 1docker container ls 复制代码在两个容器之间互ping ping test1ping test2 复制代码用ping来测试连接,它会解析成对端的ip host模式 如果启动容器的时候使用host模式，那么这个容器将不会获得一个独立的Network Namespace，而是和宿主机共用一个 Network Namespace。容器将不会虚拟出自己的网卡，配置自己的 IP 等，而是使用宿主机的 IP 和端口。但是，容器的其他方面，如文件系统、进程列表等还是和宿主机隔离的。 建立两台以网络模式为主机模式的主机 12docker run -itd --net=host --name test3 busyboxdocker run -itd --net=host --name test4 busybox 进入到容器中 12docker exec -it test3 /bin/bashdocker exec -it test4 /bin/bash 查看网络信息 12ifconfig route -n container模式 这个模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。 12345678910建一个container模式的容器docker run -itd --net=container:test1 --name test5 busybox进入到容器docker exec -it test5 /bin/bashdocker exec -it test1 /bin/bash查看网络信息ifconfigroute -n","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://overtalk.site/tags/docker/"}]},{"title":"ssh 的一些坑","slug":"ssh-notes","date":"2019-10-31T09:06:26.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/10/31/ssh-notes/","link":"","permalink":"https://overtalk.site/2019/10/31/ssh-notes/","excerpt":"","text":"ssh 中的小坑 起因 今天用 VMware-Fusion 创建新的虚拟机，因为直接操作终端，无法复制粘贴，所以我用本机ssh连接到虚拟机中 遇到这样的问题： 12345678910111213@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!Someone could be eavesdropping on you right now (man-in-the-middle attack)!It is also possible that a host key has just been changed.The fingerprint for the ECDSA key sent by the remote host isSHA256:jl/PgGqyvsX6LohbWIJpfF6KqJpACrHeqSbSEQN1gqk.Please contact your system administrator.Add correct host key in /Users/qinhan/.ssh/known_hosts to get rid of this message.Offending ECDSA key in /Users/qinhan/.ssh/known_hosts:28ECDSA host key for 172.16.52.132 has changed and you have requested strict checking.Host key verification failed. 经过google,出现这个问题的原因是,第一次使用SSH连接时，会生成一个认证，储存在客户端的known_hosts中。 可使用以下指令查看：1ssh-keygen -l -f ~/.ssh/known_hosts 问题原因 之前创建的虚拟机被我删掉，然后重新建了。 但是ip却没有变。 有的时候由于服务器重新安装系统了，也会出现以上错误。 解决1ssh-keygen -R 服务器端的ip地址 会出现以下提示 123# Host [服务器IP] found: line 1 type RSA/用户home目录/.ssh/known_hosts updated.Original contents retained as /用户home目录/.ssh/known_hosts.old 重新连接即可","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"ssh","slug":"ssh","permalink":"https://overtalk.site/tags/ssh/"}]},{"title":"go mod 使用教程","slug":"go-mod","date":"2019-10-31T07:53:42.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/10/31/go-mod/","link":"","permalink":"https://overtalk.site/2019/10/31/go-mod/","excerpt":"","text":"go mod使用简介 go mod是什么 Golang从诞生之初就一直有个被诟病的问题：缺少一个行之有效的“官方”包依赖管理工具。其原因是在Google内部，所有人都是在一个代码库上进行开发的，因此并不是非常需要。但Golang变成一个社区化的工程语言之后，这个问题被放大了。 GOPATH不符合一般开发者习惯，大部分人更习惯maven、node modules之类的方式 GOPATH无法有效的管理版本依赖，没有一个地方能够表明依赖包的具体版本号，无法形成有效的版本配套关系 在Golang 1.5发布了vendor特性之后，社区在vendor基础上开发了很多包管理工具，例如glide, dep(这个最悲催，已经半官方了，结果横刀杀出来一个go mod)，等等，具体参见拙文go依赖包管理工具对比 。但说实话，都不是非常满意。 你可能会说dep，glide我用的都挺爽的，有什么不满意的？ 其实我不喜欢的是vendor这个特性。开发过前端的同学对node modules一定印象深刻，得益于前端混乱的包管理，一个普通的web前端，其node modules往往非常巨大，而且它是每工程的，也就是说如果有2个前端工程，就会有两份巨大的node moudles，里面有成千上万个文件，常常造成IDE挂死，也非常浪费硬盘。 那么，vendor是不是到后期也会变成这样呢？同样的库，同样的版本，就因为在不同的工程里用了，就要在vendor里单独搞一份，不浪费吗？所以这些基于vendor的包管理工具，都会有这个问题。 相比之下maven这种本地缓存库的管理方式就好很多。 Golang 1.11 版本引入的 go mod ，其思想类似maven：摒弃vendor和GOPATH，拥抱本地库。 先来看看怎么用。 go mod 具体介绍前提工作 把 golang 升级到 1.11（现在1.12 已经发布了，建议使用1.12） 设置 GO111MODULE GO111MODULE GO111MODULE 有三个值：off, on和auto（默认值）。 GO111MODULE=off，go命令行将不会支持module功能，寻找依赖包的方式将会沿用旧版本那种通过vendor目录或者GOPATH模式来查找。 GO111MODULE=on，go命令行会使用modules，而一点也不会去GOPATH目录下查找。 GO111MODULE=auto，默认值，go命令行将会根据当前目录来决定是否启用module功能。这种情况下可以分为两种情形： 当前目录在GOPATH/src之外且该目录包含go.mod文件 当前文件在包含go.mod文件的目录下面。 1当modules 功能启用时，依赖包的存放位置变更为$GOPATH/pkg，允许同一个package多个版本并存，且多个项目可以共享缓存的 module。 go mod 命令 golang 提供了 go mod命令来管理包。 go mod 有以下命令： 命令 说明 download download modules to local cache(下载依赖包) edit edit go.mod from tools or scripts（编辑go.mod) graph print module requirement graph (打印模块依赖图) init initialize new module in current directory（在当前目录初始化mod） tidy add missing and remove unused modules(拉取缺少的模块，移除不用的模块) vendor make vendored copy of dependencies(将依赖复制到vendor下) verify verify dependencies have expected content (验证依赖是否正确） why explain why packages or modules are needed(解释为什么需要依赖) go mod 使用新项目 1.在GOPATH 目录之外新建一个目录，并使用go mod init 初始化生成go.mod 文件 12345678910➜ ~&gt; mkdir hello➜ ~&gt; cd hello➜ ~/hello&gt; go mod init hellogo: creating new go.mod: module hello➜ ~/hello&gt; lsgo.mod➜ ~/hello&gt; cat go.modmodule hellogo 1.13 go命令(‘go build’, ‘go test’, 甚至 ‘go list’)执行时，会自己去修改go.mod文件。 go mod 的拉取指定版本 在go.mod中指定版本 在使用go get 如果我们想指定一些版本信息, 可以参照下面的操作: 12345// 根据tag go get -u github.com/gin-gonic/gin@v1.3.0 // 根据commit idgo get github.com/xx/xx@0f1dbe038589903023daa297102f8688641dbe73 Tips 此外，一些墙外的包（golang.org/x/…）如果下载有问题，可以说设置代理1export GOPROXY=https://goproxy.io","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"C++ - 类型转化","slug":"cpp-cast","date":"2019-10-30T08:03:00.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/10/30/cpp-cast/","link":"","permalink":"https://overtalk.site/2019/10/30/cpp-cast/","excerpt":"","text":"C++ 类型转化 概述 C++中的类型转换分为两种： 隐式类型转换； 显式类型转换。 而对于隐式变换，在很多时候，不经意间就发生了，比如int类型和float类型相加时，int类型就会被隐式的转换位float类型，然后再进行相加运算。而关于隐式转换不是今天总结的重点，重点是显式转换。 在标准C++中有四个类型转换符：static_cast、dynamic_cast、const_cast和reinterpret_cast；下面将对它们一一的进行总结。 const_cast 常量指针被转化成非常量指针，并且仍然指向原来的对象； 常量引用被转换成非常量引用，并且仍然指向原来的对象； const_cast一般用于修改指针。如const char *p形式。 const_cast的作用是用来改变表达式里面的常量性（const）或易变性（volatile）。12345678910111213141516#include &lt;iostream&gt;using std::cout;using std::endl;int main(void)&#123; const int b = 10; //b = 11 报错，因为b是一个常量对象 int * pc = const_cast&lt;int *&gt;(&amp;b); *pc = 11; cout &lt;&lt; \"*pc = \" &lt;&lt; *pc &lt;&lt; endl;//b原来地址的数据现在可由*pc来改变，即解除const cout &lt;&lt; \"b = \" &lt;&lt; b &lt;&lt; endl; //b其实类似(编译器处理问题)#define b 10 不会变的 return 0;&#125; static_cast static_cast的转换格式： 1static_cast &lt;type-id&gt; (expression) 将expression转换为type-id类型，主要用于非多态类型之间的转换，不提供运行时的检查来确保转换的安全性。主要在以下几种场合中使用： 1.基本数据类型之间的转换，如把int转换成char，把int转换成enum 2.用于类层次结构中基类和子类之间指针或引用的转换。 进行上行转换（把子类的指针或引用转换成基类表示）是安全的； 进行下行转换（把基类指针或引用转换成子类指针或引用）时，由于没有动态类型检查，所以是不安全的。 3.把void指针转换成目标类型的指针(不安全!!) 12345678//隐式的类型转换int firstnumber=10, secondnumber = 100 ;double result=(double)firstnumber/secondnumber;cout &lt;&lt; result &lt;&lt; endl;//使用static_dynamicdouble result2 = static_cast&lt;double&gt;(firstnumber)/static_cast&lt;double&gt; (secondnumber);cout &lt;&lt; result2 &lt;&lt; endl; dynamic_cast 用于多态类型的转换 dynamic_cast的转换格式： 1dynamic_cast &lt;type-id&gt; (expression) 将expression转换为type-id类型，type-id必须是 类的指针、类的引用 或者是 void* 如果type-id是指针类型，那么expression也必须是一个指针 如果type-id是一个引用，那么expression也必须是一个引用 dynamic_cast主要用于类层次间的上行转换和下行转换，还可以用于类之间的交叉转换。 dynamic_cast主要用于 父类 &amp; 子类 对象之间的转换 子类对象 -&gt; 父类对象 时，dynamic_cast和static_cast的效果是一样的； 父类对象 -&gt; 子类对象 时，dynamic_cast具有类型检查的功能，比static_cast更安全。 在多态类型之间的转换主要使用dynamic_cast，因为类型提供了运行时信息。 子类对象 -&gt; 父类对象 比如B继承自A，B转换为A，进行上行转换时，是安全的，于static_cast相同，如下：12345678910111213#include &lt;iostream&gt;using namespace std;class A&#123;&#125;;class B : public A&#123;&#125;;int main()&#123; B *pB = new B; A *pA = dynamic_cast&lt;A *&gt;(pB); // Safe and will succeed&#125; 多重继承之间的上行转换 C继承自B，B继承自A，这种多重继承的关系；但是，关系很明确，使用dynamic_cast进行转换时，也是很简单的：123456789101112131415class A&#123;&#125;;class B : public A&#123;&#125;;class C : public B&#123;&#125;;int main()&#123; C *pC = new C; B *pB = dynamic_cast&lt;B *&gt;(pC); // OK A *pA = dynamic_cast&lt;A *&gt;(pC); // OK&#125; 而上述的转换，static_cast和dynamic_cast具有同样的效果。而这种上行转换，也被称为隐式转换；比如我们在定义变量时经常这么写：B *pB = new C;这和上面是一个道理的，只是多加了一个dynamic_cast转换符而已。 父类对象 -&gt; 子类对象 （这个真的是重点）如果expression是type-id的基类，使用dynamic_cast进行转换时，在运行时就会检查expression是否真正的指向一个type-id类型的对象，如果是，则能进行正确的转换，获得对应的值；否则返回NULL，如果是引用，则在运行时就会抛出异常123456789101112131415class B&#123; virtual void f()&#123;&#125;;&#125;;class D : public B&#123; virtual void f()&#123;&#125;;&#125;;void main()&#123; B* pb = new D; // unclear but ok B* pb2 = new B; D* pd = dynamic_cast&lt;D*&gt;(pb); // ok: pb actually points to a D D* pd2 = dynamic_cast&lt;D*&gt;(pb2); // pb2 points to a B not a D, now pd2 is NULL&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - 模版（template）","slug":"cpp-template","date":"2019-10-30T07:30:01.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/10/30/cpp-template/","link":"","permalink":"https://overtalk.site/2019/10/30/cpp-template/","excerpt":"","text":"C++ 学习笔记 C++ tepmlate 简介 Template所代表的 泛型编程 是C++语言中的重要的组成部分，本文是基础篇的第一部分。 为什么要有泛型编程 C++是一门强类型语言，所以无法做到像动态语言（python javascript）那样子，编写一段通用的逻辑，可以把任意类型的变量传进去处理。泛型编程弥补了这个缺点，通过把通用逻辑设计为模板，摆脱了类型的限制，提供了继承机制以外的另一种抽象机制，极大地提升了代码的可重用性。 注意：模板定义本身不参与编译，而是编译器根据模板的用户使用模板时提供的类型参数生成代码，再进行编译，这一过程被称为模板实例化。用户提供不同的类型参数，就会实例化出不同的代码。 函数模版函数模板定义 把处理不同类型的公共逻辑抽象成函数，就得到了函数模板。1函数模板可以声明为inline或者constexpr的，将它们放在template之后，返回值之前即可。 普通函数模板 下面定义了一个名叫compare的函数模板，支持多种类型的通用比较逻辑。123456789101112template&lt;typename T&gt;int compare(const T&amp; left, const T&amp; right) &#123; if (left &lt; right) &#123; return -1; &#125; if (right &lt; left) &#123; return 1; &#125; return 0;&#125;compare&lt;int&gt;(1, 2); //使用模板函数 成员函数模板 不仅普通函数可以定义为模板，类的成员函数也可以定义为模板。 12345678910class Printer &#123;public: template&lt;typename T&gt; void print(const T&amp; t) &#123; cout &lt;&lt; t &lt;&lt;endl; &#125;&#125;;Printer p;p.print&lt;const char*&gt;(\"abc\"); //打印abc template 中不仅仅可以是一个 typename, 也可以是具体类型的变量 123456789101112131415template&lt;typename T, int N&gt;class Array &#123;private: T m_Array[N];public: void ShowSize() &#123; std::cout &lt;&lt; N &lt;&lt; std::endl; &#125;&#125;;Array&lt;int, 2&gt; p;// Array&lt;std::string, 2&gt; p;p.ShowSize(); //打印 2 为什么成员函数模板不能是虚函数(virtual)？ 1这是因为c++ compiler在parse一个类的时候就要确定vtable的大小，如果允许一个虚函数是模板函数，那么compiler就需要在parse这个类之前扫描所有的代码，找出这个模板成员函数的调用（实例化），然后才能确定vtable的大小，而显然这是不可行的，除非改变当前compiler的工作机制。 实参推断 为了方便使用，除了直接为函数模板指定类型参数之外，我们还可以让编译器从传递给函数的实参推断类型参数，这一功能被称为模板实参推断。 123compare(1, 2); //推断T的类型为intcompare(1.0, 2.0); //推断T的类型为doublep.print(\"abc\"); //推断T的类型为const char* 有意思的是，还可以通过把函数模板赋值给一个指定类型的函数指针，让编译器根据这个指针的类型，对模板实参进行推断。1int (*pf) (const int&amp;, const int&amp;) = compare; //推断T的类型为int 当返回值类型也是参数时 当一个模板函数的返回值类型需要用另外一个模板参数表示时，你无法利用实参推断获取全部的类型参数，这时有两种解决办法： 返回值类型与参数类型完全无关，那么就需要显示的指定返回值类型，其他的类型交给实参推断。 1注意：此行为与函数的默认实参相同，我们必须从左向右逐一指定。 12345678910111213template&lt;typename T1, typename T2, typename T3&gt;T1 sum(T2 v2, T3 v3) &#123; return static_cast&lt;T1&gt;(v2 + v3);&#125;auto ret = sum&lt;long&gt;(1L, 23); //指定T1, T2和T3交由编译器来推断template&lt;typename T1, typename T2, typename T3&gt;T3 sum_alternative(T1 v1, T2 v2) &#123; return static_cast&lt;T1&gt;(v1 + v2);&#125;auto ret = sum_alternative&lt;long&gt;(1L, 23); //error，只能从左向右逐一指定auto ret = sum_alternative&lt;long,int,long&gt;(1L,23); //ok, 谁叫你把最后一个T3作为返回类型的呢? 返回值类型可以从参数类型中获得，那么把函数写成尾置返回类型的形式，就可以愉快的使用实参推断了。 1234567891011template&lt;typename It&gt;auto sum(It beg, It end) -&gt; decltype(*beg) &#123; decltype(*beg) ret = *beg; for (It it = beg+1; it != end; it++) &#123; ret = ret + *it; &#125; return ret;&#125;vector&lt;int&gt; v = &#123;1, 2, 3, 4&#125;;auto s = sum(v.begin(), v.end()); //s = 10 实参推断时的自动类型转换 编译器进行模板实参推断时通常不会对实参进行类型转换，只有以下几种情况例外： 普通对象赋值给const引用 int a = 0; -&gt; const T&amp; 数组名转换为头指针 int a[10] = {0}; -&gt; T* 函数名转换为函数指针 void func(int a){…} -&gt; T* 函数模板重载 函数模板之间，函数模板与普通函数之间可以重载。编译器会根据调用时提供的函数参数，调用能够处理这一类型的最特殊的版本。在特殊性上，一般按照如下顺序考虑： 1.普通函数 2.特殊模板（限定了T的形式的，指针、引用、容器等） 3.普通模板（对T没有任何限制的） 对于如何判断某个模板更加特殊，原则如下：如果模板B的所有实例都可以实例化模板A，而反过来则不行，那么B就比A特殊。 1234567891011121314151617181920template&lt;typename T&gt;void func(T&amp; t) &#123; //通用模板函数 cout &lt;&lt; \"In generic version template \" &lt;&lt; t &lt;&lt; endl;&#125;template&lt;typename T&gt;void func(T* t) &#123; //指针版本 cout &lt;&lt; \"In pointer version template \"&lt;&lt; *t &lt;&lt; endl;&#125;void func(string* s) &#123; //普通函数 cout &lt;&lt; \"In normal function \" &lt;&lt; *s &lt;&lt; endl;&#125;int i = 10;func(i); //调用通用版本，其他函数或者无法实例化或者不匹配func(&amp;i); //调用指针版本，通用版本虽然也可以用，但是编译器选择最特殊的版本string s = \"abc\";func(&amp;s); //调用普通函数，通用版本和特殊版本虽然也都可以用，但是编译器选择最特化的版本func&lt;&gt;(&amp;s); //调用指针版本，通过&lt;&gt;告诉编译器我们需要用template而不是普通函数 模板函数特化 有时通用的函数模板不能解决个别类型的问题，我们必须对此进行定制，这就是函数模板的特化。函数模板的特化必须把所有的模版参数全部指定。1234567template&lt;&gt;void func(int i) &#123; cout &lt;&lt; \"In special version for int \"&lt;&lt; i &lt;&lt; endl; &#125;int i = 10;func(i); //调用特化版本 类模板函数模板定义 类模板也是公共逻辑的抽象，通常用来作为容器（例如：vector）或者行为（例如：clonable）的封装。 类模板 下面定义了一个Printer类模板，负责打印以及转化为string。 12345678910111213141516171819202122232425template&lt;typename T&gt;class Printer &#123;public: // explicit 修饰单个形式参数的构造函数，指定改函数只能显示的调用 explicit Printer(const T&amp; param):t(param)&#123;&#125; string&amp;&amp; to_string(); //定义在内部 void print() &#123; cout &lt;&lt; t &lt;&lt; endl; &#125;private: T t;&#125;;//定义在外部template&lt;typename T&gt;string&amp;&amp; Printer&lt;T&gt;::to_string() &#123; strstream ss; ss &lt;&lt; t; return std::move(string(ss.str()));&#125;Printer p(1); //errorPrinter&lt;int&gt; p = 1; //error, 因为构造函数有explicit进行修饰Printer&lt;int&gt; p(1); //ok 与函数模板不同，类模板不能推断实例化。所以你只能显示指定类型参数使用Printer p(1)，而不能让编译器自行推断Printer p(1)。 1类模板的成员函数既可以定义在内部，也可以定义在外部。定义在内部的被隐式声明为inline，定义在外部的类名之前必须加上template的相关声明。 类模板中的成员函数模板 我们还可以把类模板和函数模板结合起来，定义一个含有成员函数模板的类模板。123456789101112131415161718192021template&lt;typename T&gt;class Printer &#123;public: // explicit 修饰单个形式参数的构造函数，指定改函数只能显示的调用 explicit Printer(const T&amp; param):t(param)&#123;&#125; //成员函数模板 template&lt;typename U&gt; void add_and_print(const U&amp; u);private: T t;&#125;;//注意这里要有两层template的说明template&lt;typename T&gt;template&lt;typename U&gt;void Printer&lt;T&gt;::add_and_print(const U&amp; u) &#123; cout &lt;&lt; t + u &lt;&lt; endl;&#125;Printer&lt;int&gt; p(42);p.add_and_print(1.1); //自动推断U为double，打印出43.1 类模板Tips类模板中的static成员 类模板中可以声明static成员，在类外定义的时候要增加template相关的关键词。另外，需要注意的是：每个不同的模板实例都会有一个独有的static成员对象。 12345678910111213141516template&lt;typename T&gt;class Printer &#123;public: explicit Printer(const T&amp; param):t(param)&#123;&#125; static int s_value;private: T t;&#125;;template&lt;typename T&gt; //注意这里的定义方式int Printer&lt;T&gt;::s_value = 1;Printer&lt;int&gt; pi(1);Printer&lt;int&gt; pi2(1);Printer&lt;double&gt; pd(1.0);pi.s_value += 1; //pi和pi2中的改变了，pd的没改变 其实这个结论是显然的，static成员属于实例化后的类，不同的实例化当然有不同static成员。就像上面的例子一样，pi.s_value += 1只影响到了Printer，而不会影响到Printer。 1函数模板中的static局部变量也有类似的工作方式。 类模板成员函数实例化 为了节省资源，类模板实例化时并不是每个成员函数都实例化了，而是使用到了哪个成员函数，那个成员函数才实例化。 123456789101112131415template&lt;typename T&gt;class Printer &#123;public: explicit Printer(const T&amp; param):t(param)&#123;&#125; void print() &#123; cout &lt;&lt; t &lt;&lt; endl; &#125; private: T t; &#125;;class empty&#123;&#125;;empty e;Printer&lt;empty&gt; p(e); //ok 虽然成员函数print无法通过编译，但是因为没有使用到，也就没有实例化print，所以没有触发编译错误。 类模板别名 为了简化代码，我们可以使用typedef为类模板的某个实例定义一个别名，也可以使用using语句固定一个或多个类型参数（这有点偏特化的意思了）。123456typedef std::pair&lt;int, int&gt; PairOfInt; //ok，为std::pair&lt;int, int&gt;定义了一个别名template &lt;typename T&gt; using WithNum = std::pair&lt;T, int&gt;; //ok，相当于定义了一个std::pair的偏特化PairOfInt poi; //实际类型，std::pair&lt;int, int&gt;WithNum&lt;std::string&gt; strs; //实际类型，std::pair&lt;string, int&gt;WithNum&lt;int&gt; ints; //实际类型，std::pair&lt;int, int&gt; 特化与偏特化类模板的特化与偏特化 就像函数模板重载那样，你可以通过特化（偏特化）类模板来为特定的类型指定你想要的行为。类模板的特化（偏特化）只需要模板名称相同并且特化列表&lt;&gt;中的参数个数与原始模板对应上即可，模板参数列表不必与原始模板相同模板名称相同。一个类模板可以有多个特化，与函数模板相同，编译器会自动实例化那个最特殊的版本。1234567891011121314151617181920212223242526272829303132333435363738394041424344template&lt;typename T&gt; //基本模板class S &#123;public: void info() &#123; printf(\"In base template\\n\"); &#125;&#125;;template&lt;&gt; //特化class S&lt;int&gt; &#123; public: void info() &#123; printf(\"In int specialization\\n\"); &#125;&#125;;template&lt;typename T&gt; //偏特化class S&lt;T*&gt; &#123;public: void info() &#123; printf(\"In pointer specialization\\n\"); &#125;&#125;;template&lt;typename T, typename U&gt; //另外一个偏特化class S&lt;T(U)&gt; &#123;public: void info() &#123; printf(\"In function specialization\\n\"); &#125;&#125;;int func(int i) &#123; return 2 * i;&#125;S&lt;float&gt; s1;s1.info(); //调用base模板 S&lt;int&gt; s2;s2.info(); //调用int特化版本S&lt;float*&gt; s3;s3.info(); //调用T*特化版本 S&lt;decltype(func)&gt; s4;s4.info(); //调用函数特化版本 提供了所有类型实参的特化是完全特化，只提供了部分类型实参或者T的类型受限（例如：T）的特化被认为是不完整的，所以也被称为偏特化。完全特化的结果是一个实际的class，而偏特化的结果是另外一个同名的模板。* 类模板成员特化 除了可以特化类模板之外，还可以对类模板中的成员函数和普通静态成员变量进行特化。 123456789101112131415161718192021222324252627template&lt;typename T&gt; class S &#123;public: void info() &#123; printf(\"In base template\\n\"); &#125; static int code;&#125;;template&lt;typename T&gt;int S&lt;T&gt;::code = 10;template&lt;&gt;int S&lt;int&gt;::code = 100; //普通静态成员变量的int特化template&lt;&gt;void S&lt;int&gt;::info() &#123; //成员函数的int特化 printf(\"In int specialization\\n\");&#125; S&lt;float&gt; s1;s1.info(); //普通版本printf(\"Code is: %d\\n\", s1.code); //code = 10S&lt;int&gt; s2; s2.info(); //int特化版本printf(\"Code is: %d\\n\", s2.code); //code = 100","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"algorithm - 排序","slug":"algorithm-sort","date":"2019-10-30T03:24:34.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/10/30/algorithm-sort/","link":"","permalink":"https://overtalk.site/2019/10/30/algorithm-sort/","excerpt":"","text":"leetcode 算法题解法 排序部分 题目连接 排序算法总结算法分类 冒泡排序 稳定 对相邻的元素进行两两比较，顺序相反则进行交换，这样，每一趟会将最小或最大的元素“浮”到顶端，最终达到完全有序。就好像一串气泡一样，最终从小到大或从大到小依次排下来。123456789101112131415vector&lt;int&gt; bubble(vector&lt;int&gt; nums) &#123; // 第一层循环从最后一个数字开始 // 每经历一次最外层循环，i位上的数确定下来 for (int i = nums.size()-1; i &gt; 0; --i) &#123; // 用于从0开始依次冒泡，将较大的数往后推 for (int j = 0; j &lt; i; ++j)&#123; if (nums[j] &gt; nums[j+1]) &#123; int temp = nums[j+1]; nums[j+1] = nums[j]; nums[j] = temp; &#125; &#125; &#125; return nums;&#125; 选择排序 不稳定 每一次从待排序的数据元素中选出最小（或最大）的一个元素，存放在序列的起始位置，直到全部待排序的数据元素排完。 比如序列[5， 5， 3]第一次就将第一个[5]与[3]交换，导致第一个5挪动到第二个5后面123456789101112131415vector&lt;int&gt; choose(vector&lt;int&gt; nums) &#123; // 第一层循环从第一个数字开始 // 每经历一次最外层循环，i位上的数确定下来 for (int i = 0; i &lt; nums.size()-1; ++i) &#123; // 依次将nums[i]和后面的数进行比较，将最小的数放到i位 for (int j = i+1; j &lt; nums.size(); ++j)&#123; if (nums[j] &lt; nums[i]) &#123; int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; &#125; &#125; &#125; return nums;&#125; 插入排序 稳定 把一个新的元素插入已排好序的数组形成一个新的已排好序的数组 从第一个元素开始，取下一个元素比较后实现排序，形成新的数组， 再取第三个元素与该数组比较， 比较时从该数组的最后一位开始比较， 若新元素比与其比较的元素小，则将该比较的元素后移以为， 直到新元素比该数组左边找到其应该插入的位置。1234567891011121314151617181920vector&lt;int&gt; insert(vector&lt;int&gt; nums) &#123; // 插入排序默认从第二个数开始 for (int i = 1; i &lt; nums.size(); ++i) &#123; // 记录下这个值 int temp = nums[i]; // 开始值前一个位置 int j = i-1; while (j &gt;= 0) &#123; // 找到被排序数的位置 if (temp &gt;= nums[j]) &#123; break; &#125; // 被排序位置比nums[j]小，将nums[j]往后移动，继续和前面的比较 nums[j+1] = nums[j]; j--; &#125; nums[j+1] = temp; &#125; return nums;&#125; 快速排序 思路详情请见连接1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;public: vector&lt;int&gt; quickSort(vector&lt;int&gt;&amp; nums) &#123; quick(nums, 0, nums.size()-1); return nums; &#125;private: void quick(vector&lt;int&gt;&amp; nums, int originLeft, int originRight) &#123; if (originLeft &gt; originRight) &#123; return; &#125; int left = originLeft, right = originRight, baseValue = nums[originLeft]; while (left &lt; right) &#123; // 移动右边 (划重点，一定要先移动右边的啊！！！) while (left &lt; right &amp;&amp; nums[right] &gt;= baseValue) &#123; right--; &#125; // 移动左边 while (left &lt; right &amp;&amp; nums[left] &lt;= baseValue) &#123; left++; &#125; if (left &lt; right) &#123; int temp = nums[left]; nums[left] = nums[right]; nums[right] = temp; &#125; &#125; // 调换base nums[originLeft] = nums[left]; nums[left] = baseValue; // 递归 quick(nums, originLeft, left-1); quick(nums, left+1, originRight); &#125;&#125;; 归并排序 归并排序具体工作原理如下（假设序列共有n个元素）： 将序列中每相邻的两个数字进行归并操作（merge）, 形成 floor（n/2）个序列排序之后每个序列包含两个元素 将上述序列在此进行归并，形成 floor（n/4）个序列，每个序列包含四个元素 重复步骤二，知道所有的元素排序完毕 归并排序是稳定的排序算法，时间复杂度为O(nlogn)，如果是使用链表实现的话，空间复杂度可以达到O(1) 但是如果是使用数组来存储的话，在归并的过程中，需要临时的空间来储存归并好的数据，所以空间复杂度为O(n) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class Solution &#123;public: bool mergeSort(vector&lt;int&gt;&amp; nums) &#123; int base = 1, size = nums.size(); while (base &lt; size) &#123; for (int i = 0; i &lt; size; i = i + base*2) &#123; merge(nums, i, i+base, i + base*2); &#125; base = base * 2; &#125; &#125;private: // for example // startIndex = 0 // middleIndex = 4 // endIndex = 8 void merge(vector&lt;int&gt;&amp; nums, int startIndex, int middleIndex, int endIndex) &#123; int size = nums.size(); if (middleIndex &gt;= size) &#123; middleIndex = size; endIndex = size; &#125; else if (endIndex &gt;= size) &#123; endIndex = size; &#125; int i = startIndex, j = middleIndex; vector&lt;int&gt; temp; while (i &lt; middleIndex &amp;&amp; j &lt; endIndex) &#123; if (nums[j] &lt; nums[i]) &#123; temp.push_back(nums[j]); j++; &#125; else &#123; temp.push_back(nums[i]); i++; &#125; &#125; if (i == middleIndex) &#123; while (j &lt; endIndex) &#123; temp.push_back(nums[j]); j++; &#125; &#125; else &#123; while (i &lt; middleIndex) &#123; temp.push_back(nums[i]); i++; &#125; &#125; for (int i = 0; i &lt; temp.size(); ++i) &#123; nums[startIndex+i] = temp[i]; &#125; &#125;&#125;; 堆排序1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;vector&gt;void swap(std::vector&lt;int&gt; &amp;src, int i, int j) &#123; int temp = src[i]; src[i] = src[j]; src[j] = temp;&#125;void sink(std::vector&lt;int&gt; &amp;src, int k, int N) &#123; while (true) &#123; int i = k * 2; if (i &gt; N) &#123; break; &#125; if (i &lt; N &amp;&amp; src[i + 1] &gt; src[i]) &#123; i++; &#125; if (src[k] &lt; src[i]) &#123; swap(src, k, i); &#125; k = i; &#125;&#125;void heapSort(std::vector&lt;int&gt; &amp;src) &#123; if (src.size() &lt;= 1) &#123; return; &#125; int N = src.size() - 1; for (int k = N / 2; k &gt;= 1; k--) &#123; sink(src, k, N); &#125; while (N &gt; 1) &#123; swap(src, 1, N); N--; sink(src, 1, N); &#125;&#125; Some Problems of Leetcode区间 开始刷leetcode的排序相关的题目，首先遇到两题就是有关于区间合并的问题 题目1 题目2 第一题就是给你若干个区间，他们中可以合并的进行合并 第二题是给若干个排序了的区间，和一个单独的区间，将其合并 第二题可以看作是第一题的一个特例子，第二题中，将所有的区间放到数组中，然后在调用第一题的解法即可 这个主要说说第一题的解法 1按照区间的左边界限将区间进行排序，让后从左到右进行遍历，依次合并可以合并的即可。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://overtalk.site/tags/algorithm/"}]},{"title":"C++ - 构造函数与析构函数","slug":"cpp-constructor","date":"2019-10-29T15:34:45.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/10/29/cpp-constructor/","link":"","permalink":"https://overtalk.site/2019/10/29/cpp-constructor/","excerpt":"","text":"C++ 构造函数 &amp; 析构函数 构造函数 C++规定，每个类必须有构造函数，没有构造函数就不能创建对象。 若没有提供任何构造函数，那么c++提供自动提供一个默认的构造函数，该默认构造函数是一个没有参数的构造函数，它仅仅负责创建对象而不做任何赋值操作。 只要类中提供了任意一个构造函数，那么c++就不在自动提供默认构造函数。 构造函数在类中的定义和类名相同，并且没有任何返回类型。 C++规定如果一个类对象是另外一个类的数据成员，那么在创建对象的时候系统将自动调用哪个类的构造函数。 一个类的成员如果是另外一个类的对象的话，不能在类中使用带参数的构造函数进行初始化 构造函数定义为私有，可以防止该类被直接实例化。一般用于Singleton实现 拷贝构造函数 和 赋值运算符 在默认情况下（用户没有定义，但是也没有显式的删除），编译器会自动的隐式生成一个 拷贝构造函数 和 赋值运算符 ，它们只会按位拷贝对象所在的内存（浅拷贝）。 还有一点需要注意的是，拷贝构造函数必须以引用的方式传递参数 (const reference)。 这是因为，在值传递的方式传递给一个函数的时候，会调用拷贝构造函数生成函数的实参。如果拷贝构造函数的参数仍然是以值的方式，就会无限循环的调用下去，直到函数的栈溢出。 拷贝构造函数和赋值运算符的行为比较相似，都是将一个对象的值复制给另一个对象；但是其结果却有些不同: 拷贝构造函数使用传入对象的值生成一个新的对象的实例， 而赋值运算符是将对象的值复制给一个已经存在的实例。 这种区别从两者的名字也可以很轻易的分辨出来，拷贝构造函数也是一种构造函数，那么它的功能就是创建一个新的对象实例；赋值运算符是执行某种运算，将一个对象的值复制给另一个对象（已经存在的）。 调用的是拷贝构造函数还是赋值运算符，主要是看是否有新的对象实例产生。如果产生了新的对象实例，那调用的就是拷贝构造函数；如果没有，那就是对已有的对象赋值，调用的是赋值运算符。 调用拷贝构造函数主要有以下场景： 对象作为函数的参数，以值传递的方式传给函数。 对象作为函数的返回值，以值的方式从函数返回 使用一个对象给另一个对象初始化 看下面一个例子，程序会crash，正确的做法就是自己写 复制构造函数1234567891011121314151617181920212223242526272829303132#include &lt;string&gt;class String&#123;private: char* m_Buffer; unsigned int m_Size;public: String(const char* s) &#123; m_Size = strlen(s); m_Buffer = new char[m_Size + 1]; memcpy(m_Buffer, s, m_Size); m_Buffer[m_Size] = 0; &#125; ~String() &#123; delete[] m_Buffer; &#125;&#125;;int main()&#123; String str = \"QinHan\"; // 隐式转换 // str2 &amp; str3 他们在析构函的时候都会出现重复 delete 的问题 // `m_Buffer` 指向 heap 上的同一个地址，会被释放两次，crash // 另外，下面两种写法其实都是调用了拷贝构造函数，因为都有新的对象产生 String str2 = str; String str3(str); return 0;&#125; explicit关键字 如果类A有一个构造函数 A(int n)，则以下代码是正确的1A a = 3; // “单参数构造函数”被自动型别转换（这是一个隐式转换） 可以通过explicit关键字，阻止“以赋值语法进行带有转型操作的初始化”。 还是上述的例子，构造函数改成 explicit A(int n)，则上述写法无法编译通过，需要改成：A a(3); 一种特殊的构造函数的写法 如果按照一般的写法，成员变量会被赋值两次，第一次是初始值，然后再进行一次赋值12345class Entity&#123; Entity() :name(\"Unknown\"), score(0) &#123;&#125;&#125; 析构函数 析构函数 的定义：析构函数也是特殊的类成员函数，它没有返回类型，没有参数，不能随意调用，也没有重载，只有在类对象的生命期结束的时候，由系统自动调用。 析构函数与构造函数的不同：析构函数与构造函数最主要大不同就是在于调用期不同，构造函数可以有参数可以重载！ 成员的构造是按照在类中定义的顺序进行的，而不是按照构造函数说明后的冒号顺序进行构造的。 Q&amp;Adelete 某个类的指针会调用该类的析构函数么？ 会的，如果不调用的话怎么析构一个类. 不过指针所指向的对象必须是在堆中用new关键词开创的 如果指针指向的是一个栈中的对象,会引起调用两种析构函数而导致程序错误 1234class obob a;ob *p=&amp;a;delete p; // 这样会导致调用两次析构函数.是会引起程序错误的 只有 123class obob * p= new ob;delete p; //这样是正确的 对于 new 创建的对象，只有调用 delete 才能析构。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - 容器","slug":"cpp-container","date":"2019-10-28T08:17:15.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/10/28/cpp-container/","link":"","permalink":"https://overtalk.site/2019/10/28/cpp-container/","excerpt":"","text":"C++ 学习笔记C++ Container 浅析 容器的定义 容器是特定类型对象的集合 在没有使用容器之前，我们可能会用数组解决一些问题。使用数组解决问题，那么我们必须要知道或者估算出大约要存储多少个对象，这样我们会创建能够容纳这些对象的内存空间大小。当我们要处理一些完全不知道要存储多少对象的问题时，数组显的力不从心。我们可以使用容器来解决这个问题。容器具有很高的可扩展性，我们不需要预先告诉它要存储多少对象，只要创建一个容器，并合理的调用它所提供的方法，所有的处理细节由容器自身完成。 通用容器的分类 通用容器分为3类：顺序容器、关联容器、容器适配器 顺序容器 顺序容器是一种元素之间有顺序的线性表，是一种线性结构的可序群集。这和我们数据结构课程上所讲的线性表是一样的。顺序容器中的每个元素位置是固定的，除非你使用了插入或者删除操作改变了这个位置。顺序容器不会根据元素的特点排序而是直接保存了元素操作时的逻辑顺序。比如我们一次性对一个顺序容器追加三个元素，这三个元素在容器中的相对位置和追加时的逻辑次序是一致的。 顺序容器的类型： 类别 简介 vector 可变大小数组，一段连续的内存空间，支持快速随机访问。在尾部之外的位置插入或者删除元素可能很慢。 deque 双端队列。支持快速随机访问。在头尾位置插入、删除速度很快。 list 双向链表。只支持双向顺序访问。在list中任何位置进行插入、删除操作速度都很快。 forward_list 单向链表。只支持单向顺序访问。在链表的任何位置进行插入、删除操作都很快。(C++11标准新加) array 固定大小数组。支持快速随机访问。不能添加或者删除元素。(C++11标准新加) string 与vector相似的容器，但专门用于保存字符。随机访问快，在尾部插入删除快。 关于各容器的操作，实在是太多了，下面的示例程序列举一些比较常见的操作和用法。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;string&gt;#include &lt;deque&gt;#include &lt;list&gt;#include &lt;forward_list&gt;#include &lt;array&gt;using namespace std;int main()&#123; /*--------------------- vector容器的一些操作 ------------------*/ vector&lt;int&gt; vect1; // 定义一个vector容器 vect1.push_back(1); // push_back: 向容器的末尾添加元素 vect1.push_back(2); vect1.push_back(3); vect1.pop_back(); // pop_back: 去除末尾的元素 vect1.insert(vect1.begin() + 1, 8); // 在某个位置插入一个元素,效率低，不适合大批操作 vect1.at(0); // at:取某个位置的元素 vect1.capacity(); // capacity: 不分配新的内存空间的前提下它最多能保存多少元素。这个和下面的size 是有区别的！！ vect1.size(); // size: 已经保存的元素的数目 vect1.empty(); // empty：判断容器是否为空 vect1.front(); // front：取第一个元素 vect1.back(); // back：取最后一个元素 vect1.erase(vect1.begin() + 1); // erase：删除指定位置的元素 vector&lt;int&gt; vect2; vect2.assign(vect1.begin(), vect1.end()); // 赋值操作 /*------------------------------------------------------------*/ // 其他容器操作都和vector差不多，以下列举一些其他容器特有的操作 /*--------------------- string容器一些操作 --------------------*/ string str1 = \"Hello Ace\"; // string的几种构造方法 string str2(\"Hello World\"); string str3(str1, 6); // 从str1下标6开始构造， str3 -&gt; Ace string str4 = str2.substr(0, 5); // 求子串： str4 -&gt; Hello string str5 = str2.substr(6); // 求子串： str5 -&gt; World string str6 = str2.substr(6, 11); // 求子串： str6 -&gt; World // string str7 = str2.substr(12); // 抛异常： out_of_range string str8 = str2.replace(6, 5, \"Game\"); // 替换：str8 -&gt; Hello Game 从位置6开始，删除5个字符，并替换成\"Game\" string str9 = str2.append(\", Hello Beauty\");// 追加字符串： str9 -&gt; Hello World, Hello Beauty auto pos1 = str1.find(\"Ace\"); // 查找字符串 : pos1 -&gt; 6 ,返回第一次出现字符串的位置，如果没找着，则返回npos int res = str1.compare(\"Hello, Ace\"); // 比较字符串： res -&gt; -1, 根据str1是等于、大于还是小于参数指定的字符串， 返回0、整数或者负数 string str10 = \"Pi = 3.14159\"; double pi = stod(str10.substr(str10.find_first_of(\"+-.0123456789\"))); // 数值转换： pi -&gt; 3.14159 /*------------------------------------------------------------*/ /*--------------------- deque容器一些操作 --------------------*/ deque&lt;int&gt; d1; d1.push_back(1); // 尾后压入元素 d1.push_back(2); d1.push_back(3); d1.push_front(4); // 队头压入元素 d1.push_front(5); d1.push_front(6); d1.pop_back(); // 尾后弹出一个元素 d1.pop_front(); // 队头弹出一个元素 d1.front(); // 取队头元素 d1.back(); // 取队尾元素 /*------------------------------------------------------------*/ /*--------------------- list容器一些操作 --------------------*/ list&lt;int&gt; l; l.push_back(1); // 尾后压入元素 l.push_back(2); l.push_back(3); l.push_front(4); // 队头压入元素 l.push_front(5); l.push_front(6); l.pop_back(); // 尾后弹出一个元素 l.pop_front(); // 队头弹出一个元素 l.front(); // 取队头元素 l.back(); // 取队尾元素 l.insert(l.begin(), 88); // 某个位置插入元素(性能好) l.remove(2); // 删除某个元素(和所给值相同的都删除) l.reverse(); // 倒置所有元素 l.erase(--l.end()); // 删除某个位置的元素(性能好) /*------------------------------------------------------------*/ /*--------------------- forward_list容器一些操作 --------------*/ forward_list&lt;int&gt; fl = &#123;1, 2, 3, 4, 5, 6, 7, 8, 9&#125;; fl.push_front(0); // 压入元素，该容器没有push_back方法 auto prev = fl.before_begin(); // 表示fl的\"首前元素\" auto curr = fl.begin(); // 表示fl的第一个元素 // 循环遍历 while (curr != fl.end()) // 表示仍有元素要处理 &#123; if (*curr % 2) // 若元素为奇数，则删除 &#123; curr = fl.erase_after(prev); // 删除它并移动curr &#125; else &#123; prev = curr; // 移动迭代器curr，指向下一个元素，prev指向curr之前的元素 ++curr; &#125; &#125; // 操作后： fl = &#123;0, 2, 4, 6, 8&#125; /*------------------------------------------------------------*/ /*--------------------- array容器一些操作 --------------------*/ array&lt;int, 5&gt; myArray1 = &#123; 1, 2, 3, 4, 5 &#125;; // 定义一个一维数组 array&lt;array&lt;int, 2&gt;, 3&gt; myArray2 = &#123;1, 2, 3, 4, 5, 6&#125;; // 定义一个二维数组 array&lt;int, 5&gt; myArray3 = &#123;6, 7, 8, 9, 10&#125;; array&lt;int, 5&gt; myArray4; // 此数组并未初始化 // array.resize(); // array 不能有改变容器大小的操作，它的效率比vector高 myArray1.swap(myArray3);// 交换两个数组的的元素 myArray4 = myArray1; // 支持直接这样赋值，原生的数组不可以这样。它把值全部复制过去，而不是引用 myArray1.assign(0); // 把myArray1的元素全部置为0 // 遍历数组元素 for (int i = 0; i &lt; myArray1.size(); ++i) &#123; cout &lt;&lt; myArray1[i] &lt;&lt; endl; &#125; /*------------------------------------------------------------*/ return 0;&#125; 关联容器 关联容器(associative-container)和顺序容器有着根本的不同：关联容器中元素定义是按关键字来保存和访问的。与之相对，顺序容器中的元素是按他们在容器中的位置来顺序保存和访问的。虽然关联容器的很多行为和顺序容器相同，但其不同之处反映了关键字的作用。 关联容器支持高效的关键字查询和访问。标准库一共定义了8个关联容器，最主要的类型是map和set。8个容器中，每个容器： 是一个map或者是一个set。map保存关键字-值对；set只保存关键字。 要求关键字唯一或者不要求。 保持关键字有序或者不保证有序。 关联容器类型： 按关键字有序保存元素 类别 简介 map 关联数组；保存关键字-值对 set 关键字即值，即只保存关键字的容器 multimap 关键字可重复的map multiset 关键字可重复的set 无序集合 类别 简介 unordered_map 用哈希函数组织的map unordered_set 用哈希函数组织的set unordered_multimap 哈希组织的map;关键字可以重复出现 unordered_multiset 哈希组织的set;关键字可以重复出现 从上面的容器名称可以看出：允许重复关键字的容器名字都包含multi；而使用哈希技术的容器名字都以unordered开头。 map的使用 下面的程序是统计每个单词在输入中出现的次数：1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;map&gt;#include &lt;string&gt;using namespace std;int main()&#123; // 统计每个单词在输入中出现的次数 map&lt;string, size_t&gt; word_count; // string到map的空map string word; while (cin &gt;&gt; word) &#123; ++word_count[word]; // 提取word的计数器并将其加1 &#125; for (const auto &amp;w : word_count) // 遍历map的每个元素 &#123; cout &lt;&lt; w.first &lt;&lt; \"出现的次数为: \" &lt;&lt; w.second &lt;&lt; endl; &#125; return 0;&#125; set的使用 对上面那个统计单词的程序做一个扩展，忽略常见单词。比如 the and or then等。 我们使用set保存想要忽略的单词，只对不在集合中的单词进行统计。123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;map&gt;#include &lt;set&gt;#include &lt;string&gt;using namespace std;int main()&#123; // 统计每个单词在输入中出现的次数 map&lt;string, size_t&gt; word_count; // string到map的空map set&lt;string&gt; exclude = &#123;\"The\", \"But\", \"And\", \"Or\", \"An\", \"A\", \"the\", \"but\", \"and\", \"or\", \"an\", \"a\"&#125;; string word; while (cin &gt;&gt; word) &#123; // 只统计不在exclude中的单词。find调用返回一个迭代器，如果在集合中，返回的迭代器指向其该关键中。否则返回尾后迭代器 if (exclude.find(word) == exclude.end()) &#123; ++word_count[word]; // 提取word的计数器并将其加1 &#125; &#125; for (const auto &amp;w : word_count) // 遍历map的每个元素 &#123; cout &lt;&lt; w.first &lt;&lt; \"出现的次数为: \" &lt;&lt; w.second &lt;&lt; endl; &#125; return 0;&#125; 容器适配器 除了顺序容器外，标准库还定义了三个顺序容器适配器:stack、 queue和priority_queue。 适配器(adaptor)是标准库的一个通用概念。容器、迭代器和函数都有适配器。 1本质上，一个适配器是一种机制，能使某种事物的行为看起来像另一种事物一样。 所有容器适配器都支持的操作和类型 操作名 简介 size_type : 一种类型，足以保存当前类型的最大对象的大小 value_type : 元素类型 container_type : 实现适配器的底层容器类型 A a : 创建一个名为a的空适配器 A a(c) : 创建一个名为a的适配器，带有容器c的一个拷贝 关系运算符 : 每个适配器都支持所有关系运算符： ==、！=、&lt;、&lt;=、&gt;、和&gt;=。这些运算符返回底层容器的比较结果。 a.empty() : 若a包含任何元素，返回fasle，反正返回true a.size() : 返回a中的元素数目 swap(a, b) : 或写作a.swap(b)、b.swap(a)。交换a和b的内容。a和b必须有相同的类型，包括底层容器类型也必须相同 栈适配器(stack)的额外操作 操作名 简介 s.pop() : 删除栈顶元素，但不返回该元素值。 s.push(item) : 创建一个新元素压入栈顶 s.emplace(args) : 同push，其值由args构造 s.top() : 返回栈顶元素，但不将元素弹出栈 queue和priority_queue的额外操作 操作名 简介 q.pop() 返回queue的首元素或priority_queue的最高优先级的元素，但不删除此元素。 q.front() 返回首元素或者尾元素，但不删除此元素 q.back() 只使用于queue q.top() 返回最高优先级元素，但不删除此元素 q.push(item) 在queue末尾或者priority_queue中恰当的位置创建一个元素，其值为item q.emplace(args) 同push,其值由args构造 栈默认基于deque实现。queue默认基于deque实现。priority_queue默认基于vector实现。 stack和queue的使用方法比较简单，priority_queue在存储自己定义的数据结构时，必须重载 operator &lt; 或者自己写仿函数。下面给个简单的例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;iostream&gt;#include &lt;queue&gt;using namespace std;struct Node&#123; int x; int y;&#125;;struct MyCmp&#123; // 自定义的比较函数 bool operator ()(Node a, Node b) &#123; if (a.x == b.x) &#123; return a.y &gt; b.y; &#125; return a.x &gt; b.x; &#125;&#125;;int main()&#123; // priority_queue&lt;Type, Container, Functional&gt; // Type 为数据类型，Container 为保存数据的容器，Functional 为元素比较方式 priority_queue&lt;Node, vector&lt;Node&gt;, MyCmp&gt; myQueue; // 添加一些元素 for (int i = 1; i &lt;= 10; ++i) &#123; Node node; node.x = i; node.y = i * i; myQueue.push(node); &#125; // 遍历元素 while (!myQueue.empty()) &#123; cout &lt;&lt; myQueue.top().x &lt;&lt; \",\" &lt;&lt; myQueue.top().y &lt;&lt; endl; myQueue.pop(); // 出队 &#125; return 0;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"C++ - Vector","slug":"cpp-vector","date":"2019-10-25T10:58:42.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/10/25/cpp-vector/","link":"","permalink":"https://overtalk.site/2019/10/25/cpp-vector/","excerpt":"","text":"C++ 学习笔记C++ vector 容器浅析 数组简介 数组其实是一个指针 12int example[5]; // in stackint* ptr = example; 数组取值的两种方式 12345*(example+2) = 5;example[1] = 3;*(ptr+2) = 5;ptr[1] = 3; 一段神奇的代码 123456// error, 申请数组变量大小不可以是变量int size = 5;int a[size];// correctstatic const int size = 5;int a[size]; mem in stack/heap C++ 程序中的内存分为两个部分： 栈（stack）：在函数内部声明的所有变量都将占用栈内存。 堆（heap）：这是程序中未使用的内存，在程序运行时可用于动态分配内存 在 C++ 中，您可以使用特殊的运算符（new）为给定类型的变量在运行时分配堆（heap）内的内存，这会返回所分配的空间地址。 如果您不再需要动态分配的内存空间，可以使用 delete 运算符，删除之前由 new 运算符分配的内存 标准库的数组123456789101112#include &lt;iostream&gt;#include &lt;array&gt;#pragma pack(2)int main() &#123; std::array&lt;int, 5&gt; e; std::cout&lt;&lt; e.size() &lt;&lt; std::endl; return 0;&#125; 什么是vector？ 向量（Vector）是C++中的一种数据结构,确切的说是一个类。一个封装了动态大小数组的顺序容器（Sequence Container）。跟任意其它类型容器一样，它能够存放各种类型的对象。vector是一个能够存放任意类型的动态数组。 使用vector之前要导入头文件 1#include&lt;vector&gt; 其中vector是一个定义于namespace std内的模板（template）： 1234namespace std&#123; template &lt;class T, class Allocator = allocator&lt;T&gt; &gt; class vector;&#125; vector中的元素可以使任意类型，但是必须能够赋值和拷贝。第二个参数可有可无，是用来定义内存模型（memory model），缺省的内存模型是C++标准库提供的allocator。 容器特性 1.顺序序列 顺序容器中的元素按照严格的线性顺序排序。可以通过元素在序列中的位置访问对应的元素。 2.动态数组 支持对序列中的任意元素进行快速直接访问，甚至可以通过指针算述进行该操作。操供了在序列末尾相对快速地添加/删除元素的操作。 3.能够感知内存分配器的（Allocator-aware） 容器使用一个内存分配器对象来动态地处理它的存储需求。 常用函数：构造函数 函数名 说明 vector() 创建一个空vector vector(int nSize) 创建一个vector,元素个数为nSize vector(int nSize,const t&amp; t) 创建一个vector，元素个数为nSize,且值均为t vector(const vector&amp;) 复制构造函数 vector(begin,end) 复制[begin,end)区间内另一个数组的元素到vector中 demo 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;void show(vector&lt;int&gt; v) &#123; cout &lt;&lt; \"vector : \"; for (auto val : v) &#123; cout &lt;&lt; val &lt;&lt; \" \"; &#125; cout &lt;&lt; endl;&#125;int main() &#123; vector&lt;int&gt; v; //定义一个空 vector 对象 vector&lt;int&gt; v1(10); //定义一个具有 10 个元素的 vector 对象（int 型元素默认初始化为 0） vector&lt;int&gt; v2(3,5); //v = &#123; 5, 5, 5 &#125; vector&lt;int&gt; v3(v); //v1 = v vector&lt;int&gt; v4 = &#123; 1, 2, 3 &#125;; vector&lt;int&gt; v5 = v; show(v); show(v1); show(v2); show(v3); show(v4); show(v5);&#125; 结果如下 123456vector : vector : 0 0 0 0 0 0 0 0 0 0 vector : 5 5 5 vector : vector : 1 2 3 vector : 增加函数 函数名 说明 void push_back(const T&amp; x) 向量尾部增加一个元素X iterator insert(iterator it,const T&amp; x) 向量中迭代器指向元素前增加一个元素x iterator insert(iterator it,int n,const T&amp; x) 向量中迭代器指向元素前增加n个相同的元素x iterator insert(iterator it,const_iterator first,const_iterator last) 向量中迭代器指向元素前插入另一个相同类型向量的[first,last)间的数据 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;void show(vector&lt;int&gt; v) &#123; cout &lt;&lt; \"vector : \"; for (auto val : v) &#123; cout &lt;&lt; val &lt;&lt; \" \"; &#125; cout &lt;&lt; endl;&#125;int main() &#123; vector&lt;int&gt; v = &#123; 1, 2, 3 &#125;; v.push_back(4); // v = &#123; 1, 2, 3, 4 &#125;; show(v); v.insert(v.begin(), 4); // v = &#123; 4, 1, 2, 3, 4 &#125;; show(v); v.insert(v.begin(), 3,0); // v = &#123; 0, 0, 0, 4, 1, 2, 3, 4 &#125;; show(v); vector&lt;int&gt; v1 = &#123; 1, 2 &#125;; vector&lt;int&gt; v2 = &#123; 3, 4 &#125;; v2.insert(v2.begin(), v1.begin(), v1.end()); // v = &#123; 1, 2, 3, 4 &#125;; show(v2);&#125; 结果如下1234vector : 1 2 3 4 vector : 4 1 2 3 4 vector : 0 0 0 4 1 2 3 4 vector : 1 2 3 4 删除函数 函数名 说明 iterator erase(iterator it) 删除向量中迭代器指向元素 iterator erase(iterator first,iterator last) 删除向量中[first,last)中元素 void pop_back() 删除向量中最后一个元素 void clear() 清空向量中所有元素 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;void show(vector&lt;int&gt; v) &#123; cout &lt;&lt; \"vector : \"; for (auto val : v) &#123; cout &lt;&lt; val &lt;&lt; \" \"; &#125; cout &lt;&lt; endl;&#125;int main() &#123; vector&lt;int&gt; v = &#123; 1, 2, 3, 4, 5 &#125;; v.pop_back(); // v = &#123;1, 2, 3, 4&#125;; show(v); v.erase(v.begin()); // v = &#123; 2, 3, 4&#125;; show(v); v.erase(v.begin(), v.begin()+2); // v = &#123;4&#125;; show(v); v.clear(); // v = &#123;&#125;; show(v);&#125; 结果如下1234vector : 1 2 3 4 vector : 2 3 4 vector : 4 vector : 遍历函数 函数名 说明 reference at(int pos) 返回pos位置元素的引用 reference front() 返回首元素的引用 reference back() 返回尾元素的引用 iterator begin() 返回向量头指针，指向第一个元素 iterator end() 返回向量尾指针，指向向量最后一个元素的下一个位置 reverse_iterator rbegin() 反向迭代器，指向最后一个元素 reverse_iterator rend() 反向迭代器，指向第一个元素之前的位置 123456789101112131415#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;int main() &#123; vector&lt;int&gt; v = &#123; 1, 2, 3, 4, 5 &#125;; cout &lt;&lt; v.at(2) &lt;&lt; endl; cout &lt;&lt; v[2] &lt;&lt; endl; cout &lt;&lt; v.front() &lt;&lt; endl; cout &lt;&lt; v.back() &lt;&lt; endl; cout &lt;&lt; *v.begin() &lt;&lt; endl; // 数组头元素的指针 cout &lt;&lt; *(v.end()-1) &lt;&lt; endl; // 数组最后一个元素的下一个位置指针&#125; 结果如下123456331515 判断函数 函数名 说明 bool empty() const 判断向量是否为空，若为空，则向量中无元素 123456789101112#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;int main() &#123; vector&lt;int&gt; v1 = &#123; 1, 2, 3, 4, 5 &#125;; vector&lt;int&gt; v2; cout &lt;&lt; \"v1 is empty : \" &lt;&lt; v1.empty() &lt;&lt; endl; cout &lt;&lt; \"v2 is empty : \" &lt;&lt; v2.empty() &lt;&lt; endl;&#125; 结果如下12v1 is empty : 0v2 is empty : 1 大小函数 函数名 说明 int size() const 返回向量中元素的个数 int capacity() const 返回当前向量张红所能容纳的最大元素值 int max_size() const 返回最大可允许的vector元素数量值 1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;void show(vector&lt;int&gt; v) &#123; cout &lt;&lt; \"vector : \"; for (auto val : v) &#123; cout &lt;&lt; val &lt;&lt; \" \"; &#125; cout &lt;&lt; endl;&#125;int main() &#123; vector&lt;int&gt; v1 = &#123; 1, 2, 3, 4, 5 &#125;; cout &lt;&lt; \"size : \" &lt;&lt; v1.size() &lt;&lt; endl; cout &lt;&lt; \"capacity : \" &lt;&lt; v1.capacity() &lt;&lt; endl; cout &lt;&lt; \"max_size : \" &lt;&lt; v1.max_size() &lt;&lt; endl;&#125; 结果如下123size : 5capacity : 5max_size : 4611686018427387903 其他函数 函数名 说明 void swap(vector&amp;) 交换两个同类型向量的数据 void assign(int n,const T&amp; x) 设置向量中第n个元素的值为x void assign(const_iterator first,const_iterator last) 向量中[first,last)中元素设置成当前向量元素 小技巧使用 C++ 11 新特性访问1234567vector&lt;int&gt; v = &#123; 1, 2, 3, 4 &#125;;//将 v 中值为奇数的元素置为 0for (auto n : v) &#123; if (n%2) cout &lt;&lt; n;&#125;// 输出：1 3 查找一个元素是否在 vector 中123vector&lt;int&gt; v = &#123; 1, 2, 3, 4 &#125;;auto it_1 = find(v.begin(), v.end(), 1); // it_1 = v.begin();autp it_2 = find(v.begin(), v.end(), 9); // it_2 = v.end(); 倒序遍历123456vector&lt;int&gt; nums = &#123;1,2,3,4,5,6,7&#125;;auto begin = nums.rbegin();while (begin != nums.rend()) &#123; cout &lt;&lt; *begin &lt;&lt; endl; begin++;&#125; Vector 和 数组的区别 数组是c++中类似vector的数据结构，它们都可以对一种类型进行储存，既都是容器。虽说两者有相似之处，但也有显著的区别，c++ primer的作者说到，在实际的编程中，我们作为程序员应该避免用到低级数组和指针，而更应该多用高级的vector和迭代器。 一些使用 vector 的建议 好好使用 reserve 方法（用于申请足够的空间来储存变量），可以有效的减少 容量不足-&gt;重新申请空间-&gt;copy 的过程","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"Redis Notes","slug":"redis-notes","date":"2019-10-25T06:47:51.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/10/25/redis-notes/","link":"","permalink":"https://overtalk.site/2019/10/25/redis-notes/","excerpt":"","text":"Redis 踩坑笔记 概述 记录一下在使用redis的过程中碰到的一些问题 1.redis磁盘满了无法持久化报错信息1MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error. 出错原因： 强制关闭Redis快照导致不能持久化 这里在重新发一下redis 的回写机制 Redis的数据回写机制分同步和异步两种， 同步回写即SAVE命令，主进程直接向磁盘回写数据。在数据大的情况下会导致系统假死很长时间，所以一般不是推荐的。 异步回写即BGSAVE命令，主进程fork后，复制自身并通过这个新的进程回写磁盘，回写结束后新进程自行关闭。由于这样做不需要主进程阻塞，系统不会假死，一般默认会采用这个方法。 简单地说：Redis在保存数据到硬盘时为了避免主进程假死，需要Fork一份主进程，然后在Fork进程内完成数据保存到硬盘的操作，如果主进程使用了4GB的内存，Fork子进程的时候需要额外的4GB，此时内存就不够了，Fork失败，进而数据保存硬盘也失败了。 解决方案Solution1 ：直接修改内核参数12vm.overcommit_memory = 1sysctl -p 使内核参数生效 Linux内核会根据参数vm.overcommit_memory参数的设置决定是否放行。 如果 vm.overcommit_memory = 1，直接放行 vm.overcommit_memory = 0：则比较 此次请求分配的虚拟内存大小和系统当前空闲的物理内存加上swap，决定是否放行。 vm.overcommit_memory = 2：则会比较 进程所有已分配的虚拟内存加上此次请求分配的虚拟内存和系统当前的空闲物理内存加上swap，决定是否放行。 Solution2 ：将 stop-writes-on-bgsave-error 设置为 no1127.0.0.1:6379&gt; config set stop-writes-on-bgsave-error no 默认配置 stop-writes-on-bgsave-error yes当bgsave出错时数据将不能修改 只是忽略了错误，你的rdb持久化仍然会错误，导致rdb备份失效，出现你这个问题最好检查一下： redis程序用户是否有rdb文件的读写权限。 rdbfork子进程备份数据时，redis占用内存会翻一倍，看看你服务器此时内存够用不。 顺道补充一下，如何备份redis到其他的地方12345678# redis-cli127.0.0.1:6379&gt; CONFIG SET dir /data/tmpOK127.0.0.1:6379&gt; CONFIG SET dbfilename temp.rdbOK127.0.0.1:6379&gt; BGSAVEBackground saving started127.0.0.1:6379&gt; 这样就可以备份数据到/data/tmp/temp.rdb中了","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://overtalk.site/tags/Redis/"}]},{"title":"计算机网络 - IP 详解","slug":"network-ip","date":"2019-10-24T05:26:05.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/10/24/network-ip/","link":"","permalink":"https://overtalk.site/2019/10/24/network-ip/","excerpt":"","text":"上次在 计算机网络（三）详解了tcp协议 本文来对 ip 这个单独的协议进行更加详细的叙述 IPIP 地址由网络和主机两部分标识组成 如下图，网络标识在数据链路的每个段配置不同的值。网络标识必须保证相互连接的每个段的地址不相重复。而相同段内相连的主机必须有相同的网络地址。IP 地址的“主机标识”则不允许在同一个网段内重复出现。由此，可以通过设置网络地址和主机地址，在相互连接的整个网络中保证每台主机的 IP 地址都不会相互重叠。即 IP 地址具有了唯一性。 如下图，IP 包被转发到途中某个路由器时，正是利用目标 IP 地址的网络标识进行路由。因为即使不看主机标识，只要一见到网络标识就能判断出是否为该网段内的主机。 IP 地址的分类 IP 地址分为四个级别，分别为A类、B类、C类、D类。它根据 IP 地址中从第 1 位到第 4 位的比特列对其网络标识和主机标识进行区分。 A 类 IP 地址是首位以 “0” 开头的地址。从第 1 位到第 8 位是它的网络标识。用十进制表示的话，0.0.0.0~127.0.0.0 是 A 类的网络地址。A 类地址的后 24 位相当于主机标识。因此，一个网段内可容纳的主机地址上限为16,777,214个。 B 类 IP 地址是前两位 “10” 的地址。从第 1 位到第 16 位是它的网络标识。用十进制表示的话，128.0.0.0~191.255.0.0 是 B 类的网络地址。B 类地址的后 16 位相当于主机标识。因此，一个网段内可容纳的主机地址上限为65,534个。 C 类 IP 地址是前三位为 “110” 的地址。从第 1 位到第 24 位是它的网络标识。用十进制表示的话，192.0.0.0~223.255.255.0 是 C 类的网络地址。C 类地址的后 8 位相当于主机标识。因此，一个网段内可容纳的主机地址上限为254个。 D 类 IP 地址是前四位为 “1110” 的地址。从第 1 位到第 32 位是它的网络标识。用十进制表示的话，224.0.0.0~239.255.255.255 是 D 类的网络地址。D 类地址没有主机标识，常用于多播。 在分配 IP 地址时关于主机标识有一点需要注意。即要用比特位表示主机地址时，不可以全部为 0 或全部为 1。因为全部为 0 只有在表示对应的网络地址或 IP 地址不可以获知的情况下才使用。而全部为 1 的主机通常作为广播地址。因此，在分配过程中，应该去掉这两种情况。这也是为什么 C 类地址每个网段最多只能有 254（ 28 - 2 = 254）个主机地址的原因。 广播地址 广播地址用于在同一个链路中相互连接的主机之间发送数据包。将 IP 地址中的主机地址部分全部设置为 1，就成了广播地址。 广播分为本地广播和直接广播两种。在本网络内的广播叫做本地广播；在不同网络之间的广播叫做直接广播。 IP 多播 多播用于将包发送给特定组内的所有主机。由于其直接使用 IP 地址，因此也不存在可靠传输。 相比于广播，多播既可以穿透路由器，又可以实现只给那些必要的组发送数据包。请看下图： 多播使用 D 类地址。因此，如果从首位开始到第 4 位是 “1110”，就可以认为是多播地址。而剩下的 28 位可以成为多播的组编号。 此外， 对于多播，所有的主机（路由器以外的主机和终端主机）必须属于 224.0.0.1 的组，所有的路由器必须属于 224.0.0.2 的组。 子网掩码 现在一个 IP 地址的网络标识和主机标识已不再受限于该地址的类别，而是由一个叫做“子网掩码”的识别码通过子网网络地址细分出比 A 类、B 类、C 类更小粒度的网络。这种方式实际上就是将原来 A 类、B 类、C 类等分类中的主机地址部分用作子网地址，可以将原网络分为多个物理网络的一种机制。 子网掩码用二进制方式表示的话，也是一个 32 位的数字。它对应 IP 地址网络标识部分的位全部为 “1”，对应 IP 地址主机标识的部分则全部为 “0”。由此，一个 IP 地址可以不再受限于自己的类别，而是可以用这样的子网掩码自由地定位自己的网络标识长度。当然，子网掩码必须是 IP 地址的首位开始连续的 “1”。 对于子网掩码，目前有两种表示方式。第一种是，将 IP 地址与子网掩码的地址分别用两行来表示。以 172.20.100.52 的前 26 位是网络地址的情况为例，如下： IP 地址 172. 20. 100. 52 子网掩码 255. 255. 255. 192 - - - - - 网络地址 172. 20. 100. 0 子网掩码 255. 255. 255. 192 - - - - - 广播地址 172. 20. 100. 63 子网掩码 255. 255. 255. 192 第二种表示方式是，在每个 IP 地址后面追加网络地址的位数用 “/ ” 隔开，如下： IP 地址 172. 20. 100. 52 网络地址 172. 20. 100. 0 广播地址 172. 20. 100. 63 另外，在第二种方式下记述网络地址时可以省略后面的 “0” 。例如：172.20.0.0/26 跟 172.20/26 其实是一个意思。 路由 发送数据包时所使用的地址是网络层的地址，即 IP 地址。然而仅仅有 IP 地址还不足以实现将数据包发送到对端目标地址，在数据发送过程中还需要类似于“指明路由器或主机”的信息，以便真正发往目标地址。保存这种信息的就是路由控制表。 该路由控制表的形成方式有两种：一种是管理员手动设置，另一种是路由器与其他路由器相互交换信息时自动刷新。前者也叫做静态路由控制，而后者叫做动态路由控制。 IP 协议始终认为路由表是正确的。然后，IP 本身并没有定义制作路由控制表的协议。即 IP 没有制作路由控制表的机制。该表示由一个叫做“路由协议”的协议制作而成。 IP 地址与路由控制 IP 地址的网络地址部分用于进行路由控制。 路由控制表中记录着网络地址与下一步应该发送至路由器的地址。 在发送 IP 包时，首先要确定 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有相同网络地址的记录，根据该记录将 IP 包转发给相应的下一个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择一个最为吻合的网络地址。 IP 分包与组包 每种数据链路的最大传输单元（MTU）都不尽相同，因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的 MTU 也就不同。 任何一台主机都有必要对 IP 分片进行相应的处理。分片往往在网络上遇到比较大的报文无法一下子发送出去时才会进行处理。 经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行。路由器虽然做分片但不会进行重组。 路径 MTU 发现 分片机制也有它的不足。如路由器的处理负荷加重之类。因此，只要允许，是不希望由路由器进行 IP 数据包的分片处理的。 为了应对分片机制的不足，“路径 MTU 发现” 技术应运而生。路径 MTU 指的是，从发送端主机到接收端主机之间不需要分片是最大 MTU 的大小。即路径中存在的所有数据链路中最小的 MTU 。 进行路径 MTU 发现，就可以避免在中途的路由器上进行分片处理，也可以在 TCP 中发送更大的包。 IPv6 IPv6（IP version 6）是为了根本解决 IPv4 地址耗尽的问题而被标准化的网际协议。IPv4 的地址长度为 4 个 8 位字节，即 32 比特。而 IPv6 的地址长度则是原来的 4 倍，即 128 比特，一般写成 8 个 16 位字节。 IPv6 的特点 IP 得知的扩大与路由控制表的聚合。 性能提升。包首部长度采用固定的值（40字节），不再采用首部检验码。简化首部结构，减轻路由器负担。路由器不再做分片处理。 支持即插即用功能。即使没有DHCP服务器也可以实现自动分配 IP 地址。 采用认证与加密功能。应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能。 多播、Mobile IP 成为扩展功能。 IPv6 中 IP 地址的标记方法 一般人们将 128 比特 IP 地址以每 16 比特为一组，每组用冒号（“：”）隔开进行标记。 而且如果出现连续的 0 时还可以将这些 0 省略，并用两个冒号（“：：”）隔开。但是，一个 IP 地址中只允许出现一次两个连续的冒号。 IPv6 地址的结构 IPv6 类似 IPv4，也是通过 IP 地址的前几位标识 IP 地址的种类。 在互联网通信中，使用一种全局的单播地址。它是互联网中唯一的一个地址，不需要正式分配 IP 地址。 全局单播地址 全局单播地址是指世界上唯一的一个地址。它是互联网通信以及各个域内部通信中最为常用的一个 IPv6 地址。 格式如下图所示，现在 IPv6 的网络中所使用的格式为，n = 48，m = 16 以及 128 - n - m = 64。即前 64 比特为网络标识，后 64 比特为主机标识。 链路本地单播地址 链路本地单播地址是指在同一个数据链路内唯一的地址。它用于不经过路由器，在同一个链路中的通信。通常接口 ID 保存 64 比特版的 MAC 地址。 唯一本地地址 唯一本地地址是不进行互联网通信时所用的地址。 唯一本地地址虽然不会与互联网连接，但是也会尽可能地随机生成一个唯一的全局 ID。 L 通常被置为 1 全局 ID 的值随机决定 子网 ID 是指该域子网地址 接口 ID 即为接口的 ID IPv6 分段处理 IPv6 的分片处理只在作为起点的发送端主机上进行，路由器不参与分片。 IPv6 中最小 MTU 为 1280 字节，因此，在嵌入式系统中对于那些有一定系统资源限制的设备来说，不需要进行“路径 MTU 发现”，而是在发送 IP 包时直接以 1280 字节为单位分片送出。 IP 协议相关技术 IP 旨在让最终目标主机收到数据包，但是在这一过程中仅仅有 IP 是无法实现通信的。必须还有能够解析主机名称和 MAC 地址的功能，以及数据包在发送过程中异常情况处理的功能。 DNS 我们平常在访问某个网站时不适用 IP 地址，而是用一串由罗马字和点号组成的字符串。而一般用户在使用 TCP/IP 进行通信时也不使用 IP 地址。能够这样做是因为有了 DNS （Domain Name System）功能的支持。DNS 可以将那串字符串自动转换为具体的 IP 地址。 这种 DNS 不仅适用于 IPv4，还适用于 IPv6。 ARP 只要确定了 IP 地址，就可以向这个目标地址发送 IP 数据报。然而，在底层数据链路层，进行实际通信时却有必要了解每个 IP 地址所对应的 MAC 地址。 ARP 是一种解决地址问题的协议。以目标 IP 地址为线索，用来定位下一个应该接收数据分包的网络设备对应的 MAC 地址。不过 ARP 只适用于 IPv4，不能用于 IPv6。IPv6 中可以用 ICMPv6 替代 ARP 发送邻居探索消息。 RARP 是将 ARP 反过来，从 MAC 地址定位 IP 地址的一种协议。 ICMP ICMP 的主要功能包括，确认 IP 包是否成功送达目标地址，通知在发送过程当中 IP 包被废弃的具体原因，改善网络设置等。 IPv4 中 ICMP 仅作为一个辅助作用支持 IPv4。也就是说，在 IPv4 时期，即使没有 ICMP，仍然可以实现 IP 通信。然而，在 IPv6 中，ICMP 的作用被扩大，如果没有 ICMPv6，IPv6 就无法进行正常通信。 DHCP 如果逐一为每一台主机设置 IP 地址会是非常繁琐的事情。特别是在移动使用笔记本电脑、只能终端以及平板电脑等设备时，每移动到一个新的地方，都要重新设置 IP 地址。 于是，为了实现自动设置 IP 地址、统一管理 IP 地址分配，就产生了 DHCP（Dynamic Host Configuration Protocol）协议。有了 DHCP，计算机只要连接到网络，就可以进行 TCP/IP 通信。也就是说，DHCP 让即插即用变得可能。 DHCP 不仅在 IPv4 中，在 IPv6 中也可以使用。 NAT NAT（Network Address Translator）是用于在本地网络中使用私有地址，在连接互联网时转而使用全局 IP 地址的技术。 除转换 IP 地址外，还出现了可以转换 TCP、UDP 端口号的 NAPT（Network Address Ports Translator）技术，由此可以实现用一个全局 IP 地址与多个主机的通信。 NAT（NAPT）实际上是为正在面临地址枯竭的 IPv4 而开发的技术。不过，在 IPv6 中为了提高网络安全也在使用 NAT，在 IPv4 和 IPv6 之间的相互通信当中常常使用 NAT-PT。 IP 隧道 如上图的网络环境中，网络 A 与网络 B 之间无法直接进行通信，为了让它们之间正常通信，这时必须得采用 IP 隧道的功能。 IP 隧道可以将那些从网络 A 发过来的 IPv6 的包统合为一个数据，再为之追加一个 IPv4 的首部以后转发给网络 C。 一般情况下，紧接着 IP 首部的是 TCP 或 UDP 的首部。然而，现在的应用当中“ IP 首部的后面还是 IP 首部”或者“ IP 首部的后面是 IPv6 的首部”等情况与日俱增。这种在网络层的首部后面追加网络层首部的通信方法就叫做“ IP 隧道”。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"ip","slug":"ip","permalink":"https://overtalk.site/tags/ip/"}]},{"title":"计算机网络 - TCP 详解","slug":"network-tcp","date":"2019-10-24T03:51:46.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/10/24/network-tcp/","link":"","permalink":"https://overtalk.site/2019/10/24/network-tcp/","excerpt":"","text":"上次在 计算机网络（二）详解了tcp/ip协议群 本文来对 tcp 这个单独的协议进行更加详细的叙述 三次握手（重点） TCP 提供面向有连接的通信传输。面向有连接是指在数据通信开始之前先做好两端之间的准备工作。 所谓三次握手是指建立一个 TCP 连接时需要客户端和服务器端总共发送三个包以确认连接的建立。在socket编程中，这一过程由客户端执行connect来触发。 下面来看看三次握手的流程图： 第一次握手：客户端将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给服务器端，客户端进入SYN_SENT状态，等待服务器端确认。 第二次握手：服务器端收到数据包后由标志位SYN=1知道客户端请求建立连接，服务器端将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给客户端以确认连接请求，服务器端进入SYN_RCVD状态。 第三次握手：客户端收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给服务器端，服务器端检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，客户端和服务器端进入ESTABLISHED状态，完成三次握手，随后客户端与服务器端之间可以开始传输数据了。 四次挥手（重点） 四次挥手即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务端任一方执行close来触发。 由于TCP连接是全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。 下面来看看四次挥手的流程图： 中断连接端可以是客户端，也可以是服务器端。 第一次挥手：客户端发送一个FIN=M，用来关闭客户端到服务器端的数据传送，客户端进入FIN_WAIT_1状态。意思是说”我客户端没有数据要发给你了”，但是如果你服务器端还有数据没有发送完成，则不必急着关闭连接，可以继续发送数据。 第二次挥手：服务器端收到FIN后，先发送ack=M+1，告诉客户端，你的请求我收到了，但是我还没准备好，请继续你等我的消息。这个时候客户端就进入FIN_WAIT_2 状态，继续等待服务器端的FIN报文。 第三次挥手：当服务器端确定数据已发送完成，则向客户端发送FIN=N报文，告诉客户端，好了，我这边数据发完了，准备好关闭连接了。服务器端进入LAST_ACK状态。 第四次挥手：客户端收到FIN=N报文后，就知道可以关闭连接了，但是他还是不相信网络，怕服务器端不知道要关闭，所以发送ack=N+1后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。服务器端收到ACK后，就知道可以断开连接了。客户端等待了2MSL后依然没有收到回复，则证明服务器端已正常关闭，那好，我客户端也可以关闭连接了。最终完成了四次握手。 上面是一方主动关闭，另一方被动关闭的情况，实际中还会出现同时发起主动关闭的情况， 具体流程如下图： 通过序列号与确认应答提高可靠性 在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个已收到消息的通知。这个消息叫做确认应答（ACK）。当发送端将数据发出之后会等待对端的确认应答。如果有确认应答，说明数据已经成功到达对端。反之，则数据丢失的可能性很大。 在一定时间内没有等待到确认应答，发送端就可以认为数据已经丢失，并进行重发。由此，即使产生了丢包，仍然能够保证数据能够到达对端，实现可靠传输。 未收到确认应答并不意味着数据一定丢失。也有可能是数据对方已经收到，只是返回的确认应答在途中丢失。这种情况也会导致发送端误以为数据没有到达目的地而重发数据。 此外，也有可能因为一些其他原因导致确认应答延迟到达，在源主机重发数据以后才到达的情况也屡见不鲜。此时，源主机只要按照机制重发数据即可。 对于目标主机来说，反复收到相同的数据是不可取的。为了对上层应用提供可靠的传输，目标主机必须放弃重复的数据包。为此我们引入了序列号。 序列号是按照顺序给发送数据的每一个字节（8位字节）都标上号码的编号。接收端查询接收数据 TCP 首部中的序列号和数据的长度，将自己下一步应该接收的序列号作为确认应答返送回去。通过序列号和确认应答号，TCP 能够识别是否已经接收数据，又能够判断是否需要接收，从而实现可靠传输。 重发超时的确定 重发超时是指在重发数据之前，等待确认应答到来的那个特定时间间隔。 如果超过这个时间仍未收到确认应答，发送端将进行数据重发。最理想的是，找到一个最小时间，它能保证“确认应答一定能在这个时间内返回”。 TCP 要求不论处在何种网络环境下都要提供高性能通信，并且无论网络拥堵情况发生何种变化，都必须保持这一特性。为此，它在每次发包时都会计算往返时间及其偏差。将这个往返时间和偏差时间相加，重发超时的时间就是比这个总和要稍大一点的值。 在 BSD 的 Unix 以及 Windows 系统中，超时都以0.5秒为单位进行控制，因此重发超时都是0.5秒的整数倍。不过，最初其重发超时的默认值一般设置为6秒左右。 数据被重发之后若还是收不到确认应答，则进行再次发送。此时，等待确认应答的时间将会以2倍、4倍的指数函数延长。 此外，数据也不会被无限、反复地重发。达到一定重发次数之后，如果仍没有任何确认应答返回，就会判断为网络或对端主机发生了异常，强制关闭连接。并且通知应用通信异常强行终止。 以段为单位发送数据 在建立 TCP 连接的同时，也可以确定发送数据包的单位，我们也可以称其为“最大消息长度”（MSS）。最理想的情况是，最大消息长度正好是 IP 中不会被分片处理的最大数据长度。 TCP 在传送大量数据时，是以 MSS 的大小将数据进行分割发送。进行重发时也是以 MSS 为单位。 MSS 在三次握手的时候，在两端主机之间被计算得出。两端的主机在发出建立连接的请求时，会在 TCP 首部中写入 MSS 选项，告诉对方自己的接口能够适应的 MSS 的大小。然后会在两者之间选择一个较小的值投入使用。 利用窗口控制提高速度 TCP 以1个段为单位，每发送一个段进行一次确认应答的处理。这样的传输方式有一个缺点，就是包的往返时间越长通信性能就越低。 为解决这个问题，TCP 引入了窗口这个概念。确认应答不再是以每个分段，而是以更大的单位进行确认，转发时间将会被大幅地缩短。也就是说，发送端主机，在发送了一个段以后不必要一直等待确认应答，而是继续发送。如下图所示： 窗口大小就是指无需等待确认应答而可以继续发送数据的最大值。上图中窗口大小为4个段。这个机制实现了使用大量的缓冲区，通过对多个段同时进行确认应答的功能 滑动窗口控制 上图中的窗口内的数据即便没有收到确认应答也可以被发送出去。不过，在整个窗口的确认应答没有到达之前，如果其中部分数据出现丢包，那么发送端仍然要负责重传。为此，发送端主机需要设置缓存保留这些待被重传的数据，直到收到他们的确认应答。 在滑动窗口以外的部分包括未发送的数据以及已经确认对端已收到的数据。当数据发出后若如期收到确认应答就可以不用再进行重发，此时数据就可以从缓存区清除。 收到确认应答的情况下，将窗口滑动到确认应答中的序列号的位置。这样可以顺序地将多个段同时发送提高通信性能。这种机制也别称为滑动窗口控制。 窗口控制中的重发控制 在使用窗口控制中， 出现丢包一般分为两种情况： ① 确认应答未能返回的情况。在这种情况下，数据已经到达对端，是不需要再进行重发的，如下图： ② 某个报文段丢失的情况。接收主机如果收到一个自己应该接收的序列号以外的数据时，会针对当前为止收到数据返回确认应答。如下图所示，当某一报文段丢失后，发送端会一直收到序号为1001的确认应答，因此，在窗口比较大，又出现报文段丢失的情况下，同一个序列号的确认应答将会被重复不断地返回。而发送端主机如果连续3次收到同一个确认应答，就会将其对应的数据进行重发。这种机制比之前提到的超时管理更加高效，因此也被称为高速重发控制。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"https://overtalk.site/tags/tcp/"}]},{"title":"计算机网络 - TCP/IP 详解","slug":"network-tcpip","date":"2019-10-24T03:08:52.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/10/24/network-tcpip/","link":"","permalink":"https://overtalk.site/2019/10/24/network-tcpip/","excerpt":"","text":"上次在 计算机网络（一）中引出了tcp/ip协议 本文来对 tcp/ip协议群 进行更加详细的叙述 本文篇幅也比较长，先来一张思维导图。 TCP/IP 基础TCP/IP 的具体含义 TCP/IP 不仅仅是指 TCP 和 IP 两种协议。它只是利用 IP 进行通信时所必须用到的协议群的统称。具体来说，IP 或 ICMP、TCP 或 UDP、TELNET 或 FTP、以及 HTTP 等都属于 TCP/IP 协议。他们与 TCP 或 IP 的关系紧密，是互联网必不可少的组成部分。TCP/IP 一词泛指这些协议，因此，有时也称 TCP/IP 为网际协议群。 互联网进行通信时，需要相应的网络协议，TCP/IP 原本就是为使用互联网而开发制定的协议族。因此，互联网的协议就是 TCP/IP，TCP/IP 就是互联网的协议。 数据包包、帧、数据包、段、消息 以上五个术语都用来表述数据的单位，大致区分如下： 包可以说是全能性术语； 帧用于表示数据链路层中包的单位； 数据包是 IP 和 UDP 等网络层以上的分层中包的单位； 段则表示 TCP 数据流中的信息； 消息是指应用协议中数据的单位。 每个分层中，都会对所发送的数据附加一个首部，在这个首部中包含了该层必要的信息，如发送的目标地址以及协议相关信息。通常，为协议提供的信息为包首部，所要发送的内容为数据。在下一层的角度看，从上一层收到的包全部都被认为是本层的数据。 网络中传输的数据包由两部分组成：一部分是协议所要用到的首部，另一部分是上一层传过来的数据。首部的结构由协议的具体规范详细定义。在数据包的首部，明确标明了协议应该如何读取数据。反过来说，看到首部，也就能够了解该协议必要的信息以及所要处理的数据。包首部就像协议的脸。 数据处理流程 下图以用户 a 向用户 b 发送邮件为例子： ① 应用程序处理 首先应用程序会进行编码处理，这些编码相当于 OSI 的表示层功能； 编码转化后，邮件不一定马上被发送出去，这种何时建立通信连接何时发送数据的管理功能，相当于 OSI 的会话层功能。 ② TCP 模块的处理 TCP 根据应用的指示，负责建立连接、发送数据以及断开连接。TCP 提供将应用层发来的数据顺利发送至对端的可靠传输。为了实现这一功能，需要在应用层数据的前端附加一个 TCP 首部。 ③ IP 模块的处理 IP 将 TCP 传过来的 TCP 首部和 TCP 数据合起来当做自己的数据，并在 TCP 首部的前端加上自己的 IP 首部。IP 包生成后，参考路由控制表决定接受此 IP 包的路由或主机。 ④ 网络接口（以太网驱动）的处理 从 IP 传过来的 IP 包对于以太网来说就是数据。给这些数据附加上以太网首部并进行发送处理，生成的以太网数据包将通过物理层传输给接收端。 ⑤ 网络接口（以太网驱动）的处理 主机收到以太网包后，首先从以太网包首部找到 MAC 地址判断是否为发送给自己的包，若不是则丢弃数据。 如果是发送给自己的包，则从以太网包首部中的类型确定数据类型，再传给相应的模块，如 IP、ARP 等。这里的例子则是 IP 。 ⑥ IP 模块的处理 IP 模块接收到 数据后也做类似的处理。从包首部中判断此 IP 地址是否与自己的 IP 地址匹配，如果匹配则根据首部的协议类型将数据发送给对应的模块，如 TCP、UDP。这里的例子则是 TCP。 另外吗，对于有路由器的情况，接收端地址往往不是自己的地址，此时，需要借助路由控制表，在调查应该送往的主机或路由器之后再进行转发数据。 ⑦ TCP 模块的处理 在 TCP 模块中，首先会计算一下校验和，判断数据是否被破坏。然后检查是否在按照序号接收数据。最后检查端口号，确定具体的应用程序。数据被完整地接收以后，会传给由端口号识别的应用程序。 ⑧ 应用程序的处理 接收端应用程序会直接接收发送端发送的数据。通过解析数据，展示相应的内容。 传输层中的 TCP 和 UDP TCP/IP 中有两个具有代表性的传输层协议，分别是 TCP 和 UDP。 TCP 是面向连接的、可靠的流协议。流就是指不间断的数据结构，当应用程序采用 TCP 发送消息时，虽然可以保证发送的顺序，但还是犹如没有任何间隔的数据流发送给接收端。TCP 为提供可靠性传输，实行“顺序控制”或“重发控制”机制。此外还具备“流控制（流量控制）”、“拥塞控制”、提高网络利用率等众多功能。 UDP 是不具有可靠性的数据报协议。细微的处理它会交给上层的应用去完成。在 UDP 的情况下，虽然可以确保发送消息的大小，却不能保证消息一定会到达。因此，应用有时会根据自己的需要进行重发处理。 TCP 和 UDP 的优缺点无法简单地、绝对地去做比较：TCP 用于在传输层有必要实现可靠传输的情况；而在一方面，UDP 主要用于那些对高速传输和实时性有较高要求的通信或广播通信。TCP 和 UDP 应该根据应用的目的按需使用。 端口号 数据链路和 IP 中的地址，分别指的是 MAC 地址和 IP 地址。前者用来识别同一链路中不同的计算机，后者用来识别 TCP/IP 网络中互连的主机和路由器。在传输层也有这种类似于地址的概念，那就是端口号。端口号用来识别同一台计算机中进行通信的不同应用程序。因此，它也被称为程序地址。 根据端口号识别应用 一台计算机上同时可以运行多个程序。传输层协议正是利用这些端口号识别本机中正在进行通信的应用程序，并准确地将数据传输。 通过 IP 地址、端口号、协议号进行通信识别 仅凭目标端口号识别某一个通信是远远不够的。 ① 和② 的通信是在两台计算机上进行的。它们的目标端口号相同，都是80。这里可以根据源端口号加以区分。 ③ 和 ① 的目标端口号和源端口号完全相同，但它们各自的源 IP 地址不同。 此外，当 IP 地址和端口号全都一样时，我们还可以通过协议号来区分（TCP 和 UDP）。 端口号的确定 标准既定的端口号：这种方法也叫静态方法。它是指每个应用程序都有其指定的端口号。但并不是说可以随意使用任何一个端口号。例如 HTTP、FTP、TELNET 等广为使用的应用协议中所使用的端口号就是固定的。这些端口号被称为知名端口号，分布在 01023 之间；除知名端口号之外，还有一些端口号被正式注册，它们分布在 102449151 之间，不过这些端口号可用于任何通信用途。 时序分配法：服务器有必要确定监听端口号，但是接受服务的客户端没必要确定端口号。在这种方法下，客户端应用程序完全可以不用自己设置端口号，而全权交给操作系统进行分配。动态分配的端口号范围在 49152~65535 之间。 端口号与协议 端口号由其使用的传输层协议决定。因此，不同的传输层协议可以使用相同的端口号。 此外，那些知名端口号与传输层协议并无关系。只要端口一致都将分配同一种应用程序进行处理。 UDP UDP 不提供复杂的控制机制，利用 IP 提供面向无连接的通信服务。 并且它是将应用程序发来的数据在收到的那一刻，立即按照原样发送到网络上的一种机制。即使是出现网络拥堵的情况，UDP 也无法进行流量控制等避免网络拥塞行为。 此外，传输途中出现丢包，UDP 也不负责重发。 甚至当包的到达顺序出现乱序时也没有纠正的功能。 如果需要以上的细节控制，不得不交由采用 UDP 的应用程序去处理。 UDP 常用于一下几个方面：1.包总量较少的通信（DNS、SNMP等）；2.视频、音频等多媒体通信（即时通信）；3.限定于 LAN 等特定网络中的应用通信；4.广播通信（广播、多播）。 TCP TCP 与 UDP 的区别相当大。它充分地实现了数据传输时各种控制功能，可以进行丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在 UDP 中都没有。 此外，TCP 作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。 根据 TCP 的这些机制，在 IP 这种无连接的网络上也能够实现高可靠性的通信（ 主要通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现）。 关于IP更加详细的介绍请见计算机网络（三）：TCP 详解 网络层中的 IP 协议 IP（IPv4、IPv6）相当于 OSI 参考模型中的第3层——网络层。网络层的主要作用是“实现终端节点之间的通信”。这种终端节点之间的通信也叫“点对点通信”。 网络的下一层——数据链路层的主要作用是在互连同一种数据链路的节点之间进行包传递。而一旦跨越多种数据链路，就需要借助网络层。网络层可以跨越不同的数据链路，即使是在不同的数据链路上也能实现两端节点之间的数据包传输。 IP 大致分为三大作用模块，它们是 IP 寻址、路由（最终节点为止的转发）以及 IP 分包与组包。 IP地址 在计算机通信中，为了识别通信对端，必须要有一个类似于地址的识别码进行标识。在数据链路中的 MAC 地址正是用来标识同一个链路中不同计算机的一种识别码。 作为网络层的 IP ,也有这种地址信息，一般叫做 IP 地址。IP 地址用于在“连接到网络中的所有主机中识别出进行通信的目标地址”。因此，在 TCP/IP 通信中所有主机或路由器必须设定自己的 IP 地址。 不论一台主机与哪种数据链路连接，其 IP 地址的形式都保持不变。 IP 地址（IPv4 地址）由32位正整数来表示。IP 地址在计算机内部以二进制方式被处理。然而，由于我们并不习惯于采用二进制方式，我们将32位的 IP 地址以每8位为一组，分成4组，每组以 “.” 隔开，再将每组数转换成十进制数。如下： 2^8 2^8 2^8 2^8 2^8 10101100 00010100 00000001 00000001 （2进制） 10101100. 00010100. 00000001. 00000001 （2进制） 172. 20. 1. 1 （10进制） IP地址详解 IP地址（IPv4 地址）由32位正整数来表示，由（网络标识 + 主机识别） 定义 网络标识 对应的网络地址(不是ip地址哦) 一个网段内可容纳的主机地址上限 A IP 地址是首位以 “0” 开头的地址 1 ~ 8 0.0.0.0 ~ 127.0.0.0 16,777,214 B IP 地址是首位以 “10” 开头的地址 1 ~ 16 128.0.0.0 ~ 191.255.0.0 65,534 C IP 地址是首位以 “110” 开头的地址 1 ~ 24 192.0.0.0 ~ 223.255.255.0 254 D IP 地址是首位以 “1110” 开头的地址 1 ~ 32 224.0.0.0 ~ 239.255.255.255 没有主机标识，常用于多播 在分配 IP 地址时关于主机标识有一点需要注意。即要用比特位表示主机地址时，不可以全部为 0 或全部为 1。 因为全部为 0 只有在表示对应的网络地址或 IP 地址不可以获知的情况下才使用。 而全部为 1 的主机通常作为广播地址。因此，在分配过程中，应该去掉这两种情况。这也是为什么 C 类地址每个网段最多只能有 254（ 28 - 2 = 254）个主机地址的原因。 关于IP更加详细的介绍请见计算机网络（四）：IP 详解","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"https://overtalk.site/tags/tcp/"},{"name":"ip","slug":"ip","permalink":"https://overtalk.site/tags/ip/"}]},{"title":"计算机网络 - OSI & TCP/IP","slug":"network","date":"2019-10-23T04:54:13.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/10/23/network/","link":"","permalink":"https://overtalk.site/2019/10/23/network/","excerpt":"","text":"本篇博客主要用于记录我匮乏的网络相关的知识 作为一个 Web 程序员👨‍💻‍，对于网络模型你应该了解，知道网络到底是怎么进行通信的，进行工作的，为什么服务器能够接收到请求，做出响应。这里面的原理应该是每个 Web 程序员应该了解的。 网络七层模型 - OSI OSI（Open System Interconnection）是一个开放性的通行系统 互连参考模型 。 是一个 理论模型 ；实际工业中并没有这么设计的。 网络模型历史及起源 网络模型不是一开始就有的，在网络刚发展时，网络协议是由各互联网公司自己定义的，比如那时的巨头网络公司 IBM、微软、苹果、思科等等，他们每家公司都有自己的网络协议，各家的协议也是不能互通的，那时候大家觉得这是可以的，但对消费者来说这实际上是技术垄断，因为你买了苹果的设备就不能用微软的设备，因为他们的协议不是一样的，没有统一的标准来规范网络协议，都是这些公司的私有协议。 这样大大的阻碍了互联网的发展，为了解决这个问题，国际标准化组织 1984 提出的模型标准，简称 OSI（Open Systems Interconnection Model），这是一个标准，并非实现。 OSI 模型是从上往下的，越底层越接近硬件，越往上越接近软件，这七层模型分别是物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。 这种分层模型是我们计算机科学中常用的方法，分层直接通过规定好的接口进行交互，每一层其实对它的上层或下层都是一个黑盒，其实它的上层和下层也不关心它内部的实现，只关心它们之间进行交互的接口，接口是规定的信息，要给到什么都是规定好的。 这种分层模型的好处就是可以对任何一层进行独立升级、优化，只要保持接口不变那么这个模型整体就不会有问题，比如说物理层从以太网线到光纤，我们的网络速度大大提高，但是整个技术革新的时候，其他层是没有做更多工作的，工作只在物理层完成。这样做的好处也同时提高了我们技术的发展革新速度。 通信示意图 分层功能指责 分层名称 功能 1 物理层 负责比特流与电子信号之间的互换 2 数据链路层 将0、1序列划分为具有意义的数据帧传送给对端 3 网络层 负责将数据传输到目标地址。目标地址可以使多个网络通过路由器连接而成的某一个地址。因此这一层主要负责寻址和路由选择 4 传输层 管理两个节点之间的数据传输（确保数据被可靠的传输到目标地址） 5 会话层 负责建立和断开通信连接（数据流动的逻辑通路），以及数据的分割等数据传输相关的管理 6 表示层 将应用处理的信息转换为适合网络传输的格式，或者将来自下一层的数据转换为上层能处理的格式。它主要负责数据格式的转换 7 应用层 为应用程序提供服务并规定应用程序中通讯相关的细节，也就是为应用提供服务 总结一下 在7层模型中，每一层都提供一个特殊的网络功能。从网络功能的角度观察： 下面4层（物理层、数据链路层、网络层和传输层）主要提供数据传输和交换功能，即以节点到节点之间的通信为主； 第4层作为上下两部分的桥梁，是整个网络体系结构中最关键的部分； 而上3层（会话层、表示层和应用层）则以提供用户与应用程序之间的信息和数据处理功能为主。 简言之，下4层主要完成通信子网的功能，上3层主要完成资源子网的功能。 TCP/IP 通常说TCP/IP是Internet协议族，而不单单是TCP和IP这两个协议。其他的例如：文件传输（FTP）和电子邮件（SMTP）等，而TCP协议和IP协议是保证数据完整传输的两个基本的重要协议。 TCP/IP是实际上的网络体系结构和协议标准 TCP/IP是四层模型结构 TCP/IP和OSI的对比 注：在TCP/IP中的各层名称也有不同： 应用层 传输层 网络层 数据链路层","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Network","slug":"Network","permalink":"https://overtalk.site/tags/Network/"}]},{"title":"Mac上的工具软件","slug":"tools","date":"2019-10-23T02:55:36.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/10/23/tools/","link":"","permalink":"https://overtalk.site/2019/10/23/tools/","excerpt":"","text":"记录一下个人的mac开发工具 编程IDE VsCode Goland Clion PyCharm Xcode Sublime Text 开发工具 git gui docker oss-browser iTerm2 Postman Vmware Fusion File Zilla Dash 数据库相关 Sequel Pro (mysql 可视化工具) 下载地址 rdm （redis 可视化工具） 下载地址 Robo 3T （mongo 可视化工具） 小工具 有道词典 Keka （解压缩工具） karabiner （修改键位） 1 password Go2Shell (从Finder中直接打开终端) iStat Menus (cpu，内存，网络 检测工具) FinderPath (在Finder中可以修改路径) paste (记录上次的复制粘贴) Notion (文档编辑) Typora (markdown编辑工具)","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"mac","slug":"mac","permalink":"https://overtalk.site/tags/mac/"}]},{"title":"golang csv 解析","slug":"go-csv","date":"2019-10-22T12:08:43.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/10/22/go-csv/","link":"","permalink":"https://overtalk.site/2019/10/22/go-csv/","excerpt":"","text":"golang 操作csv文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105package mainimport ( \"bytes\" \"encoding/csv\" \"flag\" \"fmt\" \"io\" \"io/ioutil\" \"os\")var ( fileName = \"test.csv\" mode string)type Book struct &#123; Author string Title string&#125;func (book *Book) toSlice() []string &#123; return []string&#123;book.Author, book.Title&#125;&#125;func toCSV(lines [][]string, w io.Writer) error &#123; n := csv.NewWriter(w) for _, line := range lines &#123; err := n.Write(line) if err != nil &#123; return err &#125; &#125; n.Flush() return n.Error()&#125;func writeCSV() error &#123; // init books := []Book&#123; Book&#123; Author: \"F Scott Fitzgerald\", Title: \"The Great Gatsby\", &#125;, Book&#123; Author: \"J D Salinger\", Title: \"The Catcher in the Rye\", &#125;, &#125; var items [][]string for _, book := range books &#123; items = append(items, book.toSlice()) &#125; buffer := new(bytes.Buffer) if err := toCSV(items, buffer); err != nil &#123; return err &#125; // save to files f, err := os.Create(fileName) defer f.Close() if err != nil &#123; return err &#125; _, err = f.WriteString(buffer.String()) return err&#125;func readCSV() error &#123; f, err := ioutil.ReadFile(fileName) if err != nil &#123; return err &#125; buffer := bytes.NewBufferString(string(f)) csvReader := csv.NewReader(buffer) csvReader.Comma = ';' csvReader.Comment = '-' records, err := csvReader.ReadAll() if err != nil &#123; return err &#125; fmt.Println(records) return nil&#125;func main() &#123; flag.StringVar(&amp;mode, \"mode\", \"\", \"read/write csv file\") flag.Parse() switch mode &#123; case \"write\": writeCSV() case \"read\": readCSV() default: flag.Usage() &#125;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"Ansible","slug":"ansible","date":"2019-10-22T06:46:49.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/10/22/ansible/","link":"","permalink":"https://overtalk.site/2019/10/22/ansible/","excerpt":"","text":"ansible是一款基于ssh管理服务器的工具 这儿是 中文文档 和 English Docs 简介 ansible是个什么东西呢？官方的title是“Ansible is Simple IT Automation”——简单的自动化IT工具。这个工具的目标有这么几项：自动化部署APP；自动化管理配置项；自动化的持续交互；自动化的（AWS）云服务管理。所有的这几个目标从本质上来说都是在一个台或者几台服务器上，执行一系列的命令而已。通俗的说就是批量的在远程服务器上执行命令 。当然，最主要的是它是基于 paramiko 开发的。这个paramiko是什么呢？它是一个纯Python实现的ssh协议库。因此fabric和ansible还有一个共同点就是不需要在远程主机上安装client/agents，因为它们是基于ssh来和远程主机通讯的。简单归纳一下： Ansible:—基于 Python paramiko 开发，分布式，无需客户端，轻量级，配置语法使用 YMAL 及 Jinja2模板语言，更强的远程命令执行操作 类似的自动化运维工具有很多常用的还有： Puppet（基于 Ruby 开发，采用 C/S 架构，扩展性强，基于 SSL，远程命令执行相对较弱） 安装 mac 123456brew install ansible``` - linux```bashyum -y install ansible 安装好之后，需要编辑被管理机器的host 12345678910111213#编辑添加ansible的hosts配置文件vim /etc/ansible/hosts [group1]192.168.18.91[group2]192.168.18.92[group3]192.168.18.93[all:vars]ansible_ssh_user=root 测试是否可通 12345678910111213141516171819202122ansible all -m ping192.168.18.91 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"ping\": \"pong\"&#125;192.168.18.92 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"ping\": \"pong\"&#125;192.168.18.93 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"ping\": \"pong\"&#125; 一些简单的ansible命令12345678# as bruceansible all -m ping -u bruce# as bruce, sudoing to rootansible all -m ping -u bruce --sudo# as bruce, sudoing to batmanansible all -m ping -u bruce --sudo --sudo-user batman# 所有的目标节点运行命令(俗称ad-hoc命令)ansible all -a \"/bin/echo hello\" Inventory文件 Ansible 可同时操作属于一个组的多台主机,组和主机之间的关系通过 inventory 文件配置. 默认的文件路径为 /etc/ansible/hosts 除默认文件外,你还可以同时使用多个 inventory 文件 主机与组 /etc/ansible/hosts 文件的格式 12345678910mail.example.com[webservers]foo.example.combar.example.com[dbservers]one.example.comtwo.example.comthree.example.com 方括号[]中是组名 一个系统可以属于不同的组,比如一台服务器可以同时属于 webserver组 和 dbserver组.这时属于两个组的变量都可以为这台主机所用,至于变量的优先级关系将于以后的章节中讨论. 如果有主机的SSH端口不是标准的22端口,可在主机名之后加上端口号 1badwolf.example.com:5309 给IP设置别名 1jumper ansible_ssh_port=5555 ansible_ssh_host=192.168.1.50 一组相似的 hostname , 可简写如下: 12[databases]db-[a:f].example.com 主机变量 前面已经提到过,分配变量给主机很容易做到,这些变量定义后可在 playbooks 中使用:123[atlanta]host1 http_port=80 maxRequestsPerChild=808host2 http_port=303 maxRequestsPerChild=909 组的变量 也可以定义属于整个组的变量:1234567[atlanta]host1host2[atlanta:vars]ntp_server=ntp.atlanta.example.comproxy=proxy.atlanta.example.com 把一个组作为另一个组的子成员 可以把一个组作为另一个组的子成员,以及分配变量给整个组使用. 这些变量可以给 /usr/bin/ansible-playbook 使用,但不能给 /usr/bin/ansible 使用:1234567891011121314151617181920212223[atlanta]host1host2[raleigh]host2host3[southeast:children]atlantaraleigh[southeast:vars]some_server=foo.southeast.example.comhalon_system_timeout=30self_destruct_countdown=60escape_pods=2[usa:children]southeastnortheastsouthwestnorthwest 分文件定义 Host 和 Group 变量 在 inventory 主文件中保存所有的变量并不是最佳的方式.还可以保存在独立的文件中,这些独立文件与 inventory 文件保持关联. 不同于 inventory 文件(INI 格式),这些独立文件的格式为 YAML. 假设 inventory 文件的路径为: 1/etc/ansible/hosts 假设有一个主机名为 ‘foosball’, 主机同时属于两个组,一个是 ‘raleigh’, 另一个是 ‘webservers’. 那么以下配置文件(YAML 格式)中的变量可以为 ‘foosball’ 主机所用.依次为 ‘raleigh’ 的组变量,’webservers’ 的组变量,’foosball’ 的主机变量: 123/etc/ansible/group_vars/raleigh/etc/ansible/group_vars/webservers/etc/ansible/host_vars/foosball Inventory 参数的说明 如同前面提到的,通过设置下面的参数,可以控制 ansible 与远程主机的交互方式,其中一些我们已经讲到过: 1234567891011121314151617181920212223242526272829303132ansible_ssh_host 将要连接的远程主机名.与你想要设定的主机的别名不同的话,可通过此变量设置.ansible_ssh_port ssh端口号.如果不是默认的端口号,通过此变量设置.ansible_ssh_user 默认的 ssh 用户名ansible_ssh_pass ssh 密码(这种方式并不安全,我们强烈建议使用 --ask-pass 或 SSH 密钥)ansible_sudo_pass sudo 密码(这种方式并不安全,我们强烈建议使用 --ask-sudo-pass)ansible_sudo_exe (new in version 1.8) sudo 命令路径(适用于1.8及以上版本)ansible_connection 与主机的连接类型.比如:local, ssh 或者 paramiko. Ansible 1.2 以前默认使用 paramiko.1.2 以后默认使用 'smart','smart' 方式会根据是否支持 ControlPersist, 来判断'ssh' 方式是否可行.ansible_ssh_private_key_file ssh 使用的私钥文件.适用于有多个密钥,而你不想使用 SSH 代理的情况.ansible_shell_type 目标系统的shell类型.默认情况下,命令的执行使用 'sh' 语法,可设置为 'csh' 或 'fish'.ansible_python_interpreter 目标主机的 python 路径.适用于的情况: 系统中有多个 Python, 或者命令路径不是\"/usr/bin/python\",比如 \\*BSD, 或者 /usr/bin/python 不是 2.X 版本的 Python.我们不使用 \"/usr/bin/env\" 机制,因为这要求远程用户的路径设置正确,且要求 \"python\" 可执行程序名不可为 python以外的名字(实际有可能名为python26). 与 ansible_python_interpreter 的工作方式相同,可设定如 ruby 或 perl 的路径.... 一个主机文件的例子: 1234some_host ansible_ssh_port=2222 ansible_ssh_user=manageraws_host ansible_ssh_private_key_file=/home/example/.ssh/aws.pemfreebsd_host ansible_python_interpreter=/usr/local/bin/pythonruby_module_host ansible_ruby_interpreter=/usr/bin/ruby.1.9.3 Ansible的配置文件 ansible配置文件，ansible.cfg Ansible 的配置文件的查找顺序如下： 环境变量 ANSIBLE_CONFIG 当前目录下的 ansible.cfg （这个比较重要，一般用这个比较多） home 目录下的 ~/.ansible.cfg /etc/ansible/ansible.cfg Ansible 使用找到的第一个文件，忽略其余的。 配置文件的几个组成部分: [defaults] —&gt;通用默认配置 [privilege_escalation] —&gt; 提权配置 [paramiko_connection] [ssh_connection] [accelerate] 例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159[defaults] ---&gt;通用默认配置# some basic default values...inventory = /etc/ansible/hosts 这个是默认库文件位置,脚本,或者存放可通信主机的目录#library = /usr/share/my_modules/ Ansible默认搜寻模块的位置remote_tmp = $HOME/.ansible/tmp Ansible 通过远程传输模块到远程主机,然后远程执行,执行后在清理现场.在有些场景下,你也许想使用默认路径希望像更换补丁一样使用pattern = * 如果没有提供“hosts”节点,这是playbook要通信的默认主机组.默认值是对所有主机通信forks = 5 在与主机通信时的默认并行进程数 ，默认是5dpoll_interval = 15 当具体的poll interval 没有定义时,多少时间回查一下这些任务的状态, 默认值是5秒sudo_user = root sudo使用的默认用户 ，默认是root#ask_sudo_pass = True 用来控制Ansible playbook 在执行sudo之前是否询问sudo密码.默认为no#ask_pass = True 控制Ansible playbook 是否会自动默认弹出密码transport = smart 通信机制.默认 值为’smart’。如果本地系统支持 ControlPersist技术的话,将会使用(基于OpenSSH)‘ssh’,如果不支持讲使用‘paramiko’.其他传输选项包括‘local’, ‘chroot’,’jail’等等#remote_port = 22 远程SSH端口。 默认是22module_lang = C 模块和系统之间通信的计算机语言，默认是C语言# plays will gather facts by default, which contain information about# the remote system.## smart - gather by default, but don't regather if already gathered# implicit - gather by default, turn off with gather_facts: False# explicit - do not gather by default, must say gather_facts: Truegathering = implicit 控制默认facts收集（远程系统变量）. 默认值为’implicit’, 每一次play,facts都会被收集# additional paths to search for roles in, colon separated#roles_path = /etc/ansible/roles roles 路径指的是’roles/’下的额外目录,用于playbook搜索Ansible roles# uncomment this to disable SSH key host checking#host_key_checking = False 检查主机密钥# change this for alternative sudo implementationssudo_exe = sudo 如果在其他远程主机上使用另一种方式执sudu操作.可以使用该参数进行更换# what flags to pass to sudo 传递sudo之外的参数#sudo_flags = -H# SSH timeout SSH超时时间timeout = 10# default user to use for playbooks if user is not specified# (/usr/bin/ansible will use current user as default)#remote_user = root 使用/usr/bin/ansible-playbook链接的默认用户名，如果不指定，会使用当前登录的用户名# logging is off by default unless this path is defined# if so defined, consider logrotate#log_path = /var/log/ansible.log 日志文件存放路径# default module name for /usr/bin/ansible#module_name = command ansible命令执行默认的模块# use this shell for commands executed under sudo# you may need to change this to bin/bash in rare instances# if sudo is constrained#executable = /bin/sh 在sudo环境下产生一个shell交互接口. 用户只在/bin/bash的或者sudo限制的一些场景中需要修改# if inventory variables overlap, does the higher precedence one win# or are hash values merged together? The default is 'replace' but# this can also be set to 'merge'.#hash_behaviour = replace 特定的优先级覆盖变量# list any Jinja2 extensions to enable here:#jinja2_extensions = jinja2.ext.do,jinja2.ext.i18n 允许开启Jinja2拓展模块# if set, always use this private key file for authentication, same as # if passing --private-key to ansible or ansible-playbook#private_key_file = /path/to/file 私钥文件存储位置# format of string &#123;&#123; ansible_managed &#125;&#125; available within Jinja2 # templates indicates to users editing templates files will be replaced.# replacing &#123;file&#125;, &#123;host&#125; and &#123;uid&#125; and strftime codes with proper values.ansible_managed = Ansible managed: &#123;file&#125; modified on %Y-%m-%d %H:%M:%S by &#123;uid&#125; on &#123;host&#125; 这个设置可以告知用户,Ansible修改了一个文件,并且手动写入的内容可能已经被覆盖.# by default, ansible-playbook will display \"Skipping [host]\" if it determines a task# should not be run on a host. Set this to \"False\" if you don't want to see these \"Skipping\" # messages. NOTE: the task header will still be shown regardless of whether or not the # task is skipped.#display_skipped_hosts = True 显示任何跳过任务的状态 ，默认是显示# by default (as of 1.3), Ansible will raise errors when attempting to dereference # Jinja2 variables that are not set in templates or action lines. Uncomment this line# to revert the behavior to pre-1.3.#error_on_undefined_vars = False 如果所引用的变量名称错误的话, 将会导致ansible在执行步骤上失败# by default (as of 1.6), Ansible may display warnings based on the configuration of the# system running ansible itself. This may include warnings about 3rd party packages or# other conditions that should be resolved if possible.# to disable these warnings, set the following value to False:#system_warnings = True 允许禁用系统运行ansible相关的潜在问题警告# by default (as of 1.4), Ansible may display deprecation warnings for language# features that should no longer be used and will be removed in future versions.# to disable these warnings, set the following value to False:#deprecation_warnings = True 允许在ansible-playbook输出结果中禁用“不建议使用”警告# (as of 1.8), Ansible can optionally warn when usage of the shell and# command module appear to be simplified by using a default Ansible module# instead. These warnings can be silenced by adjusting the following# setting or adding warn=yes or warn=no to the end of the command line # parameter string. This will for example suggest using the git module# instead of shelling out to the git command.# command_warnings = False 当shell和命令行模块被默认模块简化的时,Ansible 将默认发出警告# set plugin path directories here, separate with colonsaction_plugins = /usr/share/ansible_plugins/action_plugins callback_plugins = /usr/share/ansible_plugins/callback_pluginsconnection_plugins = /usr/share/ansible_plugins/connection_pluginslookup_plugins = /usr/share/ansible_plugins/lookup_pluginsvars_plugins = /usr/share/ansible_plugins/vars_pluginsfilter_plugins = /usr/share/ansible_plugins/filter_plugins# by default callbacks are not loaded for /bin/ansible, enable this if you# want, for example, a notification or logging callback to also apply to # /bin/ansible runs#bin_ansible_callbacks = False 用来控制callback插件是否在运行 /usr/bin/ansible 的时候被加载. 这个模块将用于命令行的日志系统,发出通知等特性# don't like cows? that's unfortunate.# set to 1 if you don't want cowsay support or export ANSIBLE_NOCOWS=1 #nocows = 1 默认ansible可以调用一些cowsay的特性 开启/禁用：0/1# don't like colors either?# set to 1 if you don't want colors, or export ANSIBLE_NOCOLOR=1#nocolor = 1 输出带上颜色区别， 开启/关闭：0/1# the CA certificate path used for validating SSL certs. This path # should exist on the controlling node, not the target nodes# common locations:# RHEL/CentOS: /etc/pki/tls/certs/ca-bundle.crt# Fedora : /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem# Ubuntu : /usr/share/ca-certificates/cacert.org/cacert.org.crt#ca_file_path = # the http user-agent string to use when fetching urls. Some web server# operators block the default urllib user agent as it is frequently used# by malicious attacks/scripts, so we set it to something unique to # avoid issues.#http_user_agent = ansible-agent# if set to a persistent type (not 'memory', for example 'redis') fact values# from previous runs in Ansible will be stored. This may be useful when# wanting to use, for example, IP information from one group of servers# without having to talk to them in the same playbook run to get their# current IP information.fact_caching = memory# retry files#retry_files_enabled = False#retry_files_save_path = ~/.ansible-retry[privilege_escalation]#become=True#become_method=sudo#become_user=root#become_ask_pass=False[paramiko_connection]# uncomment this line to cause the paramiko connection plugin to not record new host# keys encountered. Increases performance on new host additions. Setting works independently of the# host key checking setting above.#record_host_keys=False# by default, Ansible requests a pseudo-terminal for commands executed under sudo. Uncomment this# line to disable this behaviour.#pty=False[ssh_connection]# ssh arguments to use# Leaving off ControlPersist will result in poor performance, so use # paramiko on older platforms rather than removing it#ssh_args = -o ControlMaster=auto -o ControlPersist=60s# The path to use for the ControlPath sockets. This defaults to# \"%(directory)s/ansible-ssh-%%h-%%p-%%r\", however on some systems with# very long hostnames or very long path names (caused by long user names or # deeply nested home directories) this can exceed the character limit on# file socket names (108 characters for most platforms). In that case, you # may wish to shorten the string below.# # Example: # control_path = %(directory)s/%%h-%%r#control_path = %(directory)s/ansible-ssh-%%h-%%p-%%r# Enabling pipelining reduces the number of SSH operations required to # execute a module on the remote server. This can result in a significant # performance improvement when enabled, however when using \"sudo:\" you must # first disable 'requiretty' in /etc/sudoers## By default, this option is disabled to preserve compatibility with# sudoers configurations that have requiretty (the default on many distros).# #pipelining = False# if True, make ansible use scp if the connection type is ssh # (default is sftp)#scp_if_ssh = True[accelerate]accelerate_port = 5099accelerate_timeout = 30accelerate_connect_timeout = 5.0# The daemon timeout is measured in minutes. This time is measured# from the last activity to the accelerate daemon.accelerate_daemon_timeout = 30 # If set to yes, accelerate_multi_key will allow multiple# private keys to be uploaded to it, though each user must# have access to the system via SSH to add a new key. The default# is \"no\".#accelerate_multi_key = yes[selinux]# file systems that require special treatment when dealing with security context# the default behaviour that copies the existing context or uses the user default# needs to be changed to use the file system dependant context.#special_context_filesystems=nfs,vboxsf,fuse Playbooks Playbooks 是 Ansible的配置,部署,编排语言.他们可以被描述为一个需要希望远程主机执行命令的方案,或者一组IT程序运行的命令集合. playbook 由一个或多个 ‘plays’ 组成.它的内容是一个以 ‘plays’ 为元素的列表. 在 play 之中,一组机器被映射为定义好的角色.在 ansible 中,play 的内容,被称为 tasks,即任务.在基本层次的应用中,一个任务是一个对 ansible 模块的调用 demo 如下所示，其中仅包含一个 play： 123456789101112131415161718---- hosts: webservers vars: http_port: 80 max_clients: 200 remote_user: root tasks: - name: ensure apache is at the latest version yum: pkg=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: ensure apache is running service: name=httpd state=started handlers: - name: restart apache service: name=httpd state=restarted Playbook基础主机与用户 你可以为 playbook 中的每一个 play,个别地选择操作的目标机器是哪些,以哪个用户身份去完成要执行的步骤（called tasks）. hosts 行的内容是一个或多个组或主机的 patterns,以逗号为分隔符，remote_user 就是账户名: 123---- hosts: webservers remote_user: root 再者,在每一个 task 中,可以定义自己的远程用户: 1234567---- hosts: webservers remote_user: root tasks: - name: test connection ping: remote_user: yourname 也支持从 sudo 执行命令: 1234---- hosts: webservers remote_user: yourname sudo: yes 同样的,你可以仅在一个 task 中,使用 sudo 执行命令,而不是在整个 play 中使用 sudo: 123456---- hosts: webservers remote_user: yourname tasks: - service: name=nginx state=started sudo: yes 你也可以登陆后,sudo 到不同的用户身份,而不是使用 root: 12345---- hosts: webservers remote_user: yourname sudo: yes sudo_user: postgres Tasks 列表 每一个 play 包含了一个 task 列表（任务列表）. 每一个 task 必须有一个名称 name, 一个 task 在其所对应的所有主机上（通过 host pattern 匹配的所有主机）执行完毕之后,下一个 task 才会执行. 有一点需要明白的是（很重要）,在一个 play 之中,所有 hosts 会获取相同的任务指令,这是 play 的一个目的所在,也就是将一组选出的 hosts 映射到 task. 在运行 playbook 时（从上到下执行）,如果一个 host 执行 task 失败,这个 host 将会从整个 playbook 的 rotation 中移除. 如果发生执行失败的情况,请修正 playbook 中的错误,然后重新执行即可. 执行一个Playbook 这里的示例是并行的运行 playbook,并行的级别 是10 :1ansible-playbook playbook.yml -f 10 Playbook 角色(Roles) 和 Include 语句 为了避免将playbook写成一个超大的文件 Include 导入 task 一个 task include file 由一个普通的 task 列表所组成，像这样: 12345678---# possibly saved as tasks/foo.yml- name: placeholder foo command: /bin/foo- name: placeholder bar command: /bin/bar Include 指令看起来像下面这样，在一个 playbook 中，Include 指令可以跟普通的 task 混合在一起使用: 123tasks: - include: tasks/foo.yml 举个例子，如果我们要部署多个 wordpress 实例，我们可将所有的 wordpress task 写在一个 wordpress.yml 文件中， 然后像下面这样使用 wordpress.yml 文件: 1234tasks: - include: wordpress.yml wp_user=timmy - include: wordpress.yml wp_user=alice - include: wordpress.yml wp_user=bob 如果你运行的是 Ansible 1.4 及以后的版本，include 语法可更为精简，这种写法同样允许传递列表和字典参数: 12tasks: - &#123; include: wordpress.yml, wp_user: timmy, ssh_keys: [ 'keys/one.txt', 'keys/two.txt' ] &#125; Include 导入 handlers 重启 apache 的 handler 1234---# this might be in a file like handlers/handlers.yml- name: restart apache service: name=apache state=restarted 然后在你的主 playbook 文件中，在一个 play 的最后使用 include 包含 handlers.yml: 12handlers: - include: handlers/handlers.yml Roles 你现在已经学过 tasks 和 handlers，那怎样组织 playbook 才是最好的方式呢？简单的回答就是：使用 roles ! Roles 基于一个已知的文件结构，去自动的加载某些 vars_files，tasks 以及 handlers。基于 roles 对内容进行分组，使得我们可以容易地与其他用户分享 roles 。 一个项目的结构如下: 1234567891011121314151617181920site.ymlwebservers.ymlfooservers.ymlroles/ common/ files/ templates/ tasks/ handlers/ vars/ defaults/ meta/ webservers/ files/ templates/ tasks/ handlers/ vars/ defaults/ meta/ 一个 playbook 如下: 12345---- hosts: webservers roles: - common - webservers 这个 playbook 为一个角色 ‘x’ 指定了如下的行为： 如果 roles/x/tasks/main.yml 存在, 其中列出的 tasks 将被添加到 play 中 如果 roles/x/handlers/main.yml 存在, 其中列出的 handlers 将被添加到 play 中 如果 roles/x/vars/main.yml 存在, 其中列出的 variables 将被添加到 play 中 如果 roles/x/meta/main.yml 存在, 其中列出的 “角色依赖” 将被添加到 roles 列表中 (1.3 and later) 所有 copy tasks 可以引用 roles/x/files/ 中的文件，不需要指明文件的路径。 所有 script tasks 可以引用 roles/x/files/ 中的脚本，不需要指明文件的路径。 所有 template tasks 可以引用 roles/x/templates/ 中的文件，不需要指明文件的路径。 所有 include tasks 可以引用 roles/x/tasks/ 中的文件，不需要指明文件的路径。 如果 roles 目录下有文件不存在，这些文件将被忽略。比如 roles 目录下面缺少了 ‘vars/’ 目录，这也没关系。 而且，如果你愿意，也可以使用参数化的 roles，这种方式通过添加变量来实现，比如: 1234567---- hosts: webservers roles: - common - &#123; role: foo_app_instance, dir: '/opt/a', port: 5000 &#125; - &#123; role: foo_app_instance, dir: '/opt/b', port: 5001 &#125; 当一些事情不需要频繁去做时，你也可以为 roles 设置触发条件，像这样: 12345---- hosts: webservers roles: - &#123; role: some_role, when: \"ansible_os_family == 'RedHat'\" &#125; 最后，你可能希望给 roles 分配指定的 tags。比如： 12345---- hosts: webservers roles: - &#123; role: foo, tags: [\"bar\", \"baz\"] &#125; 如果 play 仍然包含有 ‘tasks’ section，这些 tasks 将在所有 roles 应用完成之后才被执行。 如果你希望定义一些 tasks，让它们在 roles 之前以及之后执行，你可以这样做: 123456789101112131415---- hosts: webservers pre_tasks: - shell: echo 'hello' roles: - &#123; role: some_role &#125; tasks: - shell: echo 'still busy' post_tasks: - shell: echo 'goodbye' 角色默认变量(Role Default Variables) 角色默认变量允许你为 included roles 或者 dependent roles(见下) 设置默认变量。要创建默认变量，只需在 roles 目录下添加 defaults/main.yml 文件。这些变量在所有可用变量中拥有最低优先级，可能被其他地方定义的变量(包括 inventory 中的变量)所覆盖。 角色依赖(Role Dependencies) “角色依赖” 使你可以自动地将其他 roles 拉取到现在使用的 role 中。”角色依赖” 保存在 roles 目录下的 meta/main.yml 文件中。这个文件应包含一列 roles 和 为之指定的参数，下面是在 roles/myapp/meta/main.yml 文件中的示例:12345---dependencies: - &#123; role: common, some_parameter: 3 &#125; - &#123; role: apache, port: 80 &#125; - &#123; role: postgres, dbname: blarg, other_parameter: 12 &#125; Variables To be continued 条件选择 To be continued 循环 To be continued","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"ssh","slug":"ssh","permalink":"https://overtalk.site/tags/ssh/"}]},{"title":"Golang Notes","slug":"go-notes","date":"2019-10-22T02:02:57.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/10/22/go-notes/","link":"","permalink":"https://overtalk.site/2019/10/22/go-notes/","excerpt":"","text":"Golang使用过程中的一些笔记 TCP 使用net.Listen()来接受tcp请求时候，如果不指定addr，则会随机一个端口12345678910111213141516171819202122232425262728package mainimport ( \"fmt\" \"log\" \"net\")func main() &#123; l, err := net.Listen(\"tcp\", \"\") if err != nil &#123; log.Fatal(err) &#125; fmt.Println(l.Addr()) for &#123; c, err := l.Accept() if err != nil &#123; log.Println(err) continue &#125; go func(c net.Conn) &#123; c.(*net.TCPConn).SetKeepAlive(true) // nolint: errcheck // todo something &#125;(c) &#125;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"Socks5","slug":"network-socks5","date":"2019-10-21T07:40:10.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/10/21/network-socks5/","link":"","permalink":"https://overtalk.site/2019/10/21/network-socks5/","excerpt":"","text":"socks5是一种网络传输协议，主要用于客户端与目标服务器之间的透明传递。 socks5 是一个简单的代理协议，这里是RFC·整个协议其实就是在建立TCP连接之后，真正的内容传输之前，加一点内容 主要工作流程 客户端连接上代理服务器之后需要发送请求告知服务器目前的socks协议版本以及支持的认证方式 代理服务器收到请求后根据其设定的认证方式返回给客户端 如果代理服务器不需要认证，客户端将直接向代理服务器发起真实请求 代理服务器收到该请求之后连接客户端请求的目标服务器 代理服务器开始转发客户端与目标服务器之间的流量 认证过程2.1 客户端发出请求 建立TCP连接之后，Client发送如下数据：12345+----+----------+----------+|VER | NMETHODS | METHODS |+----+----------+----------+| 1 | 1 | 1 to 255 |+----+----------+----------+ VER 是指SOCKS协议版本，以为是socks5，所以值就是0x05 NMETHODS 是指有多少个可以使用的方法，也就是客户端支持的认证方法，有以下值： 0x00 NO AUTHENTICATION REQUIRED 不需要认证 0x01 GSSAPI 参考:GenericSecurityServicesApplicationProgram_Interface 0x02 USERNAME/PASSWORD 用户名密码认证 0x03 to 0x7f IANA ASSIGNED 一般不用。INNA保留。 0x80 to 0xfe RESERVED FOR PRIVATE METHODS 保留作私有用处。 0xFF NO ACCEPTABLE METHODS 不接受任何方法/没有合适的方法 METHODS 就是方法值，有多少个方法就有多少个byte 2.2 Server返回可以使用的方法 收到Client的请求之后，Server选择一个自己也支持的认证方案，然后返回：12345+----+--------+|VER | METHOD |+----+--------+| 1 | 1 |+----+--------+ VER 和 METHOD 的取值与上一节相同 2.3 客户端告知目标地址12345+----+-----+-------+------+----------+----------+|VER | CMD | RSV | ATYP | DST.ADDR | DST.PORT |+----+-----+-------+------+----------+----------+| 1 | 1 | X'00' | 1 | Variable | 2 |+----+-----+-------+------+----------+----------+ VER 还是版本，取值是 0x05 CMD 是指要做啥，取值如下： CONNECT 0x01 连接，用于客户端请求服务器进行代理，此时绑定的地址是指代理服务器连接到目标机器时的ip和端口 BIND 0x02 端口监听(也就是在Server上监听一个端口)，用于客户端向服务器上报自己的反向连接监听地址（应用场景如 FTP 下载，客户端需要接受来自服务器的连接 UDP ASSOCIATE 0x03 使用UDP，用于请求建立到 UDP 数据报中继的连接 RSV 是保留位，值是 0x00 ATYP 是目标地址类型，有如下取值： 0x01 IPv4 0x03 域名 0x04 IPv6 DST.ADDR 就是目标地址的值了，如果是IPv4，那么就是4 bytes，如果是IPv6那么就是16 bytes，如果是域名，那么第一个字节代表 接下来有多少个字节是表示目标地址 DST.PORT 两个字节代表端口号 2.4 服务端回复 SOCKS服务器通常将根据源评估请求和目标地址，并返回一个或多个回复消息12345+----+-----+-------+------+----------+----------+|VER | REP | RSV | ATYP | BND.ADDR | BND.PORT |+----+-----+-------+------+----------+----------+| 1 | 1 | X'00' | 1 | Variable | 2 |+----+-----+-------+------+----------+----------+ VER 还是版本，值是 0x05 REP 是状态码，取值如下： 0x00 succeeded，代理服务器连接目标服务器成功 0x01 general SOCKS server failure，代理服务器故障 0x02 connection not allowed by ruleset，代理服务器规则集不允许连接 0x03 Network unreachable，网络无法访问 0x04 Host unreachable，目标服务器无法访问（主机名无效） 0x05 Connection refused，连接目标服务器被拒绝 0x06 TTL expired，TTL已过期 0x07 Command not supported，不支持的命令 0x08 Address type not supported，不支持的目标服务器地址类型 0x09 to 0xff unassigned，0xFF 未分配 RSV 保留位，取值为 0x00 ATYP 是目标地址类型，有如下取值： 0x01 IPv4 0x03 域名 0x04 IPv6 DST.ADDR 就是目标地址的值了，如果是IPv4，那么就是4 bytes，如果是IPv6那么就是16 bytes，如果是域名，那么第一个字节代表 接下来有多少个字节是表示目标地址 DST.PORT 两个字节代表端口号 2.5 通信过程 经过认证与命令过程后，客户端与代理服务器进入正常通信，客户端发送需要请求到目标服务器的数据给代理服务器，代理服务器转发这些数据，并把目标服务器的响应转发给客户端，起到一个“透明代理”的功能。 到了这个阶段基本就是数据转发了,tcp就直接转发,udp还须要做点工作。 客户端发送给代理服务器和代理服务器返回给客户端的数据都需要包装下12345+----+------+------+----------+----------+----------+|RSV | FRAG | ATYP | DST.ADDR | DST.PORT | DATA |+----+------+------+----------+----------+----------+| 2 | 1 | 1 | Variable | 2 | Variable |+----+------+------+----------+----------+----------+ 具体的字段含义和上述的一样，就不具体细说了，其中最后的data表示用户字段","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Socks5","slug":"Socks5","permalink":"https://overtalk.site/tags/Socks5/"}]},{"title":"Leetcode 编程笔记","slug":"algorithm-leetcode","date":"2019-10-15T08:24:17.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/10/15/algorithm-leetcode/","link":"","permalink":"https://overtalk.site/2019/10/15/algorithm-leetcode/","excerpt":"","text":"leetcode 算法题解法 持续更新 两数之和 题目12345678910111213141516171819202122232425# 将slice编程器数组，在进行求解func twoSum(nums []int, target int) []int &#123; // turn slice to map numsMap := make(map[int][]int) for index, value := range nums &#123; if numsMap[value] == nil &#123; numsMap[value] = []int&#123;&#125; &#125; numsMap[value] = append(numsMap[value], index) &#125; for value, indexArr1 := range numsMap &#123; indexArr2, isExist := numsMap[target-value] if isExist &#123; if target == value*2 &amp;&amp; len(indexArr1)&gt;=2 &#123; return []int&#123;indexArr1[0], indexArr1[1]&#125; &#125; else if target == value*2 &amp;&amp; len(indexArr1)&lt;2 &#123; return nil &#125; return []int&#123;indexArr1[0], indexArr2[0]&#125; &#125; &#125; return nil&#125; 无重复字符的最长子串 题目 滑动窗口详解1234567891011121314151617181920# 使用滑动窗口func lengthOfLongestSubstring(s string) int &#123; var i, j, max int for j &lt; len(s) &#123; if strings.Contains(s[i:j], string(s[j])) &#123; // 遇到重复的 if max &lt; j-i &#123; max = j-i &#125; i++ continue &#125; j++ &#125; if max &lt; j-i &#123; return j-i &#125; return max&#125; 最长回文子串 题目 中心扩展法12345678910111213141516171819202122# 使用滑动窗口func longestPalindrome(s string) string &#123; s = strings.Replace(s, \"\", \"|\", -1) retStr := \"\" length := len(s) for i:=0; i&lt;length; i++ &#123; left := i right := i for left-1&gt;=0 &amp;&amp; right+1&lt;length &#123; if s[left-1] != s[right+1] &#123; break &#125; left-- right++ &#125; if len(retStr) &lt; (right-left+1) &#123; retStr = s[left:right+1] &#125; &#125; return strings.Replace(retStr, \"|\", \"\", -1) &#125; 整数反转 题目123456789101112# 这一题其实不难，主要为下一题作准备func reverse(x int) ( num int) &#123; for x != 0 &#123; num = num*10 + x%10 x = x / 10 &#125; // 使用 math 包中定义好的最大最小值 if num &gt; math.MaxInt32 || num &lt; math.MinInt32 &#123; return 0 &#125; return&#125; 回文数 题目123456789101112131415161718192021222324# 判断一个数是不是回文数，可以先将其反转，然后在判断与原来的数是否相等func isPalindrome(x int) bool &#123; if x &lt; 0 &#123; return false &#125; reverseX := reverse(x) if reverseX == x &#123; return true &#125; return false&#125;func reverse(x int) ( num int) &#123; for x != 0 &#123; num = num*10 + x%10 x = x / 10 &#125; // 使用 math 包中定义好的最大最小值 if num &gt; math.MaxInt32 || num &lt; math.MinInt32 &#123; return 0 &#125; return&#125; 三数之和 [题目](https://leetcode-cn.com/problems/3sum/） 思路（双指针法思路）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;map&gt;using namespace std;class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; ret; int size = nums.size(); if (size &lt; 3) &#123; return ret; &#125; sort(nums.begin(), nums.end()); for (int i = 0; i &lt; nums.size()-2; ++i) &#123; int r1 = i+1; int r2 = size-1; // 最小的数大于0 if (nums[i] &gt; 0) &#123; continue; &#125; if ( i != 0 &amp;&amp; nums[i]==nums[i-1]) &#123; continue; &#125; while(r1 &lt; r2) &#123; int sum = nums[i] + nums[r1] + nums[r2]; if (sum&gt;0) &#123; r2 = moveR2(nums, r2); &#125; else if (sum&lt;0) &#123; r1 = moveR1(nums, r1); &#125; else &#123; ret.push_back(vector&lt;int&gt;&#123;nums[i], nums[r1], nums[r2]&#125;); r1 = moveR1(nums, r1); r2 = moveR2(nums, r2); &#125; &#125; &#125; return ret; &#125; int moveR1(vector&lt;int&gt;&amp; nums, int r1)&#123; int temp = nums[r1]; r1++; while (r1 &lt; nums.size()) &#123; if (nums[r1] != temp) &#123; break; &#125; r1++; &#125; return r1; &#125; int moveR2(vector&lt;int&gt;&amp; nums, int r2)&#123; int temp = nums[r2]; r2--; while (r2 &gt;= 0) &#123; if (nums[r2] != temp) &#123; break; &#125; r2--; &#125; return r2; &#125;&#125;;int main() &#123; vector&lt;int&gt; test = &#123;-2,0,0,2,2&#125;; Solution s; auto result = s.threeSum(test); for (auto i : result)&#123; cout&lt;&lt; i[0] &lt;&lt; i[1] &lt;&lt; i[2] &lt;&lt; endl; &#125;&#125; 最接近的三数之和 [题目](https://leetcode-cn.com/problems/3sum-closest/） 思路（双指针法思路） 这个题目和上个题目类似，都是先固定一个参数，再通过两个指针收尾移动的方法来确定12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Solution &#123;public: int threeSumClosest(vector&lt;int&gt;&amp; nums, int target) &#123; sort(nums.begin(), nums.end()); int size = nums.size(); if (size &lt; 3) &#123; return 0; &#125; int nearest = nums[0] + nums[1] + nums[size-1]; int difference = abs(nums[0] + nums[1] + nums[size-1] - target); for (int i = 0; i &lt; size-2; ++i) &#123; int r1 = i+1; int r2 = size-1; int roundNearest = nums[i] + nums[r1] + nums[r2]; int roundDifference = abs(nums[i] + nums[r1] + nums[r2] - target); while(r1 &lt; r2) &#123; int sum = nums[i] + nums[r1] + nums[r2]; if (abs(sum-target) &lt; roundDifference) &#123; roundDifference = abs(sum-target); roundNearest = sum; &#125; if (sum &lt; target) &#123; r1++; &#125; else if (sum &gt; target)&#123; r2--; &#125; else &#123; return target; &#125; &#125; if (difference &gt; roundDifference) &#123; nearest = roundNearest; difference = roundDifference; &#125; &#125; return nearest; &#125;&#125;; 矩形重叠 题目 思路： 将其映射到x，y轴上，如果相交的话，则x，y上也必定都相交 12345678910111213141516func isRectangleOverlap(rec1 []int, rec2 []int) bool &#123; xArr := []int&#123;rec1[0], rec1[2], rec2[0], rec2[2]&#125; yArr := []int&#123;rec1[1], rec1[3], rec2[1], rec2[3]&#125; xLen := (rec1[2] - rec1[0]) + (rec2[2] - rec2[0]) yLen := (rec1[3] - rec1[1]) + (rec2[3] - rec2[1]) sort.Ints(xArr) sort.Ints(yArr) if xArr[3]-xArr[0] &lt; xLen &amp;&amp; yArr[3]-yArr[0] &lt; yLen &#123; return true &#125; return false&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://overtalk.site/tags/algorithm/"}]},{"title":"flag包","slug":"go-flag","date":"2019-10-14T16:43:20.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/10/14/go-flag/","link":"","permalink":"https://overtalk.site/2019/10/14/go-flag/","excerpt":"","text":"Golang Flags包的使用简介 需要从外部传入一些依赖参数的的时候，一般来说有如下的两种方案： 配置文件 利用flags包，从命令行传入 配置文件的方法我之前介绍过解决方案，有兴趣的可以去这里看看 demo 话不多说，直接上例子 123456789101112131415161718192021222324package mainimport ( \"flag\" \"fmt\")var ( arg1 string arg2 int arg3 bool)func init() &#123; flag.StringVar(&amp;arg1, \"arg1\", \"defaultArg1\", \"arg1\") flag.IntVar(&amp;arg2, \"arg2\", 12, \"arg2\") flag.BoolVar(&amp;arg3, \"arg3\", false, \"arg3\") flag.Parse()&#125;func main() &#123; fmt.Println(\"arg1 = \", arg1) fmt.Println(\"arg2 = \", arg2) fmt.Println(\"arg3 = \", arg3)&#125; 运行 123456789&gt; go run aaa.go -hUsage of /var/folders/sx/zv6vr6pd4gsc1vv2fmbq5dyw0000gn/T/go-build386487880/b001/exe/aaa: -arg1 string arg1 (default \"defaultArg1\") -arg2 int arg2 (default 12) -arg3 arg3exit status 2 1234567891011# 默认值&gt; go run aaa.go arg1 = defaultArg1arg2 = 12arg3 = false# 参数传入&gt; go run aaa.go -arg1 test -arg2 1000 -arg3 truearg1 = testarg2 = 1000arg3 = true flag包参数传入 定义命令行参数有3种方式 flag.Xxx() 其中 Xxx 可以是 Int、String，Bool 等；返回一个相应类型的指针。 12345// Int defines an int flag with specified name, default value, and usage string.// The return value is the address of an int variable that stores the value of the flag.func Int(name string, value int, usage string) *int &#123; return CommandLine.Int(name, value, usage)&#125; demo 1var ip = flag.Int(\"flagname\", 1234, \"help message for flagname\") 第一个参数 ：flag名称为flagname 第二个参数 ：flagname默认值为1234 第三个参数 ：flagname的提示信息 flag.XxxVar() 将 flag 绑定到一个变量上 12345// IntVar defines an int flag with specified name, default value, and usage string.// The argument p points to an int variable in which to store the value of the flag.func (f *FlagSet) IntVar(p *int, name string, value int, usage string) &#123; f.Var(newIntValue(value, p), name, usage)&#125; demo 12var flagValue intflag.IntVar(&amp;flagValue, \"flagname\", 1234, \"help message for flagname\") 第一个参数 ：接收flagname的实际值的 第二个参数 ：flag名称为flagname 第三个参数 ：flagname默认值为1234 第四个参数 ：flagname的提示信息 flag.Var() 用于自定义类型，首先来个demo123456789101112131415161718192021222324252627282930313233343536373839404142package mainimport ( \"flag\" \"fmt\" \"strings\")type mySlice []string/* Value接口：type Value interface &#123; String() string Set(string) error&#125;实现flag包中的Value接口，将命令行接收到的值用,分隔存到slice里*///new一个存放命令行参数值的slicefunc newMySlice(val []string, p *[]string) *mySlice &#123; *p = val return (*mySlice)(p)&#125;func (s *mySlice) Set(val string) error &#123; *s = mySlice(strings.Split(val, \",\")) return nil&#125;func (s *mySlice) String() string &#123; *s = mySlice(strings.Split(\"default value\", \",\")) return \"\"&#125;func main() &#123; var mySlices []string flag.Var(newMySlice([]string&#123;&#125;, &amp;mySlices), \"my-slice\", \"my slices\") flag.Parse() //打印结果slice接收到的值 fmt.Println(mySlices)&#125; 这样通过 -my-slice “go,php” mySlices 得到的就是 [go, php]。如果不加-my-slice参数则打印默认值[default value] flag.Var()函数的第一个入参是一个接口1234567891011121314// Value is the interface to the dynamic value stored in a flag.// (The default value is represented as a string.)//// If a Value has an IsBoolFlag() bool method returning true,// the command-line parser makes -name equivalent to -name=true// rather than using the next command-line argument.//// Set is called once, in command line order, for each flag present.// The flag package may call the String method with a zero-valued receiver,// such as a nil pointer.type Value interface &#123; String() string Set(string) error&#125; 看注释可以看出来，如果没有传入，则调用String()函数；如果有传入，则调用Set()函数 flag包的Set 适用于n功能合1，但是只有单入口的main.go 首先看flag包中的函数1234567891011// NewFlagSet returns a new, empty flag set with the specified name and// error handling property. If the name is not empty, it will be printed// in the default usage message and in error messages.func NewFlagSet(name string, errorHandling ErrorHandling) *FlagSet &#123; f := &amp;FlagSet&#123; name: name, errorHandling: errorHandling, &#125; f.Usage = f.defaultUsage return f&#125; demo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package mainimport ( \"flag\" \"fmt\" \"os\")func main() &#123; var ( serverFlag struct &#123; mysqlAddr string port int &#125; clientFlag struct &#123; serverAddr string port int &#125; ) flag.Usage = func() &#123; fmt.Fprintf(os.Stderr, \"Usage: %s &#123;client|server&#125; \\n\", os.Args[0]) flag.PrintDefaults() &#125; // set client flags clientSet := flag.NewFlagSet(\"client\", flag.ExitOnError) clientSet.StringVar(&amp;clientFlag.serverAddr, \"server\", \"127.0.0.1\", \"server address\") clientSet.IntVar(&amp;clientFlag.port, \"port\", 1080, \"server port\") // set server flags serverSet := flag.NewFlagSet(\"server\", flag.ExitOnError) serverSet.StringVar(&amp;serverFlag.mysqlAddr, \"mysql\", \"127.0.0.1:6379\", \"mysql address\") serverSet.IntVar(&amp;serverFlag.port, \"port\", 1080, \"server port\") if len(os.Args) &lt; 2 &#123; flag.Usage() os.Exit(1) &#125; switch os.Args[1] &#123; case \"client\": clientSet.Parse(os.Args[2:]) case \"server\": serverSet.Parse(os.Args[2:]) default: flag.Usage() os.Exit(1) &#125; if serverSet.Parsed() &#123; fmt.Println(\"server \") fmt.Println(serverFlag) &#125; if clientSet.Parsed() &#123; fmt.Println(\"client\") fmt.Println(clientFlag) &#125;&#125; 这样就实现了二合一","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"正则表达式","slug":"regex","date":"2019-10-14T14:13:44.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/10/14/regex/","link":"","permalink":"https://overtalk.site/2019/10/14/regex/","excerpt":"","text":"元字符空白字符 字符 描述 \\f 匹配一个换页符 \\n 匹配一个换行符 \\r 匹配一个回车符 \\t 匹配一个制表符 \\v 匹配一个垂直制表符 表示位置的字符 字符 描述 \b^ 匹配输入字符串开始的位置 $ 匹配输入字符串结尾的位置 常用 字符 描述 \\d 匹配一个数字字符。等价于 [0-9] \\D 匹配一个非数字字符。等价于 [^0-9] \\w 匹配字母、数字、下划线。等价于’[A-Za-z0-9_]’ \\W 匹配非字母、数字、下划线。等价于 ‘[^A-Za-z0-9_]’ \\s 匹配任何空白字符，包括空格、制表符、换页符 \\S 匹配任何非空白字符。等价于 [^ \\f\\n\\r\\t\\v] . 匹配除换行符（\\n、\\r）之外的任何单个字符。要匹配包括 ‘\\n’ 在内的任何字符，请使用像”(. \\b 匹配一个单词边界，也就是指单词和空格间的位置。例如， ‘er\\b’ 可以匹配”never” 中的 ‘er’，但不能匹配 “verb” 中的 ‘er’ \\B 与 \\b 相反：er\\B’ 能匹配 “verb” 中的 ‘er’，但不能匹配 “never” 中的 ‘er’ Demo12# 匹配以ing结尾的单词ing\\b 12# 匹配11位数的中国手机号1\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d 区间 字符 描述 [0-9] 匹配0-9之间的数字 [A-Z] 匹配A-Z之间的数组，也可以组合 [A-Za-z0-9] 限定符 字符 描述 * 匹配前面的 子表达式 &gt;=0次，例如，zo* 能匹配 “z” 以及 “zoo”。* 等价于{0,} + 匹配前面的 子表达式 &gt;=1次，例如，’zo+’ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,} ？ 匹配前面的 子表达式 0/1次，例如，”do(es)?” 可以匹配 “do” 、 “does” 中的 “does” 、 “doxy” 中的 “do” 。? 等价于 {0,1} {n} n 是一个非负整数。匹配确定的 n 次。例如，’o{2}’ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 o {n,} n 是一个非负整数。至少匹配n 次。例如，’o{2,}’ 不能匹配 “Bob” 中的 ‘o’，但能匹配 “foooood” 中的所有 o。’o{1,}’ 等价于 ‘o+’。’o{0,}’ 则等价于 ‘o*’ {n,m} m 和 n 均为非负整数，其中n &lt;= m。最少匹配 n 次且最多匹配 m 次。例如，”o{1,3}” 将匹配 “fooooood” 中的前三个 o。’o{0,1}’ 等价于 ‘o?’。请注意在逗号和两个数之间不能有空格 上面学习了：区间、限定符，结合元字符，有了他们三种12# 匹配九位数的qq邮箱[0-9]&#123;9&#125;@qq.com 123# 身份证号\\d&#123;17&#125;[0-9Xx]|\\d&#123;15&#125;# 网上查询了一下，1999开始身份证是从15位变成17位的 12# ip地址\\d&#123;0,3&#125;.\\d&#123;0,3&#125;.\\d&#123;0,3&#125;.\\d&#123;0,3&#125; 普通字符 &amp; 转义12# 例子\\w[-\\w.+]*@([A-Za-z0-9][-A-Za-z0-9]+\\.)+[A-Za-z]&#123;2,14&#125; @ 就是普通字符，标识必定会出现的内容。 比如:匹配域名 juejin.im,你完全可以用 1https://juejin.im 但由于符号 /、.、(、) 等等在正则是特殊字符，所以需要用转义符 \\ 转义 1https:\\/\\/juejin\\.im 接下来说一些正则表达式中的一些重要概念喽 子表达式1用圆括号组成一个比较复杂的匹配模式，那么一个圆括号的部分我们可以看作是一个子表达式。 举例 var reg=/(\\d)([a-z]*)/gi (\\d)就是第一个子表达式 ([a-z]) 是第二个子表达式","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"regex","slug":"regex","permalink":"https://overtalk.site/tags/regex/"}]},{"title":"C++ - Virtual关键字","slug":"cpp-virtual","date":"2019-10-12T23:02:52.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/10/12/cpp-virtual/","link":"","permalink":"https://overtalk.site/2019/10/12/cpp-virtual/","excerpt":"","text":"C++ 学习笔记 C++ 关键字 — virtual 简介 来说一下 c++ 中 virtual 关键字的作用 class 中的 虚函数demo1123456789101112131415161718192021222324252627282930313233343536373839#include &lt;iostream&gt;class Entity&#123;public: void name() &#123; std::cout &lt;&lt; \"Entity\" &lt;&lt; std::endl; &#125;&#125;;class Player : public Entity&#123;private: std::string p_name;public: Player(const std::string&amp; name)&#123; p_name = name; &#125; void name() &#123; std::cout &lt;&lt; p_name &lt;&lt; std::endl; &#125;&#125;;void PrintName(Entity* e)&#123; e-&gt;name();&#125;// 程序的主函数int main( )&#123; Entity* e1 = new Entity(); PrintName(e1); Player* p = new Player(\"qinhan\"); PrintName(p); return 0;&#125; Player 继承了 Entity，但是运行结果如下：12EntityEntity demo2 增加关键字 virtual &amp; override virtual 写在 base class 的需要被重写的函数前面 override 写在 sub class 的重写函数后面 123456789101112131415161718192021222324252627282930313233343536373839#include &lt;iostream&gt;class Entity&#123;public: virtual void name() &#123; std::cout &lt;&lt; \"Entity\" &lt;&lt; std::endl; &#125;&#125;;class Player : public Entity&#123;private: std::string p_name;public: Player(const std::string&amp; name)&#123; p_name = name; &#125; void name() override &#123; std::cout &lt;&lt; p_name &lt;&lt; std::endl; &#125;&#125;;void PrintName(Entity* e)&#123; e-&gt;name();&#125;// 程序的主函数int main( )&#123; Entity* e1 = new Entity(); PrintName(e1); Player* p = new Player(\"qinhan\"); PrintName(p); return 0;&#125; 运行结果如下： 12Entityqinhan 纯虚函数 base class 中定义纯虚函数，但是没有任何实现，强制 sub class 去实现 接口 的定义就是只包含 纯虚函数，让 sub class 去实现所有的接口 接口 类没有实例 这儿的接口和 golang 中的接口很类似了 demo123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;class Entity&#123;public: virtual void name() = 0; // 后面的 =0 表明它是纯虚函数&#125;;class Player : public Entity&#123;private: std::string p_name;public: Player(const std::string&amp; name)&#123; p_name = name; &#125; void name() override &#123; std::cout &lt;&lt; p_name &lt;&lt; std::endl; &#125;&#125;;void PrintName(Entity* e)&#123; e-&gt;name();&#125;// 程序的主函数int main( )&#123; Entity* e1 = new Player(\"\"); PrintName(e1); Player* p = new Player(\"qinhan\"); PrintName(p); return 0;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"mysql学习笔记","slug":"mysql","date":"2019-10-12T11:04:16.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/10/12/mysql/","link":"","permalink":"https://overtalk.site/2019/10/12/mysql/","excerpt":"","text":"MySQL架构 首先来一张 MySQL 的架构示意图 MySQL 是一个分层架构，包含 Server 层 和 存储引擎层 两部分，Server 层包括了连接器，查询缓存，分析器，优化器，执行器等，涵盖 MySQL 大多数核心服务功能，以及所有的内置函数，所有的跨存储引擎的功能都在这一层实现，不如存储过程，触发器，视图等。而存储引擎层负责数据的存储和提取，其架构模式是插件式的，支持 InnoDB、MyISAM 、Memory 等。InnoDB 从 MySQL5.5.5 版本开始成为了默认存储引擎。 连接器 在进行所有的操作之前，我们会先进行连接数据库，例如执行命令：mysql -h 127.0.0.1 -u root -P 3306 -p，紧接着输入密码，这个时候连接器会执行密码验证和权限读取 连接成功之后，如果没有后续动作，这个连接就处于空闲状态（show processlist Command 列为 Sleep），如果客户端太长时间没有活动，连接器就会自动将其断开，这个时间是由 wait_timeout 参数控制，默认为 8 小时。 需要注意的是，MySQL 建立连接的过程还是较为繁琐的，首先必要的 TCP 三次握手，还有权限验证查询等，因此我们应该尽量使用长连接，也即是客户端的查询请求尽可能在一个连接上面，不要执行一次操作就断开重新连接一次。但是在使用长连接之后，MySQL 的内存又是涨得很快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的， 而且这些连接占用的内存只有在连接断开的时候才会被释放。所以长连接累计可能会导致 MySQL 被系统强行 OOM，解决方案可以参考： 定期断开长连接，使用一段时间或者程序里面判断执行过一个占用内存的大查询后，断开连接然后重连。 如果使用的是 MySQL5.7 以上的版本，可以在每次执行一个较大的操作后，通过执行 mysql_rest_connection 来重新初始化连接资源。这个过程不会做权限验证，但是会将连接恢复到刚刚创建完的时候。 查询缓存 这个功能 MySQL 5.7.20 就弃用了。 分析器 在执行语句之前，MySQL 首先必须知道本次操作的意图，所以需要对 SQL 做解析，分析器会做词法分析，分析输入的由空格组成的每个字符串代表什么。例如，当你输入查询语句：select ID from T，MySQL 会从这个语句根据 select 识别出这是一个查询语句，将 ID 翻译成表 T 的一个列。做完了这些识别之后，MySQL 就要做语法分析，语法分析根据语法规则，判断输入的SQL语句是否满足 MySQL 语法。 如果输入不对，大概就是下面这样的一个提示：ERROR 1064 (42000): You have an error in your SQL syntax;。 优化器 经过分析器的意图识别之后，MySQL 就知道你要做什么了，在开始执行之前，还要优化一下，比如在表里面有多个索引的时候决定使用哪个索引，或者在一个语句有多表关联的时候，决定各个表的连接顺序。 执行器 经过前面的步骤，MySQL 已经知道你要做什么，紧接着就是执行语句，但是开始执行之前，要先判断一下当前连接的用户对这个表有没有执行的权限，没有就会返回没有权限的错误 如果有权限，就打开表，根据之前已经制定好的查询计划去调用这个表存储引擎的接口读取数据，比如如果上面的例子中，如果 表 T 中 ID 列没有索引，那么执行操作如下： 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中； 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。 到这里，就算是这个语句执行完了。 日志系统 查询语句的过程更新语句都会走一遍，除此之外，更新流程还涉及两个重要的日志模块：redo log（重做日志）和 binlog （归档日志） 重做日志（redo log） 物理日志 在 MySQL 中，并不是每一次更新都会写入磁盘，因为如果这样做，就得涉及到从磁盘找到那条记录，然后更新，整个 IO 成本，查找成本相当高。为了解决这个问题，MySQL 设计者使用了一种叫做 WAL （Write-Ahead-Logging）的技术，它的关键点技术先写日志，再写磁盘。具体来说，当有一条记录需要更新的时候， InnoDB 引擎会把记录写到 redo log 里，并且更新内存，这个时候就算更新完成了。同时，InnoDB 引擎会在适当的时候，将这个记录更新到磁盘，而这个更新操作往往是在系统比较空闲的时候 InnoDB 的 redo log 是固定大小的，由变量 innodb_log_file_size 和 innodb_log_files_in_group 设置，默认是2个48GBd的文件，它被设定为从头开始写，写到末尾由从头循环写，如下图所示： write pos 记录当前的位置，一边写一遍后移，写到第3号我呢就爱你末尾后就回到第0号文件开头，checkpoint 是当前要查出的位置，也是往后推移并且循环的，擦除记录前要把记录更新到磁盘。write pos 和 checkpoint 之间的绿色位置表示可以用来记录新的操作。如果 write pos 追上 checkpoint，这个时候不再执行更新操作，需要停下来擦掉一部分记录，腾出空间。 有了 redo-log，InnoDB 就可以做到即使数据库异常重启，之前提交的记录也不会丢失，这个能力称之为 crash-safe。 归档日志 (Binary Log) 逻辑日志 MySQL 从整体架构上来说，分为 Server 层和存储层，前者负责 MySQL 功能相关，后者负责数据存储。前面所说的 redo-log 就是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，叫做 Binary Log，简称：binlog。 会有两份日志的重要原因是最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。 对比下这两个日志的不同点： redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 我们再看 执行器和 InnoDB 是如何处理这个 SQL的： update T set c=c+1 where ID=2; 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。 有了 binlog，即使在误删数据之后，结合备份数据库，可以做到数据恢复。例如，如果我们的数据库一天一次备份，保留15天之内的 binlog，那么按道理说我们可以恢复到半个月以内的任意一个时间点。日志提交分为两个阶段，主要是为了防止在日志提交期间，MySQL 奔溃恢复，binlog 和 redolog 不一致，在使用 binlog 恢复数据的时候，造成数据不一致。 另外，建议将参数 innodb_flush_log_at_trx_commit 和 sync_binlog 都设置为1，表示在每次事务提交的时候，将 redolog 和 binlog 都持久化到磁盘。 MySQL锁 数据库锁设计的初衷是处理并发问题，作为多用户共享的资源，当出现并发访问的时候，数据库是需要合理地控制资源的访问规则，而锁就是来实现这些访问规则的重要数据结构。根据加锁的范围，MySQL 里面锁的可以分为全局锁，表级锁和行锁三类 全局锁 全局锁就是对整个数据库实例加锁，MySQL提供了一个加全局读锁的方法，命令式：flush tables with read lock(FTWRL)。当你让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增改删）、数据定义语句（包括建表，修改表结构等）和更新类事务的提交语句。 全局库的典型使用场景是，做全库逻辑备份，也就是把整库每个表都 select 出来成文本。让个库都处于只读状态是很危险的： 如果在主库上做备份，那么备份期间都不能执行更新，业务基本上就得停摆； 如果在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。 为了解决 FTWRL 期间不能写入的问题，MySQL 有用于做逻辑备份的工具：mysqldump，当mysqldump 使用 –single-transaction 参数的时候，导数据之前会启动事务，并且设置隔离级别为可重复读，而由于 MVCC 的支持，这个过程中数据是可以正常更新的。但是这个需要引擎支持这个隔离级别，所以，single-transaction 方法适用于所有表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 的方法，这也是替换 MyISAM 为了 InnoDB 的原因之一。除了 FTWRL 的方法之外，还可以配置 InnoDB 用于只读，详见 Configuring InnoDB for Read-Only Operation。可以使用命令 unlock tables 释放 FTWRL 添加的全局读锁。 表级锁 MySQL 有两种表级锁，一种是表锁，一种是元数据锁（meta data lock, MDL）。 表锁 锁表与 FTWRL 类似，可以使用 unlock tables 主动释放锁，也可以在客户端断开的时候释放锁。需要注意的是，lock tables 除了限制别的线程读写外，也限定了本线程接下来的操作对象。举个例子来说，如果在某个线程中执行 lock table t1 read, t2 write，那么其他线程写 t1，读 t2 都会被阻塞，同时，在线程A执行 unlock tables 命令之前，也只能读 t1, 写 t2。在还没有更细粒度锁出现的时候，锁表是常用的处理并发方式。对于 InnoDB 这种支持行锁的引擎来说，一般不使用 lock tables 命令控制并发。 元数据锁 另一类表级锁是 MDL（meta data lock），MDL 不需要显示使用，在访问换一个表的时候会自动加上，作用是保证读写的正确性。想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做更改，删了一列，肯定是不行的。 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查的时候，加 MDL 读锁，当要做对表结构变更的操作的时候，加 MDL 写锁。 读锁之间不互斥，因此可以多线程对同一张表增删改查； 读写锁之间，写锁之间是互斥的，是用来保证表结构的安全性。如果有两个线程同时给一个表加字段，其中一个要等另一个执行完才能执行； 虽然 MDL 锁是系统默认会加的，但却是你不能忽略的一个机制。比如下面这个例子，我经常看到有人掉到这个坑里：给一个小表加个字段，导致整个库挂了。你肯定知道，给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。我们来看一下下面的操作序列，假设表 t 是一个小表。 我们可以看到 session A 先启动，这时候会对表 t 加一个 MDL 读锁。由于 session B 需要的也是 MDL 读锁，因此可以正常执行。之后 session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。你现在应该知道了，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。 行锁 行锁是在存储引擎层由各个存储引擎自己实现的，但是并非所有的存储引擎都支持，MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能靠表级锁，对于使用这种引擎的表，同一张表同一个时刻只能有一个更新在执行，这回影响业务并发度。InnoDB 支持行锁，这也是被作为默认引擎的原因之一。 行锁就是针对数据表中行记录的锁，这个很好理解，比如事务 A 更新了一行，而这个时候 B 事务也要更新这一行，那么必须等待 A 事务执行完成后才能进行。 对于下面的例子，事务 B 的执行会是什么样子呢？（假设 id 是表 t 的主键） 由于A事务在执行过程中持有两个记录的行锁，而且都是在 commit 的时候释放的。也就是说 在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束才释放，这个就是两阶段协议。基于这个设定，我们应该得出结论，如果你的事务中需要锁多个行，要把最可能造成锁冲突，最可能影响并发度的锁尽量往后放。 死锁和死锁检测 当并发系统中不同线程出现资源循环依赖，涉及的线程都在等待别的线程释放资源的时，就会导致这几个线程都进入无限等待的时候，成为死锁，我们举个例子说明情况。 这个时候，A事务在等待B事务释放 id=2 这行的锁，而 B事务在等待A事务释放 id=1 这行的锁，事务A和事务B互相等待对方的资源释放，就进入了死锁状态。当出现死锁以后，有两种策略： 直接进入等待，直到超时，超时时间通过参数 innodb_lock_wait_timeout 控制。 发起死锁检测，发现出现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行，innodb_deadlock_detect 用于开启这个功能。 在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。每当一个事务被锁主的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁，这个过程在随着并发线程的增加，会消耗大量的 CPU 资源。对于这种热点数据更新的问题可以考虑将死锁检测临时关掉，或者控制并发度，以减少对 CPU 资源的消耗。 索引 索引的出现就是为了提高数据的查询效率，承担书籍目录的功能。实现索引的方式有很多种，所以就有了索引模型的概念，可以用于提高读写效率的数据结构很多，例如：哈希表，有序数组和搜索树。但是哈希表这种数据结构只支持等值查询，而有序数组虽然在等值查询和范围查询中表现很不错，但是却在插入的时候变得很麻烦，而二叉搜索数作为课本中的经典数据结构，他可以将读写的时间复杂度都控制在 O(logn) 以内，不过在MySQL中，索引不仅仅是在内存中存储，还有持久化到磁盘，使用二叉搜索树存储，记录越多，数的高度就越大，导致读写磁盘的次数就增加，因为就出现了 N 叉树。以 InnoDB 为例，这个 N 差不多是 1200，因此当数的高度是4的时候，就可以存储 17亿 的数据量了，这种 N 叉叉树已经被广泛用于数据库引擎中。 InnoDB 索引模型 InnoDB 中，表都是根据逐渐以索引的形式存放的，这种存储方式被称为索引组织表，InnoDB 使用了 B+ 树索引模型，所以数据都是存放在 B+ 树中的。每一个在 InnoDB 中对应一颗 B+ 树。 假设，我们有一个主键列为 ID 的表，表中有字段k，并且在 k 上有索引。这个表的创建语句如下： 12345mysql&gt; create table T( id int primary key, k int not null, name varchar(16), index (k))engine=InnoDB; 表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下。 从图中看出，索引类型分为主键索引和非主键索引，主键索引叶子节点的内容是整行的数据，InnoDB 中，主键索引也被成为聚簇索引。非主键索引叶子节点的内容是主键的值，InnoDB 中，非主键索引也被称为二级索引。 因此在查询的时候，基于主键索引的查询只需查询一棵树，而基于非主键索引的数据要多查询一棵树。 B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。 而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。 为了减少索引维护的成本，所以我们一本看到这样的建表规范：表必须包含自增主键，自增主键是指在自增列上定义的主键，在建表语句中一般这样描述：NOT NULL PRIMARY KEY AUTO_INCREMENT，插入记录的时候，可以不用指定这个自增列的值，系统会自动获取自增列的最大值并且加1作为下一条记录该列的值。 而当使用有业务逻辑的字段做主键，则往往不容易保证有序插入，这样会增加写数据的成本。除了性能之外，我们还可以从存储空间的角度来考虑，假设表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键还是自增字段呢？由于每个非主键索引树中叶子节点上都是主键的值，如果用身份证号做主键，则需要20个字节的，如果用整形做主键，只要4个字节。显然，主键长度越小，普通索引叶子节点就越小，普通索引占用的空间就越小。因此，从性能和存储空间来考虑，自增主键往往是更合理的选择。然而，当在用于缓存形式的 KV 表中，由于表只包含一个唯一索引，所以使用业务字段做主键更为划算。 在重建索引的时候，重建普通索引可以按如下的流程操作： 12alter table T drop index;alter table T add index(k); 重建主键索引则需要： 1alter table T engine=InnoDB; 因为删除或者创建主键都会重建表，按照普通索引的重建做法，第一个流程就白执行了 覆盖索引 基于前面的讨论，继续探讨对于下下面这个表： 12345678mysql&gt; create table T (ID int primary key,k int NOT NULL DEFAULT 0, s varchar(16) NOT NULL DEFAULT '',index k(k))engine=InnoDB;insert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg'); 在执行语句 select * from T where k between 3 and 5 时，是按照下面的顺序操作的： 在以 k 列值构建的索引上找到 k=3 的记录，取得 ID=300; 再到 ID 索引数上找到 ID=300 对应的行； 在 k 索引树取下一个值 k=5，取得 ID=500； 再回到 ID 索引树查到 ID=500 对应的行； 在 k 索引树取下一个值 k=6，不满足条件，结束。 这个过程中，回到主键索引树搜索的过程，我们称为回表，这个例子中，由于要查询的数据只有在主键上有，所以不得不回表。那么应该如何避免回表呢？如果执行的语句是 select ID from T where k between 3 and 5，因为 ID 的值已经在 k 索引树上了，所以就不用回表了，换句话说，这个查询里面，索引 k 已经 覆盖 了我们的查询需求，因此我们称索引 k 为覆盖索引。 由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。 基于上面覆盖索引的说明，我们讨论一个问题：在一个市民信息表中，是否有必要将身份证号和名字字段建立联合索引？ 12345678910CREATE TABLE `tuser` (`id` int(11) NOT NULL,`id_card` varchar(32) DEFAULT NULL,`name` varchar(32) DEFAULT NULL,`age` int(11) DEFAULT NULL,`ismale` tinyint(1) DEFAULT NULL,PRIMARY KEY (`id`),KEY `id_card` (`id_card`),KEY `name_age` (`name`,`age`)) ENGINE=InnoDB 身份证号是市民的唯一标识，也就是说，如果有根据身份证号查询市民信息的需求，只要在身份证字段上建立索引就够了。而再建立一个联合索引（身份证号，姓名），是否浪费空间？但是，如果现在有需要根据身份证号查询姓名的需求，那么这个索引就变的有意义了，不用回表。但是，建立这种冗余覆盖索引，势必影响写入的效率以及加大存储空间消耗。 最左前缀 承接上面，如果我们要再根据身份证号查询家庭住址，然后再建立一个覆盖索引（身份证号，家庭住址），那样就太。。。。不过我们可以利用 索引的最左前缀来定位记录，减少创建索引。为了说明这个概念，我们用 (name, age) 这个联合索引分析。 可以看到，索引项是按照索引定义里面出现的字段顺序排序的。当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果。如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是”where name like ‘张 %’”。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。 所以，我们在建立联合索引的时候，索引字段的顺序显得比较重要了，如果通过调整顺序就能少维护一个索引，那么这个顺序应该优先采用。所以前面的问题中，联合索引（身份证号，姓名）就能支持 “根据身份真好查住址” 这个需求了。但是如果在有联合索引（a,b）的情况下，又有基于 a,b 各自的查询的时候，是需要单独为 b 创建索引的，也就是说，需要同时维护 (a,b) 和 (b) 这两个索引。 MySQL 5.6 引入了 索引下推（ICP），对基于最左前缀匹配的查询做了查询优化。 普通索引和唯一索引的选择 我们将通过分析普通索引和唯一索引对查询和更新操作性能的影响来得出结论。 查询过程 假设执行的查询语句是 select id from T where k=5，这个查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，然后可以再数据页内通过二分法来定位记录： 对于普通索引来说，查到满足条件的第一个记录之后，需要查找下一个记录，知道碰到第一个不满足 k=5 条件的记录； 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止检索； 由于 InnoDB 的读写是按照数据页为单位进行读写的，也就是说，当需要读一条记录的时候，并不只是将这条记录从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小是 16KB，所以就查询来说，二者的差距不大，对于普通索引来说，就是多了指针向下查询的过程。当然，如果 k=5 恰好是这个数据页最后的一个记录，那么取下一条记录，就需要读取下一个数据页，这个操作会稍微复杂一些。但是我们之前计算过，一个数据页可以存放近千个 key，因此出现这种情况的概率会很低。 更新过程 在对比普通索引和唯一索引对更新语句性能影响的问题之外，先来看一个东西，change buffer。当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。 那么什么条件下能够使用 change buffer 呢？ 对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。 了解了 change buffer 的机制，我们探究一下在这种插入一条记录的过程？ 如果这个记录要更新的目标页在内存中。这时 InnoDB 处理的逻辑如下： 对于唯一索引，找到 3 和 5 之间的位置，判断没有冲突，插入这个值，语句执行结束； 对于普通索引，找到 3 和 5 之间的位置，插入这个值，语句执行结束。 这种情况下，普通索引和唯一索引对更新语句的性能影响差别只有一个判断。 如果这个记录要更新的目标页不在内存中，这时，InnoDB 处理逻辑如下： 对于唯一索引。需要将数据页读入内存，判断有没有冲突，插入新值，结束； 对于普通索引，则是将更新记录在 change buffer 中，语句执行结束 将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。 change buffer 使用场景 基于前面的介绍，change buffer 能加锁所有使用普通索引的场景吗？ 因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。 索引选择总结 普通索引和唯一索引在查询能力上没差别的，主要考虑的是对更新性能的影响，因此建议尽量使用普通索引。如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。在实际使用中，你会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。 字符串字段添加索引 假如我们的用户表中有两个 email 字段，我们在使用过程发现需要根据 email 查询用户，为了避免全表扫面，我们需要为这个字段添加索引，有两种方式： 123mysql&gt; alter table SUser add index index1(email);或者mysql&gt; alter table SUser add index index2(email(6)); 前者创建的索引里面，使用了整个 email，后者只使用了 email 的前6个字符，这两种创建索引的方式对于创建的索引大小有直接影响，很明显前者更大，但是后者虽然减小了索引结构中 key 的大小，使得降低存储空间，但是在查询时会增加额外的扫描次数。接下来我们看看下面这个查询语句是如何执行的： 1select id,name,email from SUser where email='zhangssxyz@xxx.com'; 如果使用的是 index1（即 email 整个字符串的索引结构），执行顺序是这样的： 从 index1 索引树找到满足索引值是’zhangssxyz@xxx.com’的这条记录，取得 ID2 的值； 到主键上查到主键值是 ID2 的行，判断 email 的值是正确的，将这行记录加入结果集； 取 index1 索引树上刚刚查到的位置的下一条记录，发现已经不满足 email=’zhangssxyz@xxx.com’的条件了，循环结束。 这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。 如果使用的是 index2（即 email(6) 索引结构），执行顺序是这样的： 从 index2 索引树找到满足索引值是’zhangs’的记录，找到的第一个是 ID1； 到主键上查到主键值是 ID1 的行，判断出 email 的值不是’zhangssxyz@xxx.com’，这行记录丢弃； 取 index2 上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出 ID2，再到 ID 索引上取整行然后判断，这次值对了，将这行记录加入结果集； 重复上一步，直到在 idxe2 上取到的值不是’zhangs’时，循环结束。 通过这个对比，你很容易就可以发现，使用前缀索引后，可能会导致查询语句读数据的次数变多。实质上使用前缀索引，定义好长度，就可以做到既节省空间，又不用增加太多的查询成本。那么在给前缀字符串创建索引的时候，前缀长度如何确定？这里我们就要用到一个叫做区分度的指标了，区分度越高，重复的简直越少。因此，我们可以通过统计索引上有多少个不同的值来判断使用多长的前缀，例如我们可以这样对比： 123456mysql&gt; select count(distinct left(email,4)）as L4,count(distinct left(email,5)）as L5,count(distinct left(email,6)）as L6,count(distinct left(email,7)）as L7,from SUser; 前缀索引还有另外一个缺点，就是 可能会使覆盖索引优化失效，例如查询 select id,email from SUser where email=’zhangssxyz@xxx.com’; 在使用前置索引的时候还得回表查询email。我们在对字符串字段添加索引的时候，还可以通过倒序，求hash值的方式使得较小的长度就能获得更大区分度的方式来优化。 count(*) count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。 对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。 对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。 单看这两个用法的差别的话，你能对比出来，count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。 对于 count(字段) 来说： 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加； 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。 但是 count() 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count() 肯定不是 null，按行累加。 结论：按照效率排序的话，count(字段)&lt;count(主键 id)&lt;count(1)≈count()，所以我建议你，尽量使用 count()。 最后来一个好的网址 http://blog.fudenglong.site/2019/04/21/MySQL-%E8%87%AA%E9%97%AE%E8%87%AA%E7%AD%94/","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://overtalk.site/tags/mysql/"}]},{"title":"Golang 面试题","slug":"interview-go","date":"2019-10-12T11:04:16.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/10/12/interview-go/","link":"","permalink":"https://overtalk.site/2019/10/12/interview-go/","excerpt":"","text":"以下代码有什么问题，说明原因1234567891011121314151617type student struct &#123; Name string Age int&#125;func pase_student() &#123; m := make(map[string]*student) stus := []student&#123; &#123;Name: \"zhou\", Age: 24&#125;, &#123;Name: \"li\", Age: 23&#125;, &#123;Name: \"wang\", Age: 22&#125;, &#125; for _, stu := range stus &#123; m[stu.Name] = &amp;stu &#125;&#125; 解析 foreach 解答 这样的写法初学者经常会遇到的，很危险！ 与Java的foreach一样，都是使用副本的方式。所以m[stu.Name]=&amp;stu实际上一致指向同一个指针， 最终该指针的值为遍历的最后一个struct的值拷贝。 就像想修改切片元素的属性 下面代码会输出什么？12345678910111213141516171819202122type People struct&#123;&#125;func (p *People) ShowA() &#123; fmt.Println(\"showA\") p.ShowB()&#125;func (p *People) ShowB() &#123; fmt.Println(\"showB\")&#125;type Teacher struct &#123; People&#125;func (t *Teacher) ShowB() &#123; fmt.Println(\"teacher showB\")&#125;func main() &#123; t := Teacher&#123;&#125; t.ShowA()&#125; 考点：go的组合继承 解答： 这是Golang的组合模式，可以实现OOP的继承。 被组合的类型People所包含的方法虽然升级成了外部类型Teacher这个组合类型的方法（一定要是匿名字段），但它们的方法(ShowA())调用时接受者并没有发生变化。 此时People类型并不知道自己会被什么类型组合，当然也就无法调用方法时去使用未知的组合者Teacher类型的功能。 12showAshowB 下面代码输出什么？1234567891011121314func calc(index string, a, b int) int &#123; ret := a + b fmt.Println(index, a, b, ret) return ret&#125;func main() &#123; a := 1 b := 2 defer calc(\"1\", a, calc(\"10\", a, b)) a = 0 defer calc(\"2\", a, calc(\"20\", a, b)) b = 1&#125; 考点：defer执行顺序 解答： 这道题类似第1题 需要注意到defer执行顺序和值传递 index:1肯定是最后执行的，但是index:1的第三个参数是一个函数，所以最先被调用calc(“10”,1,2)==&gt;10,1,2,3 执行index:2时,与之前一样，需要先调用calc(“20”,0,2)==&gt;20,0,2,2 执行到b=1时候开始调用，index:2==&gt;calc(“2”,0,2)==&gt;2,0,2,2 最后执行index:1==&gt;calc(“1”,1,3)==&gt;1,1,3,4 123410 1 2 320 0 2 22 0 2 21 1 3 4 是否可以编译通过？如果通过，输出什么？12345678910111213141516171819func main() &#123; i := GetValue() switch i.(type) &#123; case int: println(\"int\") case string: println(\"string\") case interface&#123;&#125;: println(\"interface\") default: println(\"unknown\") &#125;&#125;func GetValue() int &#123; return 1&#125; 解析 考点：type 编译失败，因为type只能使用在interface 以下代码有什么问题，说明原因12345func main() &#123; list := new([]int) list = append(list, 1) fmt.Println(list)&#125; 解析 不可以通过 append返回的是( []int ),而list是（ *[]int ） 可以用 list:=make([]int,0) 代替声明 是否可以编译通过？如果通过，输出什么?12345678910111213141516171819202122232425262728func main() &#123; sn1 := struct &#123; age int name string &#125;&#123;age: 11, name: \"qq\"&#125; sn2 := struct &#123; age int name string &#125;&#123;age: 11, name: \"qq\"&#125; if sn1 == sn2 &#123; fmt.Println(\"sn1 == sn2\") &#125; sm1 := struct &#123; age int m map[string]string &#125;&#123;age: 11, m: map[string]string&#123;\"a\": \"1\"&#125;&#125; sm2 := struct &#123; age int m map[string]string &#125;&#123;age: 11, m: map[string]string&#123;\"a\": \"1\"&#125;&#125; if sm1 == sm2 &#123; fmt.Println(\"sm1 == sm2\") &#125;&#125; 考点:结构体比较 进行结构体比较时候，只有相同类型的结构体才可以比较，结构体是否相同不但与属性类型个数有关，还与属性顺序相关1234sn3:= struct &#123; name string age int&#125;&#123;age:11,name:\"qq\"&#125; sn3与sn1就不是相同的结构体了，不能比较。 还有一点需要注意的是结构体是相同的，但是结构体属性中有不可以比较的类型，如map,slice。 如果该结构属性都是可以比较的，那么就可以使用“==”进行比较操作。 可以使用reflect.DeepEqual进行比较12345if reflect.DeepEqual(sn1, sm) &#123; fmt.Println(\"sn1 ==sm\")&#125;else &#123; fmt.Println(\"sn1 !=sm\")&#125; 所以编译不通过： invalid operation: sm1 == sm2 是否可以编译通过？如果通过，输出什么1234567891011const ( x = iota y z = \"zz\" k p = iota)func main() &#123; fmt.Println(x,y,z,k,p)&#125; 考点：iota 结果10 1 zz zz 4 下面函数有什么问题123456789package mainconst cl = 100var bl = 123func main() &#123; println(&amp;bl,bl) println(&amp;cl,cl)&#125; 考点:常量 常量不同于变量的在运行期分配内存，常量通常会被编译器在预处理阶段直接展开，作为指令数据使用 1cannot take the address of cl","categories":[{"name":"interview","slug":"interview","permalink":"https://overtalk.site/categories/interview/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"},{"name":"interview","slug":"interview","permalink":"https://overtalk.site/tags/interview/"}]},{"title":"ssh 端口转发","slug":"ssh-port-forward","date":"2019-10-10T15:13:30.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/10/10/ssh-port-forward/","link":"","permalink":"https://overtalk.site/2019/10/10/ssh-port-forward/","excerpt":"","text":"简介 从前我以为 SSH 只是为了登录到远程服务器，没想到它的端口转发这么强大，简直惊呆了我自己，首先我从今天遇到的问题先说起吧。我们服务器上跑了个数据库，当然它只配置了localhost访问，为了在不改变其他配置（新增用户，允许白名单域名访问）的情况下能访问数据库，该怎么办？答案是使用SSH 端口转发 例如，我的数据库运行在服务器：xinhuxx.com 上，那么现在本地建立端口转发： 123ssh root@xinhuxx.com -L 53306:127.0.0.1:3306 -N# 后台运行ssh root@xinhuxx.com -L 53306:127.0.0.1:3306 -N -f 然后使用客户端连接数据库： 1mycli -h 127.0.0.1 -P 53306 -u root -p root app SSH 端口转发也被称作SSH隧道，因为它们都是通过SSH登录之后，在SSH客户端与SSH服务端之间建立了一个隧道，从而进行通信。SSH隧道是非常安全的，因为SSH是通过加密传输数据的(SSH全称为Secure Shell)。 在本文所有示例中，本地主机A为SSH客户端，远程云主机B为SSH服务端。从A1主机通过SSH登陆B1主机，指定不同的端口转发选项(-L、-R和 -D)，即可在A1与B1之间建立SSH隧道，从而进行不同的端口转发。在以下的示例中我们都假定B的ip为：112.115.9.23，它的防火墙只开放了22端口。 本地端口转发 假设主机 B 上运行了一个服务，只绑定了 127.0.0.1，端口号为：4000，现在本地主机A需要访问这个服务，在没有端口转发的情况下主机A是无法访问到主机 B 上的这个服务的。我们进行端口转发，将发送到本地端口的请求，转发到目标端口，这样就可以通过访问本地端口进而访问远程主机服务，使用 -L 参数，指定需要转发的端口，参数规则是这样的： 1-L 本地网卡地址:本地端口:目标地址:目标端口 其中本地网卡地址是可以省略的，默认为：127.0.0.1, 假设，我们将远程主机4000端口开启的服务绑定在本地5555端口上： 1ssh -L localhost:5555:localhost:4000 root@112.115.9.23 -N 这样我们就可以像在主机 B 上一样访问这个服务了。这里的 -N 参数意思是：不执行命令，仅仅是为了端口转发。 远程端口转发 A 和 B 的角色换一下，我们现在在A上运行一个服务 127.0.0.1:4000, 现在远程主机 B 需要访问这个服务，需要进行远程端口转发，将发送到远程端口的请求，转发到目标端口，这样，就可以通过访问远程端口，来访问目标端口的服务。使用 -R 参数可以达到这个效果，参数形式是这样的： 1-R 远程网卡地址:远程端口:目标地址:目标端口 假设，将远程主机的5555端口转发到本地的 4000 端口 1ssh -R localhost:5555:localhost:4000 root@112.115.9.23 -N 这样就可以在远程主机B上通过 localhost:5555 来访问我们本地的 4000 端口开启的的服务了。 动态端口转发 对于本地端口转发和远程端口转发，都存在两个一一对应的端口，分别位于SSH的客户端和服务端，而动态端口转发则只是绑定了一个本地端口，而目标地址:目标端口则是不固定的。目标地址:目标端口是由发起的请求决定的，比如，请求地址为192.168.1.100:3000，则通过SSH转发的请求地址也是192.168.1.100:3000。动态转发的参数形式这样的： 1-D 本地网卡地址:本地端口 这时，通过动态端口转发，可以将在本地主机A发起的请求，转发到远程主机B，而由B去真正地发起请求。 1ssh -D localhost:5555 root@112.115.9.23 -N 而在本地发起的请求，需要由Socket代理(Socket Proxy)转发到SSH绑定的5555端口。以 Mac 系统为例： 这样则在系统上，所有请求都会转发到 5555 端口，然后通过SSH构建的隧道进行转发，如果主机B能够访问外网的话，则可以实现科学上网。。。。 链式端口转发 假设有这样三台机器你：A（你家的），B（公司的），C（云主机），满足这几个条件： A， B 不在同一网段，B 没有公网IP，无法被直接访问到； A， B 都可以远程登录到C； C 的IP为：112.115.9.23 现在有这么个情况，你应该很熟悉的，B（公司）主机上运行了一个服务 :3000，需要在A（家）中同样以:3000访问，可以这样做： 首先将C（云主机）的某个空闲端口，假如 5555 转发到 B（公司）的 3000 端口，在 B（公司）主机上这么操作： 1ssh -R 5555:localhost:3000 root@112.115.9.23 然后，在A（家）中的主机上将本地的3000端口转发到C（云主机）的 5555 端口，在 A（家）主机上这么操作： 1ssh -L 3000:localhost:5555 root@112.115.9.23 这两步完成之后，你就可以在家里访问公司电脑上运行的服务了。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"ssh","slug":"ssh","permalink":"https://overtalk.site/tags/ssh/"}]},{"title":"golang db2struct","slug":"go-db2struct","date":"2019-09-21T14:53:02.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/09/21/go-db2struct/","link":"","permalink":"https://overtalk.site/2019/09/21/go-db2struct/","excerpt":"","text":"db2struct Converts a mysql table into a golang struc 地址 https://github.com/Shelnutt2/db2struct 安装 首先需要安装go go get github.com/Shelnutt2/db2struct/cmd/db2struct 使用 首先看看工具的使用 为了更加的通用，我写量脚本，将数据库配置以及表名等参数独立了出来，方便使用 上述参数需要放到shell脚本同级的目录之下的.config文件中 执行脚本之后，会为每个表生产一个对应的*.go文件，文件中包含了转化之后的struct，struct名、文件名就是表名 脚本如下所示： gen-model.sh1234567891011121314151617181920212223242526272829303132333435#!/usr/bin/env bash# check if db2struct existcheck()&#123; if !(hash $&#123;convert_tool&#125; 2&gt;/dev/null); then echo \"convert tool $&#123;convert_tool&#125; is absent, install...\" go get github.com/Shelnutt2/db2struct/cmd/db2struct fi&#125;# generate golang modelgen()&#123; for table in $&#123;TABLES[@]&#125;; do echo \"del old model/$&#123;table&#125;.go\" &amp;&amp; rm ../../model/$&#123;table&#125;.go struct_name=\"$(echo $&#123;table:0:1&#125; | tr '[a-z]' '[A-Z]')$&#123;table:1&#125;\" db2struct -H $&#123;HOST&#125; -u $&#123;USER&#125; -p $&#123;PASSWORD&#125; \\ --package $&#123;GO_PACKAGE_NAME&#125; -d $&#123;DB&#125; \\ --table $&#123;table&#125; --struct $&#123;struct_name&#125; \\ --target=$&#123;SAVE_PATH&#125;/$&#123;table&#125;.go \\ --json -v echo \"finish model/$&#123;table&#125;.go\\n\" done&#125;# import related configsource .configconvert_tool=db2structcheckgen 配置文件实例如下： .config1234567GO_PACKAGE_NAME=modelSAVE_PATH=../../modelHOST=127.0.0.1USER=rootPASSWORD=12345678DB=gp_ojTABLES=(\"role\" \"tag\" \"algorithm\") .config中具体参数含义如下所示： 参数名 意义 GO_PACKAGE_NAME model文件（*.go）的package name SAVE_PATH model文件（*.go）保存路径 HOST MySQL host USER MySQL username PASSWORD MySQL password DB MySQL db name TABLES MySQL 需要转化成struct的表 demo 允许结果大致如下所示： 我是通过makefile来运行的 然后在model文件夹就可以看到文件了","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"},{"name":"mysql","slug":"mysql","permalink":"https://overtalk.site/tags/mysql/"}]},{"title":"golang 大杀器之性能分析工具 PProf","slug":"go-pprof","date":"2019-08-30T14:48:36.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/08/30/go-pprof/","link":"","permalink":"https://overtalk.site/2019/08/30/go-pprof/","excerpt":"","text":"前言 写了几万行代码，提了几千个PR，上线部署之后发现 CPU占用高？内存占用高？WTF 这个时候就需要加上性能分析工具，快速定位问题所在 工具介绍 想要进行性能优化，首先瞩目在 Go 自身提供的工具链来作为分析依据，涉及如下： net/http/pprof：采集 HTTP Server 的运行时数据进行分析 runtime/pprof：采集程序（非 Server）的运行数据进行分析 因为我主要是做服务器开发，因此我只将来第一种 HTTP Server简单的demo12345678910111213141516171819202122232425package mainimport ( \"log\" \"net/http\" _ \"net/http/pprof\")func test(str string) string &#123; strBytes := []byte(str) for i := 0; i &lt; 10; i++ &#123; strBytes = append(strBytes, []byte(str)...) &#125; return string(strBytes)&#125;func main() &#123; go func() &#123; for &#123; log.Println(test(\"this is a test string, do something to use CPU &amp; MEM\\n\")) &#125; &#125;() http.ListenAndServe(\":6060\", nil)&#125; 运行这个文件，你的 HTTP 服务会多出 /debug/pprof 的 endpoint 可用于观察应用程序的情况 分析通过Web界面 访问 http://127.0.0.1:6060/debug/pprof/， 查看你的 HTTP Server 的运行情况 下面有对每一个采集的解释，我来提及几个重要的指标 profile：CPU使用情况的采集，默认进行30s的 CPU Profiling，得到一个用于分析的profile文件，如何分析后文会继续叙述。 goroutine：goroutine分析，可以看出 goroutine 的总量以及每个 goroutine 的具体执行代码 mutex：导致互斥锁的竞争持有者的堆栈跟踪 通过交互式终端 go tool pprof http://localhost:6060/debug/pprof/profile?seconds=60 该命令会采集60s的CPU使用情况，结束后进入交互命令模式，可以对采集的结果进行查看/直接导出。 列项 描述 flat 给定函数上运行耗时 flat% 同上的 CPU 运行耗时总比例 sum% 给定函数累积使用 CPU 总比例 cum 当前函数加上它之上的调用运行总耗时 cum% 同上的 CPU 运行耗时总比例 go tool pprof http://localhost:6060/debug/pprof/heap go tool pprof http://localhost:6060/debug/pprof/block go tool pprof http://localhost:6060/debug/pprof/mutex 上述三项的用法和前面所述的第一个的使用相类似，只不过采集的对象不同 PProf 可视化界面 在第一中分析方法通过Web界面下载到的文件可以通过可视化的界面来进行分析 或者在第二种分析方法中，进入交互界面之后，输入web也是可以进入图形界面的哦 具体的方法如下所示：1go tool pprof -http=:8080 cpu.prof 这样即可在 localhost:8080 中即可访问 如果出现 Could not execute dot; may need to install graphviz.，就是提示你要安装 graphviz","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"gitlab-ci的使用教程","slug":"gitlab-ci","date":"2019-08-22T15:28:04.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/08/22/gitlab-ci/","link":"","permalink":"https://overtalk.site/2019/08/22/gitlab-ci/","excerpt":"","text":"Gitlab CI 本篇博客首先介绍了如何使用gitlab的ci功能 本篇博客主要介绍如何使用gitlab的ci功能，并且搭配aliyun docker hub功能，实现特定分支有更新的时候，可以进行打镜像，并且推送到aliyun的docker hub，后续可能还会再加上基于docker hub中的镜像实现部署的部分 这篇博客的由来 最近公司打算放弃使用企业版的Github，转向使用Gitlab。刚好最近事情不太多，就尝试了一下gitlab的ci/cd功能 并且实现了自动推送镜像到aliyun的docker hub（薅羊毛啊） 顺道说一句，经过最近这一段时间使用gitlab的经历，我觉得它没有github好用（OvO） 下面部分👇有错误、不好的地方，欢迎大家指正 我做了什么 为了学习使用gitlab的ci/cd功能，我专门写了一个demo，主要就是一个最简单的golang http server，搭配写了一个Dockerfile，用于构造镜像 然后在gitlab的ci/cd中我会使用这个Dockerfile构造出镜像，来推送到 aliyun docker hub，以供后续的部署使用（目前暂时没有部署部分） 这样就模拟了一个项目从开发到线上部署的整个流程，基本全自动化，这样以后可以直接拿来用啦。 demo地址为：https://gitlab.com/qinhan-shu/dep-demo 欢迎大家的 fork，issue，star 😄 Aliyun Docker Hub Docker 在如今的web领域的地位、重要性我就不多说了，大家都懂，超级方便好用的容器技术，特别是搭配使用k8s的话 官方的 Docker Hub 超级慢，而且还是公开的。我选择使用 aliyun 免费 &amp; 快速的 Docker Hub 😂 怎么申请呢，首先注册账号，然后进入控制台，搜索 “容器镜像服务”，然后开通，设置密码，这个密码是后续你推送镜像到 aliyun Docker Hub的密码，好好保存着，然后点击 ”创建镜像仓库“，按照他的指示一步一步来就可以来。（哦对，在创建镜像仓库的时候，应该会让你先创建一个命名空间） 创建完成之后点击进入仓库，基本信息中有教你如何使用仓库的教程： Gitlab使用CI 想要使用gitlab的ci，那么你必须要有两个东西：Runner、放置于项目根目录的 .gitlab-ci.yml 文件 每当你提交代码的时候，会根据你 .gitlab-ci.yml 配置文件中的规则在 Runner 中运行。这个大概就是 gitlab ci 的实现原理。 Runner 所谓的Runner，就是ci的执行者。gitlab上有共享runner，但是我没有用，我是在自己的ecs上运行了gitlab runner，如果没有的话，使用共享的runner应该也是可以的（我没有试过，欢迎大家分享宝贵的踩坑心得）。 如何搭建自己的Runner 首先进入项目，然后依次进入：settings -&gt; CI/CD，然后展开Runner项，可以看到如下所示的一项： 它标注了为这个项目构建runner时候所使用的url和令牌。接下来就来在ecs上搭建自己的runner吧。 我推荐使用docker进行搭建，这样不需要在你的ecs上安装任何其他的东西，比较干净。当然官网也提供了单独安装runner的教程，如果大家想去直接安装runner的话也可以，教程地址：https://docs.gitlab.com/runner/install/ Docker搭建自己的Runner docker安装runner的话，第一步是安装docker： 1curl -sSL https://get.docker.com/ | sh 然后，启动runner 需要将配置卷安装到gitlab-runner容器中以用于配置和其他资源：1234docker run -d --name gitlab-runner --restart always \\ -v /srv/gitlab-runner/config:/etc/gitlab-runner \\ -v /var/run/docker.sock:/var/run/docker.sock \\ gitlab/gitlab-runner:latest 第三步就是注册，将上面图片中的url和令牌注册到Runner中，使其成为项目的Runner 1docker run --rm -t -i -v /srv/gitlab-runner/config:/etc/gitlab-runner gitlab/gitlab-runner register 接下来会依次让你输入一些东西（包括上面提到的 url和令牌 ） 输入url 12Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com )https://gitlab.com 输入令牌 12Please enter the gitlab-ci token for this runnerxxx 输入Runner的描述（可以在GitLab的UI中更改） 12Please enter the gitlab-ci description for this runner[hostname] my-runner 输入与Runner关联的tag（可以在GitLab的UI中更改） 12Please enter the gitlab-ci tags for this runner (comma separated):my-tag,another-tag 输入Runner执行程序（推荐使用docker，因为其他的我也没用过，不敢瞎推荐） 12Please enter the executor: ssh, docker+machine, docker-ssh+machine, kubernetes, docker, parallels, virtualbox, docker-ssh, shell:docker 上述步骤选择Docker作为执行程序，则会要求将默认image，用于未在 .gitlab-ci.yml 中定义镜像的项目（ 推荐使用alpine，因为小😂 ） 12Please enter the Docker image (eg. ruby:2.1):alpine:latest 完成了上述步骤之后，在返回到gitlab的项目的 settings -&gt; CI/CD，然后展开Runner项，就可以看到你刚刚注册的Runner： 到此，Runner就注册完成了 .gitlab-ci.yml 说完了Runner，接下来说说 .gitlab-ci.yml 官网的教程地址：https://docs.gitlab.com/ee/user/project/pages/getting_started_part_four.html 上面的配置文件详解我就不说了，说说Demo（https://gitlab.com/qinhan-shu/dep-demo）中的配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101# 首先是镜像的设置# 如果不设置镜像的话，则会使用之前注册runner时候最后选择的镜像# 在后续每个job中也可以单独设置镜像，如果没有设置的话，则使用这个默认的全局镜像image: golang:latest# services 是依赖的服务，因为我有一个名为 push_image 的job，这个job需要用到docker命令，将编译好的镜像推送到 aliyun docker hub# 因此启动 docker:dind 服务，就是一个 docker daemon，如果没有这个服务，push_image job就会报错了services: - docker:dind# 一些全局变量variables: # docker 镜像的驱动，选择overlay2来提速，默认驱动较慢 DOCKER_DRIVER: overlay2 # 项目名称 REPO_NAME: gitlab.com/qinhan-shu/dep-demo# 顾名思义，就是在 job 执行之前所执行的脚本before_script: - mkdir -p $GOPATH/src/$(dirname $REPO_NAME) - ln -svf $CI_PROJECT_DIR $GOPATH/src/$REPO_NAME - cd $GOPATH/src/$REPO_NAME# 这个是比较重要的一个配置项目 -- 阶段# 各个阶段依次执行，只有前面一个阶段执行完成之后才可以执行后续的阶段# 而每一个阶段可以有多个job，job就是ci执行的最小单位# 例如改配置就会分成三个阶段：# test：测试代码正确性阶段，包括了四个job（gofmt，govet，gotest，coverage）分别从四个不同的侧重点测试代码的正确性；# build：编译阶段，包括两个阶段（compile，push_image），第一个job 执行go build，第二个推送镜像到阿里云（我设置成了手动点击执行）；# deploy：部署，暂时还没有写 😂；stages: - test - build - deploy# gofmt job，后面的几个job都类似，就不一一详细叙述了，可以直接跳到最后一个job - push_imagegofmt: # 标明属于哪个stage stage: test # 执行条件，即满足下面条件才会执行。 # 除去refs，还有其他的条件，见官方文档：https://docs.gitlab.com/ee/ci/yaml/README.html#onlyexcept-basic only: # 执行分支 refs: - master # 具体这个job的执行脚本，借助了Makefile，可以参考看看项目中的 Makefile script: - make gofmtgovet: stage: test only: refs: - master script: - make govetgotest: stage: test only: refs: - master script: - make gotestcoverage: stage: test only: refs: - master script: - make coveragecompile: stage: build only: refs: - master script: - make server# push_image job：推送镜像到 aliyun docker hubpush_image: stage: build # 本job的镜像，因为需要使用到 docker 指令 image: docker:stable # 只有prod分支才执行 only: refs: - prod # 默认跳过，手动执行，在项目中的流水线中手动点击执行（考虑到不是每一次都打镜像）。 when: manual # 具体执行的脚本，首先 build， 然后push # 这儿一些敏感的账号密码之类放到了 CI/CD 的环境变量中去了 # 可以在 项目 -&gt; settings -&gt; CI/CD -&gt; Variables 中设置 script:# - COMMIT=$(git rev-parse --short HEAD) - IMAGE_NAME=registry.cn-shanghai.aliyuncs.com/qinhan-shu/dep-demo:latest - docker build -t $IMAGE_NAME -f docker/Dockerfile . - echo $&#123;DOCKER_PASSWORD&#125; | docker login --username $&#123;DOCKER_USER&#125; --password-stdin $&#123;DOCKER_REG&#125; - docker push $IMAGE_NAME 总结 后续补充上部署的部分","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"CI/CD","slug":"CI-CD","permalink":"https://overtalk.site/tags/CI-CD/"}]},{"title":"配置文件读取","slug":"go-viper","date":"2019-07-31T14:21:27.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/07/31/go-viper/","link":"","permalink":"https://overtalk.site/2019/07/31/go-viper/","excerpt":"","text":"viper 项目地址 ：github.com/spf13/viper viper是什么 go开发工具，主要是用于处理各种格式的配置文件，简化程序配置的读取问题 viper支持： 设置默认配置 支持读取JSON TOML YAML HCL 和Java属性配置文件 监听配置文件变化,实时读取读取配置文件内容 读取环境变量值 读取远程配置系统(etcd Consul)和监控配置变化 读取命令Flag值 读取buffer值 读取确切值 安装12go get github.com/fsnotify/fsnotifygo get github.com/spf13/viper viper的基本用法配置文件 json配置文件(config.json) 12345678910111213141516&#123; \"port\": 10666, \"mysql\": &#123; \"url\": \"(127.0.0.1:3306)/biezhi\", \"username\": \"root\", \"password\": \"123456\" &#125;, \"redis\": [\"127.0.0.1:6377\", \"127.0.0.1:6378\", \"127.0.0.1:6379\"], \"smtp\": &#123; \"enable\": true, \"addr\": \"mail_addr\", \"username\": \"mail_user\", \"password\": \"mail_password\", \"to\": [\"xxx@gmail.com\", \"xxx@163.com\"] &#125; &#125; yaml配置文件(config1.yaml) 1234567891011121314151617port: 10666mysql: url: \"(127.0.0.1:3306)/biezhi\" username: root password: 123456redis: - 127.0.0.1:6377 - 127.0.0.1:6378 - 127.0.0.1:6379smtp: enable: true addr: mail_addr username: mail_user password: mail_password to: - xxx@gmail.com - xxx@163.com 本地配置文件读取方式 将上述两个配置文件和下面的 main.go 放在统一目录之下，即可实现读取配置文件1234567891011121314151617181920212223242526272829303132333435package mainimport ( \"fmt\" \"log\" \"github.com/spf13/viper\")func init() &#123; // viper.SetConfigName(\"config1\") // 读取yaml配置文件 viper.SetConfigName(\"config\") // 读取json配置文件 //viper.AddConfigPath(\"/etc/appname/\") //设置配置文件的搜索目录 //viper.AddConfigPath(\"$HOME/.appname\") // 设置配置文件的搜索目录 viper.AddConfigPath(\".\") // 设置配置文件和可执行二进制文件在用一个目录 if err := viper.ReadInConfig(); err != nil &#123; if _, ok := err.(viper.ConfigFileNotFoundError); ok &#123; // Config file not found; ignore error if desired log.Println(\"no such config file\") &#125; else &#123; // Config file was found but another error was produced log.Println(\"read config error\") &#125; log.Fatal(err) // 读取配置文件失败致命错误 &#125;&#125;func main() &#123; fmt.Println(\"获取配置文件的port\", viper.GetInt(\"port\")) fmt.Println(\"获取配置文件的mysql.url\", viper.GetString(`mysql.url`)) fmt.Println(\"获取配置文件的mysql.username\", viper.GetString(`mysql.username`)) fmt.Println(\"获取配置文件的mysql.password\", viper.GetString(`mysql.password`)) fmt.Println(\"获取配置文件的redis\", viper.GetStringSlice(\"redis\")) fmt.Println(\"获取配置文件的smtp\", viper.GetStringMap(\"smtp\"))&#125; 代码详解 viper.SetConfigName(“config”) 设置配置文件名为config, 不需要配置文件扩展名, 配置文件的类型 viper会自动根据扩展名自动匹配. viper.AddConfigPath(“.”)设置配置文件搜索的目录, . 表示和当前编译好的二进制文件在同一个目录. 可以添加多个配置文件目录,如在第一个目录中找到就不不继续到其他目录中查找. viper.ReadInConfig() 加载配置文件内容 viper.Get*** 获取配置文件中配置项的信息 viper的一些高级用法 viper设置配置项的默认值 12345678// set default configviper.SetDefault(\"ContentDir\", \"content\")viper.SetDefault(\"LayoutDir\", \"layouts\")viper.SetDefault(\"Taxonomies\", map[string]string&#123;\"tag\": \"tags\", \"category\": \"categories\"&#125;)fmt.Println(viper.GetBool(\"ContentDir\"))fmt.Println(viper.GetString(\"LayoutDir\"))fmt.Println(viper.GetStringMapString(\"Taxonomies\")) 监听和重新读取配置文件 import “github.com/fsnotify/fsnotify” 12345viper.WatchConfig()viper.OnConfigChange(func(e fsnotify.Event) &#123; //viper配置发生变化了 执行响应的操作 fmt.Println(\"Config file changed:\", e.Name)&#125;) 从环境变量变量中读取 主要用到的是下面三个个方法 1234567891011121314// AutomaticEnv has Viper check ENV variables for all.// keys set in config, default &amp; flagsAutomaticEnv()// BindEnv binds a Viper key to a ENV variable.// ENV variables are case sensitive.// If only a key is provided, it will use the env key matching the key, uppercased.// EnvPrefix will be used when set when env name is not provided.BindEnv(string…) : error// SetEnvPrefix defines a prefix that ENVIRONMENT variables will use.// E.g. if your prefix is \"spf\", the env registry will look for env// variables that start with \"SPF_\".SetEnvPrefix(string) 简单的使用demo如下所示 123456789101112131415161718192021222324252627282930package main import ( \"fmt\" \"os\" \"github.com/spf13/viper\")func main() &#123; prefix := \"PROJECTNAME\" envs := map[string]string&#123; \"LOG_LEVEL\": \"INFO\", \"MODE\": \"DEV\", \"MYSQL_USERNAME\": \"root\", \"MYSQL_PASSWORD\": \"xxxx\", &#125; for k, v := range envs &#123; os.Setenv(fmt.Sprintf(\"%s_%s\", prefix, k), v) &#125; v := viper.New() v.SetEnvPrefix(prefix) v.AutomaticEnv() for k, _ := range envs &#123; fmt.Printf(\"env `%s` = %s\\n\", k, v.GetString(k)) &#125;&#125; 获取远程配置 使用github.com/spf13/viper/remote包 import _ “github.com/spf13/viper/remote” Viper 可以从例如etcd、Consul的远程Key/Value存储系统的一个路径上，读取一个配置字符串（JSON, TOML, YAML或HCL格式）. 这些值优先于默认值，但会被从磁盘文件、命令行flag、环境变量的配置所覆盖. 本人对consul比较熟悉，用它来做例子 首先在本地启动consul 1consul agent -dev 并在consul上设置名为config的json配置文件 代码如下 1234567891011121314151617181920212223242526package mainimport ( \"fmt\" \"log\" \"github.com/spf13/viper\" _ \"github.com/spf13/viper/remote\")func main() &#123; v := viper.New() v.AddRemoteProvider(\"consul\", \"localhost:8500\", \"config\") v.SetConfigType(\"json\") // Need to explicitly set this to json if err := v.ReadRemoteConfig(); err != nil &#123; log.Println(err) return &#125; fmt.Println(\"获取配置文件的port\", v.GetInt(\"port\")) fmt.Println(\"获取配置文件的mysql.url\", v.GetString(`mysql.url`)) fmt.Println(\"获取配置文件的mysql.username\", v.GetString(`mysql.username`)) fmt.Println(\"获取配置文件的mysql.password\", v.GetString(`mysql.password`)) fmt.Println(\"获取配置文件的redis\", v.GetStringSlice(\"redis\")) fmt.Println(\"获取配置文件的smtp\", v.GetStringMap(\"smtp\"))&#125; 从io.Reader中读取配置信息 首先给大家来段例子 123456789101112131415161718192021222324252627282930313233343536373839404142package mainimport ( \"bytes\" \"fmt\" \"github.com/spf13/viper\")func main() &#123; v := viper.New() v.SetConfigType(\"json\") // 设置配置文件的类型 // 配置文件内容 var jsonExample = []byte(`&#123; \"port\": 10666, \"mysql\": &#123; \"url\": \"(127.0.0.1:3306)/biezhi\", \"username\": \"root\", \"password\": \"123456\" &#125;, \"redis\": [\"127.0.0.1:6377\", \"127.0.0.1:6378\", \"127.0.0.1:6379\"], \"smtp\": &#123; \"enable\": true, \"addr\": \"mail_addr\", \"username\": \"mail_user\", \"password\": \"mail_password\", \"to\": [\"xxx@gmail.com\", \"xxx@163.com\"] &#125;&#125;`) //创建io.Reader v.ReadConfig(bytes.NewBuffer(jsonExample)) fmt.Println(\"获取配置文件的port\", v.GetInt(\"port\")) fmt.Println(\"获取配置文件的mysql.url\", v.GetString(`mysql.url`)) fmt.Println(\"获取配置文件的mysql.username\", v.GetString(`mysql.username`)) fmt.Println(\"获取配置文件的mysql.password\", v.GetString(`mysql.password`)) fmt.Println(\"获取配置文件的redis\", v.GetStringSlice(\"redis\")) fmt.Println(\"获取配置文件的smtp\", v.GetStringMap(\"smtp\"))&#125; 这个功能日常的使用情况较少，例如这样的一个情景： 配置文件放在oss上或者github某个私有仓库上，viper并没有提供直接的接口去获取，这样我们可以基于第三方托管平台的sdk写一套获取配置文件bytes的工具，将结果放入io.Reader中，再进行配置文件的解析。 上述流程感觉好像比较鸡肋，复杂了整个流程：我既然可以通过第三方的sdk直接拿到bytes，为何不自己直接进行解析呢？而要借助viper来解析。可能有人会说，配置文件如果格式不同呢？确实，viper的出现就是为了针对多种格式的配置文件。但是在正式的项目中，配置文件的格式一般不会变，可以自己写一套解析的工具，也就没有使用viper的需求了。而且对于某一种特定格式的配置文件（JSON，YAML…），Golang已经有足够强大的包来进行解析了。 但是不得不承认 viper 的实现确实是很流弊的。在一般的快速开发过程中，直接使用 viper 确实可以帮助我们省去很多的麻烦，让我们集中精力针对于业务逻辑的实现。 个人觉得可以根据实际需求在 viper 再进行一层封装，接入一些常用的第三方平台的sdk（github，aliyun oss…）,这样即可以读取本地配置文件，也可以读取远端的配置文件，可以通过命令行参数来实现 dev 模式和 deploy 模式的切换。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"golang 环境变量填充struct","slug":"go-env","date":"2019-07-30T14:35:00.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/07/30/go-env/","link":"","permalink":"https://overtalk.site/2019/07/30/go-env/","excerpt":"","text":"env to golang struct caarlos0/env是一个第三方开源的环境变量库，支持转化成struct Github：https://github.com/caarlos0/env 官方文档：https://godoc.org/github.com/caarlos0/env 用途 将环境变量转化成Go中的Struct的库 可以将项目的配置通过环境变量的形式传入 用法介绍 struct 中每个变量需要带上env的标签 如果是数组，需要设置envSeparator 如果设置envExpand标记，则将根据变量的实际值替换字符串中的环境变量（格式${var}或 $var格式），未导出的字段将被忽略。 Example1234567891011121314151617181920212223242526package mainimport ( \"fmt\" \"time\" \"github.com/caarlos0/env\")type config struct &#123; Home string `env:\"HOME\"` Port int `env:\"PORT\" envDefault:\"3000\"` IsProduction bool `env:\"PRODUCTION\"` Hosts []string `env:\"HOSTS\" envSeparator:\":\"` Duration time.Duration `env:\"DURATION\"` TempFolder string `env:\"TEMP_FOLDER\" envDefault:\"$&#123;HOME&#125;/tmp\" envExpand:\"true\"`&#125;func main() &#123; cfg := config&#123;&#125; if err := env.Parse(&amp;cfg); err != nil &#123; fmt.Printf(\"%+v\\n\", err) &#125; fmt.Printf(\"%+v\\n\", cfg)&#125; 运行123$ PRODUCTION=true HOSTS=\"host1:host2:host3\" DURATION=1s go run main.go&#123;Home:/your/home Port:3000 IsProduction:true Hosts:[host1 host2 host3] Duration:1s&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"linux 中的 systemd & systemctl","slug":"systemd","date":"2019-07-30T13:31:32.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/07/30/systemd/","link":"","permalink":"https://overtalk.site/2019/07/30/systemd/","excerpt":"","text":"centos7 上 systemd 详解 简介 CentOS 7继承了RHEL 7的新的特性，例如强大的systemd， 而systemd的使用也使得以往系统服务的/etc/init.d的启动脚本的方式就此改变， 也大幅提高了系统服务的运行效率。但服务的配置和以往也发生了极大的不同，同时变的简单而易用了许多。 CentOS 7的服务systemctl脚本存放在：/usr/lib/systemd/，有系统 system 和用户 user 之分， 即：/usr/lib/systemd/system 和 /usr/lib/systemd/user 配置文件 这里我们先要说明一下unit的文件位置，一般主要有三个目录： 123/lib/systemd/system/run/systemd/system/etc/systemd/system 这三个目录的配置文件优先级依次从低到高，如果同一选项三个地方都配置了，优先级高的会覆盖优先级低的。 系统安装时，默认会将unit文件放在/lib/systemd/system目录。如果我们想要修改系统默认的配置，比如nginx.service，一般有两种方法： 在/etc/systemd/system目录下创建nginx.service文件，里面写上我们自己的配置。 在/etc/systemd/system下面创建nginx.service.d目录，在这个目录里面新建任何以.conf结尾的文件，然后写入我们自己的配置。推荐这种做法。 /run/systemd/system这个目录一般是进程在运行时动态创建unit文件的目录，一般很少修改，除非是修改程序运行时的一些参数时，即Session级别的，才在这里做修改。 服务配置 每一个服务以.service结尾，一般会分为3部分：[Unit]、[Service]和[Install]，就以nginx为例吧，具体内容如下：12345678910111213141516[Unit]Description=nginx - high performance web serverDocumentation=http://nginx.org/en/docs/After=network.target remote-fs.target nss-lookup.target[Service]Type=forkingPIDFile=/usr/local/nginx/logs/nginx.pidExecStartPre=/usr/local/nginx/sbin/nginx -t -c /usr/local/nginx/conf/nginx.confExecStart=/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.confExecReload=/bin/kill -s HUP $MAINPIDExecStop=/bin/kill -s QUIT $MAINPIDPrivateTmp=true[Install]WantedBy=multi-user.target 配置项说明 下面分别解释下着三部分的含义 [Unit] Description : 服务的简单描述 Documentation ： 服务文档 After= : 依赖，仅当依赖的服务启动之后再启动自定义的服务单元 [Service] Type : 启动类型simple、forking、oneshot、notify、dbus Type=simple（默认值）：systemd认为该服务将立即启动，服务进程不会fork。如果该服务要启动其他服务，不要使用此类型启动，除非该服务是socket激活型 Type=forking：systemd认为当该服务进程fork，且父进程退出后服务启动成功。对于常规的守护进程（daemon），除非你确定此启动方式无法满足需求， 使用此类型启动即可。使用此启动类型应同时指定PIDFile=，以便systemd能够跟踪服务的主进程。 Type=oneshot：这一选项适用于只执行一项任务、随后立即退出的服务。可能需要同时设置 RemainAfterExit=yes 使得 systemd 在服务进程退出之后仍然认为服务处于激活状态。 Type=notify：与 Type=simple 相同，但约定服务会在就绪后向 systemd 发送一个信号，这一通知的实现由 libsystemd-daemon.so 提供 Type=dbus：若以此方式启动，当指定的 BusName 出现在DBus系统总线上时，systemd认为服务就绪。 PIDFile ： pid文件路径 Environment ： 环境变量（可以添加多个）eg ：Environment=REPO_REF=dev ExecStartPre ：启动前要做什么，上文中是测试配置文件 －t ExecStart：启动 ExecReload：重载 ExecStop：停止 PrivateTmp：True表示给服务分配独立的临时空间 [Install] WantedBy：服务安装的用户模式，从字面上看，就是想要使用这个服务的有是谁？上文中使用的是：multi-user.target ，就是指想要使用这个服务的目录是多用户。 操作示例 每一个.target实际上是链接到我们单位文件的集合,当我们执行1systemctl enable nginx.service 就会在 /etc/systemd/system/multi-user.target.wants/ 目录下新建一个 /usr/lib/systemd/system/nginx.service 文件的链接。 常用的service操作1234567891011121314151617181920212223242526272829303132333435363738394041424344# 自启动systemctl enable nginx.service# 禁止自启动systemctl disable nginx.service# 启动服务systemctl start nginx.service# 停止服务systemctl stop nginx.service# 重启服务systemctl restart nginx.service# 查看Unit定义文件systemctl cat nginx.service# 编辑Unit定义文件systemctl edit nginx.service# 重新加载Unit定义文件systemctl reload nginx.service# 列出已启动的所有unit，就是已经被加载到内存中systemctl list-units# 列出系统已经安装的所有unit，包括那些没有被加载到内存中的unitsystemctl list-unit-files# 查看服务的日志journalctl -u nginx.service # 还可以配合`-b`一起使用，只查看自本次系统启动以来的日志# 查看所有target下的unitsystemctl list-unit-files --type=target# 查看默认target，即默认的运行级别。对应于旧的`runlevel`命令systemctl get-default# 设置默认的targetsystemctl set-default multi-user.target# 查看某一target下的unitsystemctl list-dependencies multi-user.target# 切换target，不属于新target的unit都会被停止systemctl isolate multi-user.targetsystemctl poweroff # 关机systemctl reboot # 重启systemctl rescue # 进入rescue模式 Systemd + Golang Demo 下面例子通过 Systemd 部署一个最简单的 Golang Web Server 1234567891011121314151617181920package mainimport ( \"flag\" \"fmt\" \"log\" \"net/http\")func main() &#123; var address string flag.StringVar(&amp;address, \"address\", \"5353\", \"listen address\") flag.Parse() http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) &#123; fmt.Fprintf(w, \"Hello, This is a test for systemd !\\n\") &#125;) // 设置访问路由 log.Printf(\"Starting server on %s\\n\", address) log.Fatal(http.ListenAndServe(fmt.Sprintf(\":%s\", address), nil))&#125; 编译代码，并将可执行文件同步到远程服务器上 123CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o systemd-test main.gorsync -zP ./systemd-test root@gp-aliyun:/usr/local/bin/ 在远程服务器上编写服务配置，放在/etc/systemd/system/中 1234567891011[Unit]Description=Systemd TestAfter=network.target[Service]User=nobody# Execute `systemctl daemon-reload` after ExecStart= is changed.ExecStart=/usr/local/bin/systemd-test -address \"6060\"[Install]WantedBy=multi-user.target 通过systemctl启动服务 1234567# 每一次修改ExecStart都需执行systemctl daemon-reload# 启动systemctl start systemd-test.service# 查看状态systemctl status systemd-test.service 状态如下 可以通过curl进行测试：","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"systemd","slug":"systemd","permalink":"https://overtalk.site/tags/systemd/"}]},{"title":"cron","slug":"go-cron","date":"2019-07-29T14:07:37.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/07/29/go-cron/","link":"","permalink":"https://overtalk.site/2019/07/29/go-cron/","excerpt":"","text":"cron robfig/cron是一个第三方开源的任务调度库，适合于定时任务 Github：github.com/robfig/cron 官方文档：https://godoc.org/github.com/robfig/cron cron 表达式的基本格式12345用过 linux 的应该对 cron 有所了解。linux 中可以通过 crontab -e 来配置定时任务。不过，linux 中的 cron 只能精确到分钟。而我们这里要讨论的 Go 实现的 cron 可以精确到秒，除了这点比较大的区别外，cron 表达式的基本语法是类似的。（如果使用过 Java 中的 Quartz，对 cron 表达式应该比较了解，而且它和这里我们将要讨论的 Go 版 cron 很像，也都精确到秒）cron(计划任务)，顾名思义，按照约定的时间，定时的执行特定的任务（job）。cron 表达式 表达了这种约定。cron 表达式代表了一个时间集合，使用 6 个空格分隔的字段表示。 字段名 是否必须 允许的值 允许的特定字符 秒(Seconds) 是 0-59 * / , - 分(Minutes) 是 0-59 * / , - 时(Hours) 是 0-23 * / , - 日(Day of month) 是 1-31 * / , – ? 月(Month) 是 1-12 or JAN-DEC * / , - 星期(Day of week) 否 0-6 or SUM-SAT * / , – ? 123注：1）月(Month)和星期(Day of week)字段的值不区分大小写，如：SUN、Sun 和 sun 是一样的。2）星期 (Day of week)字段如果没提供，相当于是 * 特殊字符说明12345678910111213141）星号(*)表示 cron 表达式能匹配该字段的所有值。如在第5个字段使用星号(month)，表示每个月2）斜线(/)表示增长间隔，如第1个字段(minutes) 值是 3-59/15，表示每小时的第3分钟开始执行一次，之后每隔 15 分钟执行一次（即 3、18、33、48 这些时间点执行），这里也可以表示为：3/153）逗号(,)用于枚举值，如第6个字段值是 MON,WED,FRI，表示 星期一、三、五 执行4）连字号(-)表示一个范围，如第3个字段的值为 9-17 表示 9am 到 5pm 直接每个小时（包括9和17）5）问号(?)只用于日(Day of month)和星期(Day of week)，\\表示不指定值，可以用于代替 * 一些常用的的 cron spec spec 周期 */1 * * * * * 每秒 0 */5 * ? * * 每五分钟 0 0 4 * * 1 每周一凌晨四点钟 使用demo简单单个任务123456789101112131415161718192021222324package mainimport ( \"fmt\" \"time\" \"github.com/robfig/cron\")func main() &#123; c := cron.New() c.AddFunc(\"*/1 * * * * *\", func() &#123; fmt.Println(\"every 1 seconds executing\") &#125;) go c.Start() defer c.Stop() select &#123; case &lt;-time.After(time.Second * 10): return &#125;&#125; 多个定时任务1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package mainimport ( \"fmt\" \"log\" \"github.com/robfig/cron\")type TestJob struct &#123;&#125;func (t TestJob) Run() &#123; fmt.Println(\"testJob1...\")&#125;type Test2Job struct &#123;&#125;func (t Test2Job) Run() &#123; fmt.Println(\"testJob2...\")&#125;//启动多个任务func main() &#123; i := 0 c := cron.New() //AddFunc spec := \"*/5 * * * * ?\" c.AddFunc(spec, func() &#123; i++ log.Println(\"cron running:\", i) &#125;) //AddJob方法 c.AddJob(spec, TestJob&#123;&#125;) c.AddJob(spec, Test2Job&#123;&#125;) //启动计划任务 c.Start() //关闭着计划任务, 但是不能关闭已经在执行中的任务. defer c.Stop() select &#123;&#125;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"科学上网-shadowsocks","slug":"shadowsocks","date":"2019-07-26T11:14:59.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/07/26/shadowsocks/","link":"","permalink":"https://overtalk.site/2019/07/26/shadowsocks/","excerpt":"","text":"Shadowsocks 使用 利用docker搭建属于自己的shadowsocks服务器一键式部署，操作方便 基础 每一个网络请求都是有数据特征的，不同的协议具备不同的特征，比如 HTTP/HTTPS 这类请求，会很明确地得到它们要请求哪个域名；再比如 TCP 请求，它只会告诉 GFW 它们要请求哪个 IP。 ssh tunnel 是比较具有代表性的防窃听通讯隧道，通过 ssh 与境外服务器建立一条加密通道，此时的通讯 GFW 会将其视作普通的连接。由于大家都这么玩，GFW 着急了，于是它通过各种流量特征分析，渐渐的能够识别哪些连接是 ssh 隧道，并尝试性的对隧道做干扰，结果还是玩不过 GFW，众多隧道纷纷不通。 Shadowsocks 及其部署原理 具体而言，Shadowsocks 将原来 ssh 创建的 Socks5 协议拆开成 Server 端和 Client 端，两个端分别安装在境外服务器和境内设备上。123+------+ +------+ +=====+ +------+ +-------+| 设备 | &lt;-&gt; |Client| &lt;-&gt; | GFW | &lt;-&gt; |Server| &lt;-&gt; | 服务器 |+------+ +------+ +=====+ +------+ +-------+ 境外服务器购买 推荐购买centos7 提供几个以供参考： https://bandwagonhost.com/ https://virmach.com/ 服务端 Docker安装 为了实现一键式开启/停止服务，可以将shadowsocks服务运行在docker中，并且有大佬向Docker Hub上传了相关的镜像，我们可以直接拿来用。 安装docker的教程网络上有很多，我推荐一篇： https://qizhanming.com/blog/2019/01/25/how-to-install-docker-ce-on-centos-7 拉取镜像 1docker pull oddrationale/docker-shadowsocks 启动容器 命令中 12345 端口号可以根据自己的喜好进行修改 YOUR_PASSWORD 替换成自己的密码1docker run -d -p 12345:12345 oddrationale/docker-shadowsocks -s 0.0.0.0 -p 12345 -k YOUR_PASSWORD -m aes-256-cfb 客户端 Android : 可以在Google Play中下载到 https://github.com/shadowsocks/shadowsocks-android/releases Window : https://github.com/shadowsocks/shadowsocks-windows/releases MacOS : https://github.com/shadowsocks/ShadowsocksX-NG/releases","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Shadowsocks","slug":"Shadowsocks","permalink":"https://overtalk.site/tags/Shadowsocks/"},{"name":"Docker","slug":"Docker","permalink":"https://overtalk.site/tags/Docker/"}]},{"title":"redis备份工具","slug":"redis-dump","date":"2019-07-26T10:56:23.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/07/26/redis-dump/","link":"","permalink":"https://overtalk.site/2019/07/26/redis-dump/","excerpt":"","text":"Redis-port parse redis rdb file 项目地址 https://github.com/CodisLabs/redis-port 安装 https://github.com/CodisLabs/redis-port/releases 可选择macos、linux… 使用 dump 将redis中的数据导入rdb文件（本地Redis）1redis-port dump -f 127.0.0.1:6379 -a xxx(密码) -o xxx(输出文件) restore 将rdb文件数据导入redis中（本地Redis）1redis-port restore -i xxx（输入文件） -t 127.0.0.1:6379 -a xxx(密码)","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Redis备份","slug":"Redis备份","permalink":"https://overtalk.site/tags/Redis%E5%A4%87%E4%BB%BD/"}]},{"title":"一种游戏排行榜的实现方案","slug":"redis-rank","date":"2019-07-24T17:14:52.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/07/24/redis-rank/","link":"","permalink":"https://overtalk.site/2019/07/24/redis-rank/","excerpt":"","text":"Global Rank 本篇博客主要提供了一种游戏全服排行榜的实现方式，主要借助 Redis 的 Sorted Set 数据结构来实现。 将排行榜数据放在 Redis 中可以很好的适配分布式部署的服务 主要思路 当玩家的排行榜数据发送变化的时候（例如：通过新的关卡），直接更新Redis中的数据。 服务节点定期从Redis中拉去最新的排行榜数据，缓存在内存中，当玩家请求排行榜数据的时候，从内存缓存中直接拿出数据 定期清除排行榜中的数据量，只保留需要显示的数量 代码实现Redis部分 主要是三个接口（Get，Set，Del） 123456789101112131415// rank itemtype RankItem struct &#123; PlayerID string Socre int Ts int64&#125;// Value used to get a float64 to set into Redisfunc (i RankItem) Value() float64 &#123; return float64(i.Score)&#125;// interfaceSet(item *RankItem) errorGet() ([]RankItem, error)Del(maxRanksNum int64) (int64, error) 接口的实现 这儿的RedisCache是我自己封装的struct，包含client（ github.com/go-redis/redis 库中的 redis.Cmdable） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455func (c RedisCache)Set(item *RankItem) error&#123; if err := c.client.Ping().Err(); err != nil &#123; // add log ,failed to ping redis return err &#125; // if key $item.PlayerID is already exist, it will replace it with the new value err := c.client.ZAdd(pveStarRankRedisKey, redis.Z&#123;Score: item.Value(), Member: item.PlayerID&#125;).Err() if err != nil &#123; // todo : add log, failed to set &#125; return err&#125;func (c RedisCache)Get() ([]RankItem, error) &#123; if err := c.client.Ping().Err(); err != nil &#123; // add log, failed to ping redis return nil, err &#125; // get 0-99 in zset(key = pveStarRankRedisKey) results, err := c.client.ZRevRangeWithScores(pveStarRankRedisKey, 0, 99).Result() if err != nil &#123; // add log return nil, err &#125; items := make([]model.RankItem, 0, len(results)) for _, v := range results &#123; playerID := v.Member.(string) value := int(v.Score) items = append(items, model.RankItem&#123; PlayerID: playerID, Score: value, &#125;) &#125; return items, nil&#125;func (c RedisCache)Del(maxRanksNum int64) (int64, error)&#123; if err := c.client.Ping().Err(); err != nil &#123; // add log return 0, err &#125; num, err := c.client.ZCard(dbKey).Result() if err != nil &#123; // add log return 0, err &#125; availDeleteNum := num - maxRanksNum if availDeleteNum &lt;= 0 &#123; return 0, nil &#125; return c.client.ZRemRangeByRank(dbKey, 0, availDeleteNum-1).Result()&#125; Server部分 主要包含定期从Redis中拉去排行榜数据 主要的设计思路就是定时器触发拉取任务，并且存入内存中 内存缓存变量可能会被多线程访问，需要防止静态，存入 atomic.Value 中 12345678910111213141516171819202122232425262728293031type Rank struct &#123; rankRedisCache RedisCache rankData atomic.Value&#125;func (p *Rank) loopRanks() &#123; // get data from redis in 10 second var ticker = time.NewTicker(10 * time.Second) defer ticker.Stop() for range ticker.C &#123; p.loadRanksFromRedis() &#125;&#125;func (p *Rank) loadRanksFromRedis() &#123; items, err := p.rankRedisCache.Get() if err != nil &#123; // add log return &#125; if len(items) &gt; 0 &#123; p.rankData.Store(items) &#125;&#125;// get rank data form atomic valuefunc (p *Rank) GetRankData() []RankItem &#123; val, _ := p.rankData.Load().([]RankItem) return val&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://overtalk.site/tags/Redis/"},{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"Golang排序包","slug":"go-sort","date":"2019-07-24T14:10:24.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/07/24/go-sort/","link":"","permalink":"https://overtalk.site/2019/07/24/go-sort/","excerpt":"","text":"Golang 中的 sort sort包中实现了３种基本的排序算法：插入排序．快排和堆排序．和其他语言中一样，这三种方式都是不公开的，他们只在sort包内部使用．所以用户在使用sort包进行排序时无需考虑使用那种排序方式，sort.Interface定义的三个方法：获取数据集合长度的Len()方法、比较两个元素大小的Less()方法和交换两个元素位置的Swap()方法，就可以顺利对数据集合进行排序。sort包会根据实际数据自动选择高效的排序算法 核心介绍 interface Interface 123456789101112// A type, typically a collection, that satisfies sort.Interface can be// sorted by the routines in this package. The methods require that the// elements of the collection be enumerated by an integer index.type Interface interface &#123; // Len is the number of elements in the collection. Len() int // Less reports whether the element with // index i should sort before the element with index j. Less(i, j int) bool // Swap swaps the elements with indexes i and j. Swap(i, j int)&#125; func Sort(data Interface) 1234567// Sort sorts data.// It makes one call to data.Len to determine n, and O(n*log(n)) calls to// data.Less and data.Swap. The sort is not guaranteed to be stable.func Sort(data Interface) &#123; n := data.Len() quickSort(data, 0, n, maxDepth(n))&#125; func Reverse(data Interface) Interface 实现 Interface 的降序排序 1234// Reverse returns the reverse order for data.func Reverse(data Interface) Interface &#123; return &amp;reverse&#123;data&#125;&#125; 用法介绍 自定义slice进行排序的时候将 目标slice 定义成结构体，实现sort.Interface中的方法，即可以调用sort.Sort()方法进行升序排序，demo如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package mainimport ( \"fmt\" \"sort\")type Student struct &#123; name string sex bool //...&#125;type studetSlice []*Studentfunc (c studetSlice) Len() int &#123; return len(c)&#125;func (c studetSlice) Less(i, j int) bool &#123; return c[i].name &lt; c[j].name&#125;func (c studetSlice) Swap(i, j int) &#123; c[i], c[j] = c[j], c[i]&#125;func (c studetSlice) show() &#123; for i := 0; i &lt; c.Len(); i++ &#123; fmt.Printf(\"%v \", c[i]) &#125;&#125;func main() &#123; var students studetSlice for i := 10; i &gt;= 0; i-- &#123; students = append(students, &amp;Student&#123; name: fmt.Sprintf(\"student %d \", i), sex: true, &#125;) &#125; fmt.Println(\"bofore, is sorted : \", sort.IsSorted(students)) students.show() sort.Sort(students) fmt.Println(\"\\nafter, is sorted : \", sort.IsSorted(students)) students.show()&#125; 常用方法介绍1234567891011121314151617181920// 排序方法func Sort(data Interface) // 将Interface进行排序func IsSorted(data Interface) bool // 检查Interface是否已经排序func Float64s(a []float64) // 将[]float64按照升序排序func Float64sAreSorted(a []float64) bool // 检查[]float64是否已经排序func Ints(a []int) // 将[]int以升序排序func IntsAreSorted(a []int) bool // 检查[]int是否已经排序func Strings(a []string) // 将[]string以升序排序func StringsAreSorted(a []string) bool // 检查[]string是否已经排序// 查找方法func Search(n int, f func(int) bool) int // 二分法遍历[0, n), 找到最小满足f的数func SearchFloat64s(a []float64, x float64) int // 查找 x 在 a 中的index, 如果不存在, 则返回插入之后的indexfunc SearchInts(a []int, x int) int // 查找 x 在 a 中的index, 如果不存在, 则返回插入之后的indexfunc SearchStrings(a []string, x string) int // 查找 x 在 a 中的index, 如果不存在, 则返回插入之后的index// 通用slice排序func Slice(slice interface&#123;&#125;, less func(i, j int) bool) // slice 必须为slice，否则会panic；less为Less函数；不稳定排序；func SliceIsSorted(slice interface&#123;&#125;, less func(i, j int) bool) bool // 判断slice是否已经排序了func SliceStable(slice interface&#123;&#125;, less func(i, j int) bool) // Slice函数的稳定排序版本 常用slice封装IntSlice sort包封装好的int数组排序工具，核心函数如下所示： 1234567891011121314151617181920// IntSlice attaches the methods of Interface to []int, sorting in increasing order.type IntSlice []int // implement of Interface func (p IntSlice) Len() int &#123; return len(p) &#125; func (p IntSlice) Less(i, j int) bool &#123; return p[i] &lt; p[j] &#125; func (p IntSlice) Swap(i, j int) &#123; p[i], p[j] = p[j], p[i] &#125; func (p IntSlice) Sort() &#123; Sort(p) &#125; // Search returns the result of applying SearchInts to the receiver and x. func (p IntSlice) Search(x int) int &#123; return SearchInts(p, x) &#125; // SearchInts searches for x in a sorted slice of ints and returns the index // as specified by Search. The return value is the index to insert x if x is // not present (it could be len(a)). // The slice must be sorted in ascending order. // func SearchInts(a []int, x int) int &#123; return Search(len(a), func(i int) bool &#123; return a[i] &gt;= x &#125;) &#125; Float64Slice sort包封装好的float64数组排序工具，核心函数如下所示： 12345678910111213141516171819202122// Float64Slice attaches the methods of Interface to []float64, sorting in increasing order// (not-a-number values are treated as less than other values).type Float64Slice []float64 // implement of Interface func (p Float64Slice) Len() int &#123; return len(p) &#125; func (p Float64Slice) Less(i, j int) bool &#123; return p[i] &lt; p[j] || isNaN(p[i]) &amp;&amp; !isNaN(p[j]) &#125; func (p Float64Slice) Swap(i, j int) &#123; p[i], p[j] = p[j], p[i] &#125; // Sort is a convenience method. func (p Float64Slice) Sort() &#123; Sort(p) &#125; // Search returns the result of applying SearchFloat64s to the receiver and x. func (p Float64Slice) Search(x float64) int &#123; return SearchFloat64s(p, x) &#125; // SearchFloat64s searches for x in a sorted slice of float64s and returns the index // as specified by Search. The return value is the index to insert x if x is not // present (it could be len(a)). // The slice must be sorted in ascending order. // func SearchFloat64s(a []float64, x float64) int &#123; return Search(len(a), func(i int) bool &#123; return a[i] &gt;= x &#125;) &#125; StringSlice sort包封装好的string数组排序工具，核心函数如下所示： 123456789101112131415161718192021// StringSlice attaches the methods of Interface to []string, sorting in increasing order.type StringSlice []string // implement of Interface func (p StringSlice) Len() int &#123; return len(p) &#125; func (p StringSlice) Less(i, j int) bool &#123; return p[i] &lt; p[j] &#125; func (p StringSlice) Swap(i, j int) &#123; p[i], p[j] = p[j], p[i] &#125; // Sort is a convenience method. func (p StringSlice) Sort() &#123; Sort(p) &#125; // Search returns the result of applying SearchStrings to the receiver and x. func (p StringSlice) Search(x string) int &#123; return SearchStrings(p, x) &#125; // SearchStrings searches for x in a sorted slice of strings and returns the index // as specified by Search. The return value is the index to insert x if x is not // present (it could be len(a)). // The slice must be sorted in ascending order. // func SearchStrings(a []string, x string) int &#123; return Search(len(a), func(i int) bool &#123; return a[i] &gt;= x &#125;) &#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://overtalk.site/tags/Golang/"}]},{"title":"docker","slug":"docker","date":"2019-07-22T14:52:18.000Z","updated":"2022-07-19T07:53:37.893Z","comments":true,"path":"2019/07/22/docker/","link":"","permalink":"https://overtalk.site/2019/07/22/docker/","excerpt":"","text":"获取 Docker Docker 有两个可用的版本，社区版：ommunity Edition (CE)， 企业版：Enterprise Edition (EE)，Docker Community Edition（CE）非常适合希望开始使用Docker并尝试使用基于容器的应用程序的开发人员和小型团队，社区版有两个主要的更新通道，stage, edge: stage: 每个季度更新一次，稳定可靠 edge: 每月更新一次，能够体验最新的功能 Docker企业版（EE）专为企业级开发人员和IT团队而设计，他们在大规模生产中构建，发布和运行关键业务应用程序. 安装 Docker 针对 Mac 安装 CE 版本 其他的版本可以参考官方文档 Homebrew的Cask已经支持docker for Mac，因此可以使用Homebrew Cask 来进行安装： 1brew cask install docker 启动终端，查看docker是否安装成功： 123456➜ ~ docker --versionDocker version 17.12.0-ce, build c97c6d6➜ ~ docker-machine --versiondocker-machine version 0.13.0, build 9ba6da9➜ ~ docker-compose --versiondocker-compose version 1.18.0, build 8dd22a9 如果docker version，docker info 都运行正确的话，可以尝试启动一个nginx试试： 1docker run -d -p 8090:80 --name webserver nginx 一切正常的话，打开浏览器，输入：http://localhost:8090你将看到： 列出你创建的容器： 1docker ps -a 停止启动的容器： 1docker stop xxxx 删除你创建的容器： 1docker rm xxxxxx 查看已经下载的镜像： 1docker images 除此之外，一些常用的命令如下： docker命令 意义 docker version 查看docker版本 docker search xxx 从仓库中查找镜像 docker pull xxx/xxx(用户名/镜像名) 从仓库中下载镜像 docker run xxx/xxx(用户名/镜像名) 启动容器 docker ps （-l , -a…） 查看所有容器 docker inspect 容器id 查看具体容器 docker commit 容器id 从容器创建一个新的镜像 docker push xxx/xxx(用户名/镜像名) 提交镜像 docker port 容器名 查看容器的端口映射情况 镜像服务（加速器） 我们常用的Registry是docker官方的Docker Hub,这也是默认的 Registry，并拥有大量的高质量的官方镜像。还有quay.io。由于某些原因，在国内访问这些服务可能会比较慢。国内的一些云服务商提供了针对 Docker Hub 的镜像服务（Registry Mirror），这些镜像服务被称为加速器。常见的有：阿里云加速器,DaoCloud加速器； 使用Docker容器的简要说明 镜像（image）是一个轻量级的，独立的可执行程序包，包含运行一个软件所需的所有东西，包括代码运行时依赖库，环境变量和配置文件。 容器是镜像的运行时示例，镜像运行时在内存中变成的内容，默认情况下，它与主机完全隔离，只有在配置的情况下才可访问主机的端口和文件。 容器在系统内核上就地运行应用程序，同通过管理程序获得一个接入主机资源的虚拟机相比，他有更好的性能特点，容器可以获得本地访问权限，每个容器都以独立的进程运行，相比其他的应用程序，不需要更多的内存。 虚拟机 VS 容器 虚拟机通过中间层将一台或者多台独立的及其运行于物理硬件当中；而容器则是直接运行在操作系统内核之上的用户空间 容器技术的磁盘占有空间少，虚拟机部署应用包含应用和其依赖的库，还需要包含完整的操作系统，容器只需前两者。另外，虚拟机需要模拟硬件的行为，对cpu，内存消耗较大 虚拟机运行原理： 虚拟机运行客户操作系统， 注意在每个box中都有一个系统层。这是资源密集型，这将导致磁盘镜像，应用程序状态同系统设置，系统安装的依赖以及系统补丁纠缠在一起，而且容易丢失，很难复制。传统虚拟机技术就是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程； 容器运行原理： 容器可以共享一个内核，并且唯一需要在容器镜像中的信息是可执行文件及其包依赖关系，它们永远不需要安装在主机系统上。这些进程的运行就如同本地的进程一样，你可以使用docker ps命令管理他们，就像你在linux平台使用ps命令查看本地进程一样，最后，因为他们包含了所有的依赖关系，就没有配置依赖的纠葛。一个集装箱化的应用程序可以随处运行。 构建并运行你的第一个应用程序Introduction 现在是时候用docker的方式构建一个应用程序了，我们将从这个应用程序的底部开始构建，这个应用程序是一个容器，然后我们再在这一层上添加新的东西。在这个层次上面是一个服务，它定义了容器在生产环境中的行为，这个将在接下里的一节中讲到。最后在顶层是stacks，定义所有服务的交互，将在第五部分讲到。结构层次大概是这样式的： stacks Services containers（我们现在在这里） Your new development environment 过去，你写一个PythonAPP的时候，流程的第一步就是在你的电脑上安装Python运行库。但是这将造成这样的情况，不仅需要一个能完美运行应用程序的本地环境，同时还需要一个与之匹配的生产环境。 使用docker，你可以将一个基础的可移植的Python运行环境作为一个镜像，然后你的构建将包括Python基础的镜像和你的应用程序代码，确保你的应用程序，它的依赖和运行时都是在一起的。 这些可移植的镜像可以由一个叫做Dockerfile的文件来进行定义。 Dockerfile 接下来要跟着一起来动手了，只有在动手的过程中才能体会到生命的乐趣。创建一个新的目录，并且切换到新的目录下创建一个文件：Dockerfile，复制粘贴下面的内容然后保存，可以看看里面的解释。1234567891011121314151617181920# 使用一个官方的Python运行时作为基础FROM python:3.6-slim# 设置工作目录为/appWORKDIR /app# 复制当前目录的内容到/appADD . /app# 安装requirements.txt中声明包RUN pip install --trusted-host mirrors.aliyun.com --index http://mirrors.aliyun.com/pypi/simple/ -r requirements.txt# 暴露端口80给容器外部的环境EXPOSE 80# 定义一个环境变量ENV NAME World# 当容器启动的时候运行app.pyCMD [\"python\", \"app.py\"] Dockerfile中涉及到几个文件我们还没有创建，app.py以及requirements.txt。 应用程序 我们在Dockerfile所在的目录下再创建两个文件：app.py以及requirements.txt，文件内容如下所述，这就算是补全我们的应用程序，虽说简单，但是五脏俱全。 requirements.txt12FlaskRedis -app.py 1234567891011121314151617181920212223242526from flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket# Connect to Redisredis = Redis(host=\"redis\", db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route(\"/\")def hello(): try: visits = redis.incr(\"counter\") except RedisError: visits = \"&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;\" html = \"&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;\" \\ \"&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;\" \\ \"&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;\" return html.format(name=os.getenv(\"NAME\", \"world\"), hostname=socket.gethostname(), visits=visits)if __name__ == \"__main__\": app.run(host='0.0.0.0', port=80) 现在我们将看到pip install -r requirements.txt安装了flask和redis的Python扩展，应用将打印环境变量NAME以及socker.gethostname()的输出，但是由于我们没有安装redis服务，所以我们期望这里打印错误信息。 build app 现在我们构建我们的APP，在开始构建的使我们，在我们的应用目录下执行ls，应该至少看到以下这几个文件：Dockerfile, requirements.txt, app.py 现在我们执行构建命令，这将创建一个新的镜像，我们也使用-t创建一个友好的标签。 1docker build -t firstapp . 构建的镜像在哪里？可以使用docker images 查看 1docker images Run the app 运行容器的时候，我们将使用-p参数将主机的4040端口映射到容器的80端口： 1docker run -p 4040:80 firstapp 启动成功的时候你将看到一个来自容器内部的消息：* Running on http://0.0.0.0:80/ (Press CTRL+C to quit), 因为容器并不知道我们将80端口映射到了4040，所以在浏览器中输入以下URL进行访问：http://localhost:4040,我们将看到以下的结果： 使用CTRL+C进行退出 或者我们可以让容器在后台启动： 1docker run -d -p 4040:80 firstapp share your image 为了验证可移植性，我们将刚刚创建的镜像上传然后在其他地方运行。毕竟你需要知道当部署应用到生产环境的时候如何推送镜像到registry。一个registry是一系列的集合，一个仓库是一系列镜像的集合。一个 Docker Registry 中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。 以 Ubuntu 镜像 为例，ubuntu 是仓库的名字，其内包含有不同的版本标签，如，14.04, 16.04。我们可以通过 ubuntu:14.04，或者 ubuntu:16.04 来具体指定所需哪个版本的镜像。如果忽略了标签，比如 ubuntu，那将视为 ubuntu:latest。 仓库名经常以 两段式路径 形式出现，比如 jwilder/nginx-proxy，前者往往意味着 Docker Registry 多用户环境下的用户名，后者则往往是对应的软件名。但这并非绝对，取决于所使用的具体 Docker Registry 的软件或服务。 执行命令docker login使用dockerID进行登录。 执行命令docker tag image username/repository:tag 给镜像打标签，例如：docker tag firstapp gamelife1314/firstapp:0.1 执行命令docker push gamelife1314/firstapp:0.1发布镜像； 发布成功之后我们可以使用docker run -p 4040:80 gamelife1314/firstapp:0.1在任何机器上运行我们的应用程序了。 Services 在这部分中，我们扩展了应用程序并实现了负载平衡。要做到这一点，我们必须在分布式应用程序的层次结构中上一级：服务。 在分布式应用程序中，应用程序的不同部分被称为“服务”。例如，如果您想象一个视频共享站点，它可能包括一个用于将应用程序数据存储在数据库中的服务，后台运行的转码服务，一个用于前端的服务等等。 服务实际上只是“生产中的容器”。服务只运行一个镜像，但它定义了镜像运行的方式 - 应该使用哪个端口，容器应该运行多少个副本以便达到所需的容量，以及等等。Scaling a service changes the number of container instances running that piece of software, assigning more computing resources to the service in the process（扩展一个服务会改变运行该软件的容器实例的数量，已分配给程序中的服务更多的计算资源）. 第一个docker-compose.yaml文件格式 docker-compose.yaml是一个YAML格式的文件，描述了生产环境中docker的行为方式。 docker-compose.yaml: 12345678910111213141516171819version: \"3\"services: web: # 使用前一节创建的镜像 image: gamelife1314/firstapp:0.1 deploy: replicas: 5 resources: limits: cpus: \"0.1\" memory: 50M restart_policy: condition: on-failure ports: - \"4040:80\" networks: - webnetnetworks: webnet: 这个docker-compose.yaml 告诉docker做以下的事情： 从registry中拉取创建的镜像； 运行镜像的5个实例作为一个服务叫做web，限制每一个实例使用资源的上限 10% of the CPU (across all cores), 以及 50MB of RAM. 如果有一个失败，立即重启容器； 映射主机的4040端口到容器的80端口； 指示web容器通过叫做webnet的负载均衡网络共享端口80； 使用默认设置定义webnet网络； 然后运行：docker stack deploy -c docker-compose.yaml firstapp firstapp是应用程序名称； 我们单个service stack 在一个主机上运行了镜像的5个实例，可以通过docker srevice ls查看我们应用的服务id； Docker 概述 docker 基于linux内核，是一种容器技术（容器虚拟化的方案） docker 是一个可以把开发的应用程序自动的部署到容器中的一个开源引擎（Golang） docker 在虚拟化的容器执行环境中，增加了一个应用程序部署引擎 CS架构。docker客户端和docker的守护进程进行通信。Docker守护进程负责构建，运行和分发Docker容器。docker客户端可以运行在同一个机器上，但是docker客户端也可以连接远端的docker服务。docker客户端和docker守护进程的交互通过一个restfulAPI，或者Unix socket，或者一盒网络接口。 docker组成 Docker Client 客户端 Docker Daemon 守护进程 Docker Image 镜像 Docker Container 容器 Docker Registry 仓库 Docker Client / Docker Daemon （c/s架构） 终端中的一些docker命令（eg : docker pull, docker run …）通过client传给daemon（支持远程），然后返回结果 通过客户端访问守护进程，进而操作容器 Docker Image 容器的基石，容器基于镜像启动和运行 一个镜像可以作为另外镜像的底层镜像（父镜像） Docker Container 通过镜像启动，是docker的执行单元，一个container可以运行一个/多个用户进程 Docker Registry 用户保存用户的镜像，分为public和private docker 官方提供公开的仓库 Docker Hub Docker registries docker registry 用于存储docker镜像。docker hub 和 docker cloud 是公共的 registry，任何人都可以使用。docker默认从docker hub 获取镜像。当然你也可以使用自己的registry。 Docker 容器的基本操作交互式容器 docker run IMAGE [COMMAND] [ARG…] 在新的容器中执行命令 docker run -i -t IMAGE /bin/bash eg : docker run -i -t ubuntu /bin/bash -i : –interactive = true (打开标准输入) -t : –tty = true (打开tty终端) 自定义容器名称 : docker run –name=自定义名字 -i -t IMAGE /bin/bash docker start [-i] 容器名 重新启动容器(不产生新的容器) docker rm 容器名 删除已经停止的容器 守护式容器 docker run -d IMAGE [COMMAND] [ARG…] -d : 后台方式运行 docker attach 容器名 附加到运行中的容器 docker logs [-f][-t][–tail] 容器名 -f : –follows=true : 追踪日志 -t : – timestamps=true : 日志加上时间戳 –tail=”all” : tail 的意思是返回结尾出多少数量的日志，如果不指定，返回所有 docker top 容器名 查看运行中容器内所有的进程 docker exec -d [-d][-i][-t] 容器名 [COMMAND] [ARG…] 在容器内启动新的进程 docker stop 容器名 向容器发送信号，等待容器停止 docker kill 容器名 直接停止容器 容器中的部署 容器的端口映射 run [-P][-p] (大小写) -P : –publish-all=true 为容器所有暴露的端口进行映射 eg : docker run -P -i -t ubuntu /bin/bash -p : –publish=[] 指定映射容器的哪些端口, 有多种格式 只指定容器的端口 （containerPort） 宿主机的端口随机映射 eg : docker run -p 80 -i -t ubuntu /bin/bash 同时指定宿主机和容器端口 （hostPort : containerPort） 一一对应的 eg : docker run -p 80 -i -t ubuntu /bin/bash ip对应容器端口 （ip : containerPort） eg : docker run -p 0.0.0.0:80 -i -t ubuntu /bin/bash ip+端口对应容器端口 （ip+port : containerPort） eg : docker run -p 0.0.0.0:8080:80 -i -t ubuntu /bin/bash 对镜像的操作 镜像的两个重要属性 repository 镜像的仓库, eg : ubuntu, centos … tag 标签 列出镜像 docker images [OPTSIONS] [REPOSITORY] -a 查看所有的镜像 -f, –filter=[] 添加过滤条件 -q 只查看镜像的唯一id 查看镜像的具体信息 docker inspect [OPTIONS] CONTAINER/IMAGE (这个命令既支持容器的查看，也支持镜像的查看) -f : –format=”” 删除镜像 docker rmi [OPTIONS] IMAGE -f 强制删除 删除所有镜像 : docker rmi $(docekr images -q) 查找镜像 docker search [OPTIONS] TERM 拉取镜像 docker pull [OPTIONS] NAME[:TAG] -a 下载所有匹配NAME的有tag的 推送镜像 docker push NAME[:TAG] Dockerflie FROM FROM [image]:[tag] dockerfile第一条非注释的指令 MAINTAINER 作者信息，一般包含所有者以及联系方式 RUN 镜像构建过程中的指令，包含当前镜像中运行的命令，包含两种模式（shell &amp; exec） RUN [command] (shell 模式) 以 /bin/bash -c command 执行命令 eg : RUN echo hello RUN [“executable”, “param1”, “param2”] (exec 模式) 可以指定其他形式的shell来运行指令 eg : RUN [“/bin/bash”, “-c”, “echo hello”] EXPOSE 指定暴露的容器的端口 CMD 容器运行的默认命令，与前面的RUN不同的是 : 后者是构建镜像的过程中执行的命令 如果在使用 docker run 命令运行容器的时候加上了容器运行时候的指令，则cmd中的指令会被覆盖，不会执行。既：cmd用于指定容器的默认行为 CMD指令的两种模式（shell &amp; exec &amp; 特殊模式） CMD command param1 param2 (shell 模式) 以 /bin/bash -c command 执行命令 eg : CMD echo hello CMD [“executable”, “param1”, “param2”] (exec 模式) 可以指定其他形式的shell来运行指令 eg : CMD [“/bin/bash”, “-c”, “echo hello”] CMD [“param1”, “param2”] (只有一些参数) 通常与ENTERYPOINT指令配合使用，作为其默认参数 ENTERYPOINT 与CMD指令类似，也有两种模式（shell &amp; exec），但是它不会被 docker run 指令中的指令覆盖 如果需要覆盖，需要在 docker run 指令中加上--enterypoint选项 ADD &amp; COPY 将文件/目录复制到使用dockerfile构建的镜像中 用法 : ADD[COPY] [src]…[dest] src : 可以是本地地址（必须是构建目录的相对地址），也可以是url（不推荐用） dest : 镜像中的绝对路径 区别： ADD 包含类似tar的解压功能，如果只是单纯的复制文件，推荐使用COPY VOLUME 用于向基于镜像创建的容器添加卷，可以提供例如共享数据/数据持久化的功能 WORKDIR 在使用镜像创建容器时，在容器内部设置工作目录，ENTRYPOINT &amp; CMD 的命令都会在这个目录下执行 通常使用绝对路径 ENV 设置环境变量，与WORKDIR类似，构建 &amp; 运行 过程中都有效 USER 指定镜像以什么样的用户去运行 默认使用root用户 ONBUILD 为镜像添加触发器，当这个镜像被当作基础镜像的时候，这个指令就会被执行，这个镜像被构建时，会添加触发器中的指令 Docker 数据卷容器的数据卷 什么是数据卷（Data Volume） 数据卷设计的目的之一就是在于数据的永久化，既数据卷的生命周期与容器的生命周期独立，既Docker不会在容器删除的时候删除其挂载的数据卷 docker 数据卷是一个特殊设计的目录，可以绕过联合文件目录（UFS），为一个/多个容器提供访问","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://overtalk.site/tags/docker/"}]},{"title":"algorithm - 字符串和数组","slug":"algorithm-string","date":"2019-04-01T22:33:15.000Z","updated":"2022-07-19T07:53:37.889Z","comments":true,"path":"2019/04/01/algorithm-string/","link":"","permalink":"https://overtalk.site/2019/04/01/algorithm-string/","excerpt":"","text":"有关自字符串和数组的一些基本算法 1.字符串匹配 从长度为n的母串中匹配长度为m的子串 两种算法 暴力匹配 kmp 暴力匹配 顺序遍历母串，将每个字符作为匹配的起始字符，判断是否匹配子串，时间复杂度为：O(m*n)1234567891011121314151617181920212223242526272829303132int strMatch(const char* src, const char* target)&#123; // 字符串不为空 if (!strlen(target) || !strlen(src)) &#123; return -1; &#125; int index = 0; while (index &lt;= (strlen(src) - strlen(target))) &#123; int count = 0; bool flag = true; while (count &lt; strlen(target)) &#123; if (src[count+index] != target[count]) &#123; flag = false; break; &#125; count++; &#125; if (flag) &#123; return index; &#125; index++; &#125; return -1;&#125; KMP 算法 参考1 参考2 时间复杂度：O(m+n)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#include &lt;set&gt;void build_next_table(int *next, char *target_str) &#123; next[0] = 0; int target_len = strlen(target_str); // 遍历 target_str 的所有子串 for (int i = 1; i &lt; target_len; ++i) &#123; // 前缀子串 std::set&lt;std::string&gt; head_set; std::string tmp_head = \"\"; tmp_head = target_str[0]; head_set.insert(tmp_head); for (int j = 1; j &lt; i; ++j) &#123; tmp_head = tmp_head + target_str[j]; head_set.insert(tmp_head); &#125; // 后缀子串 std::set&lt;std::string&gt; tail_set; std::string tmp_tail = \"\"; tmp_tail = target_str[i]; tail_set.insert(tmp_tail); for (int j = i - 1; j &gt; 0; --j) &#123; tmp_tail = target_str[j] + tmp_tail; tail_set.insert(tmp_tail); &#125; // 共同子串的集合 std::set&lt;std::string&gt; common_set; for (const auto &amp;sub_str : head_set) &#123; if (tail_set.count(sub_str) &gt; 0) &#123; common_set.insert(sub_str); &#125; &#125; // 找出最长的共同子串 int max_len = 0; for (const auto &amp;common_str : common_set) &#123; if (common_str.size() &gt; max_len) &#123; max_len = common_str.size(); &#125; &#125; next[i] = max_len; &#125;&#125;int kmp(char *src_str, char *target_str) &#123; if (src_str == nullptr || target_str == nullptr) &#123; return -1; &#125; int src_len = strlen(src_str); int target_len = strlen(target_str); int *next = new int[src_len]; build_next_table(next, target_str); for (int i = 0; i&lt; target_len;i++) &#123; std::cout &lt;&lt; next[i] &lt;&lt; \" \"; &#125; int cur_find = 0; for (int i = 0; i &lt; src_len;) &#123; if (src_str[i] == target_str[cur_find]) &#123; i++; cur_find++; &#125; else &#123; if (cur_find == 0) &#123; ++i; &#125; else &#123; cur_find = next[cur_find-1]; &#125; &#125; if(cur_find == target_len) &#123; delete []next; return i - target_len; &#125; &#125; delete []next; return -1;&#125; 通过hash解决字符串问题 有一些关于string的算法题目，例如： 判断两个string是否为各自的排列？ 判断string中字符是否重复？ 给一个int[]和一个int，数组中是否存在两个数之和为target？ 暴力解法：先从数组中确定一个，再遍历其他的数，计算和是否为target -&gt; O(n*n) 通过 hashtable解决，将 int[] 转化成 map[int]int，计算 target-array[i] 是否在map中 -&gt; O(n) 给一个int[]，找出最长连续的子数组？ 例如：给你[31,9,74,3,4,2,1,]，返回[1,2,3,4] 思路如下： 首先使用hash table去除重复元素 遍历 hash table，对于每一个元素x，如果 x-1 存在，则这个数必定不是最长的 然后对于 x-1 不存在的元素，依次搜索 x+n，记录长度1234567891011121314151617181920212223242526272829303132// longest slice in arrayfunc maxSubString(src []int) int &#123; m := make(map[int]bool) // delete repeated for _, v := range src &#123; m[v] = true &#125; longest := 0 for value := range m &#123; // not the longest if _, isExist := m[value-1]; isExist &#123; continue &#125; tempLongest := 0 for &#123; if _, isExist := m[value+tempLongest]; !isExist &#123; break &#125; tempLongest++ &#125; if tempLongest &gt; longest &#123; longest = tempLongest &#125; &#125; return longest&#125; 给出两个字符串，返回最长的相同子串？ 动态规划 问题 例如：s1=”abcde” s2= “ace”，求两个字符串的公共子序列，答案是“ace” S{s1,s2,s3….si} T{t1,t2,t3,t4….tj} 子问题划分 (1) 如果S的最后一位等于T的最后一位，则最大子序列就是{s1,s2,s3…si-1}和{t1,t2,t3…tj-1}的最大子序列+1 (2) 如果S的最后一位不等于T的最后一位，那么最大子序列就是① {s1,s2,s3..si}和 {t1,t2,t3...tj-1} 最大子序列 ② {s1,s2,s3...si-1}和{t1,t2,t3....tj} 最大子序列 - 以上两个自序列的最大值 边界 只剩下{s1}和{t1}，如果相等就返回1，不等就返回0 使用一个表格来存储dp的结果 如果 S[i] == T[j] 则dp[i][j] = dp[i-1][j-1] + 1 否则dp[i][j] = max(dp[i][j-1],dp[i-1][j]) 123456789101112131415161718192021222324func longestCommonSubsequence(text1 string, text2 string) int &#123; var dp [][]int for i := 0; i &lt;= len(text1); i++ &#123; temp := make([]int, len(text2)+1) dp = append(dp, temp) &#125; for i := 1; i &lt;= len(text1); i++ &#123; for j := 1; j &lt;= len(text2); j++ &#123; if text1[i-1] == text2[j-1] &#123; dp[i][j] = dp[i-1][j-1] + 1 &#125; else &#123; if dp[i-1][j] &gt; dp[i][j-1] &#123; dp[i][j] = dp[i-1][j] &#125; else &#123; dp[i][j] = dp[i][j-1] &#125; &#125; &#125; &#125; return dp[len(text1)][len(text2)]&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://overtalk.site/tags/algorithm/"},{"name":"cpp","slug":"cpp","permalink":"https://overtalk.site/tags/cpp/"}]},{"title":"tcp - nodelay","slug":"network-tcp-nodelay","date":"2019-04-01T09:59:53.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/04/01/network-tcp-nodelay/","link":"","permalink":"https://overtalk.site/2019/04/01/network-tcp-nodelay/","excerpt":"","text":"TCP_NODELAY 和 Nagle算法 一、概述 在网络拥塞控制领域，有一个非常有名的算法叫做Nagle算法（Nagle algorithm），这是使用它的发明人John Nagle的名字来命名的，John Nagle在1984年首次用这个算法来尝试解决福特汽车公司的网络拥塞问题（RFC 896）。 该问题的具体描述是：如果我们的应用程序一次产生1个字节的数据，而这个1个字节数据又以网络数据包的形式发送到远端服务器，那么就很容易导致网络由于太多的数据包而过载。 比如，当用户使用Telnet连接到远程服务器时，每一次击键操作就会产生1个字节数据，进而发送出去一个数据包，所以，在典型情况下，传送一个只拥有1个字节有效数据的数据包，却要发费40个字节长包头（即ip头20字节+tcp头20字节）的额外开销，这种有效载荷（payload）利用率极其低下的情况被统称之为愚蠢窗口症候群（Silly Window Syndrome）。 可以看到，这种情况对于轻负载的网络来说，可能还可以接受，但是对于重负载的网络而言，就极有可能承载不了而轻易的发生拥塞瘫痪。 针对上面提到的这个状况，Nagle算法的改进在于：如果发送端欲多次发送包含少量字符的数据包（一般情况下，后面统一称长度小于MSS的数据包为小包，与此相对，称长度等于MSS的数据包为大包，为了某些对比说明，还有中包，即长度比小包长，但又不足一个MSS的包），则发送端会先将第一个小包发送出去，而将后面到达的少量字符数据都缓存起来而不立即发送，直到收到接收端对前一个数据包报文段的ACK确认、或当前字符属于紧急数据，或者积攒到了一定数量的数据（比如缓存的字符数据已经达到数据包报文段的最大长度）等多种情况才将其组成一个较大的数据包发送出去。 二、Nagle算法 TCP/IP协议中，无论发送多少数据，总是要在数据前面加上协议头，同时，对方接收到数据，也需要发送ACK表示确认。为了尽可能的利用网络带宽，TCP总是希望尽可能的发送足够大的数据。（一个连接会设置MSS参数，因此，TCP/IP希望每次都能够以MSS尺寸的数据块来发送数据）。 Nagle算法就是为了尽可能发送大块数据，避免网络中充斥着许多小数据块。 Nagle算法的基本定义是任意时刻，最多只能有一个未被确认的小段。 所谓“小段”，指的是小于MSS尺寸的数据块，所谓“未被确认”，是指一个数据块发送出去后，没有收到对方发送的ACK确认该数据已收到。 举个例子，一开始client端调用socket的write操作将一个int型数据(称为A块)写入到网络中，由于此时连接是空闲的（也就是说还没有未被确认的小段），因此这个int型数据会被马上发送到server端，接着，client端又调用write操作写入一个int型数据（简称B块），这个时候，A块的ACK没有返回，所以可以认为已经存在了一个未被确认的小段，所以B块没有立即被发送，一直等待A块的ACK收到（大概40ms之后），B块才被发送。 这里两个问题： 1.(这个上面已经解释过了)为什么B块要在A块的ACK到达之后才发送？ Nagle算法。 2.就是A块数据的ACK为什么40ms之后才收到？ 因为TCP/IP中不仅仅有Nagle算法(Nagle‘s Algorithm)，还有一个ACK延迟机制(TCP Delayed Ack) 。当Server端收到数据之后，它并不会马上向client端发送ACK，而是会将ACK的发送延迟一段时间（假设为t），它希望在t时间内server端会向client端发送应答数据，这样ACK就能够和应答数据一起发送，就像是应答数据捎带着ACK过去。 也就是如果一个 TCP 连接的一端启用了Nagle算法，而另一端启用了ACK延时机制，而发送的数据包又比较小，则可能会出现这样的情况：发送端在等待接收端对上一个packet的Ack才发送当前的packet，而接收端则正好延迟了此Ack的发送，那么这个正要被发送的packet就会同样被延迟。当然Delayed Ack是有个超时机制的，而默认的超时正好就是40ms。 现代的 TCP/IP 协议栈实现，默认几乎都启用了这两个功能，那岂不每次都会触发这个延迟问题？事实不是那样的。仅当协议的交互是发送端连续发送两个packet，然后立刻read的时候才会出现问题。 三、解决方案 1.优化协议 连续 write 小数据包，然后 read 其实是一个不好的网络编程模式，这样的连续 write 其实应该在应用层合并成一次 write。 2.开启TCP_NODELAY 简单地说，这个选项的作用就是禁用Nagle算法，禁止后当然就不会有它引起的一系列问题了。使用setsockopt可以做到： 1234static void _set_tcp_nodelay(int fd) &#123;int enable = 1;setsockopt(fd, IPPROTO_TCP, TCP_NODELAY, (void*)&amp;enable, sizeof(enable));&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"https://overtalk.site/tags/tcp/"},{"name":"Nagle","slug":"Nagle","permalink":"https://overtalk.site/tags/Nagle/"}]},{"title":"tcp 查缺补漏","slug":"tcp","date":"2019-03-12T23:09:21.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2019/03/12/tcp/","link":"","permalink":"https://overtalk.site/2019/03/12/tcp/","excerpt":"","text":"参考文档 参考文档 tcp 知识点 TCP头部结构和字段介绍 TCP三次握手 TCP四次挥手 TCP超时重传 TCP流量控制 滑动窗口 TCP拥塞控制 慢启动、拥塞避免、快重传、快恢复 TCP的四种定时器 TCP粘包/拆包问题 TCP头部结构和字段介绍 其中比较重要的字段有： 序号（sequence number）：Seq序号，占32位，用来标识从TCP源端向目的端发送的字节流，发起方发送数据时对此进行标记。 确认号（acknowledgement number）：Ack序号，占32位，只有ACK标志位为1时，确认序号字段才有效，Ack=Seq+1。 标志位（Flags）：共6个，即URG、ACK、PSH、RST、SYN、FIN等。具体含义如下： URG：紧急指针（urgent pointer）有效。 ACK：确认序号有效。 PSH：接收方应该尽快将这个报文交给应用层。 RST：重置连接。 SYN：发起一个新连接。 FIN：释放一个连接。 需要注意的是： 不要将确认序号Ack与标志位中的ACK搞混了。确认方Ack=发起方Seq+1，两端配对。 TCP三次握手详解 所谓的三次握手即TCP连接的建立。这个连接必须是一方主动打开，另一方被动打开的。以下为客户端主动发起连接的图解： 握手之前主动打开连接的客户端结束CLOSED阶段，被动打开的服务器端也结束CLOSED阶段，并进入LISTEN阶段。随后开始“三次握手”： （1）首先客户端向服务器端发送一段TCP报文，其中： 标记位为SYN，表示“请求建立新连接”; 序号为Seq=X（X一般为1）； 随后客户端进入SYN-SENT阶段。 （2）服务器端接收到来自客户端的TCP报文之后，结束LISTEN阶段。并返回一段TCP报文，其中： 标志位为SYN和ACK，表示“确认客户端的报文Seq序号有效，服务器能正常接收客户端发送的数据，并同意创建新连接”（即告诉客户端，服务器收到了你的数据）； 序号为Seq=y； 确认号为Ack=x+1，表示收到客户端的序号Seq并将其值加1作为自己确认号Ack的值；随后服务器端进入SYN-RCVD阶段。 （3）客户端接收到来自服务器端的确认收到数据的TCP报文之后，明确了从客户端到服务器的数据传输是正常的，结束SYN-SENT阶段。并返回最后一段TCP报文。其中： 标志位为ACK，表示“确认收到服务器端同意连接的信号”（即告诉服务器，我知道你收到我发的数据了）； 序号为Seq=x+1，表示收到服务器端的确认号Ack，并将其值作为自己的序号值； 确认号为Ack=y+1，表示收到服务器端序号Seq，并将其值加1作为自己的确认号Ack的值； 随后客户端进入ESTABLISHED阶段。 服务器收到来自客户端的“确认收到服务器数据”的TCP报文之后，明确了从服务器到客户端的数据传输是正常的。结束SYN-SENT阶段，进入ESTABLISHED阶段。 在客户端与服务器端传输的TCP报文中，双方的确认号Ack和序号Seq的值，都是在彼此Ack和Seq值的基础上进行计算的，这样做保证了TCP报文传输的连贯性。一旦出现某一方发出的TCP报文丢失，便无法继续”握手”，以此确保了”三次握手”的顺利完成。 此后客户端和服务器端进行正常的数据传输。这就是“三次握手”的过程。 为什么需要三次握手？ 首先我们要知道信道是不可靠的，但是我们要建立可靠的连接发送可靠的数据，也就是数据传输是需要可靠的。在这个时候三次握手是一个理论上的最小值，并不是说是tcp协议要求的，而是为了满足在不可靠的信道上传输可靠的数据所要求的。 在《计算机网络》一书中其中有提到，三次握手的目的是“为了防止已经失效的连接请求报文段突然又传到服务端，因而产生错误”。 这种情况是：一端(client)A发出去的第一个连接请求报文并没有丢失，而是因为某些未知的原因在某个网络节点上发生滞留，导致延迟到连接释放以后的某个时间才到达另一端(server)B。本来这是一个早已失效的报文段，但是B收到此失效的报文之后，会误认为是A再次发出的一个新的连接请求，于是B端就向A又发出确认报文，表示同意建立连接。如果不采用“三次握手”，那么只要B端发出确认报文就会认为新的连接已经建立了，但是A端并没有发出建立连接的请求，因此不会去向B端发送数据，B端没有收到数据就会一直等待，这样B端就会白白浪费掉很多资源。如果采用“三次握手”的话就不会出现这种情况，B端收到一个过时失效的报文段之后，向A端发出确认，此时A并没有要求建立连接，所以就不会向B端发送确认，这个时候B端也能够知道连接没有建立。 TCP四次挥手详解 TCP连接的释放(解除)。连接的释放必须是一方主动释放，另一方被动释放。以下为客户端主动发起释放连接的图解： 挥手之前主动释放连接的客户端结束ESTABLISHED阶段。随后开始“四次挥手”： （1）首先客户端想要释放连接，向服务器端发送一段TCP报文，其中： 标记位为FIN，表示“请求释放连接“； 序号为Seq=U； 随后客户端进入FIN-WAIT-1阶段，即半关闭阶段。并且停止在客户端到服务器端方向上发送数据，但是客户端仍然能接收从服务器端传输过来的数据。 注意：这里不发送的是正常连接时传输的数据(非确认报文)，而不是一切数据，所以客户端仍然能发送ACK确认报文。 （2）服务器端接收到从客户端发出的TCP报文之后，确认了客户端想要释放连接，随后服务器端结束ESTABLISHED阶段，进入CLOSE-WAIT阶段（半关闭状态）并返回一段TCP报文，其中： 标记位为ACK，表示“接收到客户端发送的释放连接的请求”； 序号为Seq=V； 确认号为Ack=U+1，表示是在收到客户端报文的基础上，将其序号Seq值加1作为本段报文确认号Ack的值； 随后服务器端开始准备释放服务器端到客户端方向上的连接。 客户端收到从服务器端发出的TCP报文之后，确认了服务器收到了客户端发出的释放连接请求，随后客户端结束FIN-WAIT-1阶段，进入FIN-WAIT-2阶段 前”两次挥手”既让服务器端知道了客户端想要释放连接，也让客户端知道了服务器端了解了自己想要释放连接的请求。于是，可以确认关闭客户端到服务器端方向上的连接了 （3）服务器端自从发出ACK确认报文之后，经过CLOSED-WAIT阶段，做好了释放服务器端到客户端方向上的连接准备，再次向客户端发出一段TCP报文，其中： 标记位为FIN，ACK，表示“已经准备好释放连接了”。注意：这里的ACK并不是确认收到服务器端报文的确认报文。 序号为Seq=W； 确认号为Ack=U+1；表示是在收到客户端报文的基础上，将其序号Seq值加1作为本段报文确认号Ack的值。 随后服务器端结束CLOSE-WAIT阶段，进入LAST-ACK阶段。并且停止在服务器端到客户端的方向上发送数据，但是服务器端仍然能够接收从客户端传输过来的数据。 （4）客户端收到从服务器端发出的TCP报文，确认了服务器端已做好释放连接的准备，结束FIN-WAIT-2阶段，进入TIME-WAIT阶段，并向服务器端发送一段报文，其中： 标记位为ACK，表示“接收到服务器准备好释放连接的信号”。 序号为Seq=U+1；表示是在收到了服务器端报文的基础上，将其确认号Ack值作为本段报文序号的值。 确认号为Ack=W+1；表示是在收到了服务器端报文的基础上，将其序号Seq值作为本段报文确认号的值。 随后客户端开始在TIME-WAIT阶段等待2MSL 为什么要客户端要等待2MSL呢？见后文。 服务器端收到从客户端发出的TCP报文之后结束LAST-ACK阶段，进入CLOSED阶段。由此正式确认关闭服务器端到客户端方向上的连接。 客户端等待完2MSL之后，结束TIME-WAIT阶段，进入CLOSED阶段，由此完成“四次挥手”。 后“两次挥手”既让客户端知道了服务器端准备好释放连接了，也让服务器端知道了客户端了解了自己准备好释放连接了。于是，可以确认关闭服务器端到客户端方向上的连接了，由此完成“四次挥手”。 与“三次挥手”一样，在客户端与服务器端传输的TCP报文中，双方的确认号Ack和序号Seq的值，都是在彼此Ack和Seq值的基础上进行计算的，这样做保证了TCP报文传输的连贯性，一旦出现某一方发出的TCP报文丢失，便无法继续”挥手”，以此确保了”四次挥手”的顺利完成。 4.1 为什么需要四次握手？ 为了确保数据能够完成传输。 关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭SOCKET,也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。 释放连接时为什么TIME-WAIT状态必须等待2MSL时间？ 首先说下什么是MSL: MSL是Maximum Segment Lifetime英文的缩写，中文可以译为“报文最大生存时间”，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。 第一，为了保证A发送的最后一个ACK报文能够到达B。这个ACK报文段有可能丢失，因而使处在LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认。B会超时重传这个FIN+ACK报文段，而A就能在2MSL时间内收到这个重传的FIN+ACK报文段，重置时间等待计时器（2MSL）。如果A在TIME-WAIT状态不等待一段时间，而是在发送完ACK报文段后就立即释放连接，就无法收到B重传的FIN+ACK报文段，因而也不会再发送一次确认报文段。这样，B就无法按照正常的步骤进入CLOSED状态。 第二，A在发送完ACK报文段后，再经过2MSL时间，就可以使本连接持续的时间所产生的所有报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求的报文段。 客户端突然挂掉了怎么办？ 正常连接时，客户端突然挂掉了，如果没有措施处理这种情况，那么就会出现客户端和服务器端出现长时期的空闲。解决办法是在服务器端设置保活计时器，每当服务器收到客户端的消息，就将计时器复位。超时时间通常设置为2小时。若服务器超过2小时没收到客户的信息，他就发送探测报文段。若发送了10个探测报文段，每一个相隔75秒，还没有响应就认为客户端出了故障，因而终止该连接。 TCP超时重传 原理是在发送某一个数据以后就开启一个计时器，在一定时间内如果没有得到发送的数据报的ACK报文，那么就重新发送数据，直到发送成功为止。 影响超时重传机制协议效率的一个关键参数是重传超时时间（RTO，Retransmission TimeOut）。RTO的值被设置过大过小都会对协议造成不利影响。 RTO设长了，重发就慢，没有效率，性能差。 RTO设短了，重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。 连接往返时间（RTT，Round Trip Time），指发送端从发送TCP包开始到接收它的立即响应所消耗的时间。 RTO理论上最好是网络 RTT 时间，但又受制于网络距离与瞬态时延变化，所以实际上使用自适应的动态算法（例如 Jacobson 算法和 Karn 算法等）来确定超时时间。 TCP流量控制 参考连接 一条TCP连接每一侧主机都为该连接设置了接收缓存。当该TCP连接收到了正确的、按序的字节后，他就将数据放入接收缓存。相关联的应用进程会从该缓存中读取数据。但不必是数据一到达就立即读取。事实上，接收方也许正忙于其他任务，甚至要过很长时间后才读取该数据。如果某个应用进程读取比较缓慢，但是发送方发送的太多、太快，发送的数据就会很容易地使该连接的接收缓存溢出。 TCP为它的应用程序提供了流量控制服务(flow-control service)以消除发送方使接收方缓存溢出的可能性。流量控制因此是一个速度匹配服务，即发送方的发送速率与接收方应用程序的读取速率相匹配。 流量控制的实现 TCP通过让发送方维护一个称为接收窗口(receive window)的变量(TCP报文段首部的接收窗口字段)来提供流量控制。通俗的讲，接收窗口用于给发送方一个指示－－该接收方还有多少可用的缓存空间。因为TCP是全双工通信，在连接两端的发送方都各自维护了一个接收窗口。 如上图所示RcvBuffer是接收缓存的总大小，buffered data是当前已经缓存了的数据，而free buffer space是当前剩余的缓存空间大小,rwnd的值就是free buffer space。主机B通过把当前的rwnd值放入到它发送给主机A的报文段首部的接收窗口字段中，通知主机A它在该连接的缓存中还有多少可用空间。 而主机A则将自己发往主机B的序号空间中未确认的数据量控制在rwnd值的范围内,这样就可以避免主机A使主机B的接收缓存溢出。 拥塞控制为什么需要拥塞控制? 我们在前面讲到过，在TCP协议中，分组丢失一般是当网络变得拥塞时由路由器缓存溢出引起的。因此分组重传是作为网络拥塞的征兆来对待，但是却无法处理导致网络拥塞的原因，因为有太多的源想以过高的速率发送数据。一旦网络发生拥塞，分组所经历的时延会变大，分组丢失的可能性会变大，发送端需要重传的分组会变多，这只会导致网络越来越拥塞，形成恶性循环。因此，为了处理网络拥塞，需要一些机制以在面临网络拥塞时遏制发送方。 拥塞控制方法 在实践中采用了两种主要的拥塞控制方法，这两种方法是根据网络层是否为传输层拥塞控制提供了显示帮助来区分。它们是端到端拥塞控制和网路辅助的拥塞控制。 端到端拥塞控制 在端到端的拥塞控制中，网路层没有为运输层提供显示支持。即使网络中存在拥塞，端系统也必须通过对网络行为的观察(如分组的丢失与时延)来推理判断之。 网络辅助的拥塞控制 在网络辅助的拥塞控制中，网络层构件(即路由器)向发送方提供关于网络中拥塞状态的显示反馈信息。拥塞信息从网络反馈到发送发通常有两种方式:直接反馈信息可以由网络路由器发给发送方，这种方式的通知通常采用一种阻塞分组的形式；第二种方法是路由器标记或更新从发送方流向接收方的分组中的某个字段来指示拥塞的产生，一旦收到一个标记的分组后，接收方就会向发送方发送该网络拥塞指示。 TCP拥塞控制 TCP是通过端到端的方法来解决拥塞控制的，因为IP层不会向端系统提供有关网络拥塞的反馈信息。 TCP报文段的丢失被认为是网络拥塞的一个迹象，TCP会相应的减小其窗口长度。这里我们需要明确的几个问题是: TCP发送方如何限制它向其连接发送流量的速率? TCP发送方如何感知从它到目的地之间的路径上存在拥塞呢? 当感知到了拥塞时，采用何种算法来改变其发送速率呢? 首先我们来考虑TCP发送方怎样限制它向网络发送流量的速率。与流量控制一样，在发送方的TCP拥塞控制机制中跟踪了一个额外的变量，即拥塞窗口(congestion window)。拥塞窗口表示为cwnd,通过这个拥塞窗口，我们就能够对发送方向其连接发送数据的速率进行限制。具体的措施是:让一个发送方中未确认的数据量不会超过cwnd和rwnd的最小值，即: 1LastByteSend - LastByteAcked &lt;= min&#123;cwnd,rwnd&#125; LastByteSend, LastByteAcked 分别是最后一个发送的字节的序号和最后一个被确认的字节的序号。 如前所述TCP发送方通过捕获到丢包时间的产生感知从它到目的地之间的路径上存在拥塞。 在拥塞情况发生时，我们可以通过减小cwnd的值来减小发送方发送数据的速率。那么如果没有拥塞发生呢?如果没有拥塞，我们应该增加cwnd的值来增大发送方发送数据的速率。发送方发送速率过大会导致网络拥塞，甚至拥塞崩溃；而如果发送方过于谨慎，发送太慢则不能充分利用带宽。因此根据网络情况合理设置cwnd的值非常重要。 在概述了TCP拥塞控制之后，现在我们来考虑一下广受赞誉的TCP拥塞控制算法。该算法包括三部分:慢启动，拥塞避免，快速重传，快速恢复。 慢启动 参考链接 当一条TCP连接开始，cwnd值通常初始置为一个MSS较小值。这使得初始发送速率为MSS/RTT。在慢启动(slow-start)状态，cwnd的值以1个MSS开始并且每当传输的报文段首次被确认就增加一个MSS。 何时结束慢启动阶段的指数增长呢？ 如果存在一个由超时指示的丢包事件，TCP发送方将cwnd设置为1并重新开始慢启动过程。它还将第二个状态变量的值ssthresh（慢启动阈值）设置为cwnd/2，即当检测到拥塞时将ssthresh置为拥塞窗口值的一半。 当检测到拥塞时ssthresh设为cwnd的一半，当到达或超过ssthresh的值时，结束慢启动并且TCP转移到拥塞避免模式。 如果检测到3个冗余ACK，这时TCP执行一种快速重传并进入快速恢复状态。 拥塞避免 每个RTT只将cwnd的值增加一个MSS：对于TCP发送方无论何时到达一个新的确认，就将cwnd增加一个MSS(MSS/cwnd)字节。例如，如果MSS是1460字节，并且cwnd是14600字节，则在一个RTT内发送10个报文段。每个到达ACK增加1/10MSS的拥塞窗口长度，因此在收到对所有10个报文段的确认后，拥塞窗口的值将增加了一个MSS。当出现超时时，TCP的拥塞避免与慢启动阶段一样。当出现丢包时，网络继续从发送方向接收方交付报文段，当接收到3个冗余ACK时，将ssthresh的值置为cwnd的一半，同时将cwnd的值减半加上3个MSS。 快速恢复 对收到的每个用冗余ACK，cwnd值增加一个MSS。 当对丢失报文段的一个ACK到达时，TCP在降低cwnd进入拥塞避免状态。 如果出现超时事件，执行如同慢启动和拥塞避免中相同的动作后，迁移到慢启动状态.","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"https://overtalk.site/tags/tcp/"}]},{"title":"Lua - 面对对象的编程","slug":"lua-oop","date":"2018-11-01T05:51:29.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2018/11/01/lua-oop/","link":"","permalink":"https://overtalk.site/2018/11/01/lua-oop/","excerpt":"","text":"lua 面对对象的编程 类 在 Lua 中，我们可以使用表和函数实现面向对象。将函数和相关的数据放置于同一个表中就形成了一个对象。 请看文件名为 account.lua 的源码： 12345678910111213141516171819202122local _M = &#123;&#125;local mt = &#123; __index = _M &#125;function _M.deposit (self, v) self.balance = self.balance + vendfunction _M.withdraw (self, v) if self.balance &gt; v then self.balance = self.balance - v else error(\"insufficient funds\") endendfunction _M.new (self, balance) balance = balance or 0 return setmetatable(&#123;balance = balance&#125;, mt)endreturn _M 引用代码示例 12345678910local account = require(\"account\")local a = account:new()a:deposit(100)local b = account:new()b:deposit(50)print(a.balance) --&gt; output: 100print(b.balance) --&gt; output: 50 上面这段代码 “setmetatable({balance = balance}, mt)”，其中 mt 代表 { __index = _M } ，这句话值得注意。根据我们在元表这一章学到的知识，我们明白，setmetatable 将 _M 作为新建表的原型，所以在自己的表内找不到 ‘deposit’、’withdraw’ 这些方法和变量的时候，便会到 __index 所指定的 _M 类型中去寻找。 继承 继承可以用元表实现，它提供了在父类中查找存在的方法和变量的机制。在 Lua 中是不推荐使用继承方式完成构造的，这样做引入的问题可能比解决的问题要多，下面一个是字符串操作类库，给大家演示一下。12345678910111213141516171819202122232425262728---------- s_base.lualocal _M = &#123;&#125;local mt = &#123; __index = _M &#125;function _M.upper (s) return string.upper(s)endreturn _M---------- s_more.lualocal s_base = require(\"s_base\")local _M = &#123;&#125;_M = setmetatable(_M, &#123; __index = s_base &#125;)function _M.lower (s) return string.lower(s)endreturn _M---------- test.lualocal s_more = require(\"s_more\")print(s_more.upper(\"Hello\")) -- output: HELLOprint(s_more.lower(\"Hello\")) -- output: hello 成员私有性 在动态语言中引入成员私有性并没有太大的必要，反而会显著增加运行时的开销，毕竟这种检查无法像许多静态语言那样在编译期完成。下面的技巧把对象作为各方法的 upvalue，本身是很巧妙的，但会让子类继承变得困难，同时构造函数动态创建了函数，会导致构造函数无法被 JIT 编译。 在 Lua 中，成员的私有性，使用类似于函数闭包的形式来实现。在我们之前的银行账户的例子中，我们使用一个工厂方法来创建新的账户实例，通过工厂方法对外提供的闭包来暴露对外接口。而不想暴露在外的例如 balance 成员变量，则被很好的隐藏起来。 1234567891011121314151617181920function newAccount (initialBalance) local self = &#123;balance = initialBalance&#125; local withdraw = function (v) self.balance = self.balance - v end local deposit = function (v) self.balance = self.balance + v end local getBalance = function () return self.balance end return &#123; withdraw = withdraw, deposit = deposit, getBalance = getBalance &#125;enda = newAccount(100)a.deposit(100)print(a.getBalance()) --&gt; 200print(a.balance) --&gt; nil","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"lua","slug":"lua","permalink":"https://overtalk.site/tags/lua/"}]},{"title":"Lua - 元表","slug":"lua-metatable","date":"2018-11-01T05:38:30.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2018/11/01/lua-metatable/","link":"","permalink":"https://overtalk.site/2018/11/01/lua-metatable/","excerpt":"","text":"lua 元表 什么是元表 首先lua中的number类型是可以执行一些操作的，比如 121 + 1 //21 - 1 //0 如果我们定义两个复数如下，希望能实现其的加法 123local a = &#123;1, 2&#125;local b = &#123;3, 4&#125;// 相加我们希望得到 &#123;4， 6&#125; 如果我们直接相加这两个变量，lua解释器会告诉我们有错误。 这个时候我们就可以通过元表的方式来达到我们期望的结果，元表可以理解为 一个元操作或者行为的集合。可以通过 setmetatable 设置table的元表 getmetatable获取任意变量的元表。一个新的table创建时元表为空。 表达式a+b，在Lua中是按照以下步骤进行的 先判断a和b两者之一是否有元表 检查该元表中是否有一个叫__add的字段；如果找到了该字段，就调用该字段对应的值，这个值对应的是一个方法； 在Lua中，每个值都有一个元表，table和userdata类型的每个变量都可以有各自独立的元表，而其他类型的值则共享其类型所属的单一元表。 12345678local m = &#123; __add = function (a, b) return &#123;a[1] + b[1], a[2] + b[2]&#125; end&#125;local a = setmetatable(&#123;1,2&#125;, m)local b = setmetatable(&#123;3,4&#125;, m)// 这时a + b 就会得到结果 &#123;4, 6&#125; 如何设置元表 在 Lua 5.1 语言中，元表 (metatable) 的表现行为类似于 C++ 语言中的操作符重载，例如我们可以重载 “add” 元方法 (metamethod)，来计算两个 Lua 数组的并集；或者重载 “index” 方法，来定义我们自己的 Hash 函数。Lua 提供了两个十分重要的用来处理元表的方法，如下： setmetatable(table, metatable)：此方法用于为一个表设置元表。 getmetatable(table)：此方法用于获取表的元表对象。 设置元表的方法很简单，如下： 123456local mytable = &#123;&#125;local mymetatable = &#123;&#125;setmetatable(mytable, mymetatable)-- 上面的代码可以简写成如下的一行代码：local mytable = setmetatable(&#123;&#125;, &#123;&#125;) 修改元表 通过重载 “__add” 元方法来计算集合的并集实例： 12345678910111213141516171819202122local set1 = &#123;10, 20, 30&#125; -- 集合local set2 = &#123;20, 40, 50&#125; -- 集合-- 将用于重载__add的函数，注意第一个参数是selflocal union = function (self, another) local set = &#123;&#125; local result = &#123;&#125; -- 利用数组来确保集合的互异性 for i, j in pairs(self) do set[j] = true end for i, j in pairs(another) do set[j] = true end -- 加入结果集合 for i, j in pairs(set) do table.insert(result, i) end return resultendsetmetatable(set1, &#123;__add = union&#125;) -- 重载 set1 表的 __add 元方法local set3 = set1 + set2for _, j in pairs(set3) do io.write(j..\" \") --&gt;output：30 50 20 40 10end 除了加法可以被重载之外，Lua 提供的所有操作符都可以被重载： 元方法 含义 __add” + 操作 __sub” - 操作 其行为类似于 “add” 操作 __mul” * 操作 其行为类似于 “add” 操作 __div” / 操作 其行为类似于 “add” 操作 __mod” % 操作 其行为类似于 “add” 操作 __pow” ^ （幂）操作 其行为类似于 “add” 操作 __unm” 一元 - 操作 __concat” .. （字符串连接）操作 __len” # 操作 __eq” == 操作 函数 getcomphandler 定义了 Lua 怎样选择一个处理器来作比较操作 仅在两个对象类型相同且有对应操作相同的元方法时才起效 __lt” &lt; 操作 __le” &lt;= 操作 除了操作符之外，如下元方法也可以被重载，下面会依次解释使用方法： 元方法 含义 “__index” 取下标操作用于访问 table[key] “__newindex” 赋值给指定下标 table[key] = value “__tostring” 转换成字符串 “__call” 当 Lua 调用一个值时调用 “__mode” 用于弱表(week table) “__metatable” 用于保护metatable不被访问 __index 元方法 下面的例子中，我们实现了在表中查找键不存在时转而在元表中查找该键的功能： 123456789mytable = setmetatable(&#123;key1 = \"value1\"&#125;, --原始表 &#123;__index = function(self, key) --重载函数 if key == \"key2\" then return \"metatablevalue\" end end&#125;)print(mytable.key1,mytable.key2) --&gt; output：value1 metatablevalue 关于 index 元方法，有很多比较高阶的技巧，例如：index 的元方法不需要非是一个函数，他也可以是一个表。 12t = setmetatable(&#123;[1] = \"hello\"&#125;, &#123;__index = &#123;[2] = \"world\"&#125;&#125;)print(t[1], t[2]) --&gt;hello world 第一句代码有点绕，解释一下：先是把 {__index = {}} 作为元表，但 __index 接受一个表，而不是函数，这个表中包含 [2] = “world” 这个键值对。 所以当 t[2] 去在自身的表中找不到时，在 __index 的表中去寻找，然后找到了 [2] = “world” 这个键值对。 __index 元方法还可以实现给表中每一个值赋上默认值；和 __newindex 元方法联合监控对表的读取、修改等比较高阶的功能，待读者自己去开发吧。 __tostring 元方法 与 Java 中的 toString() 函数类似，可以实现自定义的字符串转换。123456789101112arr = &#123;1, 2, 3, 4&#125;arr = setmetatable(arr, &#123;__tostring = function (self) local result = '&#123;' local sep = '' for _, i in pairs(self) do result = result ..sep .. i sep = ', ' end result = result .. '&#125;' return resultend&#125;)print(arr) --&gt; &#123;1, 2, 3, 4&#125; __call 元方法 __call 元方法的功能类似于 C++ 中的仿函数，使得普通的表也可以被调用。123456789functor = &#123;&#125;function func1(self, arg) print (\"called from\", arg)endsetmetatable(functor, &#123;__call = func1&#125;)functor(\"functor\") --&gt; called from functorprint(functor) --&gt; output：0x00076fc8 （后面这串数字可能不一样） __metatable 元方法 假如我们想保护我们的对象使其使用者既看不到也不能修改 metatables。我们可以对 metatable 设置了 __metatable 的值，getmetatable 将返回这个域的值，而调用 setmetatable 将会出错：1234Object = setmetatable(&#123;&#125;, &#123;__metatable = \"You cannot access here\"&#125;)print(getmetatable(Object)) --&gt; You cannot access heresetmetatable(Object, &#123;&#125;) --&gt; 引发编译器报错","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"lua","slug":"lua","permalink":"https://overtalk.site/tags/lua/"}]},{"title":"Lua - string库","slug":"lua-string","date":"2018-11-01T05:25:41.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2018/11/01/lua-string/","link":"","permalink":"https://overtalk.site/2018/11/01/lua-string/","excerpt":"","text":"lua string 链接🔗","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"lua","slug":"lua","permalink":"https://overtalk.site/tags/lua/"}]},{"title":"Lua - 文件","slug":"lua-file","date":"2018-11-01T05:16:24.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2018/11/01/lua-file/","link":"","permalink":"https://overtalk.site/2018/11/01/lua-file/","excerpt":"","text":"lua 文件操作 文件操作 Lua I/O 库提供两种不同的方式处理文件：隐式文件描述，显式文件描述。 这些文件 I/O 操作，在 OpenResty 的上下文中对事件循环是会产生阻塞效应。OpenResty 比较擅长的是高并发网络处理，在这个环境中，任何文件的操作，都将阻塞其他并行执行的请求。实际中的应用，在 OpenResty 项目中应尽可能让网络处理部分、文件 I/0 操作部分相互独立，不要揉和在一起。 隐式文件描述 设置一个默认的输入或输出文件，然后在这个文件上进行所有的输入或输出操作。所有的操作函数由 io 表提供。 打开已经存在的 test1.txt 文件，并读取里面的内容 12345678910111213141516file = io.input(\"test1.txt\") -- 使用 io.input() 函数打开文件repeat line = io.read() -- 逐行读取内容，文件结束时返回nil if nil == line then break end print(line)until (false)io.close(file) -- 关闭文件--&gt; outputmy test filehellolua 在 test1.txt 文件的最后添加一行 “hello world” 1234file = io.open(\"test1.txt\", \"a+\") -- 使用 io.open() 函数，以添加模式打开文件io.output(file) -- 使用 io.output() 函数，设置默认输出文件io.write(\"\\nhello world\") -- 使用 io.write() 函数，把内容写到文件io.close(file) 在相应目录下打开 test1.txt 文件，查看文件内容发生的变化。 显式文件描述 使用 file:XXX() 函数方式进行操作, 其中 file 为 io.open() 返回的文件句柄。 打开已经存在的 test2.txt 文件，并读取里面的内容 1234567891011file = io.open(\"test2.txt\", \"r\") -- 使用 io.open() 函数，以只读模式打开文件for line in file:lines() do -- 使用 file:lines() 函数逐行读取文件 print(line)endfile:close()--&gt;outputmy test2hello lua 在 test2.txt 文件的最后添加一行 “hello world” 123file = io.open(\"test2.txt\", \"a\") -- 使用 io.open() 函数，以添加模式打开文件file:write(\"\\nhello world\") -- 使用 file:write() 函数，在文件末尾追加内容file:close() 在相应目录下打开 test2.txt 文件，查看文件内容发生的变化。 文件操作函数io.open (filename [, mode]) 按指定的模式 mode，打开一个文件名为 filename 的文件，成功则返回文件句柄，失败则返回 nil 加错误信息。模式： 模式 含义 文件不存在时 “r” 读模式(默认) 返回nil加错误信息 “w” 写模式 创建文件 “a” 添加模式 创建文件 “r+” 更新模式，保存之前的数据 返回nil加错误信息 “w+” 更新模式，清除之前的数据 创建文件 “a+” 添加更新模式，保存之前的数据,在文件尾进行添加 创建文件 模式字符串后面可以有一个 ‘b’，用于在某些系统中打开二进制文件。 注意 “w” 和 “wb” 的区别 “w” 表示文本文件。某些文件系统(如 Linux 的文件系统)认为 0x0A 为文本文件的换行符，Windows 的文件系统认为 0x0D0A 为文本文件的换行符。为了兼容其他文件系统（如从 Linux 拷贝来的文件），Windows 的文件系统在写文件时，会在文件中 0x0A 的前面加上 0x0D。使用 “w”，其属性要看所在的平台。 “wb” 表示二进制文件。文件系统会按纯粹的二进制格式进行写操作，因此也就不存在格式转换的问题。（Linux 文件系统下 “w” 和 “wb” 没有区别） file:close () 关闭文件。注意：当文件句柄被垃圾收集后，文件将自动关闭。句柄将变为一个不可预知的值。 io.close ([file]) 关闭文件，和 file:close() 的作用相同。没有参数 file 时，关闭默认输出文件。 file:flush () 把写入缓冲区的所有数据写入到文件 file 中。 io.flush () 相当于 file:flush()，把写入缓冲区的所有数据写入到默认输出文件。 io.input ([file]) 当使用一个文件名调用时，打开这个文件（以文本模式），并设置文件句柄为默认输入文件； 当使用一个文件句柄调用时，设置此文件句柄为默认输入文件； 当不使用参数调用时，返回默认输入文件句柄。 file:lines () 返回一个迭代函数, 每次调用将获得文件中的一行内容, 当到文件尾时，将返回 nil，但不关闭文件。 io.lines ([filename]) 打开指定的文件 filename 为读模式并返回一个迭代函数, 每次调用将获得文件中的一行内容, 当到文件尾时，将返回 nil，并自动关闭文件。若不带参数时 io.lines() 等价于 io.input():lines() 读取默认输入设备的内容，结束时不关闭文件。 io.output ([file]) 类似于 io.input，但操作在默认输出文件上。 file:read (…) 按指定的格式读取一个文件。按每个格式将返回一个字符串或数字, 如果不能正确读取将返回 nil，若没有指定格式将指默认按行方式进行读取。格式： 格式 含义 “*n” 读取一个数字 “*a” 从当前位置读取整个文件。若当前位置为文件尾，则返回空字符串 “*l” 读取下一行的内容。若为文件尾，则返回nil。(默认) number 读取指定字节数的字符。若为文件尾，则返回nil。如果number为0,则返回空字符串，若为文件尾,则返回nil io.read (…) 相当于 io.input():read io.type (obj) 检测 obj 是否一个可用的文件句柄。如果 obj 是一个打开的文件句柄，则返回 “file” 如果 obj 是一个已关闭的文件句柄，则返回 “closed file” 如果 obj 不是一个文件句柄，则返回 nil。 file:write (…) 把每一个参数的值写入文件。参数必须为字符串或数字，若要输出其它值，则需通过 tostring 或 string.format 进行转换。 io.write (…) 相当于 io.output():write。 file:seek ([whence] [, offset]) 设置和获取当前文件位置，成功则返回最终的文件位置(按字节，相对于文件开头),失败则返回 nil 加错误信息。缺省时，whence 默认为 “cur”，offset 默认为 0 。 参数 whence： whence 含义 “set” 文件开始 “cur” 文件当前位置(默认) “end” 文件结束 file:setvbuf (mode [, size]) 设置输出文件的缓冲模式。模式： 模式 含义 “no” 没有缓冲，即直接输出 “full” 全缓冲，即当缓冲满后才进行输出操作(也可调用flush马上输出) “line” 以行为单位，进行输出 最后两种模式，size 可以指定缓冲的大小（按字节），忽略 size 将自动调整为最佳的大小。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"lua","slug":"lua","permalink":"https://overtalk.site/tags/lua/"}]},{"title":"Lua - 时间日期","slug":"lua-date","date":"2018-11-01T05:12:23.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2018/11/01/lua-date/","link":"","permalink":"https://overtalk.site/2018/11/01/lua-date/","excerpt":"","text":"lua 日期时间函数 日期时间函数 在 Lua 中，函数 time、date 和 difftime 提供了所有的日期和时间功能。 在 OpenResty 的世界里，不推荐使用这里的标准时间函数，因为这些函数通常会引发不止一个昂贵的系统调用，同时无法为 LuaJIT JIT 编译，对性能造成较大影响。推荐使用 ngx_lua 模块提供的带缓存的时间接口，如 ngx.today, ngx.time, ngx.utctime, ngx.localtime, ngx.now, ngx.http_time，以及 ngx.cookie_time 等。 所以下面的部分函数，简单了解一下即可。 os.time ([table]) 如果不使用参数 table 调用 time 函数，它会返回当前的时间和日期（它表示从某一时刻到现在的秒数）。如果用 table 参数，它会返回一个数字，表示该 table 中 所描述的日期和时间（它表示从某一时刻到 table 中描述日期和时间的秒数）。table 的字段如下： 字段名称 取值范围 year 四位数字 month 1–12 day 1–31 hour 0–23 min 0–59 sec 0–61 isdst boolean（true表示夏令时） 对于 time 函数，如果参数为 table，那么 table 中必须含有 year、month、day 字段。其他字缺省时段默认为中午（12:00:00）。 123print(os.time()) --&gt;output 1438243393a = &#123; year = 1970, month = 1, day = 1, hour = 8, min = 1 &#125;print(os.time(a)) --&gt;output 60 os.difftime (t2, t1) 返回 t1 到 t2 的时间差，单位为秒123456local day1 = &#123; year = 2015, month = 7, day = 30 &#125;local t1 = os.time(day1)local day2 = &#123; year = 2015, month = 7, day = 31 &#125;local t2 = os.time(day2)print(os.difftime(t2, t1)) --&gt;output 86400 os.date ([format [, time]]) 把一个表示日期和时间的数值，转换成更高级的表现形式。其第一个参数 format 是一个格式化字符串，描述了要返回的时间形式。第二个参数 time 就是日期和时间的数字表示，缺省时默认为当前的时间。使用格式字符 “*t”，创建一个时间表。 123456789101112131415161718192021local tab1 = os.date(\"*t\") --返回一个描述当前日期和时间的表local ans1 = \"&#123;\"for k, v in pairs(tab1) do --把tab1转换成一个字符串 ans1 = string.format(\"%s %s = %s,\", ans1, k, tostring(v))endans1 = ans1 .. \"&#125;\"print(\"tab1 = \", ans1)local tab2 = os.date(\"*t\", 360) --返回一个描述日期和时间数为360秒的表local ans2 = \"&#123;\"for k, v in pairs(tab2) do --把tab2转换成一个字符串 ans2 = string.format(\"%s %s = %s,\", ans2, k, tostring(v))endans2 = ans2 .. \"&#125;\"print(\"tab2 = \", ans2)--&gt;outputtab1 = &#123; hour = 17, min = 28, wday = 5, day = 30, month = 7, year = 2015, sec = 10, yday = 211, isdst = false,&#125;tab2 = &#123; hour = 8, min = 6, wday = 5, day = 1, month = 1, year = 1970, sec = 0, yday = 1, isdst = false,&#125; 该表中除了使用到了 time 函数参数 table 的字段外，这还提供了星期（wday，星期天为 1）和一年中的第几天（yday，一月一日为 1）。 除了使用 “*t” 格式字符串外，如果使用带标记（见下表）的特殊字符串，os.date 函数会将相应的标记位以时间信息进行填充，得到一个包含时间的字符串。 表如下： 格式字符 含义 %a 一星期中天数的简写（例如：Wed） %A 一星期中天数的全称（例如：Wednesday） %b 月份的简写（例如：Sep） %B 月份的全称（例如：September） %c 日期和时间（例如：07/30/15 16:57:24） %d 一个月中的第几天[01 ~ 31] %H 24小时制中的小时数[00 ~ 23] %I 12小时制中的小时数[01 ~ 12] %j 一年中的第几天[001 ~ 366] %M 分钟数[00 ~ 59] %m 月份数[01 ~ 12] %p “上午（am）”或“下午（pm）” %S 秒数[00 ~ 59] %w 一星期中的第几天[1 ~ 7 = 星期天 ~ 星期六] %x 日期（例如：07/30/15） %X 时间（例如：16:57:24） %y 两位数的年份[00 ~ 99] %Y 完整的年份（例如：2015） %% 字符’%’ 123456print(os.date(\"today is %A, in %B\"))print(os.date(\"now is %x %X\"))--&gt;outputtoday is Thursday, in Julynow is 07/30/15 17:39:22","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"lua","slug":"lua","permalink":"https://overtalk.site/tags/lua/"}]},{"title":"Lua - 数学库","slug":"lua-math","date":"2018-11-01T05:06:21.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2018/11/01/lua-math/","link":"","permalink":"https://overtalk.site/2018/11/01/lua-math/","excerpt":"","text":"lua 数学库 数学库 Lua 数学库由一组标准的数学函数构成。数学库的引入丰富了 Lua 编程语言的功能，同时也方便了程序的编写。常用数学函数见下表： 函数名 函数功能 math.rad(x) 角度x转换成弧度 math.deg(x) 弧度x转换成角度 math.max(x, …) 返回参数中值最大的那个数，参数必须是number型 math.min(x, …) 返回参数中值最小的那个数，参数必须是number型 math.random ([m [, n]]) 不传入参数时，返回 一个在区间[0,1)内均匀分布的伪随机实数；只使用一个整数参数m时，返回一个在区间[1, m]内均匀分布的伪随机整数；使用两个整数参数时，返回一个在区间[m, n]内均匀分布的伪随机整数 math.randomseed (x) 为伪随机数生成器设置一个种子x，相同的种子将会生成相同的数字序列 math.abs(x) 返回x的绝对值 math.fmod(x, y) 返回 x对y取余数 math.pow(x, y) 返回x的y次方 math.sqrt(x) 返回x的算术平方根 math.exp(x) 返回自然数e的x次方 math.log(x) 返回x的自然对数 math.log10(x) 返回以10为底，x的对数 math.floor(x) 返回最大且不大于x的整数 math.ceil(x) 返回最小且不小于x的整数 math.pi 圆周率 math.sin(x) 求弧度x的正弦值 math.cos(x) 求弧度x的余弦值 math.tan(x) 求弧度x的正切值 math.asin(x) 求x的反正弦值 math.acos(x) 求x的反余弦值 math.atan(x) 求x的反正切值 demo 1234567891011121314151617181920212223print(math.pi) --&gt;output 3.1415926535898print(math.rad(180)) --&gt;output 3.1415926535898print(math.deg(math.pi)) --&gt;output 180print(math.sin(1)) --&gt;output 0.8414709848079print(math.cos(math.pi)) --&gt;output -1print(math.tan(math.pi / 4)) --&gt;output 1print(math.atan(1)) --&gt;output 0.78539816339745print(math.asin(0)) --&gt;output 0print(math.max(-1, 2, 0, 3.6, 9.1)) --&gt;output 9.1print(math.min(-1, 2, 0, 3.6, 9.1)) --&gt;output -1print(math.fmod(10.1, 3)) --&gt;output 1.1print(math.sqrt(360)) --&gt;output 18.97366596101print(math.exp(1)) --&gt;output 2.718281828459print(math.log(10)) --&gt;output 2.302585092994print(math.log10(10)) --&gt;output 1print(math.floor(3.1415)) --&gt;output 3print(math.ceil(7.998)) --&gt;output 8 另外使用 math.random() 函数获得伪随机数时，如果不使用 math.randomseed() 设置伪随机数生成种子或者设置相同的伪随机数生成种子，那么得得到的伪随机数序列是一样的。 1234math.randomseed (100) --把种子设置为100print(math.random()) --&gt;output 0.0012512588885159print(math.random(100)) --&gt;output 57print(math.random(100, 360)) --&gt;output 150 稍等片刻，再次运行上面的代码。 1234math.randomseed (100) --把种子设置为100print(math.random()) --&gt;output 0.0012512588885159print(math.random(100)) --&gt;output 57print(math.random(100, 360)) --&gt;output 150 两次运行的结果一样。为了避免每次程序启动时得到的都是相同的伪随机数序列，通常是使用当前时间作为种子。 1234math.randomseed (os.time()) --把100换成os.time()print(math.random()) --&gt;output 0.88369396038697print(math.random(100)) --&gt;output 66print(math.random(100, 360)) --&gt;output 228 稍等片刻，再次运行上面的代码。 1234math.randomseed (os.time()) --把100换成os.time()print(math.random()) --&gt;output 0.88946195867794print(math.random(100)) --&gt;output 68print(math.random(100, 360)) --&gt;output 129","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"lua","slug":"lua","permalink":"https://overtalk.site/tags/lua/"}]},{"title":"Lua - table库","slug":"lua-table","date":"2018-11-01T04:59:43.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2018/11/01/lua-table/","link":"","permalink":"https://overtalk.site/2018/11/01/lua-table/","excerpt":"","text":"lua table table 库 table 库是由一些辅助函数构成的，这些函数将 table 作为数组来操作。 下标从 1 开始 在 Lua 中，数组下标从 1 开始计数。 官方解释：Lua lists have a base index of 1 because it was thought to be most friendly for non-programmers, as it makes indices correspond to ordinal element positions. 确实，对于我们数数来说，总是从 1 开始数的，而从 0 开始对于描述偏移量这样的东西有利。而 Lua 最初设计是一种类似 XML 的数据描述语言，所以索引（index）反应的是数据在里面的位置，而不是偏移量。 在初始化一个数组的时候，若不显式地用键值对方式赋值，则会默认用数字作为下标，从 1 开始。由于在 Lua 内部实际采用哈希表和数组分别保存键值对、普通值，所以不推荐混合使用这两种赋值方式。 123456local color=&#123;first=\"red\", \"blue\", third=\"green\", \"yellow\"&#125;print(color[\"first\"]) --&gt; output: redprint(color[1]) --&gt; output: blueprint(color[\"third\"]) --&gt; output: greenprint(color[2]) --&gt; output: yellowprint(color[3]) --&gt; output: nil 从其他语言过来的开发者会觉得比较坑的一点是，当我们把 table 当作栈或者队列使用的时候，容易犯错，追加到 table 的末尾用的是 s[#s+1] = something，而不是 s[#s] = something，而且如果这个 something 是一个 nil 的话，会导致这一次压栈（或者入队列）没有存入任何东西，#s 的值没有变。如果 s = { 1, 2, 3, 4, 5, 6 }，你令 s[4] = nil，#s 会令你“匪夷所思”地变成 3。 table.getn 获取长度 取长度操作符写作一元操作 #。字符串的长度是它的字节数（就是以一个字符一个字节计算的字符串长度）。 对于常规的数组，里面从 1 到 n 放着一些非空的值的时候，它的长度就精确的为 n，即最后一个值的下标。如果数组有一个“空洞”（就是说，nil 值被夹在非空值之间），那么 #t 可能是指向任何一个是 nil 值的前一个位置的下标（就是说，任何一个 nil 值都有可能被当成数组的结束）。这也就说明对于有“空洞”的情况，table 的长度存在一定的 不可确定性。 1234567891011121314151617local tblTest1 = &#123; 1, a = 2, 3 &#125;print(\"Test1 \" .. table.getn(tblTest1))local tblTest2 = &#123; 1, nil &#125;print(\"Test2 \" .. table.getn(tblTest2))local tblTest3 = &#123; 1, nil, 2 &#125;print(\"Test3 \" .. table.getn(tblTest3))local tblTest4 = &#123; 1, nil, 2, nil &#125;print(\"Test4 \" .. table.getn(tblTest4))local tblTest5 = &#123; 1, nil, 2, nil, 3, nil &#125;print(\"Test5 \" .. table.getn(tblTest5))local tblTest6 = &#123; 1, nil, 2, nil, 3, nil, 4, nil &#125;print(\"Test6 \" .. table.getn(tblTest6)) 我们使用 Lua 5.1 和 LuaJIT 2.1 分别执行这个用例，结果如下： 1234567891011121314# lua test.luaTest1 2Test2 1Test3 3Test4 1Test5 3Test6 1# luajit test.luaTest1 2Test2 1Test3 1Test4 1Test5 1Test6 1 这一段的输出结果，就是这么 匪夷所思。请问，你以后还敢在 Lua 的 table 中用 nil 值吗？如果你继续往后面加 nil，你可能会发现点什么。你可能认为你发现的是个规律。但是，你千万不要认为这是个规律，因为这是错误的。 不要在 Lua 的 table 中使用 nil 值，如果一个元素要删除，直接 remove，不要用 nil 去代替。 table.concat (table [, sep [, i [, j ] ] ]) 对于元素是 string 或者 number 类型的表 table，返回 table[i]..sep..table[i+1] ··· sep..table[j] 连接成的字符串。填充字符串 sep 默认为空白字符串。起始索引位置 i 默认为 1，结束索引位置 j 默认是 table 的长度。如果 i 大于 j，返回一个空字符串。12345local a = &#123;1, 3, 5, \"hello\" &#125;print(table.concat(a)) -- output: 135helloprint(table.concat(a, \"|\")) -- output: 1|3|5|helloprint(table.concat(a, \" \", 4, 2)) -- output:print(table.concat(a, \" \", 2, 4)) -- output: 3 5 hello table.insert (table, [pos ,] value) 在（数组型）表 table 的 pos 索引位置插入 value，其它元素向后移动到空的地方。pos 的默认值是表的长度加一，即默认是插在表的最后。123456789local a = &#123;1, 8&#125; --a[1] = 1,a[2] = 8table.insert(a, 1, 3) --在表索引为1处插入3print(a[1], a[2], a[3])table.insert(a, 10) --在表的最后插入10print(a[1], a[2], a[3], a[4])--&gt;output3 1 83 1 8 10 table.maxn (table) 返回（数组型）表 table 的最大索引编号；如果此表没有正的索引编号，返回 0。 当长度省略时，此函数通常需要 O(n) 的时间复杂度来计算 table 的末尾。因此用这个函数省略索引位置的调用形式来作 table 元素的末尾追加，是高代价操作。 123456789local a = &#123;&#125;a[-1] = 10print(table.maxn(a))a[5] = 10print(table.maxn(a))--&gt;output05 此函数的行为不同于 # 运算符，因为 # 可以返回数组中任意一个 nil 空洞或最后一个 nil 之前的元素索引。当然，该函数的开销相比 # 运算符也会更大一些。 table.remove (table [, pos]) 在表 table 中删除索引为 pos（pos 只能是 number 型）的元素，并返回这个被删除的元素，它后面所有元素的索引值都会减一。pos 的默认值是表的长度，即默认是删除表的最后一个元素。 123456789101112local a = &#123; 1, 2, 3, 4&#125;print(table.remove(a, 1)) --删除速索引为1的元素print(a[1], a[2], a[3], a[4])print(table.remove(a)) --删除最后一个元素print(a[1], a[2], a[3], a[4])--&gt;output12 3 4 nil42 3 nil nil table.sort (table [, comp]) 按照给定的比较函数 comp 给表 table 排序，也就是从 table[1] 到 table[n]，这里 n 表示 table 的长度。 比较函数有两个参数，如果希望第一个参数排在第二个的前面，就应该返回 true，否则返回 false。 如果比较函数 comp 没有给出，默认从小到大排序。 12345678910111213local function compare(x, y) --从大到小排序 return x &gt; y --如果第一个参数大于第二个就返回true，否则返回falseendlocal a = &#123; 1, 7, 3, 4, 25&#125;table.sort(a) --默认从小到大排序print(a[1], a[2], a[3], a[4], a[5])table.sort(a, compare) --使用比较函数进行排序print(a[1], a[2], a[3], a[4], a[5])--&gt;output1 3 4 7 2525 7 4 3 1 table 其他非常有用的函数 LuaJIT 2.1 新增加的 table.new 和 table.clear 函数是非常有用的。前者主要用来预分配 Lua table 空间，后者主要用来高效的释放 table 空间，并且它们都是可以被 JIT 编译的。具体可以参考一下 OpenResty 捆绑的 lua-resty-* 库，里面有些实例可以作为参考。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"lua","slug":"lua","permalink":"https://overtalk.site/tags/lua/"}]},{"title":"Lua - module","slug":"lua-module","date":"2018-11-01T04:45:21.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2018/11/01/lua-module/","link":"","permalink":"https://overtalk.site/2018/11/01/lua-module/","excerpt":"","text":"lua 模块 模块 从 Lua 5.1 语言添加了对模块和包的支持。一个 Lua 模块的数据结构是用一个 Lua 值（通常是一个 Lua 表或者 Lua 函数）。一个 Lua 模块代码就是一个会返回这个 Lua 值的代码块。 可以使用内建函数 require() 来加载和缓存模块。简单的说，一个代码模块就是一个程序库，可以通过 require 来加载。模块加载后的结果通过是一个 Lua table，这个表就像是一个命名空间，其内容就是模块中导出的所有东西，比如函数和变量。require 函数会返回 Lua 模块加载后的结果，即用于表示该 Lua 模块的 Lua 值。 require 函数 Lua 提供了一个名为 require 的函数用来加载模块。要加载一个模块，只需要简单地调用 require “file” 就可以了，file 指模块所在的文件名。这个调用会返回一个由模块函数组成的 table，并且还会定义一个包含该 table 的全局变量。 在 Lua 中创建一个模块最简单的方法是：创建一个 table，并将所有需要导出的函数放入其中，最后返回这个 table 就可以了。相当于将导出的函数作为 table 的一个字段，在 Lua 中函数是第一类值，提供了天然的优势。 使用demo 把下面的代码保存在文件 my.lua 中 1234567891011local foo=&#123;&#125;local function getname() return \"Lucy\"endfunction foo.greeting() print(\"hello \" .. getname())endreturn foo 把下面代码保存在文件 main.lua 中，然后执行 main.lua，调用上述模块。 123-- 相对路径为 local fp = require(\"./xxx/my\")local fp = require(\"my\")fp.greeting() --&gt;output: hello Lucy 注：对于需要导出给外部使用的公共模块，处于安全考虑，是要避免全局变量的出现。 我们可以使用 lj-releng 或 luacheck 工具完成全局变量的检测。 具体参考本章的 局部变量 和 “测试” 一章的 代码静态分析 。","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"lua","slug":"lua","permalink":"https://overtalk.site/tags/lua/"}]},{"title":"Lua - 基础","slug":"lua-basic","date":"2018-11-01T04:32:23.000Z","updated":"2022-07-19T07:53:37.897Z","comments":true,"path":"2018/11/01/lua-basic/","link":"","permalink":"https://overtalk.site/2018/11/01/lua-basic/","excerpt":"","text":"lua 基础篇 简介 过程动态语言 变量名没有类型，值才有类型，变量名在运行时可与任何类型的值绑定; 语言只提供唯一一种数据结构，称为表(table)，它混合了数组、哈希，可以用任何类型的值作为 key 和 value。提供了一致且富有表达力的表构造语法，使得 Lua 很适合描述复杂的数据; 函数是一等类型，支持匿名函数和正则尾递归(proper tail recursion); 支持词法定界(lexical scoping)和闭包(closure); 提供 thread 类型和结构化的协程(coroutine)机制，在此基础上可方便实现协作式多任务; 运行期能编译字符串形式的程序文本并载入虚拟机执行; 通过元表(metatable)和元方法(metamethod)提供动态元机制(dynamic meta-mechanism)，从而允许程序运行时根据需要改变或扩充语法设施的内定语义; 能方便地利用表和动态元机制实现基于原型(prototype-based)的面向对象模型; 从 5.1 版开始提供了完善的模块机制，从而更好地支持开发大型的应用程序; lua 中的数据类型 例子 类型 “hello world!” string print function true boolean 3 / 3.04 number nil nil nil (空) nil 是一种类型，Lua 将 nil 用于表示“无效值”。一个变量在第一次赋值前的默认值是 nil，将 nil 赋予给一个全局变量就等同于删除它。 boolean（布尔） 布尔类型，可选值 true/false；Lua 中 nil 和 false 为“假”，其它所有值均为“真”。比如 0 和空字符串就是“真”； number（数字） math.floor（向下取整） math.ceil（向上取整） string（字符串） 字符串的表达方式 1、使用一对匹配的单引号。例：’hello’。 2、使用一对匹配的双引号。例：”abclua”。 3、字符串还可以用一种长括号（即[[ ]]）括起来的方式定义。我们把两个正的方括号（即[[）间插入 n 个等号定义为第 n 级正长括号。就是说，0 级正的长括号写作 [[ ，一级正的长括号写作 [=[，如此等等。反的长括号也作类似定义；举个例子，4 级反的长括号写作 ]====]。一个长字符串可以由任何一级的正的长括号开始，而由第一个碰到的同级反的长括号结束。整个词法分析过程将不受分行限制，不处理任何转义符，并且忽略掉任何不同级别的长括号。这种方式描述的字符串可以包含任何东西，当然本级别的反长括号除外。例：[[abc\\nbc]]，里面的 “\\n” 不会被转义。 Lua 的字符串是不可改变的值，不能像在 c 语言中那样直接修改字符串的某个字符，而是根据修改要求来创建一个新的字符串。Lua 也不能通过下标来访问字符串的某个字符。 在 Lua 实现中，Lua 字符串一般都会经历一个“内化”（intern）的过程，即两个完全一样的 Lua 字符串在 Lua 虚拟机中只会存储一份。每一个 Lua 字符串在创建时都会插入到 Lua 虚拟机内部的一个全局的哈希表中。 这意味着 创建相同的 Lua 字符串并不会引入新的动态内存分配操作，所以相对便宜（但仍有全局哈希表查询的开销）， 内容相同的 Lua 字符串不会占用多份存储空间， 已经创建好的 Lua 字符串之间进行相等性比较时是 O(1) 时间度的开销，而不是通常见到的 O(n). table table 如果作为函数的入参的话，是地址传递 Table 类型实现了一种抽象的“关联数组”。“关联数组”是一种具有特殊索引方式的数组，索引通常是字符串（string）或者 number 类型，但也可以是除 nil 以外的任意类型的值。 在内部实现上，table 通常实现为一个哈希表、一个数组、或者两者的混合。具体的实现为何种形式，动态依赖于具体的 table 的键分布特点。 function 在 Lua 中，函数 也是一种数据类型，函数可以存储在变量中，可以通过参数传递给其他函数，还可以作为其他函数的返回值。 有名函数的定义本质上是匿名函数对变量的赋值。为说明这一点，考虑 123456function foo()end-- 等价于foo = function ()end 123456local function foo()end-- 等价于local foo = function ()end 表达式关系运算符 注意：Lua 语言中“不等于”运算符的写法为：~= 在使用“==”做等于判断时，要注意对于 table, userdate 和函数， Lua 是作引用比较的。也就是说，只有当两个变量引用同一个对象时，才认为它们相等。可以看下面的例子： 12345678910local a = &#123; x = 1, y = 0&#125;local b = &#123; x = 1, y = 0&#125;if a == b then print(\"a==b\")else print(\"a~=b\")end---output:a~=b 逻辑运算符 逻辑运算符 说明 and 逻辑与 or 逻辑或 not 逻辑非 Lua 中的 and 和 or 是不同于 c 语言的。在 c 语言中，and 和 or 只得到两个值 1 和 0，其中 1 表示真，0 表示假。而 Lua 中 and 的执行过程是这样的： a and b 如果 a 为 nil，则返回 a，否则返回 b; a or b 如果 a 为 nil，则返回 b，否则返回 a。 12345678910local c = nillocal d = 0local e = 100print(c and d) --&gt;打印 nilprint(c and e) --&gt;打印 nilprint(d and e) --&gt;打印 100print(c or d) --&gt;打印 0print(c or e) --&gt;打印 100print(not c) --&gt;打印 trueprint(not d) --&gt;打印 false 注意：所有逻辑操作符将 false 和 nil 视作假，其他任何值视作真，对于 and 和 or，“短路求值”，对于 not，永远只返回 true 或者 false。 字符串连接 在 Lua 中连接两个字符串，可以使用操作符“..”（两个点）。如果其任意一个操作数是数字的话，Lua 会将这个数字转换成字符串。 注意，连接操作符只会创建一个新字符串，而不会改变原操作数。也可以使用 string 库函数 string.format 连接字符串。 由于 Lua 字符串本质上是只读的，因此字符串连接运算符几乎总会创建一个新的（更大的）字符串。这意味着如果有很多这样的连接操作（比如在循环中使用 .. 来拼接最终结果），则性能损耗会非常大。在这种情况下，推荐使用 table 和 table.concat() 来进行很多字符串的拼接，例如： 12345local pieces = &#123;&#125;for i, elem in ipairs(my_list) do pieces[i] = my_process(elem)endlocal res = table.concat(pieces) 控制结构if-else123456789score = 90if score == 100 then print(\"Very good!Your score is 100\")elseif score &gt;= 60 then print(\"Congratulations, you have passed it,your score greater or equal to 60\")--此处可以添加多个elseifelse print(\"Sorry, you do not pass the exam! \")end while Lua 跟其他常见语言一样，提供了 while 控制结构，语法上也没有什么特别的。但是没有提供 do-while 型的控制结构，但是提供了功能相当的 repeat。 123while 表达式 do--bodyend 值得一提的是，Lua 并没有像许多其他语言那样提供类似 continue 这样的控制语句用来立即进入下一个循环迭代（如果有的话）。因此，我们需要仔细地安排循环体里的分支，以避免这样的需求。 没有提供 continue，却也提供了另外一个标准控制语句 break，可以跳出当前循环。 repeat 控制结构 - (do while) Lua 中的 repeat 控制结构类似于其他语言（如：C++ 语言）中的 do-while，但是控制方式是刚好相反的。简单点说，执行 repeat 循环体后，直到 until 的条件为真时才结束，而其他语言（如：C++ 语言）的 do-while 则是当条件为假时就结束循环。 以下代码将会形成死循环： 1234x = 10repeat print(x)until false Lua 中的 repeat 也可以在使用 break 退出。 for for 语句有两种形式：数字 for（numeric for）和范型 for（generic for）。 数字型 for123for var = begin, finish, step do --bodyend 关于数字 for 需要关注以下几点： 1.var 从 begin 变化到 finish，每次变化都以 step 作为步长递增 var - 2.begin、finish、step 三个表达式只会在循环开始时执行一次 3 .第三个表达式 step 是可选的，默认为 1 4.控制变量 var 的作用域仅在 for 循环内，需要在外面控制，则需将值赋给一个新的变量 5.循环过程中不要改变控制变量的值，那样会带来不可预知的影响 如果不想给循环设置上限的话，可以使用常量 math.huge： 123456for i = 1, math.huge do if (0.3*i^3 - 20*i^2 - 500 &gt;=0) then print(i) break endend for 泛型 泛型 for 循环通过一个迭代器（iterator）函数来遍历所有值： 1234567891011-- 打印数组a的所有值local a = &#123;\"a\", \"b\", \"c\", \"d\"&#125;for i, v in ipairs(a) do print(\"index:\", i, \" value:\", v)end-- output:index: 1 value: aindex: 2 value: bindex: 3 value: cindex: 4 value: d Lua 的基础库提供了 ipairs，这是一个用于遍历数组的迭代器函数。在每次循环中，i 会被赋予一个索引值，同时 v 被赋予一个对应于该索引的数组元素值。 下面是另一个类似的示例，演示了如何遍历一个 table 中所有的 key 1234-- 打印table t中所有的keyfor k in pairs(t) do print(k)end 从外观上看泛型 for 比较简单，但其实它是非常强大的。通过不同的迭代器，几乎可以遍历所有的东西， 而且写出的代码极具可读性。 标准库提供了几种迭代器，包括: 用于迭代文件中每行的（io.lines） 迭代 table 元素的（pairs） 迭代数组元素的（ipairs） 迭代字符串中单词的（string.gmatch） … break, return 关键字break 语句 break 用来终止 while、repeat 和 for 三种循环的执行，并跳出当前循环体， 继续执行当前循环之后的语句。 return return 主要用于从函数中返回结果，或者用于简单的结束一个函数的执行。return 只能写在语句块的最后，一旦执行了 return 语句，该语句之后的所有语句都不会再执行。 return 主要用于从函数中返回结果，或者用于简单的结束一个函数的执行。 关于函数返回值的细节可以参考 函数的返回值 章节。return 只能写在语句块的最后，一旦执行了 return 语句，该语句之后的所有语句都不会再执行。 12345local function foo() print(\"before\") do return end print(\"after\") -- 这一行语句永远不会执行到end lua 函数全局函数 &amp; 局部函数12345678function function_name (arc) -- arc 表示参数列表，函数的参数列表可以为空 -- bodyend-- 另外一种写法function_name = function (arc) -- bodyend 由于全局变量一般会污染 全局名字空间，同时也有性能损耗（即查询全局环境表的开销），因此我们应当尽量使用“局部函数”，其记法是类似的，只是开头加上 local 修饰符： 123local function function_name (arc) -- bodyend 由于函数定义本质上就是变量赋值，而变量的定义总是应放置在变量使用之前，所以函数的定义也需要放置在函数调用之前。 由于函数定义本质上就是变量赋值，而变量的定义总是应放置在变量使用之前，所以函数的定义也需要放置在函数调用之前。 123function foo.bar(a, b, c) -- body ...end 此时我们是把一个函数类型的值赋给了 foo 表的 bar 字段。换言之，上面的定义等价于 123foo.bar = function (a, b, c) print(a, b, c)end 对于此种形式的函数定义，不能再使用 local 修饰符了，因为不存在定义新的局部变量了。 函数的参数按值传递 Lua 函数的参数大部分是按值传递的。值传递就是调用函数时，实参把它的值通过赋值运算传递给形参，然后形参的改变和实参就没有关系了。在这个过程中，实参是通过它在参数表中的位置与形参匹配起来的。 1234567891011121314151617local function swap(a, b) --定义函数swap,函数内部进行交换两个变量的值 local temp = a a = b b = temp print(a, b)endlocal x = \"hello\"local y = 20print(x, y)swap(x, y) --调用swap函数print(x, y) --调用swap函数后，x和y的值并没有交换--&gt;outputhello 2020 hellohello 20 在调用函数的时候，若形参个数和实参个数不同时，Lua 会自动调整实参个数。调整规则：若实参个数大于形参个数，从左向右，多余的实参被忽略；若实参个数小于形参个数，从左向右，没有被实参初始化的形参会被初始化为 nil。 变长参数 上面函数的参数都是固定的，其实 Lua 还支持变长参数。若形参为 … , 表示该函数可以接收不同长度的参数。访问参数的时候也要使用 …。 123456789101112131415local function func( ... ) -- 形参为 ... ,表示函数采用变长参数 local temp = &#123;...&#125; -- 访问的时候也要使用 ... local ans = table.concat(temp, \" \") -- 使用 table.concat 库函数对数 -- 组内容使用 \" \" 拼接成字符串。 print(ans)endfunc(1, 2) -- 传递了两个参数func(1, 2, 3, 4) -- 传递了四个参数--&gt;output1 21 2 3 4 值得一提的是，LuaJIT 2 尚不能 JIT 编译这种变长参数的用法，只能解释执行。所以对性能敏感的代码，应当避免使用此种形式。 具名参数 Lua 还支持通过名称来指定实参，这时候要把所有的实参组织到一个 table 中，并将这个 table 作为唯一的实参传给函数。 123456789101112131415function change(arg) --change函数，改变长方形的长和宽，使其各增长一倍 arg.width = arg.width * 2 --表arg不是表rectangle的拷贝，他们是同一个表 arg.height = arg.height * 2end -- 没有return语句了local rectangle = &#123; width = 20, height = 15 &#125;print(\"before change:\", \"width = \", rectangle.width, \" height = \", rectangle.height)change(rectangle)print(\"after change:\", \"width = \", rectangle.width, \" height =\", rectangle.height)--&gt; outputbefore change: width = 20 height = 15after change: width = 40 height = 30 在常用基本类型中，除了 table 是按址传递类型外，其它的都是按值传递参数。 用全局变量来代替函数参数的不好编程习惯应该被抵制，良好的编程习惯应该是减少全局变量的使用。 函数返回值 Lua 具有一项与众不同的特性，允许函数返回多个值。Lua 的库函数中，有一些就是返回多个值。 示例代码：使用库函数 string.find，在源字符串中查找目标字符串，若查找成功，则返回目标字符串在源字符串中的起始位置和结束位置的下标。 12local s, e = string.find(\"hello world\", \"llo\")print(s, e) --&gt;output 3 5 返回多个值时，值之间用“,”隔开。 示例代码：定义一个函数，实现两个变量交换值 12345678local function swap(a, b) -- 定义函数 swap，实现两个变量交换值 return b, a -- 按相反顺序返回变量的值endlocal x = 1local y = 20x, y = swap(x, y) -- 调用 swap 函数print(x, y) --&gt; output 20 1 当函数返回值的个数和接收返回值的变量的个数不一致时，Lua 也会自动调整参数个数。 调整规则： 若返回值个数大于接收变量的个数，多余的返回值会被忽略掉； 若返回值个数小于参数个数，从左向右，没有被返回值初始化的变量会被初始化为 nil。 12345678910111213function init() --init 函数 返回两个值 1 和 \"lua\" return 1, \"lua\"endx = init()print(x)x, y, z = init()print(x, y, z)--output11 lua nil 当一个函数有一个以上返回值，且函数调用不是一个列表表达式的最后一个元素，那么函数调用只会产生一个返回值, 也就是第一个返回值。 123456789local function init() -- init 函数 返回两个值 1 和 \"lua\" return 1, \"lua\"endlocal x, y, z = init(), 2 -- init 函数的位置不在最后，此时只返回 1print(x, y, z) --&gt;output 1 2 nillocal a, b, c = 2, init() -- init 函数的位置在最后，此时返回 1 和 \"lua\"print(a, b, c) --&gt;output 2 1 lua 函数调用的实参列表也是一个列表表达式。考虑下面的例子： 123456local function init() return 1, \"lua\"endprint(init(), 2) --&gt;output 1 2print(2, init()) --&gt;output 2 1 lua 如果你确保只取函数返回值的第一个值，可以使用括号运算符，例如 123456local function init() return 1, \"lua\"endprint((init()), 2) --&gt;output 1 2print(2, (init())) --&gt;output 2 1 值得一提的是，如果实参列表中某个函数会返回多个值，同时调用者又没有显式地使用括号运算符来筛选和过滤，则这样的表达式是不能被 LuaJIT 2 所 JIT 编译的，而只能被解释执行。 全动态函数调用 调用回调函数，并把一个数组参数作为回调函数的参数。12local args = &#123;...&#125; or &#123;&#125;method_name(unpack(args, 1, table.maxn(args))) 使用场景 如果你的实参 table 中确定没有 nil 空洞，则可以简化为 1method_name(unpack(args)) 你要调用的函数参数是未知的； 函数的实际参数的类型和数目也都是未知的。 12345add_task(end_time, callback, params)if os.time() &gt;= endTime then callback(unpack(params, 1, table.maxn(params)))end 值得一提的是，unpack 内建函数还不能为 LuaJIT 所 JIT 编译，因此这种用法总是会被解释执行。对性能敏感的代码路径应避免这种用法。 小试牛刀123456789101112131415local function run(x, y) print('run', x, y)endlocal function attack(targetId) print('targetId', targetId)endlocal function do_action(method, ...) local args = &#123;...&#125; or &#123;&#125; method(unpack(args, 1, table.maxn(args)))enddo_action(run, 1, 2) -- output: run 1 2do_action(attack, 1111) -- output: targetId 1111","categories":[{"name":"编程","slug":"编程","permalink":"https://overtalk.site/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"lua","slug":"lua","permalink":"https://overtalk.site/tags/lua/"}]}]}